---
title: "Reproducible data analysis: thesis data wrangling"
subtitle: "Pacific Maritime forWater Masters Project (NSERC forWater)"
author: "Hannah J McSorley"
output: bookdown::word_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, package.startup.message = FALSE, fig.path="R-outputs_UBC-forWater-MSc_HMc/figures/")
```

# setup

note that rainmaker package is only available on GitHub (under development)
```
install.packages("devtools")
devtools::install_github("USGS-R/Rainmaker")
```

```{r wrangling packages, include = FALSE}

# load packages
library(tidyverse)  # tidyverse includes: dplyr, ggplot2, purrr, readr, forcats
library(knitr)      # tidy tables, knitting docs
library(lubridate)  # dates, times, ranges
library(broom)      # tidy stats
library(Rainmaker)  # USGS tool -- https://github.com/USGS-R/Rainmaker

```

assign time zone and create functions

```{r, function}
# time-zone note: all loggers record in standard time (no daylight savings shift)
TZ <- "Etc/GMT+8"

# create a function:
# ---- Alpha-numeric extraction function ---- #
# from http://stla.github.io/stlapblog/posts/Numextract.html
NumberXtract <- function(alphnum){
  unlist(regmatches(alphnum, gregexpr("[[:digit:]]+\\.*[[:digit:]]*", alphnum)))
}

```

# Tracking field activity

Multiple trips were taken to the field (Leech River watershed) and the trip number and/or date were used to organize files for sample identification, analytical results, joining dataframes and matching sample data to field-based data logger intervals.

This code brings in data that documents installation locations field trip tracking.

```{r, tracking}

# read in file used to track trips
trip_df <- read.csv(file = "R-inputs_UBC-forWater-MSc_HMc/Leech-FieldTrip-tracking_forWater-MSc_HMc.csv", 
                    header = TRUE)
str(trip_df)

# adjust format of dates
trip_df <- trip_df %>%
  mutate(trip = as_factor(trip),
         trip.start = lubridate::ymd(trip.start, tz = TZ),
         trip.end = lubridate::ymd(trip.end, tz = TZ),
         analysis_date_shimadzu = lubridate::ymd(analysis_date_shimadzu, tz = TZ),
         analysis_date_scan = lubridate::ymd(analysis_date_scan, tz = TZ),
         note = as.character(note))
str(trip_df)

# site installation locations
install_df <- read.csv(file = "R-inputs_UBC-forWater-MSc_HMc/Leech-installation-locations_forWater-MSc_HMc.csv",
                       header = TRUE) %>%
  mutate(Site_Number = as_factor(Site_Number))
```

# Water sample data and analytic results

Water samples were collected and transported via coolers (on ice) to UBC's EcoHydrology Lab for analysis of dissolved organic carbon (DOC) concentrations and indicators of NOM character. 

For quantification of DOC, samples were filtered with 0.45-micron PES filters; acidified to bring pH below 2; and analyzed for non-purgeable organic carbon (NPOC) via High-Temperature Combustion Method (5310-B) on a Shimadzu TOC-V.

Spectral properties of sample NOM were analyzed using a "Spectro::lyser" spectrophotometer (S::can, Vienna, Austria) which measures turbidity and the chromophoric portion of dissolved organic matter to estimate concentrations of total organic carbon (TOC), DOC as well as nitrate-nitrogen (NO^-3^-N). 

## DOC: Shimadzu TOC-V for DOC concentrations (as mg/L NPOC)

Water samples were filtered (0.45-micron PES filters) and acidified to bring pH below 2, then sparged with ultra-pure hydrocarbon-free air to drive off inorganic carbon. Following sparging, the sample was combusted to convert all organic carbon to carbon dioxide which was measured with a non-dispersive infrared gas detector to quanitify the DOC content of the sample. This method representd the most direct method of measuring DOC, as all natural organic carbon in the sample is measured. However, very small volatile organic carbon compounds would be removed in the sparging process. Because most NOM compounds are of higher molecular weight, it is unlikely that NOM DOC analytes would be removed.

```{r, TOC-V}
## Shimadzu TOC-V samples and results
# sample IDs and results from analysis of DOC (as NPOC)
# three part data munge
# 1. bring in sample tracking data (vial number, name, etc), format appropriately
# 2. bring in results data (from instrument), format appropriately
# 3. bring them together as meanigful results data (sample IDs + results)


# 1. ------------ SAMPLES ------------ #

# create a data frame of all sample ID data
# for all samples analyzed on Shimadzu TOC-V (UBC ESB 3062)


# read in all the files
shimadzu_samples <- 
  list.files(path = "R-inputs_UBC-forWater-MSc_HMc/shimadzu/samples_TOC/", 
             pattern = "*.csv") %>% 
  purrr::map(~ read_csv(file.path("R-inputs_UBC-forWater-MSc_HMc/shimadzu/samples_TOC/", .), 
                        skip = 4, col_names = TRUE)) %>% 
  reduce(rbind)

# check structure
# str(shimadzu_samples)

# correct the structure/format
shimadzu_samples <- shimadzu_samples %>% 
  dplyr::transmute(vial = as.numeric(vial),
                   site = forcats::as_factor(site),
                   sample_type = forcats::as_factor(`sample-type`),
                   sample = forcats::as_factor(sample),
                   dt_sampled = head(lubridate::ymd_hms(`date-time_sampled`, frac = TRUE, tz = TZ, truncated = 3), -1),
                   fillStage_cm = as.numeric(`fill-stage`),
                   analysis = as_factor(analysis),
                   trip = as_factor(trip))

# str(shimadzu_samples)
# head(shimadzu_samples)

#check number of trips (see 'trip_df')
# levels(shimadzu_samples$trip)

# check which sites are included
# levels(shimadzu_samples$site)

# fix naming errors for sites
shimadzu_samples$site <- shimadzu_samples$site %>% 
  plyr::revalue(c(
    "Chris" = "Chris-crk",
    "Lower-Leech-blw-confl" = "Leech-downstreamconf",
    "Leech-dwnstrm-confl" = "Leech-downstreamconf",
    "Leech-main-confl" = "Leech-downstreamconf",
    "Weeks-Lk-NE" = "Weeks-Lake",
    "J-Trib" = "West-Jordan",
    "West-jordan" = "West-Jordan",
    "W.Jarvis" = "Jarvis",
    "Rithet-N" = "Rithet",
    "Judge" = "Judge-crk"
  ))
# check sites again
# levels(shimadzu_samples$site)


# 2. ------------ RESULTS ------------ # 

# Note: annoying TOC-V export issue
# data files for analysis of trips 1-8 have 19 columns, while trips 9-23 have 18 columns
# import as two separate blocks (from two subdirectories), then alter, then merge

# assign column names = col.names():
nineteencolumns <- c("Type",	"Anal.",	"Sample Name",	"Sample ID",	"Origin",	"Cal. Curve",	"Manual Dilution	Notes",	"Date", "Time", "AM/PM",	"Spl. No.", "Inj. No.", "Analysis(Inj.)",	"Area",	"Mean Area",	"Conc.",	"Result",	"Excluded",	"Inj. Vol.")

# no "mean area" variable
eighteencolumns <- c("Type",	"Anal.",	"Sample Name",	"Sample ID",	"Origin",	"Cal. Curve",	"Manual Dilution	Notes",	"Date", "Time", "AM/PM",	"Spl. No.", "Inj. No.", "Analysis(Inj.)",	"Area",	"Conc.",	"Result",	"Excluded",	"Inj. Vol.")

## read in files and add a column indicating trip #, based on source file name

## directory 1 (trips 2-8) with 19 columns
# read in all the files (trips 2-8)
shimadzu_1 <- 
  list.files(path = "R-inputs_UBC-forWater-MSc_HMc/shimadzu/results_TOC/block1_19columns/", 
             pattern = "*.txt") %>% 
  set_names(str_extract(., "([a-z]{4,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(file = file.path("R-inputs_UBC-forWater-MSc_HMc/shimadzu/results_TOC/block1_19columns/", .), 
                              row.names = NULL, skip = 14, header = FALSE, col.names = nineteencolumns), .id = "source") %>% 
  select(-Mean.Area)
# check that there are 19 columns now (minus "Mean.Area")
# str(shimadzu_1)


## directory 2 (trips 9-23) with 18 columns
# read in all the files (trips 9 -22)
shimadzu_2 <- 
  list.files(path = "R-inputs_UBC-forWater-MSc_HMc/shimadzu/results_TOC/block2_18columns/", 
             pattern = "*.txt") %>% 
  set_names(str_extract(., "([a-z]{4,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(file = file.path("R-inputs_UBC-forWater-MSc_HMc/shimadzu/results_TOC/block2_18columns/", .), 
                              row.names = NULL, skip = 14, header = FALSE, col.names = eighteencolumns), .id = "source") 
# check structure
# str(shimadzu_2)


# combine the two blocks into one shimadzu results dataframe
shimadzu_results <- bind_rows(shimadzu_1, shimadzu_2)
# str(shimadzu_results)


# ---
## use function 'NumberXtract()'
# pull out numbers from alphanumerics to create:
# factor variable for trip numbers   (from 'source')
# numeric variable for NPOC-results  (from 'Result')
# factor variable for vial number    (from 'Sample.Name')
shimadzu_results <- shimadzu_results %>% 
  mutate(trip = as_factor(NumberXtract(source)),
         NPOC_mgL = as.numeric(NumberXtract(Result)),
         vial = as.numeric(NumberXtract(Sample.Name))) 

# check it out
# str(shimadzu_results)



# 3. ------------ SHIMADZU ANALYSIS RESULTS ------------ # 

# combine 'shimadzu_samples' with 'shimadzu_results'
TOCV_results <- shimadzu_results %>% 
  select(trip, vial, NPOC_mgL) %>% 
  group_by(trip, vial) %>% 
  summarize(NPOC_ppm = mean(NPOC_mgL)) %>% 
  right_join(shimadzu_samples, by = c("trip", "vial")) %>% 
  ungroup() 


# check head
head(TOCV_results)
# check structure
str(TOCV_results)
# check lengths match
nrow(TOCV_results) == nrow(shimadzu_samples)


# what about trip 21, which was actually in trip 20 (Cragg on 2019-12-19)
TOCV_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# update vials 19-21 to be "trip 21", for later matching with Odyssey stage data
TOCV_results <- TOCV_results %>% 
  mutate(#trip = as.character(trip),
    trip = case_when(trip == "20" & site =="Cragg-crk" & (vial == 19 | vial == 20 | vial == 21) ~ "21",
                     TRUE ~ trip),
    trip = as_factor(trip))
TOCV_results$NPOC_ppm = as.numeric(TOCV_results$NPOC_ppm)
# check to make sure it's updated:
TOCV_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# good!

```

## Spectrolyser proxy analysis results (CDOM equivalent DOC & TOC, NO~3~^-^, SAC~254~, SAC~436~)

The Spectrolyser is a full scan UV-VIS spectrophotometer. It uses a stable global calibration file to calculate equivalent concentrations of DOC, TOC, nitrate-nitrogen, and turbidity.

### Concentrations by proxy (UV-VIS)

The .par files generated by the spectrolyser contain results of equivalent concentrations based on spectral analysis and the internal global calibration file. A caveat to interpretting these results is that in order for NOM to be detected by UV-Vis absorption the molecules must absorb UV or Visible light (not all molecules do). UV-Vis absorption occurs only if the applied energy (light) can be absorbed by the molecule; in general, this required the presence of aromatic bonds (conjugated pi-bond systems in the molecule, a chromophore). Therefore, UV-Vis absorption is proportional to the molecule's degree of aromaticity.    

```{r, Spectrolyser-par}

## Spectrolyser samples and results
# sample IDs and results from analysis of optical properties
# multi-part data munge
# 1. bring in sample tracking data, format appropriately
# 2. bring in results data, format appropriately
# 3. bring them together as meanigful results data
# 4. some analyses were run in triplicate -- summarize as sample means


# 1. ------------ SAMPLES ------------ #

# create a data frame of all sample ID data
# for all samples analyzed on Scan Spectrolyser (UBC ESB 3062)


# read in all the files
spectrolyser_samples <- 
  list.files(path = "R-inputs_UBC-forWater-MSc_HMc/spectrolyser/samples_scan/", 
             pattern = "*.csv") %>% 
  purrr::map(~ read_csv(file.path("R-inputs_UBC-forWater-MSc_HMc/spectrolyser/samples_scan/", .), 
                        skip = 4, col_names = TRUE)) %>% 
  reduce(rbind)

# check structure
str(spectrolyser_samples)

# correct the structure/format
spectrolyser_samples <- spectrolyser_samples %>% 
  dplyr::transmute(measurement = as.numeric(measurement),
                   site = forcats::as_factor(site),
                   sample_type = forcats::as_factor(`sample-type`),
                   sample = forcats::as_factor(sample),
                   dt_sampled = head(lubridate::ymd_hms(`date-time_sampled`, 
                                                        frac = TRUE, tz = TZ, 
                                                        truncated = 3), -1),
                   fillStage_cm = as.numeric(`fill-stage`),
                   trip = as_factor(trip))
# check it
# str(spectrolyser_samples)
# head(spectrolyser_samples)

#check which trips were included
levels(spectrolyser_samples$trip)

# check which sites are included
levels(spectrolyser_samples$site)

# fix naming errors for sites
spectrolyser_samples$site <- spectrolyser_samples$site %>% 
  plyr::revalue(c(
    "Chris" = "Chris-crk",
    "Lower-Leech-blw-confl" = "Leech-downstreamconf",
    "Leech-main-confl" = "Leech-downstreamconf",
    "Leech-downstreamconf" = "Leech-downstreamconf",
    "J-Trib" = "West-Jordan",
    "West-jordan" = "West-Jordan",
    "W.Jarvis" = "Jarvis",
    "Judge" = "Judge-crk"
  ))
# check sites again
levels(spectrolyser_samples$site)

length(levels(spectrolyser_samples$site))
#---- samples were collected from a total of 31 sites (including lab), 6 were permanent field installations ---- #


# 2. ------------ RESULTS ------------ # 

# assign column names = col.names():
scancolumns <- c("Date", "Time",	"Status",	"Turbid.FTUeq",	"NULLTurbid",	"NO3-Neq_ppm",	"NULLNO3-Neq",	"TOCeq_ppm",	"NULLTOCeq", "DOCeq_ppm", "NULLDOCeq", "SAC254_Abs/m", "SAC254_0", "SAC436_Abs/m",	"SAC436_0",	"254-436_Abs/m", "254-436_0",	"analogIN_", "analogIN_0")

## read in files and add a column indicating trip #, based on source file name
spectrolyser_results <- 
  list.files(path = "R-inputs_UBC-forWater-MSc_HMc/spectrolyser/results_scan/") %>% 
  set_names(str_extract(., "([A-Za-z]{3,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(
    file = file.path("R-inputs_UBC-forWater-MSc_HMc/spectrolyser/results_scan/", .),
    skip = 2, header = FALSE, col.names = scancolumns), .id = "source") 

# check it out
# str(spectrolyser_results)

# pull out numbers from alphanumeric 'source' to create factor variable 'trip'
# use function 'NumberXtract()'
# add measurement numbers to each trip group (analysis order)
# drop null variables for tidiness
spectrolyser_results <- spectrolyser_results %>% 
  mutate(trip = NumberXtract(source)) %>% 
  group_by(trip) %>% 
  mutate(measurement = row_number()) %>% 
  ungroup()

# check it out
#str(spectrolyser_results)

unique(spectrolyser_results$trip)

nrow(spectrolyser_results) == nrow(spectrolyser_samples)
# oh?! they should be the same length...
# several triplicate measurements -- see section 4 for solution


# 3. ------------ SPECTROLYSER ANALYSIS RESULTS ------------ # 

# combine 'spectrolyser_samples' with 'spectrolyser_results'
SCAN_results <- spectrolyser_results %>% 
  select(-c(Date, Time, Status, NULLTurbid, NULLNO3.Neq, NULLTOCeq, NULLDOCeq, SAC254_0, SAC436_0, X254.436_Abs.m, X254.436_0, analogIN_, analogIN_0)) %>% 
  full_join(spectrolyser_samples, by = c("trip", "measurement")) %>% 
  ungroup()

# check lengths match
nrow(SCAN_results) == nrow(spectrolyser_samples)
# check head
head(SCAN_results)
# check structure
#str(SCAN_results)


# what about trip 21, which was actually in trip 20 (Cragg on 2019-12-19)
SCAN_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# update vials 19-21 to be "trip 21", for later matching with Odyssey stage data
# also change trip 24 to 23 
## the samples were analyzed in different files 
## it seemed easier to mis-label them rather than manually altering the data files
SCAN_results <- SCAN_results %>% 
  mutate(trip = case_when(trip == "20" & site =="Cragg-crk" & (measurement == 19 | measurement == 20 | measurement == 21) ~ "21",TRUE ~ trip),
         trip = as_factor(trip))

# check to make sure it's updated:
SCAN_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 
# good!

# 4. -------------  triplicates!  ------------- 
# several analyses measured the same sample in triplicate to assess instrument precision
# trips c(10, 11, 12, 13, 15, 16)
# these measurements are counted as unique samples (though they are not)
# create an average for those measured in triplicate 
# split / apply / combine
SCAN_results <- SCAN_results %>%  
  group_by(trip, site, sample_type, sample, dt_sampled, fillStage_cm) %>% 
  summarise(Turbid.FTUeq = mean(Turbid.FTUeq),
            NO3.Neq_ppm = mean(NO3.Neq_ppm),
            TOCeq_ppm = mean(TOCeq_ppm), 
            DOCeq_ppm = mean(DOCeq_ppm),
            SAC254_Abs.m = mean(SAC254_Abs.m),
            SAC436_Abs.m = mean(SAC436_Abs.m)) %>% 
  ungroup()

```

### Full scan spectrophotometry (SCAN_results, spectral fingerprints)

The Spectrolyser outputs a fingerprint file containing absorbance values at all of the wavelengths monitored. These .fp files can provide information about NOM structure. For example, the ratio of the slope between 275-295nm and the slope from 350-400nm ("slope ratio (SR)"), commonly used as an indicator of molecular weight.

```{r Spectrolyser-fp, message=FALSE}

## Spectrolyser samples and fingerprints (fp)
# sample IDs and fullscans 
# multi-part data munge
# 1. bring in sample tracking data, format appropriately
# 2. bring in results data, format appropriately
# 3. bring them together as meanigful results data
# 4. some analyses were run in triplicate -- summarize as sample means


# 1. ------------ SAMPLES ------------ #
# these data have already been loaded
# "spectrtolyser_samples"

# 2. ------------ FULLSCAN RESULTS ------------ # 

# assign column names
fullscan_colnames <- c("Date", "Time", "Status", paste0("Abs_", seq(200.0, 750.0, by = 2.5)))
## read in files and add a column indicating trip #, based on source file name
spectrolyser_fullscan <- 
  list.files(path = "R-inputs_UBC-forWater-MSc_HMc/spectrolyser/fingerprints_scan_fp/") %>% 
  set_names(str_extract(., "([A-Za-z]{3,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(
    file = file.path("R-inputs_UBC-forWater-MSc_HMc/spectrolyser/fingerprints_scan_fp/", .), 
    skip = 2, header = FALSE, col.names = fullscan_colnames), .id = "source") 

# check it out
# str(spectrolyser_fullscan)

# pull out numbers from alphanumeric 'source' to create factor variable 'trip'
# use function 'NumberXtract()'
# add measurement numbers to each trip group (analysis order)
# drop null variables for tidiness
spectrolyser_fullscan <- spectrolyser_fullscan %>% 
  mutate(trip = NumberXtract(source)) %>% 
  group_by(trip) %>%
  mutate(measurement = row_number()) %>% 
  ungroup() 

# note that trip "0" was an external calibration

# check it out
# str(spectrolyser_fullscan)
levels(spectrolyser_fullscan$trip)

colnames(spectrolyser_fullscan)

# str(spectrolyser_fullscan)
# str(spectrolyser_samples)
# combine?
nrow(spectrolyser_fullscan) == nrow(spectrolyser_samples)
# will have to handle triplicates as for .par files


# 3. ------------ SPECTROLYSER FULLSCAN RESULTS ------------ # 
# combine 'spectrolyser_samples' with 'spectrolyser_fullscan'
FULLSCAN_results <- full_join(spectrolyser_fullscan, spectrolyser_samples, 
                              by = c("trip", "measurement")) %>% 
  mutate(site = factor(site),
         sample_type = factor(sample_type),
         dt_sampled = lubridate::as_datetime(dt_sampled)
  )
# check columnnames
colnames(FULLSCAN_results)
# levels(FULLSCAN_results$site)  


# 4. -------------- fixes:

# for Cragg Creek, trip 21 was actually in trip 20 (Cragg on 2019-12-19)
# update measurements c(19:21) to be "trip 21", for later matching with Odyssey stage data
FULLSCAN_results <- FULLSCAN_results %>% 
  mutate(trip = as.character(trip),
         trip = case_when(trip == "20" & site =="Cragg-crk" & 
                            (measurement == 19 | measurement == 20 | measurement == 21) ~ "21",
                          TRUE ~ trip))


# ---  triplicates:
# several analyses measured the same sample in triplicate to assess instrument precision
# trips c(10, 11, 12, 13, 15, 16)
# these measurements are counted as unique samples (though they are not)
# create an average for those measured in triplicate 
# split / apply / combine
FULLSCAN_results <- FULLSCAN_results %>% 
  select(-c("source", "Date", "Time", "Status")) %>% 
  group_by(trip, site, sample_type, sample, dt_sampled, fillStage_cm) %>% 
  summarise_all(list(~mean(.))) %>% 
  ungroup()
```

### Spectral indices
```{r, spectral-indices}

# ------ spectral indices -------
# the absorbance values can be used to determine spectral indices
# indices are more useful for interpretation than raw ABS values

# first, check that SAC254_Abs/m is ABS/m @254nm
spectral_results <- dplyr::full_join(FULLSCAN_results, SCAN_results,
                                     by = c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm"))

# explore 
spectral_results %>%
  group_by(site, sample_type, sample, SAC254_Abs.m) %>% 
  summarise(twofiftyfour = mean(c(Abs_252.5, Abs_255)))  # actually abs at 253.75
# I believe it.

# how was turbidity?
spectral_results %>%
  filter(Turbid.FTUeq > 0) %>% 
  select(trip, site, sample_type, sample, SAC254_Abs.m, Abs_252.5, Abs_255, Turbid.FTUeq)

# how many samples will I lose by filtering out those with turbidity>0?
turby <- nrow(spectral_results %>%
                filter(Turbid.FTUeq > 0.000) %>% 
                select(trip, site, sample_type, sample, SAC254_Abs.m, Turbid.FTUeq)
)
loss <- 100*(turby/nrow(spectral_results))

# -------------------------------------------------------------------------------------------
# Spectral slopes -- from linear regression of log~e~-transformed spectra

# S1
# 275-295 nm (S~275-295~) == S1
S1 <- spectral_results %>%
  filter(Turbid.FTUeq == 0) %>%                   # remove turbid samples 
  pivot_longer(cols = Abs_275:Abs_295,            # longer is better (select only what you need)
               names_to = "wavelength_nm", values_to = "SAC_per.m") %>% 
  select(c(trip, site, sample_type, sample, dt_sampled, fillStage_cm, 
           Turbid.FTUeq, NO3.Neq_ppm, TOCeq_ppm, DOCeq_ppm, 
           SAC254_Abs.m, SAC436_Abs.m, wavelength_nm, SAC_per.m)
  ) %>% 
  mutate(wavelength_nm = as.numeric(NumberXtract(wavelength_nm))) %>%  # numeric wavelength
  mutate(lnSAC = log(SAC_per.m)) %>% 
  group_by(trip, site, sample_type, sample) %>% 
  summarise(sample_slope1 = cor(y = lnSAC, x = wavelength_nm)) 

# plot it
spectral_results %>%
  filter(Turbid.FTUeq == 0) %>% 
  pivot_longer(cols = Abs_275:Abs_295,            # longer is better (select only what you need)
               names_to = "wavelength_nm", values_to = "SAC_per.m") %>% 
  mutate(wavelength_nm = as.numeric(NumberXtract(wavelength_nm)),  # numeric wavelength
         lnSAC = log(SAC_per.m)) %>%  
  group_by(trip, site, sample_type, sample) %>% 
  ggplot(aes(x = wavelength_nm, y = lnSAC)) +
  geom_jitter() +
  geom_smooth(method = "lm")

# S2
# 350-400 nm (S~350-400~) == S2
S2 <- spectral_results %>%
  filter(Turbid.FTUeq == 0) %>%                   # remove turbid samples 
  pivot_longer(cols = Abs_350:Abs_400,            # longer is better (select only what you need)
               names_to = "wavelength_nm", values_to = "SAC_per.m") %>% 
  select(c(trip, site, sample_type, sample, dt_sampled, fillStage_cm, 
           Turbid.FTUeq, NO3.Neq_ppm, TOCeq_ppm, DOCeq_ppm, 
           SAC254_Abs.m, SAC436_Abs.m, wavelength_nm, SAC_per.m)
  ) %>% 
  mutate(wavelength_nm = as.numeric(NumberXtract(wavelength_nm))) %>%  # numeric wavelength
  mutate(lnSAC = log(SAC_per.m)) %>% 
  group_by(trip, site, sample_type, sample) %>% 
  summarise(sample_slope2 = cor(y = lnSAC, x = wavelength_nm)) 

# plot it
spectral_results %>%
  filter(Turbid.FTUeq == 0) %>% 
  pivot_longer(cols = Abs_350:Abs_400,            # longer is better (select only what you need)
               names_to = "wavelength_nm", values_to = "SAC_per.m") %>% 
  mutate(wavelength_nm = as.numeric(NumberXtract(wavelength_nm)),  # numeric wavelength
         lnSAC = log(SAC_per.m)) %>%  
  group_by(trip, site, sample_type, sample) %>% 
  ggplot(aes(x = wavelength_nm, y = lnSAC)) +
  geom_jitter() +
  geom_smooth(method = "lm")

# Summary df with slope ratios and spectral indicies
spectral_summary <- spectral_results %>%
  mutate(pseudo254 = (Abs_252.5+Abs_255)/2) %>% 
  select(trip:fillStage_cm,
         pseudo254,
         Abs_250, Abs_365
  ) %>% 
  full_join(S1) %>% 
  full_join(S2) %>% 
  mutate(SlopeRatio = sample_slope1/sample_slope2,
         E2E3 = Abs_250/Abs_365,
         trip = as_factor(trip)) %>% 
  select(-c(sample_slope1, sample_slope2))

```

## Data collation

* Join results files from Shimadzu and Spectrolyser (direct and indirect measures of DOC, plus full scan data)
* Bringing together the results from both the Shimadzu and Spectrolyser. 
* Join data frames and create additional variables to help classify the data for plotting. 

```{r, compile-analyses-results}

# join the results files from the Shimadzu TOC-V and Spectrolyser
#str(TOCV_results)   # shimadzu NPOC results (direct measure of DOC)
#str(SCAN_results)   # spectrolyser indirect results of DOC (UV-Vis)
#str(spectral_summary)  # spectrolyser full scan 250-700nm

# both have c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm")
# the variables measured are: NPOC_ppm, Turbid.FTUeq, NO3.Neq_ppm, TOCeq_ppm, DOCeq_ppm, SAC254_Abs.m, SAC436_Abs.m
# the instrument was TOCV or SCAN

# --- WIDE SUMMARY DF --- # 
sampleresults <- full_join(TOCV_results, SCAN_results, 
                           by = c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm")) %>% 
  full_join(spectral_summary, by = c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm")) %>% 
  mutate(trip = as_factor(trip),
         site = as_factor(site),
         sample_type = as_factor(sample_type),
         sample = as_factor(sample),
         analysis = factor(analysis, exclude = "TOC"),  # drop "TOC"
         analysis = factor(analysis),   # drop residual NA from removing "TOC"
         site = factor(site, exclude = "Mystery-bottle"),  # drop "mystery bottle"
         site = factor(site)) %>%  # drop residual NA from removing "mystery bottle"
  select(-c(vial))   # drop unnecessary variables
# check it out
#str(sampleresults)

# add a column of "trip_end" to have a date for each trip (plotting)
## this is a terrible method
## there must be a way to use a loop/map/apply (don't know how yet)

#sampleresults2 <-  sampleresults %>% 
#   mutate(
#    for (i in seq_along(1:22)) {
#      trip_end[i] = case_when(trip == i ~ trip_df$trip.end[i])
#        })

sampleresults <- sampleresults %>% 
  mutate(trip_end = case_when(  
    trip == "1" ~ trip_df$trip.end[1],
    trip == "2" ~ trip_df$trip.end[2],
    trip == "3" ~ trip_df$trip.end[3],
    trip == "4" ~ trip_df$trip.end[4],
    trip == "5" ~ trip_df$trip.end[5],
    trip == "6" ~ trip_df$trip.end[6],
    trip == "7" ~ trip_df$trip.end[7],
    trip == "8" ~ trip_df$trip.end[8],
    trip == "9" ~ trip_df$trip.end[9],
    trip == "10" ~ trip_df$trip.end[10],
    trip == "11" ~ trip_df$trip.end[11],
    trip == "12" ~ trip_df$trip.end[12],
    trip == "13" ~ trip_df$trip.end[13],
    trip == "14" ~ trip_df$trip.end[15],
    trip == "15" ~ trip_df$trip.end[16],
    trip == "16" ~ trip_df$trip.end[17],
    trip == "17" ~ trip_df$trip.end[18],
    trip == "18" ~ trip_df$trip.end[19],
    trip == "19" ~ trip_df$trip.end[20],
    trip == "20" ~ trip_df$trip.end[21],
    trip == "21" ~ trip_df$trip.end[22],
    trip == "22" ~ trip_df$trip.end[23],
    trip == "23" ~ trip_df$trip.end[24])) %>% 
  mutate(trip_end = lubridate::ymd(trip_end))

# add a variable to identify season 
# three seasons (early/late wet and dry) 
# and two seasons (wet/dry))    
sampleresults <- sampleresults %>% 
  mutate(trip = factor(trip, levels = 0:23),
         three_seasons = case_when(
           trip == 0 ~ "SCAN QA-QC", 
           trip %in% 1:4 ~ "early wet [Oct-Dec]",   # (second half) Oct-Dec 2018
           trip %in% 5:9 ~ "late wet [Jan-May]",           # Jan-May 2019 
           trip %in% 10:16 ~ "summer [June-Oct]",  # June-Oct (first half) 2019
           trip %in% 17:21 ~ "early wet [Oct-Dec]", # Oct-Dec 2019
           trip %in% 22:23 ~ "late wet [Jan-May]"), # Jan-Feb 2020
         two_seasons = case_when(
           trip == 0 ~ "SCAN QA-QC", 
           trip %in% 1:9 ~ "wet",   # mid-Oct 2018 to May 2019
           trip %in% 10:16 ~ "dry",  # June to mid-Oct 2019
           trip %in% 17:23 ~ "wet")) # mid-Oct 2019 to Jan 2020

# SUVA ------ 
# add a variable for SUVA = [DOC]/SAC254
sampleresults  <-  sampleresults %>% 
  mutate(SUVA = SAC254_Abs.m/NPOC_ppm)

# good!

```

## Metals data
```{r, CRD-metals}

# I collected metals samples from trip 3 to 10
# CRD provided results files (PDF report) for trips 3 to 8
# data was manually sorted from PDF (there must be a better way)
# load data
metals <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Metals_CRD-forWaterMSc_HMc/CRD-metals-data_collated-trips3-10_nocharacternulls.csv", 
                   col_names = TRUE) %>% 
  tidyr::pivot_longer(cols = WESTLEECH:CHRISCREEK,
                      names_to = "site",
                      values_to = "metals_values") %>% 
  mutate(Trip = factor(Trip),
         Parameters = factor(Parameters),
         site = factor(site))


# check site names
levels(metals$site)

# add data for NPOC, DOC_eq, and SUVA
# subset for the six installation sites & rename
metalslab <- left_join(x = metals, 
                       y = (sampleresults %>% 
                              filter(site == "Weeks-out" |
                                       site == "Leech-head" |
                                       site == "Chris-crk" |
                                       site == "Cragg-crk" |
                                       site == "West-Leech"| 
                                       site == "Tunnel",
                                     sample_type == "Grab" & sample == "Grab",
                                     analysis == "DOC") %>% 
                              mutate(site = fct_recode(site, 
                                                       WEEKSOUT = "Weeks-out", 
                                                       CHRISCREEK = "Chris-crk", 
                                                       LEECHHEAD = "Leech-head", 
                                                       CRAGGCREEK = "Cragg-crk", 
                                                       WESTLEECH = "West-Leech", 
                                                       TUNNEL = "Tunnel"))),
                       by = c("site" = "site", "Trip" = "trip")) %>%
  mutate(Trip = factor(Trip),
         Site = factor(site),
         metal_parameters = factor(Parameters)) %>% 
  drop_na(site, metal_parameters) %>% 
  select(-"BONEYARD") %>% 
  mutate()

```


# Field Data

The six pirmary research location in the Leech River watershed were equipped with vertical sampling racks (which combined passive (siphon) samplers and compact river stage loggers) colected continuous water level via Odyssey capacitiance water level loggers. Field data includes the following: 

1. The CRD provided data from their fire weather stations for precipitation and air temperature. 

2. At the six installation sites, I collected data for:

* water level (Odyssey capacitance water level loggers)
* air and water temperature (Hobo TidbiTs)

3. At the four mainstem sites (Leech Head, Cragg Creek, West Leech, Tunnel), I collected 10 minute interval triggered trail-cam photos.

## Weather data (CRD fire weather stations)

The Leech river watershed hydroclimatic regime is pluvial, therefore precipitation data is very important. There were (at the time of my research) three weather stations in proximity to the Leech:

* Chris Crk WxStn at the headwaters
* Survey Mtn WxStn at the highest peak, in the Leech (installed in 2019, short record)
* Martin's Gulch WxStn near the Leech River Tunnel (future point of diversion)

## Weather
```{r, Wx-precip}

# bring in WxStn data 
# Note: each file has a different DateTime format (be sure to lubridate)

# read it in
precip_data <- 
  list.files("R-inputs_UBC-forWater-MSc_HMc/CRD_FWx-Data/", pattern = "*.CSV") %>% 
  #set_names(str_extract(., "([A-ZA-Z]{4,}+)")) %>%
  purrr::map_dfr(~ read_csv(file.path("R-inputs_UBC-forWater-MSc_HMc/CRD_FWx-Data/", .), 
                            col_names = TRUE,
                            col_types = list("c", "c", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d"))) %>% 
  mutate(DateTime = lubridate::parse_date_time(DateTime, c("dmY HM", "Ymd HM", "Ymd HMS", "Ymd HMS Op!*")))


# create a summary datafame with mean weather data between Chris creek and Martin's Gulch
wx_mean <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  group_by(DateTime) %>% 
  select(-StationName) %>% 
  summarise_all(list(mean = mean))

```


## River stage data 

At the six installation sites, water level loggers were installed (Odyssey capacitance water level loggers). The level loggers recorded stage at 10 minute intervals. Each logger was in a stilling well with a secured external stage measuring tape; the stage data must be adjusted with an offset value to match with the observed stage in order to match sample collection to logger datetimes.


```{r, stage}

# bring in logger data and add a id column from the site file name
# note, each of the 6 sites has files named except 'Leech-Head' is named by the logger serial number (12040) 

# input samples directory path
odyssey_path <-  "R-inputs_UBC-forWater-MSc_HMc/odyssey/"

# check files  
list.files(path = odyssey_path, pattern = "*.CSV") 
# check source extract is reasonable   
list.files(path = odyssey_path, pattern = "*.CSV") %>%
  str_extract("([A-Z0-9]{4,}+)")
# Note that source names will have to be updated (mutate)

# read in all the files as one dataframe
# add source (ID) based on file names
# adjust date-time (note that there were multiple date formats output by loggers)
# time is in 24 hour clock and it seems that lubridate does not like that...
odyssey_data <- list.files(path = odyssey_path, pattern = "*.CSV") %>% 
  set_names(str_extract(., "([A-Z0-9]{4,}+)")) %>%
  purrr::map_dfr(~ read_csv(file.path(odyssey_path, .), skip = 12, 
                            col_names = c("scan_no.", "Date", "Time", "Capacitance", "stage_cm")), .id = "source") %>% 
  mutate(source = forcats::as_factor(source),
         Date = lubridate::parse_date_time(Date, c("dmy", "ydm"), tz = TZ),
         DateTime = lubridate::ymd_hms(paste(Date, Time), tz = TZ))

# check structure
# str(odyssey_data)

# check levels
levels(odyssey_data$source)
# rename site IDs
odyssey_data$source <- forcats::fct_recode(odyssey_data$source, 
                                           LeechHead = "12040",
                                           ChrisCrk = "CHRIS",
                                           CraggCrk = "CRAGG",
                                           Tunnel = "LEECH",
                                           Weeks = "WEEKS",
                                           WestLeech = "WEST")
# re-check levels
levels(odyssey_data$source)


# there is certainly a better way to do this -- with a loop or map or apply or metaprogramming
# I don't know yet and I need to move on. 
# bad technique: copy and paste x22 (I know this is bad and ugly, sorry)
# ----
odyssey_data <- odyssey_data %>%
  select(Date, source, stage_cm, DateTime) %>%
  mutate(interval = case_when(  
    Date %within% interval(trip_df$trip.start[1], trip_df$trip.end[2]) ~ trip_df$trip[2],
    Date %within% interval(trip_df$trip.end[2], trip_df$trip.end[3]) ~ trip_df$trip[3],
    Date %within% interval(trip_df$trip.end[3], trip_df$trip.end[4]) ~ trip_df$trip[4],
    Date %within% interval(trip_df$trip.end[4], trip_df$trip.end[5]) ~ trip_df$trip[5],
    Date %within% interval(trip_df$trip.end[5], trip_df$trip.end[6]) ~ trip_df$trip[6],
    Date %within% interval(trip_df$trip.end[6], trip_df$trip.end[7]) ~ trip_df$trip[7],
    Date %within% interval(trip_df$trip.end[7], trip_df$trip.end[8]) ~ trip_df$trip[8],
    Date %within% interval(trip_df$trip.end[8], trip_df$trip.end[9]) ~ trip_df$trip[9],
    Date %within% interval(trip_df$trip.end[9], trip_df$trip.end[10]) ~ trip_df$trip[10],
    Date %within% interval(trip_df$trip.end[10], trip_df$trip.end[11]) ~ trip_df$trip[11],
    Date %within% interval(trip_df$trip.end[11], trip_df$trip.end[12]) ~ trip_df$trip[12],
    Date %within% interval(trip_df$trip.end[12], trip_df$trip.end[13]) ~ trip_df$trip[13],
    Date %within% interval(trip_df$trip.end[13], trip_df$trip.end[15]) ~ trip_df$trip[15],
    Date %within% interval(trip_df$trip.end[15], trip_df$trip.end[16]) ~ trip_df$trip[16],
    Date %within% interval(trip_df$trip.end[16], trip_df$trip.end[17]) ~ trip_df$trip[17],
    Date %within% interval(trip_df$trip.end[17], trip_df$trip.end[18]) ~ trip_df$trip[18],
    Date %within% interval(trip_df$trip.end[18], trip_df$trip.end[19]) ~ trip_df$trip[19],
    Date %within% interval(trip_df$trip.end[19], trip_df$trip.end[20]) ~ trip_df$trip[20],
    Date %within% interval(trip_df$trip.end[20], trip_df$trip.end[21]) ~ trip_df$trip[21],
    Date %within% interval(trip_df$trip.end[21], trip_df$trip.end[22]) ~ trip_df$trip[22],
    Date %within% interval(trip_df$trip.end[22], trip_df$trip.end[23]) ~ trip_df$trip[23],
    Date %within% interval(trip_df$trip.end[23], trip_df$trip.end[24]) ~ trip_df$trip[24]) )
# note that interval (odyssey_data) is the same as (trip_df) trip number of analysis/collection 

# check out the head tail and middle
# head(odyssey_data)
# tail(odyssey_data, - 0.2*length(odyssey_data$Date))
# tail(odyssey_data, - 0.5*length(odyssey_data$Date))
# tail(odyssey_data, - 0.7*length(odyssey_data$Date))
# tail(odyssey_data)

# NOTE --- These logger data need to be adjusted with the observed stage offset
# -------
# offsets based on data download from fall 2019
# each offset should be added to logged data to match rack stages
offset_L.Head   <- 95-38.907   # 2020-10-11: obs 95cm, recorded = 38.907 cm
offset_WksOut   <- 26.0-20.87  # 2020-09-20: obs = 26.0 cm, recorded = 20.87
offset_ChrisCrk <- 19-13.196   # 2020-09-20: obs = 19cm, recorded = 13.196 cm
offset_CraggCrk <- 8.0 - 6.57  # 2020-09-20: obs = 8.0 cm, recorded = 6.57 cm
offset_W.Leech  <- 15.5- 12.19 # 2020-09-20: obs = 15.5 cm, recorded = 12.188 cm
offset_Tunnel   <- 0.0 - 3.35  # 2020-09-20: obs = 0 cm (HFSG = 27cm), recorded = 3.35
# ---
# these are old values (2018)...in good agreement 
# offset_L.Head   <- 60.84 # 
# offset_WksOut   <- 5.17 # add to logger (was 29, 9.5)
# offset_ChrisCrk <- 5.75 # add to logger (was 30, 7.27)
# offset_CraggCrk <- 1.43 # add to logger 19-09-20 (was 9.25)
# offset_W.Leech  <- 2.87 # add to logger (was 4.85) 
# offset_Tunnel   <- -3.32 # add to logger (negative offset, weird, was -3.17)
# ---

# corrected_stage
corr_stage <- odyssey_data %>% 
  group_by(source) %>% 
  mutate(corr_stage_cm = case_when(
    source == "LeechHead" ~ (stage_cm + offset_L.Head),
    source == "ChrisCrk" ~ (stage_cm + offset_ChrisCrk),  
    source == "CraggCrk" ~ (stage_cm + offset_CraggCrk),  
    source == "Tunnel" ~ (stage_cm + offset_Tunnel),    
    source == "Weeks" ~ (stage_cm + offset_WksOut),     
    source == "WestLeech" ~ (stage_cm + offset_W.Leech)
  )) %>% 
  ungroup() %>% 
  mutate(source = factor(source, 
                         levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")))

```



## define hydrologic events based on precip using Rainmaker::RMevents
```{r, warnings = FASLE, messages = FALSE}
# use precipitation to define events
# precip_data
# odyssey_data

Wx_CC_storms <- wx_mean %>% 
  filter(DateTime >= "2018-10-23") %>% 
  as.data.frame() %>% 
  Rainmaker::RMevents(., ieHr = 20, rainthresh = 30, rain = "Rn15_mean", time = "DateTime")

Wx_CC_storms[["storms2"]]  # list of events that surpass rainthresh (mm event depth)
Wx_CC_storms[["storms"]]   # list of all events


# rain plot with storm lines
rn_strm_plot <- subbasin_meanrain_plot <- wx_mean %>% 
  mutate(date = lubridate::as_date(DateTime),
         Rain = factor("Rain")) %>% 
  group_by(date, Rain) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(aes(colour = Rain), colour = "#0072B2") +
  scale_y_reverse() +
  labs(x = "", y = "mm /day") +
  theme_bw() +
  geom_vline(xintercept = as_date(Wx_CC_storms[["storms2"]]$StartDate))+
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Rain, ncol = 1, 
             strip.position = "right") +
  theme(legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90))

# river stage with storm lines
rv_strm_plot <- stage_plot+
  geom_vline(xintercept = Wx_CC_storms[["storms2"]]$StartDate)

# stack the two storm delineated plots
cowplot::plot_grid(rn_strm_plot, rv_strm_plot, 
                   ncol = 1, axis = "l", align = "v",
                   rel_heights = c(1,5))



```


# File Outputs

save the compiled and formatted dataframes as .csv files.
Keep this as a code-note so to prevent over-writing files accidentally

``` 
# {r output sample analysis files}

## save all compiled sample analysis as .csv files 
# keep as code note to avoid accidental over-writing later*

# TOCV_results df
# Shimadzu sample analyses results
write_csv(TOCV_results, path = "R-outputs_UBC-forWater-MSc_HMc/TOCV_results.csv", na = "NA")   

# SCAN_results df
# Spectrolyser sample analyses results
write_csv(SCAN_results, path = "R-outputs_UBC-forWater-MSc_HMc/SCAN-par_results.csv", na = "NA")  

# FULLSCAN_results df
# Spectrolyser fullscan (.fp) analyses results
write_csv(FULLSCAN_results, path = "R-outputs_UBC-forWater-MSc_HMc/SCAN-fp_results.csv", na = "NA")

# spectral_results df
# Spectrolyser fullscan (.fp) analyses results
write_csv(spectral_results, path = "R-outputs_UBC-forWater-MSc_HMc/spectral_results.csv", na = "NA")

# sampleresults df
# compiled sample analyses results (wide)
write_csv(sampleresults, 
path = "R-outputs_UBC-forWater-MSc_HMc/samples-lab-analyses_results.csv", na = "NA")  

# metalslab df
# metals sample analyses results with OC (long)
write_csv(metalslab, 
path = "R-outputs_UBC-forWater-MSc_HMc/metals-DOCgrab-sample_results-long.csv", na = "NA")  

# odyssey_data df
# stage data compiled with interval/trip
write_csv(odyssey_data, 
path = "R-outputs_UBC-forWater-MSc_HMc/Odyssey-stage_compiled.csv", na = "NA")

# corr_stage df
# baseflow and rack corrected Odyssey data
write_csv(corr_stage, 
path = "R-outputs_UBC-forWater-MSc_HMc/Odyssey-RackCorrected-stage.csv", na = "NA")

# precip_data df
# 2018-2020 weather station data compiled and formatted
write_csv(precip_data, 
path = "R-outputs_UBC-forWater-MSc_HMc/FWx-PrecipTemp_compiled.csv", na = "NA")

# wx_mean df
# 2018-2020 weather station data averages from FWx stations Chris Creek and Martins Gulch
write_csv(wx_mean, 
path = "R-outputs_UBC-forWater-MSc_HMc/FWx-Mean-LWSA_PrecipTemp.csv", na = "NA")

```



# the following code chunks and text are old (to be updated/removed):
.
.
.
.
.
.
.
.
.
.
.
# Level loggers for rack sampling time-stamps


##OLD Goal:match bottle height to logged stage

1. read in sampleresults df with analyses results, were set and collected, and fill stage (or grab sample dates)
2. read in stage data from Odyssey Capacitance water level loggers
3. fix dates, add identifying/grouping columns for source (site) & interval (event)
4. filter by site & event & analysis (DOC)
5. match samples to logged stage and extract matching date-time 
6. add DateTime stamps to sample results dataframes


I think you can do thins in a loop with i as the seq_along(site_names[i]) and j as the seq_along(event[j]) 
call vector of events for trip_df

```{r new stage match}
# first, create subset dataframes for each subbsain
stg_1 <- corr_stage %>% filter(source == "Weeks") 
samp_1 <- sampleresults %>% filter(sample_type == "Rack", analysis == "DOC", site == "Weeks")

stg_2 <- corr_stage %>% filter(source == "ChrisCrk") 
samp_2 <- sampleresults %>% filter(sample_type == "Rack", analysis == "DOC", site == "ChrisCrk")

stg_3 <- corr_stage %>% filter(source == "LeechHead") 
samp_3 <- sampleresults %>% filter(sample_type == "Rack", analysis == "DOC", site == "LeechHead")

stg_4 <- corr_stage %>% filter(source == "CraggCrk") 
samp_4 <- sampleresults %>% filter(sample_type == "Rack", analysis == "DOC", site == "CraggCrk")

stg_5 <- corr_stage %>% filter(source == "WestLeech") 
samp_5 <- sampleresults %>% filter(sample_type == "Rack", analysis == "DOC", site == "WestLeech")

stg_6 <- corr_stage %>% filter(source == "Tunnel") 
samp_6 <- sampleresults %>% filter(sample_type == "Rack", analysis == "DOC", site == "Tunnel")

# try
stg_df %>% mutate(
  occur_fill = case_when(
    (stg_df$source == samp_df$site & stg_df$interval == samp_df$trip) ~ detect_index(stg, ~.x >= level, .dir = "forward")),
  stg_fill = stg[occur_fill]
)

# try
for (i in seq_along(1:23)) { # trip or interval number
  for (s in seq_along(unique(samp_1$sample))) { #rack samples
    occur_fill[s] <- case_when(stg_1$) 
      detect_index(stg, ~ .x >= level[[s]], .right = FALSE)
  }
}

for (t in seq_along(1:23)) { # trip or interval number
for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 


# --- old
# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #
```


```{r match OC and stage}
# -------------------------------------------------------------- YOU ARE HERE
# first, filter and rename subbasin sites  to match odyssey data
subbasins <- sampleresults %>% filter(site == "Weeks-out" |
                                        site == "Leech-head" |
                                        site == "Chris-crk" |
                                        site == "Cragg-crk" |
                                        site == "West-Leech"| 
                                        site == "Tunnel") %>% 
  mutate(site = factor(site),
         # remove dashes from sub-basin names (match Odyssey names)
         site = forcats::fct_recode(site, 
                                    Weeks = "Weeks-out",
                                    ChrisCrk = "Chris-crk",
                                    LeechHead = "Leech-head",
                                    CraggCrk = "Cragg-crk", 
                                    WestLeech = "West-Leech"),
         site = factor(site, levels = # order from head to mouth
                         c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech","Tunnel")))


# previously (janky) I subset the stage df for each site
# try group_by instead
# use the df with corrected stage
stg_df <- corr_stage %>% # input with DateTimes
  group_by(source, forcats::fct_explicit_na(interval))

samp_df <- subbasins %>% # input that is missing Rack DateTimes
  filter(sample_type == "Rack", analysis == "DOC",
         (as.integer(trip) != 0)) %>% 
  mutate(trip = factor(trip, levels = 1:23)) %>% 
  group_by(site, trip)
# note that interval (stg_df) is the same as trip (samp_df)

#set up inputs for loop
## this is the stage date you're targeting (by site)
stg <- stg_df$corr_stage_cm
## this is the time series you're targeting
t.series <- stg_df$DateTime  
## this is the stage you need a date-time for
level <- samp_df$fillStage_cm  

# assign empty vectors to hold the outputs from the loop
occur_fill <- vector(length = nrow(samp_df))
stg_fill   <- vector(length = length(samp_df$sample))
time_fill  <- vector(length = length(samp_df$sample))

# ---
# try it with dplyr no loop
stg_df <- corr_stage %>% # input with DateTimes
  group_by(source, forcats::fct_explicit_na(interval)) %>% 
  purrr::detect_index(stg, ~ .x >= level[i], .dir = "forward")

# ---

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- purrr::detect_index(stg, ~ .x >= level[i], .dir = "forward")
  stg_fill[i] <- stg[occur_fill[i]]
} 

# ---

# --- attempting to base this on when interval matches and site is the same
ifelse(stg_df$interval == samp_df$trip,
       (for (i in seq_along(samp_df$sample)) {
         occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
         stg_fill[i] <- stg[occur_fill[i]]  }) ,
       "NAN")
# --- 

# ---  try it with case_when()

# ---

matcheddf <- samp_df %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])

# ------------------------------------------------------------------------------ you're here


samp_df %>% mutate(interval = for (s in seq_along(unique(stg_df$source))) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  
}
                     case_when())


for(i in seq_along(1:23))
stg_df <- filter(stage.event_df, site == site_names[1] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)



# you should be able to get the above to work
# --- wks 1
# --- INPUTS --- #
# create subset working dataframes 
# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 
# --- 


# --- wks 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- wks 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- wks 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- wks 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #



# --- wks 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #
## Event five - freezing event. L1 was recorded as being set at 91 cm but the stage was not recorded as getting that high...


# --- wks 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

## -- This could be improved - possibly with a case_when() or a loop or apply?? --- #


# combine all events into one weeks-df
# no fifth -- wks_matched <- rbind(wks_ev1_df,wks_ev2_df, wks_ev3_df, wks_ev4_df, wks_ev5_df, wks_ev6_df)
wks_matched <- rbind(wks_ev1_df,wks_ev2_df, wks_ev3_df, wks_ev4_df, wks_ev5_df, wks_ev6_df)



# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 


# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[1]
rackDOC <- wks_matched
stg_DOCplot <- plot_wks_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[1]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #

site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 


# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_wks_samp <- ggplot_gtable(ggplot_build(site.visit.plot))

```

## Leech River Head

```{r OC-stage_leech-head}

# --- Leech-Head 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- LHead 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# combine all events into one weeks-df
L.Head_matched <- rbind(L.Head_ev1_df,L.Head_ev2_df, L.Head_ev3_df, L.Head_ev4_df, L.Head_ev5_df, L.Head_ev6_df)


# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 


# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[2]
rackDOC <- L.Head_matched
stg_DOCplot <- plot_L.head_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[2]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #

site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_LHead_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## Chris Creek

```{r OC-stage_chris-creek}

# --- Chriscrk 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

# combine all events into one weeks-df
Chriscrk_matched <- rbind(Chriscrk_ev1_df, Chriscrk_ev2_df, Chriscrk_ev3_df, Chriscrk_ev4_df, Chriscrk_ev5_df, Chriscrk_ev6_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[3]
rackDOC <- Chriscrk_matched
stg_DOCplot <- plot_chris_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[3]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #

site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_Crscrk_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## Cragg Creek

```{r OC-stage_cragg}

# --- cragg 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

# combine all events into one weeks-df
# no fifth -- wks_matched <- rbind(wks_ev1_df,wks_ev2_df, wks_ev3_df, wks_ev4_df, wks_ev5_df, wks_ev6_df)
cragg_matched <- rbind(cragg_ev1_df, cragg_ev2_df, cragg_ev3_df, cragg_ev4_df, cragg_ev5_df, cragg_ev6_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[4]
rackDOC <- cragg_matched
stg_DOCplot <- plot_cragg_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[4]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #
site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_Craggcrk_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## West Leech River

```{r OC-stage_west}

# --- west 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

# combine all events into one weeks-df
west_matched <- rbind(west_ev1_df, west_ev2_df, west_ev3_df, west_ev4_df, west_ev5_df, west_ev6_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[5]
rackDOC <- west_matched
stg_DOCplot <- plot_west_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[5]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #
site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_WestL_samp <- ggplot_gtable(ggplot_build(site.visit.plot))

```

## Leech River Tunnel

```{r OC-stage_tunnel}
# this site was installed late, in December
# event 1 for the tunnel was "event 3" for all others...


# --- tunnel 1 (3)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- tunnel 2 (4)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- tunnel 3 (5)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- tunnel 4 (6)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #



# combine all events into one weeks-df
#west_ev3_df, west_ev4_df, 
tunnel_matched <- rbind(tunnel_ev1_df, tunnel_ev2_df, tunnel_ev3_df, tunnel_ev4_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[6]
rackDOC <- tunnel_matched
stg_DOCplot <- plot_tunnel_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[6]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #
site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")


# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_Tunnel_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## make rapid runoff plots with the sample hydrographs

```{r rainfall-runoff_sample_plots}

# create rainfall and stream level plots and save each as an image

# Site 1 ------------------------------- 
# Weeks Lake Outlet 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_wks_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_wks_samp$widths[2:3] <- maxWidth

rr_WksOut_CC <- grid.arrange(gpt_wx_CC, gpt_wks_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_WksOut-CC.png", rr_WksOut_CC)


# Site 2  ------------------------------- 
# Leech River Head (below colfluence of Chris and Weeks) 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_LHead_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_LHead_samp$widths[2:3] <- maxWidth

rr_LHead_CC <- grid.arrange(gpt_wx_CC, gpt_LHead_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_LHead-CC.png", rr_LHead_CC)


# Site 3  ------------------------------- 
# Chris Creek
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], gpt_Crscrk_samp$widths[2:3])
gpt_wx_CC$widths[2:3]  <- maxWidth
gpt_Crscrk_samp$widths[2:3] <- maxWidth

rr_chris_CC <- grid.arrange(gpt_wx_CC, gpt_Crscrk_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_chris-CC.png", rr_chris_CC)


# Site 4   ------------------------------- 
# Cragg Creek 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_Craggcrk_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_Craggcrk_samp$widths[2:3] <- maxWidth

rr_cragg_CC <- grid.arrange(gpt_wx_CC, gpt_Craggcrk_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_cragg-CC.png", rr_cragg_CC)


# Cragg Creek
# with MG-Wx 
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gpt_Craggcrk_samp$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gpt_Craggcrk_samp$widths[2:3] <- maxWidth

rr_cragg_MG <- grid.arrange(gpt_wx_MG, gpt_Craggcrk_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_cragg-MG.png", rr_cragg_MG)


# Site 5  ------------------------------- 
# West Leech River 
# with MG-Wx
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gpt_WestL_samp$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gpt_WestL_samp$widths[2:3] <- maxWidth

rr_WLeech_MG <- grid.arrange(gpt_wx_MG, gpt_WestL_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_WLeech-MG.png", rr_WLeech_MG)


# West Leech River
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_WestL_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_WestL_samp$widths[2:3] <- maxWidth

rr_WLeech_CC <- grid.arrange(gpt_wx_CC, gpt_WestL_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_WLeech-CC.png", rr_WLeech_CC)


# Site 6  ------------------------------- This one isn't lined up properly b/c late installation 
# Leech River Tunnel 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gpt_Tunnel_samp$widths[2:3])
gpt_wx_CC_tunnelspan$widths[2:3] <- maxWidth
gpt_Tunnel_samp$widths[2:3] <- maxWidth

rr_Tunnel_CC <- grid.arrange(gpt_wx_CC_tunnelspan, gpt_Tunnel_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_Tunnel-CC.png", rr_Tunnel_CC)

# Leech River Tunnel 
# with MG-wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gpt_Tunnel_samp$widths[2:3])
gpt_wx_MG_tunnelspan$widths[2:3] <- maxWidth
gpt_Tunnel_samp$widths[2:3] <- maxWidth

rr_Tunnel_MG <- grid.arrange(gpt_wx_MG_tunnelspan, gpt_Tunnel_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_Tunnel-MG.png", rr_Tunnel_MG)

```

## This is tidy and logical code :)
result is 'DOCresults_df'
```{r summary stats}
setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/")
# first, combine all the matched rack results (sample, levels, DOC, sample_DateTime) from each site
racksDOC <- rbind(wks_matched, L.Head_matched, Chriscrk_matched, cragg_matched, west_matched, tunnel_matched) %>%
  mutate(sample_type = "rack") %>% 
  rename(sample_DateTime = sample_time, 
         obs.filling.stage = Fill.Stage_cm,
         racksample_stage = sample_stage) %>% 
  select(-index) 

str(racksDOC)

# next, filter grabs results for DOC and combine with rack results
# grabs data (all sites) 
str(grabs_df)

grabsDOC <- grabs_df %>% 
  filter(analysis == "DOC") %>% 
  select(event = event_capture, 
         site = Site, 
         obs.filling.stage = filling.stage.cm, 
         analysis, 
         Result,
         sample_DateTime = Grab_DateTime 
  ) %>% 
  mutate(sample_type = "Grab",
         racksample_stage = "NA"
  )
# check the structures match
str(grabsDOC)
str(racksDOC)

# merge the two 
DOCresults_df <- rbind(grabsDOC, racksDOC)
str(DOCresults_df)

# add latitude and longitude so you can import this to QGIS
# check names
install_df$Sample_Name
unique(DOCresults_df$site)
site_names

# match lat and long to site names
DOCresults_df <- DOCresults_df %>% 
  mutate(
    latitude = case_when(
      DOCresults_df$site == site_names[1] ~ install_df$Latitude[1],
      DOCresults_df$site == site_names[2] ~ install_df$Latitude[2],
      DOCresults_df$site == site_names[3] ~ install_df$Latitude[3],
      DOCresults_df$site == site_names[4] ~ install_df$Latitude[4],
      DOCresults_df$site == site_names[5] ~ install_df$Latitude[5],
      DOCresults_df$site == site_names[6] ~ install_df$Latitude[6]),
    longitude = case_when(
      DOCresults_df$site == site_names[1] ~ install_df$Longitude[1],
      DOCresults_df$site == site_names[2] ~ install_df$Longitude[2],
      DOCresults_df$site == site_names[3] ~ install_df$Longitude[3],
      DOCresults_df$site == site_names[4] ~ install_df$Longitude[4],
      DOCresults_df$site == site_names[5] ~ install_df$Longitude[5],
      DOCresults_df$site == site_names[6] ~ install_df$Longitude[6])
  )

# check structure
str(DOCresults_df)

# add a column for sampling month
DOCresults_df <- DOCresults_df %>% mutate(sample_month = month(sample_DateTime, label = TRUE))
str(DOCresults_df)

# save a copy as a csv file
write.csv(DOCresults_df, file = "2019-05-26_combined-DOC-results.csv")


# --- --- --- --- #  

# summary stats
str(DOCresults_df)

DOC_stats <- DOCresults_df %>% 
  filter(analysis == "DOC") %>% 
  group_by(sample_month, site) %>% 
  summarize(count = n(), DOCmean = mean(Result), DOCsd = sd(Result), DOCmedian = median(Result), DOCmin = min(Result), DOCmax = max(Result))
head(DOC_stats)
tail(DOC_stats)
str(DOC_stats)

write.csv(DOC_stats, file = "2019-05-26_DOC-SummaryStats.csv")


# summary stats 2.0
str(DOCresults_df)

DOC_stats2 <- DOCresults_df %>% 
  filter(analysis == "DOC") %>% 
  group_by(site) %>% 
  summarize(count = n(), DOCmean = mean(Result), DOCsd = sd(Result), DOCmin = min(Result), DOCmedian = median(Result), DOCmax = max(Result))
head(DOC_stats2)
tail(DOC_stats2)
str(DOC_stats2)

write.csv(DOC_stats2, file = "2019-05-28_DOC-SummaryStats.csv")

# summary stats 3.0
str(DOCresults_df)

DOC_stats3 <- DOCresults_df %>% 
  filter(analysis == "DOC") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(), DOCmean = mean(Result), DOCsd = sd(Result), DOCmin = min(Result), DOCmedian = median(Result), DOCmax = max(Result))
head(DOC_stats3)
tail(DOC_stats3)
str(DOC_stats3)

write.csv(DOC_stats3, file = "2019-05-28_DOC-SummaryStats3.csv")

```

```{r DOC_plots}
setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/")
# check dataframe
str(DOCresults_df)

# get factors in order for tidy calls
# set sample type to be factor
DOCresults_df$sample_type <- as.factor(DOCresults_df$sample_type)
str(DOCresults_df)

# add ordered site factor (headwater to reach)
DOCresults_df$site_f <- factor(DOCresults_df$site, levels=c("Weeks-out", "Chris-crk", "Leech-head", "Cragg-crk", "West-Leech", "Tunnel"))
levels(DOCresults_df$site_f) <- site_captions2  # rename with caption names

# add ordered months (fall 2018 to spring 2019)
DOCresults_df$month_f <- factor(DOCresults_df$sample_month, levels=c("Oct", "Nov", "Dec", "Jan", "Feb", "Mar", "Apr"))

# vector to call text format for plots
textformat <- element_text(size = 14, colour = forWater_colours[4])

# make plots
# boxplot and scatter plot of DOC at all sites over first wet season
DOC_facetB.Plot <- DOCresults_df %>% filter(analysis == "DOC") %>% group_by(sample_type) %>% 
  ggplot(aes(x = month_f, y = Result, fill = sample_type, colour = sample_type)) + geom_boxplot() +
  scale_fill_manual(values = c("white", "white")) + guides(fill = FALSE) +
  geom_point(aes(colour = sample_type), size = 3) +
  scale_color_manual(values = c(forWater_colours[1], forWater_colours[5]),
                     labels = c("Grab", "Rack")) +
  theme_bw() +
  theme(legend.position = "top",
        legend.title = textformat,
        legend.text = textformat,
        axis.title = textformat,
        strip.text = element_text(size = 12, colour = forWater_colours[4]),
        axis.text = textformat) +
  labs(colour = "Sample Type:  ") +
  ylab("Dissolved Organic Carbon (mg/L NPOC)") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~site_f) 
DOC_facetB.Plot

# scatterplot of DOC at all sites over first wet season
# scatter only (better than box plot version I think)
DOC_facet_SPlot <- DOCresults_df %>% filter(analysis == "DOC") %>% group_by(sample_type) %>% 
  ggplot(aes(x = sample_DateTime, y = Result)) +
  geom_point(aes(colour = sample_type), size = 5, alpha = 0.75) +  # partially transparent points with alpha <1
  scale_color_manual(values=c(forWater_colours[4], forWater_colours[5]),
                     labels = c("Grab", "Rack")) +
  theme_bw() +
  theme(legend.position = "top",
        legend.title = textformat,
        legend.text = textformat,
        axis.title = textformat,
        strip.text = element_text(size = 12, colour = forWater_colours[4]),
        axis.text = textformat) +
  labs(colour = "Sample Type:  ") +
  ylab("DOC (mg/L NPOC)") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~site_f) 
DOC_facet_SPlot

ggsave(filename = "DOC_facet-scatterPlot_allSites.png", DOC_facet_SPlot)


# scatterplot of DOC at each site
# set it up and run a loop
# use vectors defined in chunk "tidy-names"

for (i in seq_along(site_names)) {
  g <- DOCresults_df %>% filter(analysis == "DOC" & site == site_names[i]) %>% group_by(sample_type) %>% 
    ggplot(aes(x = sample_DateTime, y = Result)) + 
    geom_point(aes(colour = sample_type), size = 5) +
    theme_bw() +
    theme(plot.caption = textformat,
          legend.position = c(0.8, 0.8),
          legend.text = textformat,
          legend.title = textformat,
          axis.text = textformat,
          axis.title = textformat) +
    labs(colour = "Sample Type") +
    #caption = paste("DOC over 2018-2019 wet season at ", site_captions[i])) +
    scale_color_manual(values=c(forWater_colours[4], forWater_colours[5]),
                       labels = c("Grab", "Rack")) +
    ylab("NPOC (mg/L DOC)") + 
    xlab("")
  
  ggsave(filename = paste("DOC_scatterPlot_",i,"_",site_names[i],".png"),
         width = 7.29, height = 4.5, units = "in")
}

# YAY that worked!!!! 
# Go back to your janky mess of plots above (when you have time) and fix that code up to be cool like this!!! :)

```


# 2019-05-27 
Retrying hydrograph plots with sample dots
this didn't work - keep trying
The problem was that I couldn't call the hydrograph plot I saved to a list to add it to a new ggplot() with geom_points
But I think I should be able to...


```{r chemograph_inprogress}



# plot_wks_stg, plot_L.head_stg, plot_chris_stg, plot_cragg_stg, plot_west_stg, plot_tunnel_stg

# try this

# assign rack + grab subset
rack_ss <- filter(DOCresults_df, analysis == "DOC" & sample_type == "rack")
grab_ss <- filter(DOCresults_df, analysis == "DOC" & sample_type == "Grab")

c <- plot_wks_stg +
  geom_point(data = rack_ss, aes(x = sample_DateTime, y = racksample_stage), colour = forWater_colours[4], size = 5) +
  geom_point(data = grab_ss, aes(x = sample_DateTime, y = obs.filling.stage), colour = forWater_colours[4], size = 5)
c 

## still not working

# old 
# --- INPUTS --- #
Site.Name <- site_names[1]
rackDOC <- wks_matched
stg_DOCplot <- plot_wks_stg
# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[1]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- get fancy --- #
c <- stg_DOCplot +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = forWater_colours[4], show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = forWater_colours[5], show.legend = FALSE) 
c 
# --- --- --- --- # end old, start new

# new

# use results df
str(DOCresults_df)
# call on 'stagePlots_list' and 'site_names' to access hydrographs and names (1:6)


# --- INPUTS --- #
Site.Name <- site_names[1]
DOCdf <- DOCresults_df %>% filter(site == site_names[1] & analysis == "DOC")
hydrograph <- stagePlots_list[1]

b <- DOCresults_df %>% filter(site == site_names[1] & analysis == "DOC") %>% 
  ggplot(aes(x = sample_DateTime, y = racksample_stage)) +
  geom_point(aes(colour = sample_type), size = 4) 
b 

# stage-plot + geom_point(sample_data)

# --- diff code example
# scatterplot of DOC at each site
# set it up and run a loop
# use vectors defined in chunk "tidy-names"

for (i in seq_along(site_names)) {
  g <- DOCresults_df %>% filter(analysis == "DOC" & site == site_names[i]) %>% group_by(sample_type) %>% 
    ggplot(aes(x = sample_DateTime, y = Result)) + 
    geom_point(aes(colour = sample_type), size = 5) +
    theme_bw() +
    theme(plot.caption = textformat,
          legend.position = c(0.8, 0.8),
          legend.text = textformat,
          legend.title = textformat,
          axis.text = textformat,
          axis.title = textformat) +
    labs(colour = "Sample Type",
         caption = paste("DOC over 2018-2019 wet season at ", site_captions[i])) +
    scale_color_manual(values=c(forWater_colours[4], forWater_colours[5]),
                       labels = c("Grab", "Rack")) +
    ylab("NPOC (mg/L DOC)") + 
    xlab("")
  
  ggsave(filename = paste("DOC_scatterPlot_",i,"_",site_names[i],".png"), g)
}

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #
```


# fix up this janky code:

```{r JankyShit_fix_gtables}

## ------- you got this far in jank repair ---------##
# set up for combo plot (rainfall-streamflow)
# save each stage plot in a list to call later
stg_gtable_list <- vector("list", 6)

for (i in seq_along(stagePlots_list)) {
  stg_gtable_list[[i]] <- ggplot_gtable(ggplot_build(stagePlots_list[i]))
}

# rename the list elements of stage plot ggplot gtables
names(stg_gtable_list) <- paste(site_names,"gtable")



# ****** YOU CANT GET RID OF THIS BECAUSE THE JANKY CHEMOGRAPHS PULL ON THESE HYDROGRAPHS - UGH *** ######
# don't use this janky shit 
# BUT -- make sure you got the the ggplot gtables set up properly in your loop (to build rapid-runoff plots (but make them better, the rain bars are too thin to see))

#### -- janky shit Below --- ####
# Janky but it works

# chose the colour you want
forWater_col <- forWater_colours[3]

# --- Weeks Lake Outlet --- #
plot_wks_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[1]), 
                       aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[1])
plot_wks_stg 

# set up for combo plot (rainfall-streamflow)
gtb_wks_stg <- ggplot_gtable(ggplot_build(plot_wks_stg))


# --- Leech River Head --- #
plot_L.head_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[2]), 
                          aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[2])
plot_L.head_stg 

# set up for combo plot (rainfall-streamflow)
gtb_L.head_stg <- ggplot_gtable(ggplot_build(plot_L.head_stg))


# --- Chris Creek --- #
plot_chris_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[3]), 
                         aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[3])
plot_chris_stg 

# set up for combo plot (rainfall-streamflow)
gtb_chris_stg <- ggplot_gtable(ggplot_build(plot_chris_stg))

## note data gap 2018-11-07 -- date of re-build. 
# Original installation by Bill Floyd was at an angle, Nov 7 Stew and Hannah re-built the station to be vertical and match other designs. 
# In the original structure, the sensor was laying against the inside of the stilling well (possibly resulting in a positive bias)
# the angled stilling well may have extended the offset (if the stilling well wasn't against the streambed). 
# all bottle heights for the pre and post period are matched to the stilling well, so they should still line up.


# --- Cragg Creek --- #
plot_cragg_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[4]), 
                         aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[4])
plot_cragg_stg 

# set up for combo plot (rainfall-streamflow)
gtb_cragg_stg <- ggplot_gtable(ggplot_build(plot_cragg_stg))


# --- West Leech River (above the confluence with Leech mainstem) --- #
plot_west_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[5]), 
                        aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[5])
plot_west_stg 

# set up for combo plot (rainfall-streamflow)
gtb_west_stg <- ggplot_gtable(ggplot_build(plot_west_stg))



# --- Tunnel --- #
plot_tunnel_stg <- ggplot(filter(stage.event_dfSS6, site == site_names[6]), 
                          aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(#axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    text = element_text(colour = forWater_colours[4]),
    axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[6])
plot_tunnel_stg 

# set up for combo plot (rainfall-streamflow)
gtb_tunnel_stg <- ggplot_gtable(ggplot_build(plot_tunnel_stg))


```

Create rainfall runoff plots

```{r rainfall-runoff_plots_janky}
# create rainfall and stream level plots and save each as an image

# Site 1 ------------------------------- 
# Weeks Lake Outlet 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_wks_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_wks_stg$widths[2:3] <- maxWidth

rr_WksOut_CC <- grid.arrange(gpt_wx_CC, gtb_wks_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_WksOut-CC.png", rr_WksOut_CC)


# Site 2  ------------------------------- 
# Leech River Head (below colfluence of Chris and Weeks) 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_L.head_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_L.head_stg$widths[2:3] <- maxWidth

rr_LHead_CC <- grid.arrange(gpt_wx_CC, gtb_L.head_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_LHead-CC.png", rr_LHead_CC)


# Site 3  ------------------------------- 
# Chris Creek
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], gtb_chris_stg$widths[2:3])
gpt_wx_CC$widths[2:3]  <- maxWidth
gtb_chris_stg$widths[2:3] <- maxWidth

rr_chris_CC <- grid.arrange(gpt_wx_CC, gtb_chris_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_chris-CC.png", rr_chris_CC)


# Site 4   ------------------------------- 
# Cragg Creek 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_cragg_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_cragg_stg$widths[2:3] <- maxWidth

rr_cragg_CC <- grid.arrange(gpt_wx_CC, gtb_cragg_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_cragg-CC.png", rr_cragg_CC)


# Cragg Creek
# with MG-Wx 
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gtb_cragg_stg$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gtb_cragg_stg$widths[2:3] <- maxWidth

rr_cragg_MG <- grid.arrange(gpt_wx_MG, gtb_cragg_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_cragg-MG.png", rr_cragg_MG)


# Site 5  ------------------------------- 
# West Leech River 
# with MG-Wx
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gtb_west_stg$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gtb_west_stg$widths[2:3] <- maxWidth

rr_WLeech_MG <- grid.arrange(gpt_wx_MG, gtb_west_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_WLeech-MG.png", rr_WLeech_MG)


# West Leech River
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_west_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_west_stg$widths[2:3] <- maxWidth

rr_WLeech_CC <- grid.arrange(gpt_wx_CC, gtb_west_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_WLeech-CC.png", rr_WLeech_CC)


# Site 6  ------------------------------- This one isn't lined up properly b/c late installation 
# Leech River Tunnel 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gtb_tunnel_stg$widths[2:3])
gpt_wx_CC_tunnelspan$widths[2:3] <- maxWidth
gtb_tunnel_stg$widths[2:3] <- maxWidth

rr_Tunnel_CC <- grid.arrange(gpt_wx_CC_tunnelspan, gtb_tunnel_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_Tunnel-CC.png", rr_Tunnel_CC)

# Leech River Tunnel 
# with MG-wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gtb_tunnel_stg$widths[2:3])
gpt_wx_MG_tunnelspan$widths[2:3] <- maxWidth
gtb_tunnel_stg$widths[2:3] <- maxWidth

rr_Tunnel_MG <- grid.arrange(gpt_wx_MG_tunnelspan, gtb_tunnel_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_Tunnel-MG.png", rr_Tunnel_MG)

```
