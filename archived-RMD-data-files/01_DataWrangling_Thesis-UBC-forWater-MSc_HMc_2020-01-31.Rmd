---
title: "Reproducible data analysis: thesis data wrangling"
subtitle: "Pacific Maritime forWater Masters Project (NSERC forWater)"
author: "Hannah J McSorley"
date: "2020-02-03"
output:
  word_document:
    toc: true
    reference_docx: word-styles-document_thesis.docx
bibliography: library.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

If needed, install required packages:
```
install.packages("tidyverse")
install.packages("knitr")      
 
```
Note that the tidyverse includes a suite of useful packages, such as:

*readr: for read_csv()
*dplyr: for MANY functions, including mutate() and piping,
*tidyr: for unnest()
*purrr: for map(), reduce()

```{r packages, include = FALSE}

# load packages
suppressPackageStartupMessages(library(tidyverse))  # includes: dplyr, ggplot2, purrr, readr, forcats, lubridate
suppressPackageStartupMessages(library(knitr))      # tidy tables
suppressPackageStartupMessages(library(lubridate))  # dates and times

```


# Naming

Create vectors to easily call installation site names from, rather than typing words (efficient and consistent for updating and calling).

```{r tidy-names}

# create a vector of site captions
# NOTE: The site "Weeks Outlet" is being called "Weeks Main Creek"
# match the order of installation from headwaters to mouth/diversion
site_captions <- c("Weeks Main Creek", 
                   "Chris Creek", 
                   "Leech River Head", 
                   "Cragg Creek", 
                   "West Leech River", 
                   "Leech River Tunnel")

# vector for site names (used in data sets variable "site")
(site_names <- c("Weeks-out", "Leech-head", "Chris-crk", "Cragg-crk", "West-Leech", "Tunnel"))

# time-zone note: all loggers record in standard time (no daylight savings shift)
# tz+/- number where the number is hours the timezone is *behind* UTC...
# So UTC-8 means a timezone abbreviated "UTC" that is ???8 hours behind the real UTC, or UTC + 8 hours

TZ <- "Etc/GMT+8"

# use forWater defined colours (hexadecimal codes) for plots
# all colours defined by forWater admin, except 'MyOrange' which I made
forWater_colours <- c(MainBlue = "#09A4D2", 
                      MainGreen = "#668536", 
                      AccentBlue = "#5B99CC", 
                      DarkGrey = "#3B3838", 
                      MyOrange = "#f4AB0E")

# colour-blind friendly pallet with grey (no black)
cbPalette <- c(grey = "#999999", 
               orange = "#E69F00", 
               lightblue = "#56B4E9", 
               green = "#009E73", 
               yellow = "#F0E442", 
               darkblue = "#0072B2", 
               red = "#D55E00", 
               pink = "#CC79A7")
```

# Tracking field activity

Multiple trips were taken to the field (Leech River watershed) and the trip number and/or date were used to organize files for sample identification, analytical results, joining dataframes and matching sample data to field-based data logger intervals.

This code brings in data that documents installation locations field trip tracking.

```{r tracking}

# read in file used to track trips
trip_df <- read.csv(file = "R-inputs_UBC-forWater-MSc_HMc/Leech-FieldTrip-tracking_forWater-MSc_HMc.csv", 
                    header = TRUE)
str(trip_df)

# adjust format of dates
trip_df <- trip_df %>%
  mutate(trip = as_factor(trip),
         trip.start = lubridate::ymd(trip.start, tz = TZ),
         trip.end = lubridate::ymd(trip.end, tz = TZ),
         analysis_date_shimadzu = lubridate::ymd(analysis_date_shimadzu, tz = TZ),
         analysis_date_scan = lubridate::ymd(analysis_date_scan, tz = TZ),
         note = as.character(note))
str(trip_df)

# site installation locations
install_df <- read.csv(file = "R-inputs_UBC-forWater-MSc_HMc/Leech-installation-locations_forWater-MSc_HMc.csv",
                       header = TRUE)
str(install_df)

install_df <- install_df %>%
  mutate(Site_Number = as_factor(Site_Number))

str(install_df)
```

# Water sample data and analytic results

Water samples were collected and transported via coolers (on ice) to UBC's EcoHydrology Lab for analysis of dissolved organic carbon (DOC) concentrations and indicators of NOM character. 

For quantification of DOC, samples were filtered with 0.45-micron PES filters; acidified to bring pH below 2; and analyzed for non-purgeable organic carbon (NPOC) via High-Temperature Combustion Method (5310-B) on a Shimadzu TOC-V [@StdMet2000].

Spectral properties of sample NOM were analyzed using a "Spectro::lyser" spectrophotometer (S::can, Vienna, Austria) which measures turbidity and the chromophoric portion of dissolved organic matter to estimate concentrations of total organic carbon (TOC), DOC as well as nitrate-nitrogen (NO^-3^-N). Samples were also measured for phosphate concentration using a field portable colouremetric test kit (HACH); each sample had phosphate concentrations below detectable limits (XXXXXX mg/L).   

Based on full scan data from the Spectrolyser (250-700nm), several indices of NOM character were determined. 
- SUVA254 --- Specific UV absorbance at 254nm is the ratio of UV absorption (sspectral absorbance coeffeicient, SAC, m^-1^) at 254nm normalized to DOC concentration (mgL^-1^). SUVA254 correlates strongly with DOM aromaticity [@Helms2008].
It was been shown that UV spectral slopes are useful semiquantitative indicators for assessing NOM molecular weights [@Helms2008]. 
- Spectral slopes 1 & 2 --- the slope of spectral intensity over the shorter wavelength range of 275-295nm (1) and longer wavelength range of 350-400nm (2). 
- Slope Ratio --- The ratio of spectral slopes 1 and 2, correlates well with CDOM molecular weight [@Helms2008]


## DOC: Shimadzu TOC-V for DOC concentrations (as mg/L NPOC)

Water samples were filtered (0.45-micron PES filters) and acidified to bring pH below 2, then sparged with ultra-pure hydrocarbon-free air to drive off inorganic carbon. Following sparging, the sample was combusted to convert all organic carbon to carbon dioxide which was measured with a non-dispersive infrared gas detector to quanitify the DOC content of the sample. This method representd the most direct method of measuring DOC, as all natural organic carbon in the sample is measured. However, very small volatile organic carbon compounds would be removed in the sparging process. Because most NOM compounds are of higher molecular weight, it is unlikely that NOM DOC analytes would be removed [@StdMet2000].

```{r TOC-V samples and analytical results}

## Shimadzu TOC-V samples and results
# sample IDs and results from analysis of DOC (as NPOC)
# three part data munge
# 1. bring in sample tracking data (vial number, name, etc), format appropriately
# 2. bring in results data (from instrument), format appropriately
# 3. bring them together as meanigful results data (sample IDs + results)


# 1. ------------ SAMPLES ------------ #

# create a data frame of all sample ID data
# for all samples analyzed on Shimadzu TOC-V (UBC ESB 3062)

# input samples directory path
sampledata_path_TOCV <-  "R-inputs_UBC-forWater-MSc_HMc/shimadzu/samples_TOC/"
# read in all the files
shimadzu_samples <- list.files(path = sampledata_path_TOCV, pattern = "*.csv") %>% 
  purrr::map(~ read_csv(file.path(sampledata_path_TOCV, .), skip = 4, col_names = TRUE)) %>% 
  reduce(rbind)
# check structure
str(shimadzu_samples)

# correct the sructure/format
shimadzu_samples <- shimadzu_samples %>% 
  dplyr::transmute(vial = as.numeric(vial),
                   site = forcats::as_factor(site),
                   sample_type = forcats::as_factor(`sample-type`),
                   sample = forcats::as_factor(sample),
                   dt_sampled = head(lubridate::ymd_hms(`date-time_sampled`, frac = TRUE, tz = TZ, truncated = 3), -1),
                   fillStage_cm = as.numeric(`fill-stage`),
                   analysis = as_factor(analysis),
                   trip = as_factor(trip))
str(shimadzu_samples)
head(shimadzu_samples)

#check that there are 22 trips (see 'trip_df')
levels(shimadzu_samples$trip)

# check which sites are included
levels(shimadzu_samples$site)

# fix naming errors for sites
shimadzu_samples$site <- shimadzu_samples$site %>% 
  plyr::revalue(c(
    "Chris" = "Chris-crk",
    "Lower-Leech-blw-confl" = "Leech-downstreamconf",
    "Leech-main-confl" = "Leech-downstreamconf",
    "J-Trib" = "West-Jordan",
    "West-jordan" = "West-Jordan",
    "W.Jarvis" = "Jarvis",
    "Rithet-N" = "Rithet",
    "Judge" = "Judge-crk"
  ))
# check sites again
levels(shimadzu_samples$site)

length(levels(shimadzu_samples$site))
#---- samples were collected from a total of 30 sites, 6 were permanent installations ---- #



# 2. ------------ RESULTS ------------ # 

# Note: annoying TOC-V export issue
# data files for analysis of trips 1-8 have 19 columns, while trips 9-22 have 18 columns
# import as two separate blocks (from two subdirectories), then alter, then merge

# assign column names = col.names():
nineteencolumns <- c("Type",	"Anal.",	"Sample Name",	"Sample ID",	"Origin",	"Cal. Curve",	"Manual Dilution	Notes",	"Date", "Time", "AM/PM",	"Spl. No.", "Inj. No.", "Analysis(Inj.)",	"Area",	"Mean Area",	"Conc.",	"Result",	"Excluded",	"Inj. Vol.")

# no "mean area" variable
eighteencolumns <- c("Type",	"Anal.",	"Sample Name",	"Sample ID",	"Origin",	"Cal. Curve",	"Manual Dilution	Notes",	"Date", "Time", "AM/PM",	"Spl. No.", "Inj. No.", "Analysis(Inj.)",	"Area",	"Conc.",	"Result",	"Excluded",	"Inj. Vol.")

## read in files and add a column indicating trip #, based on source file name

## directory 1 (trips 2-8) with 19 columns
# input results directory path-1
resultsdata_path1_TOCV <-  "R-inputs_UBC-forWater-MSc_HMc/shimadzu/results_TOC/block1_19columns/"
# read in all the files (trips 2-8)
shimadzu_1 <- list.files(path = resultsdata_path1_TOCV, pattern = "*.txt") %>% 
  set_names(str_extract(., "([a-z]{4,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(file = file.path(resultsdata_path1_TOCV, .), 
                              row.names = NULL, skip = 14, header = FALSE, col.names = nineteencolumns), .id = "source") %>% 
  select(-Mean.Area)
# check that there are 19 columns now (minus "Mean.Area")
str(shimadzu_1)


## directory 2 (trips 9-22) with 18 columns
# input results directory path-2
resultsdata_path2_TOCV <-  "R-inputs_UBC-forWater-MSc_HMc/shimadzu/results_TOC/block2_18columns/"
# read in all the files (trips 9 -22)
shimadzu_2 <- list.files(path = resultsdata_path2_TOCV, pattern = "*.txt") %>% 
  set_names(str_extract(., "([a-z]{4,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(file = file.path(resultsdata_path2_TOCV, .), 
                              row.names = NULL, skip = 14, header = FALSE, col.names = eighteencolumns), .id = "source") 

# check structure
str(shimadzu_2)

# combine the two blocks into one shimadzu results dataframe
shimadzu_results <- bind_rows(shimadzu_1, shimadzu_2)
str(shimadzu_results)

# ---- Alpha-numeric extraction function ---- #
# from http://stla.github.io/stlapblog/posts/Numextract.html
NumberXtract <- function(alphnum){
  unlist(regmatches(alphnum, gregexpr("[[:digit:]]+\\.*[[:digit:]]*", alphnum)))
}

## pull out numbers from alphanumerics & create:
# factor variable for trip numbers   (from 'source')
# numeric variable for NPOC-results  (from 'Result')
# factor variable for vial number    (from 'Sample.Name')
shimadzu_results <- shimadzu_results %>% 
  mutate(trip = as_factor(NumberXtract(source)),
         NPOC_mgL = as.numeric(NumberXtract(Result)),
         vial = as.numeric(NumberXtract(Sample.Name)))
# check it out
str(shimadzu_results)



# 3. ------------ SHIMADZU ANALYSIS RESULTS ------------ # 

# combine 'shimadzu_samples' with 'shimadzu_results'
TOCV_results <- shimadzu_results %>% 
  select(trip, vial, NPOC_mgL) %>% 
  group_by(trip, vial) %>% 
  summarize(NPOC_ppm = mean(NPOC_mgL)) %>% 
  right_join(shimadzu_samples, by = c("trip" = "trip", "vial" = "vial")) %>% 
  ungroup() 


# check lengths match
nrow(TOCV_results) == nrow(shimadzu_samples)
# check head
head(TOCV_results)
# check structure
str(TOCV_results)


# what about trip 21, which was actually in trip 20 (Cragg on 2019-12-19)
TOCV_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# update vials 19-21 to be "trip 21", for later matching with Odyssey stage data
TOCV_results <- TOCV_results %>% 
  mutate(trip = case_when(trip == "20" & site =="Cragg-crk" & (vial == 19 | vial == 20 | vial == 21) ~ "21",
                          TRUE ~ trip))
TOCV_results$NPOC_ppm = as.numeric(TOCV_results$NPOC_ppm)
# check to make sure it's updated:
TOCV_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# good!

```

## Spectrolyser proxy analysis results (CDOM equivalent DOC & TOC, NO~3~^-^, SAC~254~, SAC~436~)

The Spectrolyser is a full scan UV-VIS spectrophotometer. It uses a stable global calibration file to calculate equivalent concentrations of DOC, TOC, nitrate-nitrogen, and turbidity.

### Concentrations by proxy (UV-VIS)

The .par files generated by the spectrolyser contain results of equivalent concentrations based on spectral analysis and the internal global calibration file. A caveat to interpretting these results is that in order for NOM to be detected by UV-Vis absorption the molecules must absorb UV or Visible light (not all molecules do). UV-Vis absorption occurs only if the applied energy (light) can be absorbed by the molecule; in general, this required the presence of aromatic bonds (conjugated pi-bond systems in the molecule, a chromophore). Therefore, UV-Vis absorption is proportional to the molecule's degree of aromaticity.    

```{r Spectrolyser samples and .par results}

## Spectrolyser samples and results
# sample IDs and results from analysis of optical properties
# multi-part data munge
# 1. bring in sample tracking data, format appropriately
# 2. bring in results data, format appropriately
# 3. bring them together as meanigful results data
# 4. some analyses were run in triplicate -- summarize as sample means


# 1. ------------ SAMPLES ------------ #

# create a data frame of all sample ID data
# for all samples analyzed on Scan Spectrolyser (UBC ESB 3062)

# input samples directory path
sampledata_path_scan <-  "R-inputs_UBC-forWater-MSc_HMc/spectrolyser/samples_scan/"
# read in all the files
spectrolyser_samples <- list.files(path = sampledata_path_scan, pattern = "*.csv") %>% 
  purrr::map(~ read_csv(file.path(sampledata_path_scan, .), skip = 4, col_names = TRUE)) %>% 
  reduce(rbind)

# check structure
str(spectrolyser_samples)

# correct the sructure/format
spectrolyser_samples <- spectrolyser_samples %>% 
  dplyr::transmute(measurement = as.numeric(measurement),
                   site = forcats::as_factor(site),
                   sample_type = forcats::as_factor(`sample-type`),
                   sample = forcats::as_factor(sample),
                   dt_sampled = head(lubridate::ymd_hms(`date-time_sampled`, 
                                                        frac = TRUE, tz = TZ, 
                                                        truncated = 3), -1),
                   fillStage_cm = as.numeric(`fill-stage`),
                   trip = as_factor(trip))
str(spectrolyser_samples)
head(spectrolyser_samples)

#check which trips were included
levels(spectrolyser_samples$trip)

# check which sites are included
levels(spectrolyser_samples$site)

# fix naming errors for sites
spectrolyser_samples$site <- spectrolyser_samples$site %>% 
  plyr::revalue(c(
    "Chris" = "Chris-crk",
    "Lower-Leech-blw-confl" = "Leech-downstreamconf",
    "Leech-main-confl" = "Leech-downstreamconf",
    "J-Trib" = "West-Jordan",
    "West-jordan" = "West-Jordan",
    "W.Jarvis" = "Jarvis",
    "Rithet-N" = "Rithet",
    "Judge" = "Judge-crk"
  ))
# check sites again
levels(spectrolyser_samples$site)

length(levels(spectrolyser_samples$site))
#---- samples were collected from a total of 31 sites (including lab), 6 were permanent field installations ---- #


# 2. ------------ RESULTS ------------ # 

# assign column names = col.names():
scancolumns <- c("Date", "Time",	"Status",	"Turbid.FTUeq",	"NULLTurbid",	"NO3-Neq_ppm",	"NULLNO3-Neq",	"TOCeq_ppm",	"NULLTOCeq", "DOCeq_ppm", "NULLDOCeq", "SAC254_Abs/m", "SAC254_0", "SAC436_Abs/m",	"SAC436_0",	"254-436_Abs/m", "254-436_0",	"analogIN_", "analogIN_0")

## read in files and add a column indicating trip #, based on source file name
resultsdata_path_scan <-  "R-inputs_UBC-forWater-MSc_HMc/spectrolyser/results_scan/"
# read in all the files
spectrolyser_results <- list.files(path = resultsdata_path_scan) %>% 
  set_names(str_extract(., "([A-Za-z]{3,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(file = file.path(resultsdata_path_scan, .), 
                              skip = 2, header = FALSE, col.names = scancolumns), .id = "source") 

# check it out
#str(spectrolyser_results)

# pull out numbers from alphanumeric 'source' to create factor variable 'trip'
# use function 'NumberXtract()'
# add measurement numbers to each trip group (analysis order)
# drop null variables for tidiness
spectrolyser_results <- spectrolyser_results %>% 
  mutate(trip = as_factor(NumberXtract(source))) %>% 
  group_by(trip) %>% 
  mutate(measurement = row_number()) %>% 
  ungroup()

# check it out
#str(spectrolyser_results)

unique(spectrolyser_results$trip)

nrow(spectrolyser_results) == nrow(spectrolyser_samples)


# 3. ------------ SPECTROLYSER ANALYSIS RESULTS ------------ # 

# combine 'spectrolyser_samples' with 'spectrolyser_results'
SCAN_results <- spectrolyser_results %>% 
  select(-c(Date, Time, Status, NULLTurbid, NULLNO3.Neq, NULLTOCeq, NULLDOCeq, SAC254_0, SAC436_0, X254.436_Abs.m, X254.436_0, analogIN_, analogIN_0)) %>% 
  right_join(spectrolyser_samples, by = c("trip" = "trip", "measurement" = "measurement")) %>% 
  ungroup()

# check lengths match
nrow(SCAN_results) == nrow(spectrolyser_samples)
# check head
head(SCAN_results)
# check structure
#str(SCAN_results)


# what about trip 21, which was actually in trip 20 (Cragg on 2019-12-19)
SCAN_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# update vials 19-21 to be "trip 21", for later matching with Odyssey stage data
SCAN_results <- SCAN_results %>% 
  mutate(trip = case_when(trip == "20" & site =="Cragg-crk" & (measurement == 19 | measurement == 20 | measurement == 21) ~ "21",
                          TRUE ~ trip))

# check to make sure it's updated:
SCAN_results %>% filter(trip == "20" | trip == "21", site =="Cragg-crk") 

# good!

# 4. -------------  triplicates!  ------------- 
# several analyses measured the same sample in triplicate to assess intrument precision
# trips c(10, 11, 12, 13, 15, 16)
# these measurements are counted as unique samples (though they are not)
# create an average for those measured in triplicate 
# split / apply / combine
SCAN_results <- SCAN_results %>%  
  group_by(trip, site, sample_type, sample, dt_sampled, fillStage_cm) %>% 
  summarise(Turbid.FTUeq = mean(Turbid.FTUeq),
            NO3.Neq_ppm = mean(NO3.Neq_ppm),
            TOCeq_ppm = mean(TOCeq_ppm), 
            DOCeq_ppm = mean(DOCeq_ppm),
            SAC254_Abs.m = mean(SAC254_Abs.m),
            SAC436_Abs.m = mean(SAC436_Abs.m)) %>% 
  ungroup()

```

### Full scan spectrophotometry (spectral fingerprints)

The Spectrolyser outputs a fingerprint file containing absorbance values at all of the wavelengths monitored. These .fp files can provide information about NOM structure. For example, the ratio of the slope between 275-295nm and the slope from 350-400nm ("slope ratio (SR)"), commonly used as an indicator of molecular weight.

```{r Spectrolyser samples and .fp results}

## Spectrolyser samples and fingerprints (fp)
# sample IDs and fullscans 
# multi-part data munge
# 1. bring in sample tracking data, format appropriately
# 2. bring in results data, format appropriately
# 3. bring them together as meanigful results data
# 4. some analyses were run in triplicate -- summarize as sample means


# 1. ------------ SAMPLES ------------ #
# these data have already been loaded
# "spectrtolyser_samples"

# 2. ------------ FULLSCAN RESULTS ------------ # 

# assign column names
fullscan_colnames <- c("Date", "Time", "Status", paste("Abs", seq(200.0, 750.0, by = 2.5)))
## read in files and add a column indicating trip #, based on source file name
resultsdata_path_fullscan <-  "R-inputs_UBC-forWater-MSc_HMc/spectrolyser/fingerprints_scan_fp/"
# read in all the files
spectrolyser_fullscan <- list.files(path = resultsdata_path_fullscan) %>% 
  set_names(str_extract(., "([A-Za-z]{3,}+[0-9]*+)")) %>%
  purrr::map_dfr(~ read.table(file = file.path(resultsdata_path_fullscan, .), 
                              skip = 2, header = FALSE, col.names = fullscan_colnames), .id = "source") 

# check it out
# str(spectrolyser_fullscan)

# pull out numbers from alphanumeric 'source' to create factor variable 'trip'
# use function 'NumberXtract()'
# add measurement numbers to each trip group (analysis order)
# drop null variables for tidiness
spectrolyser_fullscan <- spectrolyser_fullscan %>% 
  mutate(trip = as_factor(NumberXtract(source))) %>% 
  group_by(trip) %>% 
  mutate(measurement = row_number()) %>% 
  ungroup()

# check it out
# str(spectrolyser_fullscan)

unique(spectrolyser_fullscan$trip)

nrow(spectrolyser_fullscan) == nrow(spectrolyser_samples)


# 3. ------------ SPECTROLYSER FULLSCAN RESULTS ------------ # 
# str(spectrolyser_fullscan)
# str(spectrolyser_samples)

# combine 'spectrolyser_samples' with 'spectrolyser_fullscan'
FULLSCAN_results <- right_join(spectrolyser_fullscan, spectrolyser_samples, 
                               by = c("trip" = "trip", "measurement" = "measurement")) %>% 
  ungroup()

# check lengths match
nrow(FULLSCAN_results) == nrow(spectrolyser_samples)
# check columnnames
colnames(FULLSCAN_results)

# for Cragg Creek, trip 21 was actually in trip 20 (Cragg on 2019-12-19)
# update measurements c(19:21) to be "trip 21", for later matching with Odyssey stage data
FULLSCAN_results <- FULLSCAN_results %>% 
  mutate(trip = case_when(trip == "20" & 
                            site =="Cragg-crk" & 
                            (measurement == 19 | measurement == 20 | measurement == 21) 
                          ~ "21", 
                          TRUE ~ trip))
# check
unique(FULLSCAN_results$trip)
# good!

# 4. -------------  triplicates!  ------------- 
# several analyses measured the same sample in triplicate to assess intrument precision
# trips c(10, 11, 12, 13, 15, 16)
# these measurements are counted as unique samples (though they are not)
# create an average for those measured in triplicate 
# split / apply / combine
FULLSCAN_results <- FULLSCAN_results %>% 
  select(-c("source", "Date", "Time", "Status")) %>% 
  group_by(trip, site, sample_type, sample, dt_sampled, fillStage_cm) %>% 
  summarise_all(list(~mean(.))) %>% 
  ungroup()

```

## Data collation

* Join results files from Shimadzu and Spectrolyser (direct and indirect measures of DOC, plus full scan data)
* Bringing together the results from both the Shimadzu and Spectrolyser. 
* Join data frames and create additional variables to help classify the data for plotting. 

```{r compile results of lab analyses}

# join the results files from the Shimadzu TOC-V and Spectrolyser
#str(TOCV_results)   # shimadzu NPOC results (direct measure of DOC)
#str(SCAN_results)   # spectrolyser indirect results of DOC (UV-Vis)
#str(FULLSCAN_results)  # spectrolyser full scan 250-700nm

# both have c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm")
# the variables measured are: NPOC_ppm, Turbid.FTUeq, NO3.Neq_ppm, TOCeq_ppm, DOCeq_ppm, SAC254_Abs.m, SAC436_Abs.m
# the instrument was TOCV or SCAN

# --- WIDE SUMMARY DF --- # 
sampleresults <- full_join(TOCV_results, SCAN_results, 
                           by = c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm")) %>% 
  mutate(site = as_factor(site),
         sample_type = as_factor(sample_type),
         sample = as_factor(sample),
         analysis = factor(analysis, exclude = "TOC"),  # drop "TOC"
         analysis = factor(analysis),   # drop residual NA from removing "TOC"
         site = factor(site, exclude = "Mystery-bottle"),  # drop "mystery bottle"
         site = factor(site)) %>%  # drop residual NA from removing "mystery bottle"
  select(-c(vial))  # drop unneccesary variables

#%>% removed this -- get fp right before joining 
#  full_join(FULLSCAN_results, by = c("trip", "site", "sample_type", "sample", "dt_sampled", "fillStage_cm")) %>% 
  

# check it out
#str(sampleresults)

# add a column of "trip_end" to have a date for each trip (plotting)
## this is a terrible method
## there must be a way to use a loop/map/apply (don't know how yet)
# sampleresults_wide %>% 
#  mutate(trip_end = 
#    for (i in seq(1:22)) {case_when(
#        trip == "i" ~ trip_df$trip.end[i])
#        })
sampleresults <- sampleresults %>% 
  mutate(trip_end = case_when(  
    trip == "1" ~ trip_df$trip.end[1],
    trip == "2" ~ trip_df$trip.end[2],
    trip == "3" ~ trip_df$trip.end[3],
    trip == "4" ~ trip_df$trip.end[4],
    trip == "5" ~ trip_df$trip.end[5],
    trip == "6" ~ trip_df$trip.end[6],
    trip == "7" ~ trip_df$trip.end[7],
    trip == "8" ~ trip_df$trip.end[8],
    trip == "9" ~ trip_df$trip.end[9],
    trip == "10" ~ trip_df$trip.end[10],
    trip == "11" ~ trip_df$trip.end[11],
    trip == "12" ~ trip_df$trip.end[12],
    trip == "13" ~ trip_df$trip.end[13],
    trip == "14" ~ trip_df$trip.end[14],
    trip == "15" ~ trip_df$trip.end[15],
    trip == "16" ~ trip_df$trip.end[16],
    trip == "17" ~ trip_df$trip.end[17],
    trip == "18" ~ trip_df$trip.end[18],
    trip == "19" ~ trip_df$trip.end[19],
    trip == "20" ~ trip_df$trip.end[20],
    trip == "21" ~ trip_df$trip.end[21],
    trip == "22" ~ trip_df$trip.end[22] )) %>% 
  mutate(trip_end = lubridate::ymd(trip_end))

# add a variable to identify season 
# three seasons (early/late wet and dry) 
# and two seasons (wet/dry))    
sampleresults <- sampleresults %>% 
  mutate(trip = factor(trip, levels = 0:22),
         three_seasons = case_when(
           trip == 0 ~ "SCAN QA-QC", 
           trip %in% 1:4 ~ "early wet [Oct-Dec]",   # (second half) Oct-Dec 2018
           trip %in% 5:9 ~ "late wet [Jan-May]",           # Jan-May 2019 
           trip %in% 10:16 ~ "summer [June-Oct]",  # June-Oct (first half) 2019
           trip %in% 17:21 ~ "early wet [Oct-Dec]", # Oct-Dec 2019
           trip == 22 ~ "late wet [Jan-May]"), # Jan-Feb 2020
         two_seasons = case_when(
           trip == 0 ~ "SCAN QA-QC", 
           trip %in% 1:9 ~ "wet",   # mid-Oct 2018 to May 2019
           trip %in% 10:16 ~ "dry",  # June to mid-Oct 2019
           trip %in% 17:22 ~ "wet")) # mid-Oct 2019 to Jan 2020

# SUVA ------ 
# add a variable for SUVA = [DOC]/SAC254
sampleresults  <-  sampleresults %>% 
  mutate(SUVA = NPOC_ppm/SAC254_Abs.m)

# good!

```


```{r CRD metals data}

# I collected metals samples from trip 3 to 10
# CRD provded results files (PDF report) for trips 3 to 8
# data was manually sorted from PDF (there must be a better way)
# load data
metals <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Metals_CRD-forWaterMSc_HMc/CRD-metals-data_collated-trips3-8_nocharacternulls.csv", 
                   col_names = TRUE) %>% 
  tidyr::pivot_longer(cols = WESTLEECH:CHRISCREEK,
                      names_to = "site",
                      values_to = "metals_values") %>% 
  mutate(Trip = factor(Trip),
         Parameters = factor(Parameters),
         site = factor(site))
  

# check site names
levels(metals$site)

# add data for NPOC, DOC_eq, and SUVA
# subset for the six installation sites & rename
metalslab <- left_join(x = metals, 
                       y = (sampleresults %>% 
                              filter(site == "Weeks-out" |
                                       site == "Leech-head" |
                                       site == "Chris-crk" |
                                       site == "Cragg-crk" |
                                       site == "West-Leech"| 
                                       site == "Tunnel",
                                     sample_type == "Grab" & sample == "Grab",
                                     analysis == "DOC") %>% 
                              mutate(site = fct_recode(site, 
                                                       WEEKSOUT = "Weeks-out", 
                                                       CHRISCREEK = "Chris-crk", 
                                                       LEECHHEAD = "Leech-head", 
                                                       CRAGGCREEK = "Cragg-crk", 
                                                       WESTLEECH = "West-Leech", 
                                                       TUNNEL = "Tunnel"))),
                       by = c("site" = "site", "Trip" = "trip")) %>%
  mutate(Trip = factor(Trip),
         Site = factor(site),
         metal_parameters = factor(Parameters)) %>% 
  drop_na(site, metal_parameters) %>% 
  select(-"BONEYARD") %>% 
  mutate()

```


# Field Data

The six pirmary research location in the Leech River watershed were equipped with vertical sampling racks (which combined passive (siphon) samplers and compact river stage loggers) colected continuous water level via Odyssey capacitiance water level loggers. Field data includes the following: 

1. The CRD provided data from their fire weather stations for precipitation and air temperature. 

2. At the six installation sites, I collected data for:

* water level (Odyssey capacitance water level loggers)
* air and water temperature (Hobo TidbiTs)

3. At the four mainstem sites (Leech Head, Cragg Creek, West Leech, Tunnel), I collected 10 minute interval triggered trail-cam photos.

## Weather data (CRD fire weather stations)

The Leech river watershed hydroclimatic regime is pluvial, therefore precipitation data is very important. There were (at the time of my research) three weather stations in proximity to the Leech:

* Chris Crk WxStn at the headwaters
* Survey Mtn WxStn at the highest peak, in the Leech
* Martin's Gulch WxStn near the Leech River Tunnel (future point of diversion)

```{r Wx-precip}

# bring in WxStn data 

# input samples directory path
Wx_path <-  "R-inputs_UBC-forWater-MSc_HMc/CRD_FWx-Data/"

# check files  
list.files(path = Wx_path, pattern = "*.CSV") 

# read in all the files as one dataframe
# adjust DateTime (note that each file has different DT format)
precip_data <- list.files(path = Wx_path, pattern = "*.CSV") %>% 
  purrr::map_dfr(~ read_csv(file.path(Wx_path, .), col_names = TRUE,
                            col_types = list("c", "c", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d"))) %>% 
  mutate(StationName = forcats::as_factor(StationName),
        DateTime = lubridate::parse_date_time(DateTime, c("dmy HM", "ydm HM", "ymd HM"), tz = TZ),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ))
# 91089 failed to parse... 24 hour clock issue?

```

## River stage data 

At the six installation sites, water level loggers were installed (Odyssey capacitance water level loggers). The level loggers recorded stage at 10 minute intervals. Each logger was in a stilling well with a secured external stage measuring tape; the stage data must be adjusted with an offset value to match with the observed stage in order to match sample collection to logger datetimes.


```{r stage}

# bring in logger data and add a id column from the site file name
# note, each of the 6 sites has files named except 'Leech-Head' is named by the logger serial number (12040) 

# input samples directory path
odyssey_path <-  "R-inputs_UBC-forWater-MSc_HMc/odyssey/"

# check files  
list.files(path = odyssey_path, pattern = "*.CSV") 
# check source extract is reasonable   
list.files(path = odyssey_path, pattern = "*.CSV") %>%
  str_extract("([A-Z0-9]{4,}+)")
# Note that source names will have to be updated (mutate)

# read in all the files as one dataframe
# add source (ID) based on file names
# adjust date-time (note that there were multiple date formats output by loggers)
# time is in 24 hour clock and it seems that lubridate does not like that...
odyssey_data <- list.files(path = odyssey_path, pattern = "*.CSV") %>% 
  set_names(str_extract(., "([A-Z0-9]{4,}+)")) %>%
  purrr::map_dfr(~ read_csv(file.path(odyssey_path, .), skip = 12, 
                            col_names = c("scan_no.", "Date", "Time", "Capacitance", "stage_cm")), .id = "source") %>% 
  mutate(source = forcats::as_factor(source),
         Date = lubridate::parse_date_time(Date, c("dmy", "ydm"), tz = TZ),
         DateTime = lubridate::ymd_hms(paste(Date, Time), tz = TZ))

# check structure
str(odyssey_data)

# check levels
levels(odyssey_data$source)
# rename site IDs
odyssey_data$source <- forcats::fct_recode(odyssey_data$source, 
                                           LeechHead = "12040",
                                           ChrisCrk = "CHRIS",
                                           CraggCrk = "CRAGG",
                                           Tunnel = "LEECH",
                                           Weeks = "WEEKS",
                                           WestLeech = "WEST")
# re-check levels
levels(odyssey_data$source)


# there is certainly a better way to do this -- with a loop or map or apply or metaprogramming
# I don't know yet and I need to move on. 
# bad technique: copy and paste x22 (I know this is bad and ugly, sorry)
# ----
odyssey_data <- odyssey_data %>%
  select(Date, source, stage_cm, DateTime) %>%
  mutate(interval = case_when(  
    Date %within% interval(trip_df$trip.start[1], trip_df$trip.end[2]) ~ trip_df$trip[2],
    Date %within% interval(trip_df$trip.end[2], trip_df$trip.end[3]) ~ trip_df$trip[3],
    Date %within% interval(trip_df$trip.end[3], trip_df$trip.end[4]) ~ trip_df$trip[4],
    Date %within% interval(trip_df$trip.end[4], trip_df$trip.end[5]) ~ trip_df$trip[5],
    Date %within% interval(trip_df$trip.end[5], trip_df$trip.end[6]) ~ trip_df$trip[6],
    Date %within% interval(trip_df$trip.end[6], trip_df$trip.end[7]) ~ trip_df$trip[7],
    Date %within% interval(trip_df$trip.end[7], trip_df$trip.end[8]) ~ trip_df$trip[8],
    Date %within% interval(trip_df$trip.end[8], trip_df$trip.end[9]) ~ trip_df$trip[9],
    Date %within% interval(trip_df$trip.end[9], trip_df$trip.end[10]) ~ trip_df$trip[10],
    Date %within% interval(trip_df$trip.end[10], trip_df$trip.end[11]) ~ trip_df$trip[11],
    Date %within% interval(trip_df$trip.end[11], trip_df$trip.end[12]) ~ trip_df$trip[12],
    Date %within% interval(trip_df$trip.end[12], trip_df$trip.end[13]) ~ trip_df$trip[13],
    Date %within% interval(trip_df$trip.end[13], trip_df$trip.end[14]) ~ trip_df$trip[14],
    Date %within% interval(trip_df$trip.end[14], trip_df$trip.end[15]) ~ trip_df$trip[15],
    Date %within% interval(trip_df$trip.end[15], trip_df$trip.end[16]) ~ trip_df$trip[16],
    Date %within% interval(trip_df$trip.end[16], trip_df$trip.end[17]) ~ trip_df$trip[17],
    Date %within% interval(trip_df$trip.end[17], trip_df$trip.end[18]) ~ trip_df$trip[18],
    Date %within% interval(trip_df$trip.end[18], trip_df$trip.end[19]) ~ trip_df$trip[19],
    Date %within% interval(trip_df$trip.end[19], trip_df$trip.end[20]) ~ trip_df$trip[20],
    Date %within% interval(trip_df$trip.end[20], trip_df$trip.end[21]) ~ trip_df$trip[21],
    Date %within% interval(trip_df$trip.end[21], trip_df$trip.end[22]) ~ trip_df$trip[22],
    Date %within% interval(trip_df$trip.end[22], trip_df$trip.end[23]) ~ trip_df$trip[23] ) )
# note that interval (odyssey_data) is the same as (trip_df) trip number of analysis/collection 

# check out the head tail and middle
head(odyssey_data)
tail(odyssey_data, - 0.2*length(odyssey_data$Date))
tail(odyssey_data, - 0.5*length(odyssey_data$Date))
tail(odyssey_data, - 0.7*length(odyssey_data$Date))
tail(odyssey_data)

# NOTE --- These logger data need to be adjusted with the observed stage offset


# ----- ----------- OLD -------------- ------- #
# not sure if these offsets are correct #

## stream level data (second try - bring them in, add a column with site ID combnine them into one then adjust date-times)
# Odyssey Capacitance Water level Loggers installed at 6 sites 
# sites: Weeks Outlet, Leech Rv. Head, Chris Creek, Cragg Creek, West Leech, Leech Tunnel (late install, one data block)
# 3 data blocks exist for each site, date formats are irregular in most

# correct all water level values with offset calculated based on observed and recorded stage 
offset_L.Head   <- 60.84
offset_WksOut   <- 29 # 9.5
offset_ChrisCrk <- 30 # 7.27
offset_CraggCrk <- 9.25
offset_W.Leech  <- 4.85
offset_Tunnel   <- 3.17
# ---
```

# File Outputs

save the compiled and formatted dataframes as .csv files.
Keep this as a code-note so to prevent over-writing files accidentally

``` 
# {r output sample analysis files}

## save all compiled sample analysis as .csv files 
# keep as code note to avoid accidental over-writing later*

# TOCV_results df
# Shimadzu sample analyses results
write_csv(TOCV_results, path = "R-outputs_UBC-forWater-MSc_HMc/01_TOCV_results.csv", na = "NA")   

# SCAN_results df
# Spectrolyser sample analyses results
write_csv(SCAN_results, path = "R-outputs_UBC-forWater-MSc_HMc/01_SCAN-par_results.csv", na = "NA")               

# FULLSCAN_results df
# Spectrolyser fullscan (.fp) analyses results
write_csv(FULLSCAN_results, path = "R-outputs_UBC-forWater-MSc_HMc/01_SCAN-fp_results.csv", na = "NA")               

# sampleresults df
# compiled sample analyses results (wide)
write_csv(sampleresults, path = "R-outputs_UBC-forWater-MSc_HMc/01_Lab-analyses_sample-results_wide.csv", na = "NA")  

# metalslab df
# metals sample analyses results with OC (long)
write_csv(metalslab, path = "R-outputs_UBC-forWater-MSc_HMc/01_metals-OC_sample-results_long.csv", na = "NA")  

# odyssey_data df
# stage data compiled with interval/trip
write_csv(odyssey_data, path = "R-outputs_UBC-forWater-MSc_HMc/01_Odyssey-stage_compiled.csv", na = "NA")

# precip_data df
# 2018-2020 weather station data compiled and formatted
write_csv(precip_data, path = "R-outputs_UBC-forWater-MSc_HMc/01_FWx-PrecipTemp_compiled.csv", na = "NA")

```

.
.
.
.
.
.
.
.

# the following code chunks and text are old (to be updated/removed):
.
.
.
.
.
.
.
.
.
.
.
## odyssey loggers

Make hydrographs with stage (desire is to obtain Q)

```{r hydrographs_1}

# run a loop to plot stage for each site
# save each stage plot in a list to call later
stagePlots_list <- vector("list", 6)

# vector to call text format for plots
plottextformat <- element_text(size = 14, colour = forWater_colours[4])

# save a theme vector to add to each plot
stageplottheme <- theme_bw() + 
  theme(legend.title = plottextformat,
        legend.text = plottextformat,
        axis.title = plottextformat,
        axis.text = plottextformat,
        #axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]))

# chose the colour you want
forWater_col <- forWater_colours[3]

# loop for sites 1-5
for (i in seq_along(site_names[1:5])) {
  s <- ggplot(filter(stage.event_dfSS5, site == site_names[i]), aes(x = DateTime, y = Stage_cm)) + 
    geom_point(col = forWater_col) + 
    stageplottheme +
    labs(x = "", y = "Stage (cm)", caption = site_captions[i])
  
  stagePlots_list[[i]] <- s  # save plot to list for calls later (in order of 'site_names')
  ggsave(filename = paste("Stage_Plot_",i,"_",site_names[i],".png"), s)
}

# plot the tunnel separately becasue it has a truncated stage df
s <- ggplot(filter(stage.event_dfSS5, site == site_names[6]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[6])
stagePlots_list[[6]] <- s  # save plot to list for calls later (in order of 'site_names')
ggsave(filename = paste("Stage_Plot_",6,"_",site_names[6],".png"), s)

# rename the stage plot list elements
names(stagePlots_list) <- paste(site_names,"stage")

```

it didn't work to save my graphs in a vector so here they are again, less janky but not totally elegant

```{r hydrographs_2}

# set up fresh hydrographs (currently in Janky Shit)
# note: "ggplot_gtable" sets up the plot to be used in grid layout for rapidrunoff plots

# vector to call text format for plots
plottextformat <- element_text(size = 14, colour = forWater_colours[4])

# save a theme vector to add to each plot
stageplottheme <- theme_bw() + 
  theme(legend.title = plottextformat,
        legend.text = plottextformat,
        axis.title = plottextformat,
        axis.text = plottextformat,
        #axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]))

# chose the colour you want
forWater_col <- forWater_colours[3]

# ::: Weeks Outlet 
plot_wks_stg <- 
  ggplot(filter(stage.event_dfSS5, site == site_names[1]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[i])
ggsave(filename = paste("Stage_Plot_",1,"_",site_names[1],".png"))

gtb_wks_stg <- ggplot_gtable(ggplot_build(plot_wks_stg))  


# :: Leech River Head 
plot_L.head_stg <- 
  ggplot(filter(stage.event_dfSS5, site == site_names[2]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[i])
ggsave(filename = paste("Stage_Plot_",2,"_",site_names[2],".png"))

gtb_L.head_stg <- ggplot_gtable(ggplot_build(plot_L.head_stg))


# :: Chris Creek 
plot_chris_stg <- 
  ggplot(filter(stage.event_dfSS5, site == site_names[3]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[i])
ggsave(filename = paste("Stage_Plot_",3,"_",site_names[3],".png"))

gtb_chris_stg <- ggplot_gtable(ggplot_build(plot_chris_stg))


# :: Cragg Creek 
plot_cragg_stg <- 
  ggplot(filter(stage.event_dfSS5, site == site_names[4]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[i])
ggsave(filename = paste("Stage_Plot_",4,"_",site_names[4],".png"))

gtb_cragg_stg <- ggplot_gtable(ggplot_build(plot_cragg_stg))


# :: West Leech River 
plot_west_stg <- 
  ggplot(filter(stage.event_dfSS5, site == site_names[5]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[i])
ggsave(filename = paste("Stage_Plot_",5,"_",site_names[5],".png"))

gtb_west_stg <- ggplot_gtable(ggplot_build(plot_west_stg))


# :: Tunnel
plot_tunnel_stg <-
  ggplot(filter(stage.event_dfSS6, site == site_names[6]), aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  stageplottheme +
  labs(x = "", y = "Stage (cm)", caption = site_captions[i])
ggsave(filename = paste("Stage_Plot_",6,"_",site_names[6],".png"))

gtb_tunnel_stg <- ggplot_gtable(ggplot_build(plot_tunnel_stg))
```


##Goal:match bottle height to logged stage

1. read in data files with NPOC concentrations, dates bottles were set and collected, and fill stage (or grab sample dates)
2. read in stage data from Odyssey Capacitance water level loggers
3. fix dates, add identifying/grouping columns for SITE & EVENT
4. filter by site & event & analysis (DOC)
5. match samples to logged stage and extract matching date-time 
6. add DateTime stamps to sample results dataframes

Note: in the future it might be tidier to keep grab samples and rack samples results in one file & one dataframe. They can be easily grouped. For now, we'll keep them separate (gotta make a poster).

Plot the DOC results on each hydrograph

Weeks Outlet (Drainage from Jordan Meadows)

I think you can do thins in a loop with i as the seq_along(site_names[i]) and j as the seq_along(event[j]) 
call vector of events for trip_df

```{r OC+stage_wks}
# --- wks 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- wks 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- wks 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- wks 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #



# --- wks 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #
## Event five - freezing event. L1 was recorded as being set at 91 cm but the stage was not recorded as getting that high...


# --- wks 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[1] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[1] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

wks_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

## -- This could be improved - possibly with a case_when() or a loop or apply?? --- #


# combine all events into one weeks-df
# no fifth -- wks_matched <- rbind(wks_ev1_df,wks_ev2_df, wks_ev3_df, wks_ev4_df, wks_ev5_df, wks_ev6_df)
wks_matched <- rbind(wks_ev1_df,wks_ev2_df, wks_ev3_df, wks_ev4_df, wks_ev5_df, wks_ev6_df)



# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 


# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[1]
rackDOC <- wks_matched
stg_DOCplot <- plot_wks_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[1]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #

site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 


# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_wks_samp <- ggplot_gtable(ggplot_build(site.visit.plot))

```

## Leech River Head

```{r OC-stage_leech-head}

# --- Leech-Head 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- LHead 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- L.Head 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[2] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[2] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

L.Head_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# combine all events into one weeks-df
L.Head_matched <- rbind(L.Head_ev1_df,L.Head_ev2_df, L.Head_ev3_df, L.Head_ev4_df, L.Head_ev5_df, L.Head_ev6_df)


# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 


# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[2]
rackDOC <- L.Head_matched
stg_DOCplot <- plot_L.head_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[2]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #

site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_LHead_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## Chris Creek

```{r OC-stage_chris-creek}

# --- Chriscrk 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- Chriscrk 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[3] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[3] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

Chriscrk_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

# combine all events into one weeks-df
Chriscrk_matched <- rbind(Chriscrk_ev1_df, Chriscrk_ev2_df, Chriscrk_ev3_df, Chriscrk_ev4_df, Chriscrk_ev5_df, Chriscrk_ev6_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[3]
rackDOC <- Chriscrk_matched
stg_DOCplot <- plot_chris_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[3]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #

site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_Crscrk_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## Cragg Creek

```{r OC-stage_cragg}

# --- cragg 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- cragg 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[4] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[4] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

cragg_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

# combine all events into one weeks-df
# no fifth -- wks_matched <- rbind(wks_ev1_df,wks_ev2_df, wks_ev3_df, wks_ev4_df, wks_ev5_df, wks_ev6_df)
cragg_matched <- rbind(cragg_ev1_df, cragg_ev2_df, cragg_ev3_df, cragg_ev4_df, cragg_ev5_df, cragg_ev6_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[4]
rackDOC <- cragg_matched
stg_DOCplot <- plot_cragg_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[4]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #
site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_Craggcrk_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## West Leech River

```{r OC-stage_west}

# --- west 1
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "1") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "1") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 2
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "2") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "2") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 3
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 4
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 5
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev5_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- west 6
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[5] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[5] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

west_ev6_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #

# combine all events into one weeks-df
west_matched <- rbind(west_ev1_df, west_ev2_df, west_ev3_df, west_ev4_df, west_ev5_df, west_ev6_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[5]
rackDOC <- west_matched
stg_DOCplot <- plot_west_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[5]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #
site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_WestL_samp <- ggplot_gtable(ggplot_build(site.visit.plot))

```

## Leech River Tunnel

```{r OC-stage_tunnel}
# this site was installed late, in December
# event 1 for the tunnel was "event 3" for all others...


# --- tunnel 1 (3)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "3") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "3") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev1_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- tunnel 2 (4)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "4") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "4") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev2_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- tunnel 3 (5)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "5") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "5") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)
# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev3_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #


# --- tunnel 4 (6)
# --- INPUTS --- #
# create subset working dataframes 
stg_df <- filter(stage.event_df, site == site_names[6] & event == "6") %>% 
  select(event, site, DateTime, Stage_cm)

samp_df <- filter(racks_df, analysis == "DOC" & site == site_names[6] & event == "6") %>% 
  select(event, site, sample, Fill.Stage_cm, analysis, Result)

# --- OUTPUTS --- #
# defined based on your INPUT values (no need to alter)

# this is the stage date you're targeting (by site)
stg <- stg_df$Stage_cm
# this is the time series you're targeting
t.series <- stg_df$DateTime  
# this is the stage you need a date-time for
level <- samp_df$Fill.Stage_cm 

# assign empty vectors to hold the outputs from the loop
l <- length(samp_df$sample)
occur_fill <- vector(length = l)
stg_fill   <- vector(length = l)
time_fill  <- vector(length = l)

for (i in seq_along(samp_df$sample)) {
  occur_fill[i] <- detect_index(stg, ~ .x >= level[i], .right = FALSE)
  stg_fill[i] <- stg[occur_fill[i]]
} 

tunnel_ev4_df <- samp_df %>% 
  select(event, site, Fill.Stage_cm, analysis, Result) %>% 
  mutate(index = occur_fill, sample_stage = stg_fill, sample_time = t.series[occur_fill])
# --- #



# combine all events into one weeks-df
#west_ev3_df, west_ev4_df, 
tunnel_matched <- rbind(tunnel_ev1_df, tunnel_ev2_df, tunnel_ev3_df, tunnel_ev4_df)

# --- make a plot --- #
# find the start of each visit
# use these to add vertical lines to stage plots (for your guidance)
visits <- stage.event_df %>%
  group_by(event) %>% 
  summarise(date = first(DateTime)) %>% 
  ungroup()
visits <- visits[,2]
visits <- visits[[1]]
last_visit <- (last(stage.event_df$DateTime)) 

# vector for visit line colours 
visit_col <- forWater_colours[5]
# rack sample points
point_col <- forWater_colours[5]
# grab colour
grab_col <- forWater_colours[4]


# --- INPUTS --- #
Site.Name <- site_names[6]
rackDOC <- tunnel_matched
stg_DOCplot <- plot_tunnel_stg

# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[6]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- --- --- --- #

# --- get fancy --- #
site.visit.plot <- 
  stg_DOCplot +
  #geom_vline(xintercept = visits[1:6], linetype = "solid", colour = visit_col, size = 0.7) + 
  #geom_vline(xintercept = last_visit, linetype = "solid", colour = visit_col, size = 0.7) +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = grab_col, show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = point_col, show.legend = FALSE) 
site.visit.plot 

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")


# --- fancy --- #

# set up for combo plot (rainfall-streamflow)
gpt_Tunnel_samp <- ggplot_gtable(ggplot_build(site.visit.plot))
```

## make rapid runoff plots with the sample hydrographs

```{r rainfall-runoff_sample_plots}

# create rainfall and stream level plots and save each as an image

# Site 1 ------------------------------- 
# Weeks Lake Outlet 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_wks_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_wks_samp$widths[2:3] <- maxWidth

rr_WksOut_CC <- grid.arrange(gpt_wx_CC, gpt_wks_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_WksOut-CC.png", rr_WksOut_CC)


# Site 2  ------------------------------- 
# Leech River Head (below colfluence of Chris and Weeks) 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_LHead_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_LHead_samp$widths[2:3] <- maxWidth

rr_LHead_CC <- grid.arrange(gpt_wx_CC, gpt_LHead_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_LHead-CC.png", rr_LHead_CC)


# Site 3  ------------------------------- 
# Chris Creek
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], gpt_Crscrk_samp$widths[2:3])
gpt_wx_CC$widths[2:3]  <- maxWidth
gpt_Crscrk_samp$widths[2:3] <- maxWidth

rr_chris_CC <- grid.arrange(gpt_wx_CC, gpt_Crscrk_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_chris-CC.png", rr_chris_CC)


# Site 4   ------------------------------- 
# Cragg Creek 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_Craggcrk_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_Craggcrk_samp$widths[2:3] <- maxWidth

rr_cragg_CC <- grid.arrange(gpt_wx_CC, gpt_Craggcrk_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_cragg-CC.png", rr_cragg_CC)


# Cragg Creek
# with MG-Wx 
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gpt_Craggcrk_samp$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gpt_Craggcrk_samp$widths[2:3] <- maxWidth

rr_cragg_MG <- grid.arrange(gpt_wx_MG, gpt_Craggcrk_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_cragg-MG.png", rr_cragg_MG)


# Site 5  ------------------------------- 
# West Leech River 
# with MG-Wx
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gpt_WestL_samp$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gpt_WestL_samp$widths[2:3] <- maxWidth

rr_WLeech_MG <- grid.arrange(gpt_wx_MG, gpt_WestL_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_WLeech-MG.png", rr_WLeech_MG)


# West Leech River
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gpt_WestL_samp$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gpt_WestL_samp$widths[2:3] <- maxWidth

rr_WLeech_CC <- grid.arrange(gpt_wx_CC, gpt_WestL_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_WLeech-CC.png", rr_WLeech_CC)


# Site 6  ------------------------------- This one isn't lined up properly b/c late installation 
# Leech River Tunnel 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gpt_Tunnel_samp$widths[2:3])
gpt_wx_CC_tunnelspan$widths[2:3] <- maxWidth
gpt_Tunnel_samp$widths[2:3] <- maxWidth

rr_Tunnel_CC <- grid.arrange(gpt_wx_CC_tunnelspan, gpt_Tunnel_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_Tunnel-CC.png", rr_Tunnel_CC)

# Leech River Tunnel 
# with MG-wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gpt_Tunnel_samp$widths[2:3])
gpt_wx_MG_tunnelspan$widths[2:3] <- maxWidth
gpt_Tunnel_samp$widths[2:3] <- maxWidth

rr_Tunnel_MG <- grid.arrange(gpt_wx_MG_tunnelspan, gpt_Tunnel_samp, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-sampplot_Tunnel-MG.png", rr_Tunnel_MG)

```

## This is tidy and logical code :)
result is 'DOCresults_df'
```{r summary stats}
setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/")
# first, combine all the matched rack results (sample, levels, DOC, sample_DateTime) from each site
racksDOC <- rbind(wks_matched, L.Head_matched, Chriscrk_matched, cragg_matched, west_matched, tunnel_matched) %>%
  mutate(sample_type = "rack") %>% 
  rename(sample_DateTime = sample_time, 
         obs.filling.stage = Fill.Stage_cm,
         racksample_stage = sample_stage) %>% 
  select(-index) 

str(racksDOC)

# next, filter grabs results for DOC and combine with rack results
# grabs data (all sites) 
str(grabs_df)

grabsDOC <- grabs_df %>% 
  filter(analysis == "DOC") %>% 
  select(event = event_capture, 
         site = Site, 
         obs.filling.stage = filling.stage.cm, 
         analysis, 
         Result,
         sample_DateTime = Grab_DateTime 
  ) %>% 
  mutate(sample_type = "Grab",
         racksample_stage = "NA"
  )
# check the structures match
str(grabsDOC)
str(racksDOC)

# merge the two 
DOCresults_df <- rbind(grabsDOC, racksDOC)
str(DOCresults_df)

# add latitude and longitude so you can import this to QGIS
# check names
install_df$Sample_Name
unique(DOCresults_df$site)
site_names

# match lat and long to site names
DOCresults_df <- DOCresults_df %>% 
  mutate(
    latitude = case_when(
      DOCresults_df$site == site_names[1] ~ install_df$Latitude[1],
      DOCresults_df$site == site_names[2] ~ install_df$Latitude[2],
      DOCresults_df$site == site_names[3] ~ install_df$Latitude[3],
      DOCresults_df$site == site_names[4] ~ install_df$Latitude[4],
      DOCresults_df$site == site_names[5] ~ install_df$Latitude[5],
      DOCresults_df$site == site_names[6] ~ install_df$Latitude[6]),
    longitude = case_when(
      DOCresults_df$site == site_names[1] ~ install_df$Longitude[1],
      DOCresults_df$site == site_names[2] ~ install_df$Longitude[2],
      DOCresults_df$site == site_names[3] ~ install_df$Longitude[3],
      DOCresults_df$site == site_names[4] ~ install_df$Longitude[4],
      DOCresults_df$site == site_names[5] ~ install_df$Longitude[5],
      DOCresults_df$site == site_names[6] ~ install_df$Longitude[6])
  )

# check structure
str(DOCresults_df)

# add a column for sampling month
DOCresults_df <- DOCresults_df %>% mutate(sample_month = month(sample_DateTime, label = TRUE))
str(DOCresults_df)

# save a copy as a csv file
write.csv(DOCresults_df, file = "2019-05-26_combined-DOC-results.csv")


# --- --- --- --- #  

# summary stats
str(DOCresults_df)

DOC_stats <- DOCresults_df %>% 
  filter(analysis == "DOC") %>% 
  group_by(sample_month, site) %>% 
  summarize(count = n(), DOCmean = mean(Result), DOCsd = sd(Result), DOCmedian = median(Result), DOCmin = min(Result), DOCmax = max(Result))
head(DOC_stats)
tail(DOC_stats)
str(DOC_stats)

write.csv(DOC_stats, file = "2019-05-26_DOC-SummaryStats.csv")


# summary stats 2.0
str(DOCresults_df)

DOC_stats2 <- DOCresults_df %>% 
  filter(analysis == "DOC") %>% 
  group_by(site) %>% 
  summarize(count = n(), DOCmean = mean(Result), DOCsd = sd(Result), DOCmin = min(Result), DOCmedian = median(Result), DOCmax = max(Result))
head(DOC_stats2)
tail(DOC_stats2)
str(DOC_stats2)

write.csv(DOC_stats2, file = "2019-05-28_DOC-SummaryStats.csv")

# summary stats 3.0
str(DOCresults_df)

DOC_stats3 <- DOCresults_df %>% 
  filter(analysis == "DOC") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(), DOCmean = mean(Result), DOCsd = sd(Result), DOCmin = min(Result), DOCmedian = median(Result), DOCmax = max(Result))
head(DOC_stats3)
tail(DOC_stats3)
str(DOC_stats3)

write.csv(DOC_stats3, file = "2019-05-28_DOC-SummaryStats3.csv")

```

```{r DOC_plots}
setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/")
# check dataframe
str(DOCresults_df)

# get factors in order for tidy calls
# set sample type to be factor
DOCresults_df$sample_type <- as.factor(DOCresults_df$sample_type)
str(DOCresults_df)

# add ordered site factor (headwater to reach)
DOCresults_df$site_f <- factor(DOCresults_df$site, levels=c("Weeks-out", "Chris-crk", "Leech-head", "Cragg-crk", "West-Leech", "Tunnel"))
levels(DOCresults_df$site_f) <- site_captions2  # rename with caption names

# add ordered months (fall 2018 to spring 2019)
DOCresults_df$month_f <- factor(DOCresults_df$sample_month, levels=c("Oct", "Nov", "Dec", "Jan", "Feb", "Mar", "Apr"))

# vector to call text format for plots
textformat <- element_text(size = 14, colour = forWater_colours[4])

# make plots
# boxplot and scatter plot of DOC at all sites over first wet season
DOC_facetB.Plot <- DOCresults_df %>% filter(analysis == "DOC") %>% group_by(sample_type) %>% 
  ggplot(aes(x = month_f, y = Result, fill = sample_type, colour = sample_type)) + geom_boxplot() +
  scale_fill_manual(values = c("white", "white")) + guides(fill = FALSE) +
  geom_point(aes(colour = sample_type), size = 3) +
  scale_color_manual(values = c(forWater_colours[1], forWater_colours[5]),
                     labels = c("Grab", "Rack")) +
  theme_bw() +
  theme(legend.position = "top",
        legend.title = textformat,
        legend.text = textformat,
        axis.title = textformat,
        strip.text = element_text(size = 12, colour = forWater_colours[4]),
        axis.text = textformat) +
  labs(colour = "Sample Type:  ") +
  ylab("Dissolved Organic Carbon (mg/L NPOC)") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~site_f) 
DOC_facetB.Plot

# scatterplot of DOC at all sites over first wet season
# scatter only (better than box plot version I think)
DOC_facet_SPlot <- DOCresults_df %>% filter(analysis == "DOC") %>% group_by(sample_type) %>% 
  ggplot(aes(x = sample_DateTime, y = Result)) +
  geom_point(aes(colour = sample_type), size = 5, alpha = 0.75) +  # partially transparent points with alpha <1
  scale_color_manual(values=c(forWater_colours[4], forWater_colours[5]),
                     labels = c("Grab", "Rack")) +
  theme_bw() +
  theme(legend.position = "top",
        legend.title = textformat,
        legend.text = textformat,
        axis.title = textformat,
        strip.text = element_text(size = 12, colour = forWater_colours[4]),
        axis.text = textformat) +
  labs(colour = "Sample Type:  ") +
  ylab("DOC (mg/L NPOC)") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~site_f) 
DOC_facet_SPlot

ggsave(filename = "DOC_facet-scatterPlot_allSites.png", DOC_facet_SPlot)


# scatterplot of DOC at each site
# set it up and run a loop
# use vectors defined in chunk "tidy-names"

for (i in seq_along(site_names)) {
  g <- DOCresults_df %>% filter(analysis == "DOC" & site == site_names[i]) %>% group_by(sample_type) %>% 
    ggplot(aes(x = sample_DateTime, y = Result)) + 
    geom_point(aes(colour = sample_type), size = 5) +
    theme_bw() +
    theme(plot.caption = textformat,
          legend.position = c(0.8, 0.8),
          legend.text = textformat,
          legend.title = textformat,
          axis.text = textformat,
          axis.title = textformat) +
    labs(colour = "Sample Type") +
    #caption = paste("DOC over 2018-2019 wet season at ", site_captions[i])) +
    scale_color_manual(values=c(forWater_colours[4], forWater_colours[5]),
                       labels = c("Grab", "Rack")) +
    ylab("NPOC (mg/L DOC)") + 
    xlab("")
  
  ggsave(filename = paste("DOC_scatterPlot_",i,"_",site_names[i],".png"),
         width = 7.29, height = 4.5, units = "in")
}

# YAY that worked!!!! 
# Go back to your janky mess of plots above (when you have time) and fix that code up to be cool like this!!! :)

```

See if there is a direct relationship (suspected) between DOC (from grabs) and metals resutls

import both files and combine.

```{r DOC-metals}

setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/")

# read in grab sample data
grabs_df <- read.csv("2019-05-24_Grab-Sample_TOC-V_Results.csv")
str(grabs_df)

grabs_df$analysis_date <- as.POSIXct(grabs_df$analysis_date, tz = TZ)
grabs_df <- grabs_df %>% 
  mutate(collection_DateTime = as.POSIXct(paste(collection.date, collection.time), format="%Y-%m-%d %H:%M", tz = TZ))
str(grabs_df)

# read in metals + DOC data (manually merged)
metals_df <- read.csv("Leech_metals+DOC_compiled.csv", stringsAsFactors = FALSE)
str(metals_df)

# sample collection date-time as POSIXct
metals_df$Sampling.Date <- parse_date_time(metals_df$Sampling.Date, c("Ymd HM"), tz = TZ)
rename(metals_df, Sample_DateTime = Sampling.Date)
metals_df$Site <- as.factor(metals_df$Site.1)
metals_df <- subset(metals_df, select = c(-Site.1))
str(metals_df)


# replace analytical results that are below reportable detection limits with NA
# there should be a way tidier to loop over the whole data frame rather than cherry picking the character columns 
# this works, but only if the SCV format never changes
for(i in c(9, 11, 12, 14:20, 22:26, 28, 30:36, 39, 41)) {
  is.na(metals_df[,i]) <- startsWith(metals_df[,i], "<")
}

# convert from wide to long format
# The arguments to gather():
# - data: original (wide) Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
metals_long <- gather(metals_df, key = "parameter", value = "result", 
                      NPOC_mg.L:Total.Sulphur..S._mg.L, na.rm=TRUE, convert=TRUE, factor_key=FALSE)
str(metals_long)

# results should be numeric not character
# convert all results values to numeric
metals_long$result <- sapply(metals_long$result, as.numeric)
str(metals_long)
head(metals_long)
tail(metals_long)

write.csv(metals_long, file = "R-outputs/2019-05-26_metals-long.csv")
write.csv(metals_df, file = "R-outputs/2019-05-26_metals-wide.csv")


```

```{r plot_metals}

setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/")

metals_nona <- read.csv("2019-05-26_metals-wide_filtered.csv")

# add ordered factor for headwater to reach
metals_nona$Site_f <- factor(metals_nona$Site, levels=c("Weeks-out", "Chris-crk", "Leech-head", "Cragg-crk", "West-Leech", "Tunnel"))
levels(metals_nona$Site_f) <- site_captions

metalsnames <- as.vector(colnames(metals_nona))
metalsnames

metalsnames[8]
CaCo3 <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,8])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Total Hardness (mg/L CaCO3)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
CaCo3

metalsnames[9]
Hg <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,9])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Mercury (ug/L Hg)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Hg

metalsnames[10]
Al <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,10])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Aluminum (ug/L Al)") + 
  xlab("DOC (mg/L)") +
  geom_hline(yintercept = 100, linetype = "solid", colour = forWater_colours[5], size = 0.4) +
  facet_wrap(~Site_f) 
Al

metalsnames[12]
Ba <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,12])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Barium (ug/L Ba)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Ba

metalsnames[15]
Cu <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,15])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Copper (ug/L Cu)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Cu

metalsnames[16]
Fe <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,16])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Iron (ug/L Fe)") + 
  xlab("DOC (mg/L)") +
  geom_hline(yintercept = 300, linetype = "solid", colour = forWater_colours[5], size = 0.4) +
  facet_wrap(~Site_f) 
Fe

metalsnames[17]
Mn <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,17])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Manganese (ug/L Mn)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Mn

metalsnames[19]
Si <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,19])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Silicon (ug/L Si)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Si

metalsnames[21]
Sr <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,21])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Strontium (ug/L Sr)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Sr

metalsnames[24]
Ca <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,24])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Calcium (ug/L Ca)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Ca

metalsnames[25]
Mg <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,25])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Magnesium (ug/L Mg)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Mg

metalsnames[26]
K <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,26])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("potassium (ug/L K)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
K

metalsnames[27]
Na <- metals_nona %>% 
  ggplot(aes(x = NPOC_mg.L, y = metals_nona[,27])) + 
  geom_point(aes(colour = Trip), size = 4) +
  ylab("Sodium (ug/L Na)") + 
  xlab("DOC (mg/L)") +
  facet_wrap(~Site_f) 
Na

# save pics
ggsave("metals_CaCo3.png", CaCo3)
ggsave("metals_Hg.png", Hg)
ggsave("metals_Al.png", Al)
ggsave("metals_Ba.png", Ba)
ggsave("metals_Cu.png", Cu)
ggsave("metals_Fe.png", Fe)
ggsave("metals_Mn.png", Mn)
ggsave("metals_Si.png", Si)
ggsave("metals_Sr.png", Sr)
ggsave("metals_Ca.png", Ca)
ggsave("metals_Mg.png", Mg)
ggsave("metals_K.png", K)
ggsave("metals_Na.png", Na)

```

# 2019-05-27 
Retrying hydrograph plots with sample dots
this didn't work - keep trying
The problem was that I couldn't call the hydrograph plot I saved to a list to add it to a new ggplot() with geom_points
But I think I should be able to...


```{r chemograph_inprogress}



# plot_wks_stg, plot_L.head_stg, plot_chris_stg, plot_cragg_stg, plot_west_stg, plot_tunnel_stg

# try this

# assign rack + grab subset
rack_ss <- filter(DOCresults_df, analysis == "DOC" & sample_type == "rack")
grab_ss <- filter(DOCresults_df, analysis == "DOC" & sample_type == "Grab")

c <- plot_wks_stg +
  geom_point(data = rack_ss, aes(x = sample_DateTime, y = racksample_stage), colour = forWater_colours[4], size = 5) +
  geom_point(data = grab_ss, aes(x = sample_DateTime, y = obs.filling.stage), colour = forWater_colours[4], size = 5)
c 

## still not working

# old 
# --- INPUTS --- #
Site.Name <- site_names[1]
rackDOC <- wks_matched
stg_DOCplot <- plot_wks_stg
# grab data (site name)
grabDOC <- grabs_df %>% 
  filter(analysis == "DOC" & Site == site_names[1]) %>% 
  select(Site, sample, filling.stage.cm, Grab_DateTime, Result)
# --- get fancy --- #
c <- stg_DOCplot +
  geom_point(data = grabDOC, aes(x = Grab_DateTime, y = filling.stage.cm, size = 4), colour = forWater_colours[4], show.legend = FALSE) +
  geom_point(data = rackDOC, aes(x = sample_time, y = sample_stage, size = 4), colour = forWater_colours[5], show.legend = FALSE) 
c 
# --- --- --- --- # end old, start new

# new

# use results df
str(DOCresults_df)
# call on 'stagePlots_list' and 'site_names' to access hydrographs and names (1:6)


# --- INPUTS --- #
Site.Name <- site_names[1]
DOCdf <- DOCresults_df %>% filter(site == site_names[1] & analysis == "DOC")
hydrograph <- stagePlots_list[1]

b <- DOCresults_df %>% filter(site == site_names[1] & analysis == "DOC") %>% 
  ggplot(aes(x = sample_DateTime, y = racksample_stage)) +
  geom_point(aes(colour = sample_type), size = 4) 
b 

# stage-plot + geom_point(sample_data)

# --- diff code example
# scatterplot of DOC at each site
# set it up and run a loop
# use vectors defined in chunk "tidy-names"

for (i in seq_along(site_names)) {
  g <- DOCresults_df %>% filter(analysis == "DOC" & site == site_names[i]) %>% group_by(sample_type) %>% 
    ggplot(aes(x = sample_DateTime, y = Result)) + 
    geom_point(aes(colour = sample_type), size = 5) +
    theme_bw() +
    theme(plot.caption = textformat,
          legend.position = c(0.8, 0.8),
          legend.text = textformat,
          legend.title = textformat,
          axis.text = textformat,
          axis.title = textformat) +
    labs(colour = "Sample Type",
         caption = paste("DOC over 2018-2019 wet season at ", site_captions[i])) +
    scale_color_manual(values=c(forWater_colours[4], forWater_colours[5]),
                       labels = c("Grab", "Rack")) +
    ylab("NPOC (mg/L DOC)") + 
    xlab("")
  
  ggsave(filename = paste("DOC_scatterPlot_",i,"_",site_names[i],".png"), g)
}

# save as a picture
ggsave(paste("sample-hydrgr_", Site.Name, ".png"), plot = site.visit.plot, 
       path = "C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/R-outputs/",
       width = 7.29, height = 4.5, units = "in")

# --- fancy --- #
```


# fix up this janky code:

```{r JankyShit_fix_gtables}

## ------- you got this far in jank repair ---------##
# set up for combo plot (rainfall-streamflow)
# save each stage plot in a list to call later
stg_gtable_list <- vector("list", 6)

for (i in seq_along(stagePlots_list)) {
  stg_gtable_list[[i]] <- ggplot_gtable(ggplot_build(stagePlots_list[i]))
}

# rename the list elements of stage plot ggplot gtables
names(stg_gtable_list) <- paste(site_names,"gtable")



# ****** YOU CANT GET RID OF THIS BECAUSE THE JANKY CHEMOGRAPHS PULL ON THESE HYDROGRAPHS - UGH *** ######
# don't use this janky shit 
# BUT -- make sure you got the the ggplot gtables set up properly in your loop (to build rapid-runoff plots (but make them better, the rain bars are too thin to see))

#### -- janky shit Below --- ####
# Janky but it works

# chose the colour you want
forWater_col <- forWater_colours[3]

# --- Weeks Lake Outlet --- #
plot_wks_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[1]), 
                       aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[1])
plot_wks_stg 

# set up for combo plot (rainfall-streamflow)
gtb_wks_stg <- ggplot_gtable(ggplot_build(plot_wks_stg))


# --- Leech River Head --- #
plot_L.head_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[2]), 
                          aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[2])
plot_L.head_stg 

# set up for combo plot (rainfall-streamflow)
gtb_L.head_stg <- ggplot_gtable(ggplot_build(plot_L.head_stg))


# --- Chris Creek --- #
plot_chris_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[3]), 
                         aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[3])
plot_chris_stg 

# set up for combo plot (rainfall-streamflow)
gtb_chris_stg <- ggplot_gtable(ggplot_build(plot_chris_stg))

## note data gap 2018-11-07 -- date of re-build. 
# Original installation by Bill Floyd was at an angle, Nov 7 Stew and Hannah re-built the station to be vertical and match other designs. 
# In the original structure, the sensor was laying against the inside of the stilling well (possibly resulting in a positive bias)
# the angled stilling well may have extended the offset (if the stilling well wasn't against the streambed). 
# all bottle heights for the pre and post period are matched to the stilling well, so they should still line up.


# --- Cragg Creek --- #
plot_cragg_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[4]), 
                         aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[4])
plot_cragg_stg 

# set up for combo plot (rainfall-streamflow)
gtb_cragg_stg <- ggplot_gtable(ggplot_build(plot_cragg_stg))


# --- West Leech River (above the confluence with Leech mainstem) --- #
plot_west_stg <- ggplot(filter(stage.event_dfSS5, site == site_names[5]), 
                        aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        text = element_text(colour = forWater_colours[4]),
        axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[5])
plot_west_stg 

# set up for combo plot (rainfall-streamflow)
gtb_west_stg <- ggplot_gtable(ggplot_build(plot_west_stg))



# --- Tunnel --- #
plot_tunnel_stg <- ggplot(filter(stage.event_dfSS6, site == site_names[6]), 
                          aes(x = DateTime, y = Stage_cm)) + 
  geom_point(col = forWater_col) + 
  theme_minimal() + 
  theme(#axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    text = element_text(colour = forWater_colours[4]),
    axis.text = element_text(colour = forWater_colours[4])) +
  labs(x = "", y = "Stage (cm)", caption = site_captions[6])
plot_tunnel_stg 

# set up for combo plot (rainfall-streamflow)
gtb_tunnel_stg <- ggplot_gtable(ggplot_build(plot_tunnel_stg))


```

Create rainfall runoff plots

```{r rainfall-runoff_plots_janky}

setwd("C:/Users/Hannah/Documents/UBC_MSc/Analyses+Laboratory+Tracking_forWater-MSc_HMc/Data_WORKUP_forWater-MSc_HMc/")

# create rainfall and stream level plots and save each as an image

# Site 1 ------------------------------- 
# Weeks Lake Outlet 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_wks_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_wks_stg$widths[2:3] <- maxWidth

rr_WksOut_CC <- grid.arrange(gpt_wx_CC, gtb_wks_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_WksOut-CC.png", rr_WksOut_CC)


# Site 2  ------------------------------- 
# Leech River Head (below colfluence of Chris and Weeks) 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_L.head_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_L.head_stg$widths[2:3] <- maxWidth

rr_LHead_CC <- grid.arrange(gpt_wx_CC, gtb_L.head_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_LHead-CC.png", rr_LHead_CC)


# Site 3  ------------------------------- 
# Chris Creek
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], gtb_chris_stg$widths[2:3])
gpt_wx_CC$widths[2:3]  <- maxWidth
gtb_chris_stg$widths[2:3] <- maxWidth

rr_chris_CC <- grid.arrange(gpt_wx_CC, gtb_chris_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_chris-CC.png", rr_chris_CC)


# Site 4   ------------------------------- 
# Cragg Creek 
# with CC-Wx 
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_cragg_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_cragg_stg$widths[2:3] <- maxWidth

rr_cragg_CC <- grid.arrange(gpt_wx_CC, gtb_cragg_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_cragg-CC.png", rr_cragg_CC)


# Cragg Creek
# with MG-Wx 
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gtb_cragg_stg$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gtb_cragg_stg$widths[2:3] <- maxWidth

rr_cragg_MG <- grid.arrange(gpt_wx_MG, gtb_cragg_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_cragg-MG.png", rr_cragg_MG)


# Site 5  ------------------------------- 
# West Leech River 
# with MG-Wx
maxWidth <- unit.pmax(gpt_wx_MG$widths[2:3], 
                      gtb_west_stg$widths[2:3])
gpt_wx_MG$widths[2:3] <- maxWidth
gtb_west_stg$widths[2:3] <- maxWidth

rr_WLeech_MG <- grid.arrange(gpt_wx_MG, gtb_west_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_WLeech-MG.png", rr_WLeech_MG)


# West Leech River
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC$widths[2:3], 
                      gtb_west_stg$widths[2:3])
gpt_wx_CC$widths[2:3] <- maxWidth
gtb_west_stg$widths[2:3] <- maxWidth

rr_WLeech_CC <- grid.arrange(gpt_wx_CC, gtb_west_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_WLeech-CC.png", rr_WLeech_CC)


# Site 6  ------------------------------- This one isn't lined up properly b/c late installation 
# Leech River Tunnel 
# with CC-Wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gtb_tunnel_stg$widths[2:3])
gpt_wx_CC_tunnelspan$widths[2:3] <- maxWidth
gtb_tunnel_stg$widths[2:3] <- maxWidth

rr_Tunnel_CC <- grid.arrange(gpt_wx_CC_tunnelspan, gtb_tunnel_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_Tunnel-CC.png", rr_Tunnel_CC)

# Leech River Tunnel 
# with MG-wx
maxWidth <- unit.pmax(gpt_wx_CC_tunnelspan$widths[2:3], 
                      gtb_tunnel_stg$widths[2:3])
gpt_wx_MG_tunnelspan$widths[2:3] <- maxWidth
gtb_tunnel_stg$widths[2:3] <- maxWidth

rr_Tunnel_MG <- grid.arrange(gpt_wx_MG_tunnelspan, gtb_tunnel_stg, ncol = 1, heights = c(1, 3))
ggsave("R-outputs/rr-plot_Tunnel-MG.png", rr_Tunnel_MG)

```
