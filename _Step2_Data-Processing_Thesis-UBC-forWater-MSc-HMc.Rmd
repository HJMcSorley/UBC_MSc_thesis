---
title: "Reproducible data analysis: thesis data visualization and analysis"
subtitle: "Pacific Maritime forWater Masters Project (NSERC forWater)"
author: "Hannah J McSorley"
output: bookdown::word_document2
---

___Data Visualization and Summaries___
This RMD file generates summary tables and figures but is not included in the final bookdown product (tables and figures will be added to applicable sections by reading them in).

# Set-up
```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE, warning = FALSE, message = FALSE)
```

Packages
```{r, package.startup.message = FALSE}

# load packages
library(tidyverse)  # includes: dplyr, ggplot2, purrr, readr, forcats
library(lubridate)  # dates and times
library(broom)      # tidy up
library(glue)       # glue() is an object-integrated 'paste'-like function
library(RColorBrewer) # Brewer palette for plots
library(viridis)    # nice colours for plots gradient fills
library(ggridges)   # ridge plots (density distributions)
library(cowplot)    # add-on to ggplot for layout (nice grid)
library(gghighlight)# plot highlighting
library(gridExtra)  # for plot & table layout options
library(ggpmisc)    # linear regression line values (ggplot)
library(ggpubr)     # Q-Q plots
library(car)        # stats: Companion to Applied Regression
library(synchrony)  # stats for autocorrelated & non-independent data :)
library(randomForest)
library(randomForestExplainer)

```

define colours for plots
```{r vectorize-colours}
# use forWater defined colours (hexadecimal codes) for plots
# all colours defined by forWater admin, except 'MyOrange' which I made
forWater_colours1 <- c(MainBlue = "#09A4D2", 
                       MainGreen = "#668536", 
                       AccentBlue = "#5B99CC", 
                       DarkGrey = "#3B3838", 
                       MyOrange = "#f4AB0E")

# colours updated late 2019 :\
forWater_colours2 <- c(DeepBlue = "#0A5EA6", 
                       Green = "#648326", 
                       SkyBlue = "#62ACC8", 
                       Gray = "#535353", 
                       MyOrange = "#f4AB0E")

# colour-blind friendly pallet with grey (no black)
cbPalette <- c(grey = "#999999", 
               orange = "#E69F00", 
               lightblue = "#56B4E9", 
               green = "#009E73", 
               yellow = "#F0E442", 
               darkblue = "#0072B2", 
               red = "#D55E00", 
               pink = "#CC79A7")
```

Define a function for number extraction from alphanumerics.
```{r NumberXtract}
# define functions

# ---- Alpha-numeric extraction function ---- #
# from http://stla.github.io/stlapblog/posts/Numextract.html
NumberXtract <- function(alphnum){
  unlist(regmatches(alphnum, gregexpr("[[:digit:]]+\\.*[[:digit:]]*", alphnum)))
}

```

# Load datasets
```{r, input-files, message=FALSE}
# assign timezone
TZ <- "Etc/GMT+8"

# File Inputs
#Results of data wrangling (01) were saved as .csv files for tidy loading. 
# read all compiled data files & format

# --- field data:

# Wrangled Hobo TidibiT logger data with rain events and trip IDs
Hobo_df <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Hobo_trip-event.csv", 
                    col_names = TRUE) %>% 
  mutate(location = factor(location),
         site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         trip = factor(trip), 
         event_ID = factor(event_ID), 
         rain_season = factor(rain_season),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ)) %>% 
  rename(TidbiT_location = "location")

# odyssey_data df
# stage data compiled with interval/trip
odyssey_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Odyssey-RackCorrected-stage.csv", col_names = TRUE) %>% 
  mutate(source = factor(source, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")),
         interval = factor(interval),
         event_ID = factor(event_ID),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ))

# precip_data df
# 2018-2020 weather station data compiled and formatted
precip_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/FWx-PrecipTemp_compiled.csv", col_names = TRUE) %>%
  mutate(StationName = factor(StationName),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         Precip = as.numeric(Precip), # read in as logical
         Prec_24 = as.numeric(Prec_24),
         event_ID = factor(event_ID),
         rain_season = factor(rain_season))    

# LWSA mean precip data (FWx-mean-LWSA df)
# 2018-2020 weather station data compiled and formatted
LWSA_meanWx_dat <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/FWx-Mean-LWSA_PrecipTemp.csv", col_names = TRUE) %>% 
  mutate(DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         Precip_mean = as.numeric(Precip_mean), 
         Prec_24_mean = as.numeric(Prec_24_mean))  

# rain events defined with Rainmaker::RMevents()
# mean 15-minute rainfall record from Chris Crk and Martin's gulch FWx stns
# inter-event period = 14 hrs, threshold for major event = 50mm 
events <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Wx-RainEvents.csv", 
                   col_names = TRUE) %>% 
  mutate(ID = factor(ID),
         StartDate = ymd_hms(StartDate, tz = TZ),
         EndDate = ymd_hms(EndDate, tz = TZ))


# --- sample data:

# results df
# compiled sample analyses results (wide)
# including DateTime of Rack sample collection
sampleresults_df <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Results_complete.csv", col_names = TRUE) %>%   
  mutate(DateTime = lubridate::ymd_hms(DateTime, tz = TZ), 
         DateTime_sampled = lubridate::ymd_hms(DateTime_sampled, tz = TZ),
         collection = lubridate::ymd_hms(collection, tz = TZ),
         site = factor(site),
         trip = factor(trip),
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         rain_season = factor(rain_season),
         pseudo_SUVA = pseudo254/NPOC_ppm,
         event_ID = factor(event_ID))

# metalslab df
# metals sample analyses results with OC (long)
metalslab <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/metals-DOCgrab-sample_results-long.csv", col_names = TRUE) %>% 
  mutate(dt_sampled = lubridate::ymd_hms(dt_sampled, tz = TZ),
         Trip = factor(Trip),
         site = factor(site), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         metal_parameters = factor(Parameters))

# stage_samples
# subbasin sample results with stage, timestamps, and precip event ID
stage_samples_dat <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/subbasins_matched-chemohydro-samples.csv", col_names = TRUE) %>% 
  select(-c(stage_cm)) %>% 
  mutate(site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")),
         interval = factor(interval), # stage chunk that corresponds to field trip
         trip = factor(trip),  # field trip
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),  # season estimated by month
         rain_season = factor(rain_season),  # season assigned by rain events
         event_ID = factor(event_ID),  # rain events defined by precip >50mm & 14hrs btwn events
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ), # continuous stage
         DateTime_sampled = lubridate::ymd_hms(DateTime_sampled, tz = TZ),
         NPOC_ppm = as.numeric(NPOC_ppm),
         NO3.Neq_ppm = as.numeric(NO3.Neq_ppm),
         TOCeq_ppm = as.numeric(TOCeq_ppm),
         DOCeq_ppm = as.numeric(DOCeq_ppm),
         SAC254_Abs.m = as.numeric(SAC254_Abs.m),
         pseudo254 = as.numeric(pseudo254),
         SlopeRatio = as.numeric(SlopeRatio),
         E2E3 = as.numeric(E2E3),
         E4E6 = as.numeric(E4E6),
         SUVA = as.numeric(SUVA),
         pseudo_SUVA = as.numeric(pseudo_SUVA)) 

# Treatability data from U.Waterloo (Fariba Amiri)
treatdat_UW <- 
  list.files("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", pattern = "*.csv") %>% 
  set_names(str_extract(., "([0-9]{2,}+)")) %>%
  purrr::map_dfr(~ read_csv(
    file.path("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", .), 
    col_names = TRUE, skip = 15), .id = "source") 

# Character data from U.Alberta (Julia Orlova)
NOMcharacter_UA <- read_csv("R-inputs_UBC-forWater-MSc_HMc/NOM-character-results_UofA/Orlova-J_UofA-results_PM_Hannah_Nov2019-Feb2020.csv", col_names = TRUE)

```

# WEATHER - FWx

## CC + MG 

plots: rain/snow/temp
At Chris Creek and Martin's Gulch FWx stations

```{r, FWx-plots}

# Rn15 is 15-minute rainfall (mm) 
# Prec_1 is hourly accummulated precipitation (mm)
# Temp is 15 minute intervals (degrees C)
rainplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n (mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)

# plot LWSA snow
snowplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  # note: "SnowDep" contains noise (raw), "SnowDepth" is clean(er)
  dplyr::summarise(daily_Snowmean = mean(SnowDepth, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = "Snow depth \n (m)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)+
  theme(strip.background = NULL, 
        strip.text = element_blank()) 

# plot LWSA temperature
tempplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0, 
             linetype = "dotted") +
  labs(x = "", y = "Daily air temp\n(°C)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1) +
  theme(strip.background = NULL, 
        strip.text = element_blank(),
        axis.text.x = element_text(angle = 30, hjust = 1))


# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(rainplot, snowplot, tempplot, ncol = 1, align = "v",
                   rel_heights = c(1.25,1,1.75))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA.png",
       width = 6, height = 5, units = "in")
```


table: annual precip, max snow, mean temp 

FWx for each station
```{r}
# precip_data summary
a <- precip_data %>%
  mutate(Year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017, Year != 2020) %>%   
  group_by(Year, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDepth, na.rm = TRUE), 
            annual_mean_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>% 
  ungroup() %>% 
  dplyr::rename("year" = Year,
                "station name" = StationName, 
                "annual rain. (mm)" = total_rain_mm,
                "max snow (m)" = max_snow_m,
                "mean air temp. (°C)" = annual_mean_temp, 
                "stdev air temp. (± °C)" = temp_sd,
                "mean min. air temp. (°C)" = annual_min_temp,
                "mean max. air temp. (°C)" = annual_max_temp) %>% 
  mutate(year = as.character(year)) # to join Jan-Feb table below

b <- precip_data %>%
  mutate(Year = lubridate::year(DateTime),
         Month = lubridate::month(DateTime, label = TRUE, abbr = TRUE)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017,
         Month == "Jan" | Month == "Feb") %>%   
  mutate(JanFebYr = case_when(
    Year == 2018 ~ "Jan-Feb 2018",
    Year == 2019 ~ "Jan-Feb 2019",
    Year == 2020 ~ "Jan-Feb 2020")) %>% 
  group_by(JanFebYr, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDepth, na.rm = TRUE), 
            annual_mean_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>% 
  dplyr::rename("year" = JanFebYr,
                "station name" = StationName, 
                "annual rain. (mm)" = total_rain_mm,
                "max snow (m)" = max_snow_m,
                "mean air temp. (°C)" = annual_mean_temp, 
                "stdev air temp. (± °C)" = temp_sd,
                "mean min. air temp. (°C)" = annual_min_temp,
                "mean max. air temp. (°C)" = annual_max_temp) 

# combine as full summary table
c <- bind_rows(a, b) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/FWx_LWSA-stn-summary.csv")
```


### Mean Wx LWSA 

Arithmetic means from ChrisCrk and MartinsGulch.
```{r}
# add seasons to mean weather df
LWSA_meanWx <- precip_data %>% 
  select(DateTime, rain_season) %>%  # just want to get rain_season
  right_join(LWSA_meanWx_dat, by = "DateTime") %>% 
  distinct(DateTime, .keep_all = TRUE)  # keep only individual days (duplicates from multi- stations)

# check seasons visually
a <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(date >= "2018-10-23") %>% 
  ggplot(aes(x = DateTime, y = Rn_1_mean)) +
  geom_col(aes(colour = rain_season)) +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme(text = element_text(size = 11),
        axis.text.x = element_text(angle = 60, hjust = 1))

```

plot mean FWx 
```{r}
# mean precip plot
mean_rainplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain (mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "2 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  geom_vline(xintercept = as_date("2018-10-23"), 
             colour = brewer.pal(8, "Dark2")[4],
             linetype = "dashed", size = 0.75) +
  annotate("text", label = "Project start", angle = 90, colour = brewer.pal(8, "Dark2")[8],
           x = as_date("2018-10-23")-20, y = 90)

# plot LWSA snow
mean_snowplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_SnowMax = max(SnowDepth_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_SnowMax)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = 'Snow (m)') +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "2 months", date_minor_breaks = "1 months", labels = NULL)+ 
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  geom_vline(xintercept = as_date("2018-10-23"), 
             colour = brewer.pal(8, "Dark2")[4],
             linetype = "dashed", size = 0.75)

# plot LWSA temperature
mean_tempplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = 'Air temp (°C/day)') +
  theme_bw()+
  theme(legend.position = "none",
        text = element_text(size = 11),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  scale_x_date(date_breaks = "2 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))+
  geom_vline(xintercept = as_date("2018-10-23"), 
             colour = brewer.pal(8, "Dark2")[4],
             linetype = "dashed", size = 0.75)

# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(mean_rainplot, mean_snowplot, mean_tempplot, ncol = 1, rel_heights = c(3,3,4), align = "v")

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA-means.png", width = 6, height = 5, units = "in")
```

table: mean Wx

```{r, table_mean-FWx_summary}
# mean weather summary by year
a <- precip_data %>%
  mutate(Year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017, Year != 2020) %>%  
  group_by(Year, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDepth, na.rm = TRUE),
            annual_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>%
  ungroup() %>% 
  group_by(Year) %>%
  summarise(mean_rain_mm = mean(total_rain_mm, na.rm = TRUE),
            sd_rain_mm = sd(total_rain_mm, na.rm = TRUE),
            max_snow_m = max(max_snow_m, na.rm = TRUE),
            annual_mean_temp = mean(annual_temp, na.rm = TRUE),
            temp_sd = sd(annual_temp, na.rm = TRUE),
            annual_min_temp2 = mean(annual_min_temp, na.rm = TRUE),
            annual_max_temp2 = mean(annual_max_temp, na.rm = TRUE)) %>%
  ungroup() %>% 
  dplyr::rename("Rain (mm)" = mean_rain_mm,
                "st.dev. (± mm)" = sd_rain_mm,
                "Snow depth, max. (m)" = max_snow_m,
                "Air temp., mean (°C)" = annual_mean_temp, 
                "st.dev. air temp. (± °C)" = temp_sd,
                "Min. air temp. (°C)" = annual_min_temp2,
                "Max. air temp. (°C)" = annual_max_temp2) %>% 
  mutate(Year = as.character(Year)) # to bind to Jan-Feb table below

b <- precip_data %>%
  mutate(Year = lubridate::year(DateTime),
         Month = lubridate::month(DateTime, label = TRUE, abbr = TRUE)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017,
         Month == "Jan" | Month == "Feb") %>%   
  mutate(JanFebYr = case_when(Year == 2018 ~ "Jan-Feb 2018",
                              Year == 2019 ~ "Jan-Feb 2019",
                              Year == 2020 ~ "Jan-Feb 2020")) %>% 
  group_by(JanFebYr, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDepth, na.rm = TRUE), 
            annual_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>%
  ungroup() %>% 
  group_by(JanFebYr) %>%
  summarise(mean_rain_mm = mean(total_rain_mm, na.rm = TRUE),
            sd_rain_mm = sd(total_rain_mm, na.rm = TRUE),
            mean_max_snow_m = mean(max_snow_m, na.rm = TRUE),
            annual_mean_temp = mean(annual_temp, na.rm = TRUE),
            temp_sd = sd(annual_temp, na.rm = TRUE),
            annual_min_temp2 = mean(annual_min_temp, na.rm = TRUE),
            annual_max_temp2 = mean(annual_max_temp, na.rm = TRUE)) %>%
  ungroup() %>% 
  dplyr::rename("Year" = JanFebYr,
                "Rain (mm)" = mean_rain_mm,
                "st.dev. (± mm)" = sd_rain_mm,
                "Snow depth, max. (m)" = mean_max_snow_m,
                "Air temp., mean (°C)" = annual_mean_temp, 
                "st.dev. air temp. (± °C)" = temp_sd,
                "Min. air temp. (°C)" = annual_min_temp2,
                "Max. air temp. (°C)" = annual_max_temp2) 

# combine as full summary table
c <- bind_rows(a, b) %>% write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-mean-summary.csv")
```



## RAIN EVENTS
```{r}
majEvents_summary <- events %>%
  mutate(duration = difftime(EndDate, StartDate, units = "hours"),
         duration_days = as.numeric(difftime(EndDate, StartDate, units = "days")),
         duration_hours = as.numeric(NumberXtract(duration)),
         intensity_mmhr = rain/duration_hours,
         intensity_mm24hr = rain/duration_days,
         startDate = as_date(StartDate),
         endDate = as_date(EndDate)) %>% 
  mutate(ID = as_factor(ID))

# make a table
events_table <- majEvents_summary %>% 
  mutate(duration_days = round(as.numeric(duration_days), 1)) %>% 
  select('Storm number' = stormnum,
         'Major event no.' = ID,
         'Start Date' = startDate,
         'Duration (days)' = duration_days,
         'Rainfall (mm)' = rain,
         'Intensity (mm/24-hr)' = intensity_mm24hr) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Events.csv",
            col_names = TRUE) 

# summarize all  
events_summary <- majEvents_summary %>% 
  mutate(year = year(StartDate)) %>% 
  group_by(year) %>% 
  summarise(duration_min_days = min(duration_days),
            duration_max_days = max(duration_days),
            rain_min_mm = min(rain),
            rain_max_mm = max(rain),
            intensity_min_mmhr = min(intensity_mmhr),
            intensity_max_mmhr = max(intensity_mmhr),
            ID_duration_min = ID[which(duration_days == duration_min_days)],
            ID_duration_max = ID[which(duration_days == duration_max_days)],
            ID_rain_min = ID[which(rain == rain_min_mm)],
            ID_rain_max = ID[which(rain == rain_max_mm)],
            ID_intensity_min = ID[which(intensity_mmhr == intensity_min_mmhr)],
            ID_intensity_max = ID[which(intensity_mmhr == intensity_max_mmhr)])

# make a table
events_summary %>% 
  select(year, 
         'min. duration (days)' = duration_min_days,
         'max. duration (days)' = duration_max_days,
         'min rain (mm)' = rain_min_mm, 
         'max rain (mm)' = rain_max_mm, 
         'min intensity (mm/hr)' = intensity_min_mmhr,
         'max intensity (mm/hr)' = intensity_max_mmhr) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Events-annual_min-max.csv",
            col_names = TRUE) 

```


# TEMPERATURE (Hobo)
```{r}
# update Hobo wet temperatures 
# most sites were wet by mid-September (2019) 
# all sites water loggers were wet by Oct 15
Hobo <- Hobo_df %>% 
  mutate(Temp_C_fullwet = Temp_C)

# Cragg Creek
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & site == "CraggCrk" &
                                  Date < as_date("2019-09-15"), "NA", Temp_C_fullwet)) 
# Tunnel  
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & site == "Tunnel" & 
                                  Date < as_date("2019-10-15"), "NA", Temp_C_fullwet))

# Temp_C is numeric, update from character
Hobo <- Hobo %>% 
  mutate(Temp_C = as.numeric(Temp_C)) 

```

## plot: Hobo air/water temps time & space
```{r}
# ---- over time
Hobo %>% 
  group_by(site, TidbiT_location, Date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date, y = T_daily))+
  geom_line(aes(colour = site), size = 0.6)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  geom_hline(yintercept = 0, linetype = "dashed", colour = "darkgrey", size = 0.4)+
  facet_wrap(~TidbiT_location, ncol = 1,
             scales = "free_y",
             strip.position = "left")+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Site:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs_line-by-time_daily.png", 
       width = 6, height = 6, units = "in")


# --- over space
# update the water temperature logger time frames to be equal
# all sites water loggers were submerged by 2019-10-15  
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & 
                                  Date < as_date("2019-10-15"), "NA", Temp_C_fullwet)) 

# Temp_C is numeric, update from character
Hobo <- Hobo %>% 
  mutate(Temp_C = as.numeric(Temp_C)) 

## Boxplot
Hobo %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, TidbiT_location, date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = site, y = T_daily, fill = site))+
  geom_jitter(aes(fill = site), alpha = 0.6, shape = 21)+
  geom_boxplot(alpha = 0.4)+
  scale_fill_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~TidbiT_location, 
             ncol = 1,
             scales = "free_y",
             strip.position = "left")+
  labs(x = "", y = "Mean Daily Temperature (°C)")+
  theme(legend.position = "none", 
        text = element_text(size = 12))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs_box-by-location_daily.png", 
       width = 5.5, height = 5.5, units = "in") 
```

## Compare Hobo / LWSA
```{r}

# find overlapping ranges
Hobo %>% 
  group_by(site) %>% 
  summarize(count = n(),
            earliest = first(Date),
            latest = last(Date)) %>% 
  arrange(count)

# join the air temp from subbasins with the mean LWSA temperature data to compare
# augment Hobo df to include full range of DateTime to match to FWx df

# need FWx for each site before Hobo TidbiTs were installed
# range: start = "2018-10-23" & end = "2019-08-23"
project_start <- ymd_hms("2018-10-23 01:00:00", tz = TZ) # first overlapping field day
Hobo_start <- ymd_hms("2019-08-24 01:00:00", tz = TZ)  # all TidbiTs deployed
project_end <- ymd_hms("2020-02-18 15:00:00", tz = TZ) # last overlapping field day

# create a dataframe of full DateTimes
Hobo_FWx_joiner <- 
  # FWx data came in ever 15 minutes (Hobo ever 30 min)
  tidyr::tibble(DateTime = seq(project_start, project_end, by = "15 min")) %>% 
  # and join to wide Hobo air temp data
  full_join(Hobo %>% 
              filter(TidbiT_location == "air",
                     !is.na(site),
                     DateTime < project_end) %>% 
              select(site, DateTime, Temp_C) %>% 
              pivot_wider(names_from = site, values_from = Temp_C), 
            by = c("DateTime")) %>% 
  # then, pivot longer again so each site has a full DateTime range
  pivot_longer(cols = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"), names_to = "site", values_to = "Temp_C") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  group_by(site) 

# join FWx and Hobo
# 30 minute temp intervals from start of project to end
Hobo_WxLWSA_full <- LWSA_meanWx %>%
  select(c(DateTime, Temp_mean, rain_season)) %>%
  filter(DateTime < project_end,
         DateTime >= project_start) %>% 
  full_join(Hobo_FWx_joiner, by = c("DateTime")) %>% 
  rename(FWx = "Temp_mean", Hobo = "Temp_C") %>%
  filter(lubridate::minute(DateTime) != 15,
         lubridate::minute(DateTime) != 45) %>%  # drops 15 minute Hobo nulls
  group_by(site) %>% 
  distinct() %>% # drop duplicate rows
  mutate(Date = as_date(DateTime)) %>% 
  select(c(site, Date, DateTime, Hobo, FWx, rain_season))  # reorganize for viewing


# isolate overlapping date ranges of Hobo and FWx
Hobo_WxLWSA <- Hobo_WxLWSA_full %>% 
  filter(DateTime >= Hobo_start) 
```

* density ridge comparison
```{r}
# take dataframe with both FWx and Hobo data & pivot longer
Hobo_Fwx <- Hobo_WxLWSA %>%
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx"),
               names_to = "data_source",
               values_to = "Temp_C") %>%  
  mutate(data_source = factor(data_source)) # temps as factor levels

# density ridges by TidbiT site
Hobo_Fwx %>% 
  ggplot(aes(x = Temp_C, y = fct_rev(site)))+
  ggridges::geom_density_ridges(aes(fill = data_source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw()+
  labs(x = "Air temperature (°C)",
       y = "",
       fill = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_ridgeplot-subbasins.png", 
       width = 4, height = 4, units = "in")

# do the same but with Daily mean temperatures
Hobo_Fwx_dm <- Hobo_WxLWSA %>%
  group_by(site, Date) %>% 
  summarise(Hobo = mean(Hobo),
            FWx = mean(FWx)) %>%  # daily mean temperatures
  ungroup() %>% 
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx"),
               names_to = "data_source",
               values_to = "Tdaily") %>%  
  mutate(data_source = factor(data_source)) # temps as factor levels


# --- visual checks for overlap of time period (this should look like a single line)
# check daily temp overlap
a <- Hobo_Fwx %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(site, data_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  filter(data_source == "FWx") %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = site), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Daily mean air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# perfect :)

# check daily temp overlap too
b <- Hobo_Fwx_dm %>% 
  filter(data_source == "FWx") %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = site), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Daily mean air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

unused plot, but not bad
```{r}

# unused plot (box plot with FWx as it's own box)
# set FWx like it's a site to plot as a box adjacent to the other sites
HoboFWx_sites <- Hobo %>% 
  filter(TidbiT_location == "air",
         DateTime < project_end, DateTime >= Hobo_start) %>%
  select(site, DateTime, Temp_C, rain_season) %>% 
  pivot_wider(names_from = site, values_from = Temp_C) %>%
  left_join( # only keep dates for Hobo
    LWSA_meanWx %>% select(c(DateTime, Temp_mean)) %>% filter(DateTime < project_end, DateTime >= Hobo_start), by = c("DateTime")) %>% 
  rename(FWx = "Temp_mean") %>% 
  # then, pivot longer again so each site has a full DateTime range
  pivot_longer(cols = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel", "FWx"), names_to = "site", values_to = "Temp_C") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel", "FWx"))) 

# boxplot
# compare temps from FWx to HOBO at each site
HoboFWx_sites %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = site, y = T_daily, fill = site))+
  geom_jitter(alpha = 0.6, shape = 21)+
  geom_boxplot(alpha = 0.4)+
  scale_fill_brewer(palette = "Dark2")+
  theme_bw() +
  labs(x = "", y = "Mean Daily Air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "none", 
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1))
# save
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_box-air-by-site.png", width = 5, height = 5, units = "in")

```

## Stats: FWx-Hobo differences 

### Wilcoxon tests
```{r}
# make a comparison between subbasin hobos and the LWSA FWx data


# Test temps for normality
# Normality tests (ADD TO APPENDIX)
# density by weather station source
# these should be the same 
## -- they came from the same source & are limited to the same date range
Hobo_Fwx_dm %>% 
  ggplot(aes(Tdaily))+
  geom_density(aes(colour = site))+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~ data_source)

# check with full data set also
Hobo_Fwx %>% 
  ggplot(aes(Temp_C))+
  geom_density(aes(colour = site))+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~ data_source)

# --- 
# Wilcoxon tests (not normally distributed)

# null hypothesis: there is no difference between the means
# p-value > 0.05 --> cannot reject null hypothesis (accept that there is no sig.diff)
# p-value < 0.05 --> reject the null hypothesis

# tests
test <- Hobo_Fwx_dm$Tdaily
stn <- Hobo_Fwx_dm$data_source
site <- Hobo_Fwx_dm$site

# compare temperatures from FWx versus Hobo on-site loggers
# run tests and compile results
Temp_Wilcoxon_tests <- bind_rows(
  tidy(wilcox.test(test[stn == "FWx" & site == "Weeks"], test[stn == "Hobo" & site == "Weeks"])) %>% 
    mutate(site = "Weeks"),
  tidy(wilcox.test(test[stn == "FWx" & site == "ChrisCrk"], test[stn == "Hobo" & site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk"),
  tidy(wilcox.test(test[stn == "FWx" & site == "LeechHead"], test[stn == "Hobo" & site == "LeechHead"])) %>% 
    mutate(site = "LeechHead"),
  tidy(wilcox.test(test[stn == "FWx" & site == "CraggCrk"], test[stn == "Hobo" & site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk"),
  tidy(wilcox.test(test[stn == "FWx" & site == "WestLeech"], test[stn == "Hobo" & site == "WestLeech"])) %>% 
    mutate(site = "WestLeech"),
  tidy(wilcox.test(test[stn == "FWx" & site == "Tunnel"], test[stn == "Hobo" & site == "Tunnel"])) %>% 
    mutate(site = "Tunnel"))

# summarize p-values
Wilcoxon_Temp_summary <- Temp_Wilcoxon_tests %>% 
  select(c(Site = "site", "p-value" = "p.value")) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/TidbiT-FWx-Tdaily_Wilcoxon-pvalues.csv", col_names = TRUE)

```

### Linear Regression

plot: [1:1] FWx vs HOBO
```{r}
## plot: 1:1 scatter of temperatures -- all data
HoboFwx_lm <- Hobo_WxLWSA %>% 
  ggplot(aes(x = FWx, y = Hobo))+
  geom_point(alpha = 0.35)+
  theme_bw()+
  facet_wrap(~ site)+
  labs(y = "Site temperature (°C)", x = "FWx temperature (°C)") +
  theme(text = element_text(size = 11))+
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) +
  ## to get equations include this line:
  #stat_poly_eq(formula = y ~ x, aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), parse = TRUE, rr.digits = 4)+
  stat_poly_eq(formula = y ~ x, aes(label = ..rr.label..), parse = TRUE, rr.digits = 4)


## plot: 1:1 scatter of temperatures -- daily mean only
HoboFwx_lm_means <- Hobo_WxLWSA %>% 
  group_by(site, Date) %>% 
  summarise(Hobo = mean(Hobo),
            FWx = mean(FWx)) %>% 
  ggplot(aes(x = FWx, y = Hobo))+
  geom_point(alpha = 0.5, na.rm = TRUE)+
  theme_bw()+
  facet_wrap(~ site)+
  labs(y = "Mean daily site temperature (°C)", x = "Mean daily FWx temperature (°C)") +
  theme(text = element_text(size = 11))+
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) +
  ## to get equations include this line:
  #stat_poly_eq(formula = y ~ x, aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), parse = TRUE, rr.digits = 4)+
  stat_poly_eq(formula = y ~ x, aes(label = ..rr.label..), parse = TRUE, rr.digits = 4)

# use daily means to estimate temps -- better overlap and less scatter

# arrange plots for presentation
#cowplot::plot_grid(HoboFwx_lm, HoboFwx_lm_means, ncol = 1, Labels="AUTO")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Temp_TidbiTs-FWx_lm-scatter.png", 
       width = 4, height = 4, units = "in")

```

Relate subbasins to FWx & use linear regression to estimate temperature for each subbasin 
```{r}
# lm(y ~ x) == lm(dependent ~ independent) 
# save summary object
# use wide dataframe (Hobo_WxLWSA) rather than long(Hobo_Fwx)
sites_lm <- Hobo_WxLWSA %>% 
  filter(rain_season == "wet") %>% # more even temps once rain started
  filter(Date > "2019-08-23") %>% # insure overlapping range
  group_by(site) %>% 
  summarise(slope = coefficients(lm(formula = Hobo ~ FWx))[2],
            yint_DOC = coefficients(lm(formula = Hobo ~ FWx))[1],
            r_sq = summary(lm(formula = Hobo ~ FWx))$r.squared) 

# use linear regression to calculate earlier temperatures
Hobo_FWx_filled <- Hobo_WxLWSA_full %>% 
  group_by(site) %>% 
  mutate(Predicted = case_when(# y = m*x + b
    site == "Weeks" ~ sites_lm[[1,2]]*FWx + sites_lm[[1,3]], # [[row, column]]
    site == "ChrisCrk" ~ sites_lm[[2,2]]*FWx + sites_lm[[2,3]], 
    site == "LeechHead" ~ sites_lm[[3,2]]*FWx + sites_lm[[3,3]], 
    site == "CraggCrk" ~ sites_lm[[4,2]]*FWx + sites_lm[[4,3]], 
    site == "WestLeech" ~ sites_lm[[5,2]]*FWx + sites_lm[[5,3]], 
    site == "Tunnel" ~ sites_lm[[6,2]]*FWx + sites_lm[[6,3]]
  )) %>% 
  filter(!is.na(site))




# ---- same but for daily means
# lm(y ~ x) == lm(dependent ~ independent) 
# save summary object
# use wide dataframe (Hobo_WxLWSA) rather than long(Hobo_Fwx)
sites_lm_Tdaily <- Hobo_WxLWSA %>% 
  filter(rain_season == "wet") %>% # more even temps once rain started
  filter(Date > "2019-08-23") %>% # insure overlapping range
  group_by(site, Date) %>% 
  summarise(Hobo = mean(Hobo),
            FWx = mean(FWx)) %>%
  ungroup() %>% 
  group_by(site) %>% 
  summarise(slope = coefficients(lm(formula = Hobo ~ FWx))[2],
            yint_DOC = coefficients(lm(formula = Hobo ~ FWx))[1],
            r_sq = summary(lm(formula = Hobo ~ FWx))$r.squared) 

# use linear regression to calculate earlier temperatures
Hobo_FWx_Tdaily_filled <- Hobo_WxLWSA_full %>% 
  group_by(site, Date) %>% 
  summarise(Hobo = mean(Hobo),
            FWx = mean(FWx)) %>%
  ungroup() %>% 
  group_by(site) %>% 
  mutate(Predicted = case_when(# y = m*x + b
    site == "Weeks" ~ sites_lm_Tdaily[[1,2]]*FWx + sites_lm_Tdaily[[1,3]], # [[row, column]]
    site == "ChrisCrk" ~ sites_lm_Tdaily[[2,2]]*FWx + sites_lm_Tdaily[[2,3]], 
    site == "LeechHead" ~ sites_lm_Tdaily[[3,2]]*FWx + sites_lm_Tdaily[[3,3]], 
    site == "CraggCrk" ~ sites_lm_Tdaily[[4,2]]*FWx + sites_lm_Tdaily[[4,3]], 
    site == "WestLeech" ~ sites_lm_Tdaily[[5,2]]*FWx + sites_lm_Tdaily[[5,3]], 
    site == "Tunnel" ~ sites_lm_Tdaily[[6,2]]*FWx + sites_lm_Tdaily[[6,3]]
  )) %>% 
  filter(!is.na(site))


# ------
# table: error for overlap Hobo + estimates

# isolate overlapping date range & summarize percent error
Hobo_overlapPredictionErrors <- Hobo_FWx_filled %>% 
  filter(Date > as_date(Hobo_start), Date < as_date(project_end)) %>% 
  group_by(site) %>% 
  mutate(error = ((Hobo - Predicted)/Hobo)*100) %>%  # positive error = regression under-estimated subbasin temp
  group_by(site) %>% 
  summarise(error_mean = mean(error, na.rm = TRUE),
            #Hobo_mean = mean(Hobo, na.rm = TRUE),
            #sd_Hobo = sd(Hobo, na.rm = TRUE), 
            Hobo_median = median(Hobo, na.rm = TRUE),
            Predicted_median = median(Predicted, na.rm = TRUE),
            #Predicted_mean = mean(Predicted, na.rm = TRUE),
            #sd_Predicted = sd(Predicted, na.rm = TRUE), 
            min_Hobo = min(Hobo, na.rm = TRUE),
            min_Predicted = min(Predicted, na.rm = TRUE),
            max_Hobo = max(Hobo, na.rm = TRUE),
            max_Predicted = max(Predicted, na.rm = TRUE))

# ---- do the same but for the daily mean regression
# isolate overlapping date range & summarize percent error
Hobo_overlapPredictionErrors_Tdaily <- Hobo_FWx_Tdaily_filled %>% 
  filter(Date > as_date(Hobo_start), Date < as_date(project_end)) %>% 
  group_by(site) %>% 
  mutate(error = ((Hobo - Predicted)/Hobo)*100) %>%  # positive error = regression over-estimated subbasin temp
  group_by(site) %>% 
  summarise(error_mean = mean(error, na.rm = TRUE),
            #Hobo_mean = mean(Hobo, na.rm = TRUE),
            #sd_Hobo = sd(Hobo, na.rm = TRUE), 
            Hobo_median = median(Hobo, na.rm = TRUE),
            Predicted_median = median(Predicted, na.rm = TRUE),
            #Predicted_mean = mean(Predicted, na.rm = TRUE),
            #sd_Predicted = sd(Predicted, na.rm = TRUE), 
            min_Hobo = min(Hobo, na.rm = TRUE),
            min_Predicted = min(Predicted, na.rm = TRUE),
            max_Hobo = max(Hobo, na.rm = TRUE),
            max_Predicted = max(Predicted, na.rm = TRUE)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/TidbiT-FWx_lm_prediction-errors.csv", col_names = TRUE)

# ------ 
#### plot: lines of estimated earlier +FWx +Hobo temps

# take the study period data frame with temp estimates at each site
# pivot longer
HoboFWx_filled_L <- Hobo_FWx_Tdaily_filled %>% 
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx", "Predicted"),
               names_to = "Temp_source",
               values_to = "Temp_C") %>% 
  mutate(Temp_source = factor(Temp_source))

# visualize and compare each site
HoboFWx_filled_L %>% 
  group_by(site, Temp_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = Temp_source), size = 0.5)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~site, ncol = 1,
             scales = "free_y",
             strip.position = "right")+
  labs(x = "", y = "Air temperature (°C)",
       colour = "Temp source:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d", date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# line plot of all, not separated by site
HoboFWx_filled_L %>% 
  group_by(site, Temp_source, Date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date, y = T_daily))+
  geom_line(aes(colour = Temp_source))+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Temperature:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Temp_TidbiTs-FWx-predicted_lm.png", 
       width = 5.5, height = 7, units = "in")

```

# QA-QC ANALYSIS 
```{r}
QAQC <- sampleresults_df %>% 
  filter(sample_type == "QA-QC") %>% 
  select(-c(DateTime))

# subset for calibration verification 
# extract cal-ver concentrations from sample name (with 'str_extract()')
calver <- QAQC %>% 
  filter(site == "Lab") %>% 
  select(c(site, sample_type, sample, analysis, NPOC_ppm, SAC254_Abs.m, DOCeq_ppm)) %>% 
  mutate(cal_ver = str_extract(sample, "([0-9]{1,}+\\.[0-9]{1,}+)"),
         cal_ver = as.numeric(cal_ver),
         ID = row_number(cal_ver)) %>% 
  mutate(sample_type = case_when(
    !is.na(cal_ver) ~ "cal_ver",
    is.na(cal_ver) ~ "RO" )) 
```

## laboratory QA/QC
```{r}

### blanks 
# check lab blanks
# this is a difficult measure of precision because the RO water is not the most reliably stable
calver %>% 
  filter(sample_type == "RO",
         sample == "RO" | sample == "RO_pH<2",
         NPOC_ppm != 0) %>% 
  group_by(sample) %>% 
  summarise(count = n(),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            RSD = (sd_DOC/DOC_mean)*100)

### cal vers 
# percent error calculated as 'measured' minus 'actual'
# negative error indicates the method was under-estimating DOC concentration 
# positive error indicates the method was over-estimating DOC concentration

# check cal vers for shimadzu
a <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(NPOC_ppm),
         ID != 7, ID != 4,  # error -- did not add standard 
         cal_ver != 5.7) %>%  # true concs were not calculated
  group_by(ID) %>% 
  summarise(count = n(),
            actual = mean(cal_ver),
            measured = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            percent_error = ((measured - actual)/ actual)*100) %>% 
  ungroup() %>% 
  summarise(count = sum(count),
            error_percent_mean = mean(percent_error),
            error_percent_sd = sd(percent_error))

# check cal vers for spectrolyser
b <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(DOCeq_ppm)) %>% 
  group_by(ID) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOCeq_mean = mean(DOCeq_ppm, na.rm = TRUE),
            sd_DOCeq = sd(DOCeq_ppm, na.rm = T),
            percent_error = ((DOCeq_mean - calc)/ calc)*100) %>% 
  ungroup() %>%  
  summarise(count = sum(count),
            error_percent_mean = mean(percent_error),
            error_percent_sd = sd(percent_error))

# total cal-vers included
n_calvers_total <- QAQC %>% 
  filter(site == "Lab", sample != "RO", sample != "RO_pH<2") %>% 
  summarise(n = n())

# percent error from shimadzu
error_shimadzu <- a %>% pull(error_percent_mean)

# percent error from spectrolyser
error_spectrolyser <- b %>% pull(error_percent_mean)

# average percent error from both methods:
error_overall <- (error_shimadzu + error_spectrolyser)/2

```

## Field QA/QC

Hold-time experiments (Tunnel rack)
```{r}
# three cycles of hold time experiments (A, B , C)
# each time, 5 samples were collected (grab) while 5 were placed on the rack with siphon lids
# the held samples (rack) were collected later after sitting out
# compare results between fresh and held samples

# subset QAQC df for holdtime samples
# extract set and rep values and group sets
HT <- QAQC %>% 
  filter(site == "Tunnel",
         !is.na(NPOC_ppm)) %>% 
  select(-c(sampleStage_cm, corr_stage_cm)) %>% 
  mutate(HoldTime_set = substr(sample, 10, 10), # set A, B, C
         HoldTime_rep = substr(sample, 11, 12), # replicate 1-5 (fresh) & 6-10 (held)
         HoldTime_group = case_when(
           HoldTime_rep == c(1:5) ~ "G",  # 'fresh' grab samples
           HoldTime_rep == c(6:10) ~ "R", # 'held' rack samples
         )) %>% 
  # groups
  mutate(group = case_when(
    HoldTime_set == "A" & HoldTime_rep == c(1:5) ~ "AG", # first set grabs, 2019-10-12 (trip 16)
    HoldTime_set == "A" & HoldTime_rep == c(6:10) ~ "AR", # first set rack, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(1:5) ~ "BG", # second set grabs, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(6:10) ~ "BR", # second set rack, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(1:5) ~ "CG", # third set grabs, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(6:10) ~ "CR", # third set rack, 2019-12-16 (trip 20)
  )) 
#%>% 
# filter(sample != "HoldTime-B6") %>% 
#filter(!is.na(sample))  # -----------------change

# how many days passed between collecting fresh and held samples?
a <- HT %>% 
  group_by(HoldTime_set, Date) %>% 
  summarise(group = first(group)) %>%
  group_by(HoldTime_set) %>% 
  summarize(lapse = diff.Date(Date))

# mutate lapse to HT df
HT <- full_join(HT, a, by = "HoldTime_set") %>% 
  mutate(HoldTime_set = factor(HoldTime_set, levels = c("A", "B", "C")), 
         HoldTime_rep= as_factor(HoldTime_rep), 
         HoldTime_group = as_factor(HoldTime_group), 
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR"))) %>% 
  mutate(HT_set_labels = HoldTime_set,
         HT_group_labels = HoldTime_group)


# Join Tunnel HOBO TidbiT data with HT data
HT_Hobo <- Hobo %>% 
  filter(site == "Tunnel",
         TidbiT_location == "air") %>% 
  mutate(Date = as_date(DateTime)) %>% 
  full_join(HT, by = c("site", "trip", "event_ID", "rain_season", "Date")) %>% 
  mutate(site = factor(site),
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR")))

```

### HT tests: Wilcoxon + boxplots

HT results box plots
```{r}

# create labels for plots
HT$HT_group_labels <- fct_recode(HT$HT_group_labels, Fresh = "G", Held = "R")
HT$HT_set_labels <- fct_recode(HT$HT_set_labels, "set A (held 11 days)" = "A", "set B (held 20 days)" = "B", "set C (held 34 days)" = "C")

# plot holdtime sets for different parameters
# NPOC
a <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = NPOC_ppm, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "DOC (mg/L)", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~HT_set_labels)

# SAC 254
b <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = SAC254_Abs.m, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = expression(SAC[254]~(m^-1)), x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HT_set_labels)

#E2:E3
c <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = E2E3, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = expression(E[2]:E[3]), x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HT_set_labels)

# SUVA254
d <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = SUVA, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = expression(SUVA[254]), x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HT_set_labels)

# with Estimated DOC
#cowplot::plot_grid(a, b, c, align = "v", ncol = 1, rel_heights = c(2, 1.6, 1.6))  

# without estimated DOC
cowplot::plot_grid(a, b, c, align = "v", ncol = 1, rel_heights = c(2, 1.6, 1.6))  
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_boxplots.png", 
       height = 5, width = 6, units = "in")

```

Wilcoxon tests
```{r}

# density distribution normality 
# NPOC
a <- HT %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
aa <- ggpubr::ggqqplot(data = HT, x = "NPOC_ppm",
                       color = "HoldTime_set")

# Tests UV254 abs for normality 
b <- HT %>% 
  ggplot(aes(SAC254_Abs.m))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
bb <- ggpubr::ggqqplot(data = HT, x = "SAC254_Abs.m",
                       color = "HoldTime_set")

# Tests DOC estimate abs for normality 
c <- HT %>% 
  ggplot(aes(DOCeq_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
cc <- ggpubr::ggqqplot(data = HT, x = "DOCeq_ppm",
                       color = "HoldTime_set")
# ---
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis (at 95% confidence)
# p-value < 0.05 --> reject the null hypothesis 

# run tests and compile results
# paired (before and after)
HT_Wilcoxon_tests <- bind_rows(
  ## NPOC ---
  # set A
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "AG"], HT$NPOC_ppm[HT$group == "AR"], paired = TRUE)) %>% 
    mutate(Set = "A", Analysis = "NPOC_ppm"),
  # set B 
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "BG"], HT$NPOC_ppm[HT$group == "BR"], paired = TRUE)) %>% 
    mutate(Set = "B", Analysis = "NPOC_ppm"),
  # set C
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "CG"], HT$NPOC_ppm[HT$group == "CR"], paired = TRUE)) %>% 
    mutate(Set = "C", Analysis = "NPOC_ppm"),
  ## UV-254 ---
  # set A
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "AG"], HT$SAC254_Abs.m[HT$group == "AR"], paired = TRUE)) %>% 
    mutate(Set = "A", Analysis = "SAC254_Abs.m"),
  # set B
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "BG"], HT$SAC254_Abs.m[HT$group == "BR"], paired = TRUE)) %>% 
    mutate(Set = "B", Analysis = "SAC254_Abs.m"),
  # set C
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "CG"], HT$SAC254_Abs.m[HT$group == "CR"], paired = TRUE)) %>% 
    mutate(Set = "C", Analysis = "SAC254_Abs.m"), 
  ## SUVA ---
  # set A
  tidy(wilcox.test(HT$SUVA[HT$group == "AG"], HT$SUVA[HT$group == "AR"], paired = TRUE)) %>% 
    mutate(Set = "A", Analysis = "SUVA"),
  # set B
  tidy(wilcox.test(HT$SUVA[HT$group == "BG"], HT$SUVA[HT$group == "BR"], paired = TRUE)) %>% 
    mutate(Set = "B", Analysis = "SUVA"),
  # set C
  tidy(wilcox.test(HT$SUVA[HT$group == "CG"], HT$SUVA[HT$group == "CR"], paired = TRUE)) %>% 
    mutate(Set = "C", Analysis = "SUVA"),
  ## E2:E3 ---
  # set A
  tidy(wilcox.test(HT$E2E3[HT$group == "AG"], HT$E2E3[HT$group == "AR"], paired = TRUE)) %>% 
    mutate(Set = "A", Analysis = "E2:E3"),
  # set B
  tidy(wilcox.test(HT$E2E3[HT$group == "BG"], HT$E2E3[HT$group == "BR"], paired = TRUE)) %>% 
    mutate(Set = "B", Analysis = "E2:E3"),
  # set C
  tidy(wilcox.test(HT$E2E3[HT$group == "CG"], HT$E2E3[HT$group == "CR"], paired = TRUE)) %>% 
    mutate(Set = "C", Analysis = "E2:E3")) %>% 
  # pull values  
  select(Analysis, Set, p.value) %>% 
  # pull values of interest to summarize
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***",
                              p.value < 0.05 ~ "**",
                              p.value < 0.1 ~ "*",
                              p.value > 0.1 ~ "NA")) 


```

#### HT Results summaries

table: conc results summary
```{r}
# summarize
HT_summ <- HT %>% 
  group_by(group) %>% 
  summarise(set = first(HoldTime_set),
            lapse = first(lapse),
            count = n(),
            mean_DOC = mean(NPOC_ppm),
            sd_DOC = sd(NPOC_ppm),
            RSD_DOC = (sd_DOC/mean_DOC)*100,
            
            mean_UV254 = mean(SAC254_Abs.m),
            sd_UV254 = sd(SAC254_Abs.m),
            RSD_UV254 = (sd_UV254/mean_UV254)*100,
            
            mean_SUVA = mean(SUVA),
            sd_SUVA = sd(SUVA),
            RSD_SUVA = (sd_SUVA/mean_SUVA)*100,
            
            mean_E2E3 = mean(E2E3),
            sd_E2E3 = sd(E2E3),
            RSD_E2E3 = (sd_E2E3/mean_E2E3)*100)


# summarize percent change (DOC & UV254) for each set
# vector
HTDOCresult <- HT_summ$mean_DOC
HTUVresult <- HT_summ$mean_UV254
HTSUVAresult <- HT_summ$mean_SUVA
HTE2E3result <- HT_summ$mean_E2E3
# summarize
change <- 
  tibble(set = c("A", "B", "C"),
         percent_change_DOC = c(
           round((((HTDOCresult[2]-HTDOCresult[1])/HTDOCresult[1])*100),0),
           round((((HTDOCresult[4]-HTDOCresult[3])/HTDOCresult[3])*100),0),
           round((((HTDOCresult[6]-HTDOCresult[5])/HTDOCresult[5])*100),0)),
         percent_change_UV254 = c(
           round((((HTUVresult[2]-HTUVresult[1])/HTUVresult[1])*100),0),
           round((((HTUVresult[4]-HTUVresult[3])/HTUVresult[3])*100),0),
           round((((HTUVresult[6]-HTUVresult[5])/HTUVresult[5])*100),0)),
         percent_change_SUVA = c(
           round((((HTSUVAresult[2]-HTSUVAresult[1])/HTSUVAresult[1])*100),0),
           round((((HTSUVAresult[4]-HTSUVAresult[3])/HTSUVAresult[3])*100),0),
           round((((HTSUVAresult[6]-HTSUVAresult[5])/HTSUVAresult[5])*100),0)),
         percent_change_E2E3 = c(
           round((((HTE2E3result[2]-HTE2E3result[1])/HTE2E3result[1])*100),0),
           round((((HTE2E3result[4]-HTE2E3result[3])/HTE2E3result[3])*100),0),
           round((((HTE2E3result[6]-HTE2E3result[5])/HTE2E3result[5])*100),0)))


# pull & set values for plot + table
# set dates
HT_range <- HT %>% 
  group_by(HoldTime_set) %>% 
  summarise(start = first(Date),
            end = last(Date))

# set sample dates
HT_dates <- HT %>% 
  group_by(HoldTime_set) %>% 
  mutate(lapse = as.numeric(lapse)) %>% 
  summarise(date_fresh = as_date(first(DateTime_sampled)),
            date_held = as_date(last(DateTime_sampled)),
            lapse = mean(lapse),
            half_lapse = lapse*0.5) # for labels


# summarize mean temp +/- sd for each hold-time set
A_temp <- HT_Hobo %>% 
  filter(Date %within% interval(HT_range$start[1], HT_range$end[1])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(A_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

B_temp <- HT_Hobo %>% 
  filter(Date %within% interval(HT_range$start[2], HT_range$end[2])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(B_temp = paste(format(round(.$set_temp, 1), nsmall = 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

C_temp <- HT_Hobo %>% 
  filter(Date %within% interval(HT_range$start[3], HT_range$end[3])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(C_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()


#---
# join statistical results with Hobo results
HT_tests_summary <- HT_Wilcoxon_tests %>% 
  pivot_wider(names_from = Analysis, values_from = c("p.value", "sig.diff")) %>% 
  mutate(lapse = (HT_Hobo %>% 
                    filter(!is.na(group)) %>% 
                    group_by(HoldTime_set) %>% 
                    summarise(lapse = last(lapse)))$lapse) %>% 
  full_join(change, by = c("Set" = "set")) %>% 
  select(-c(percent_change_SUVA, sig.diff_SUVA, p.value_SUVA)) %>% # drop SUVA, focus on SAC254
  # change % change values to character & rename E2:E3 to remove colon
  mutate(percent_change_DOC = as.character(round(percent_change_DOC, 0)),
         percent_change_UV254 = as.character(round(percent_change_UV254, 0)),
         percent_change_E2E3 = as.character(round(percent_change_E2E3, 0)) ) %>% 
  rename(sig.diff_E2E3 = 'sig.diff_E2:E3') %>% 
  # combine * from significance with % change (tidier table)
  mutate(percent_change_DOC = case_when(
    sig.diff_NPOC_ppm != "NA" ~ paste0(percent_change_DOC,  sig.diff_NPOC_ppm), TRUE ~ percent_change_DOC),
    percent_change_UV254 = case_when(
      sig.diff_SAC254_Abs.m != "NA" ~ paste0(percent_change_UV254,  sig.diff_SAC254_Abs.m), TRUE ~ percent_change_UV254),
    percent_change_E2E3 = case_when(
      sig.diff_E2E3 != "NA" ~ paste0(percent_change_E2E3,  sig.diff_E2E3), TRUE ~ percent_change_E2E3)) %>% 
  select(-c(sig.diff_NPOC_ppm, sig.diff_SAC254_Abs.m, sig.diff_E2E3)) %>% 
  mutate("Air temp." = c(A_temp, B_temp, C_temp)) %>% 
  select(Set, "Days held" = lapse, 
         "Air temp.",
         "DOC change (%)" = percent_change_DOC, # rename: new = old
         "p-value (DOC)" = p.value_NPOC_ppm,
         "SAC254 change (%)" = percent_change_UV254,
         "p-value (SAC254)" = p.value_SAC254_Abs.m,
         "E2:E3 change (%)" = percent_change_E2E3,
         "p-value (E2:E3)" = 'p.value_E2:E3') %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_results-summary.csv")



# Dixon's Q-test the to reject outlier in set b 
# Q = gap / range
# if Q > Qtable, that value was an outlier
Q_SAC254 <- HT %>% filter(HoldTime_set == "B",HoldTime_group == "R") %>% 
  select(HoldTime_set, HoldTime_rep, HoldTime_group, SAC254_Abs.m) %>% 
  summarise(neighbour = SAC254_Abs.m[[2]], # Rep 7
            suspect = SAC254_Abs.m[[1]], # Rep 6
            gap = (neighbour - suspect),
            range = max(SAC254_Abs.m) - min(SAC254_Abs.m),
            Q = gap/range,
            Qtable90 = 0.642,
            Qtable85 = 0.710,
            Qtable99 = 0.821)


```

Results plot -- HT megaplot
```{r}

# pivot long
HT_Hobo_L <- HT_Hobo %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(Date) %>% 
  summarise(daily_mean_T = mean(Temp_C)) %>% 
  full_join(HT_Hobo) %>% 
  pivot_longer(cols = c(daily_mean_T, Temp_C),
               values_to = "degrees_C",
               names_to = "Temp") %>% 
  mutate(Temp = factor(Temp, levels = c("Temp_C", "daily_mean_T")))

# plot it  
HT_air_plot <- HT_Hobo_L %>% 
  ggplot(aes(x = Date, y = degrees_C))+
  geom_line(aes(colour = Temp, size = Temp))+
  scale_colour_manual(values = c(forWater_colours2[["SkyBlue"]], ## 30 minute 
                                 forWater_colours2[["DeepBlue"]]), ## daily average
                      labels = c("30 minute measurement", "Daily mean"))+
  scale_size_manual(values = c(1, 1.5), labels = c("30 minute measurement", "Daily mean"))+
  guides(colour = guide_legend("Temperature:"), size = guide_legend("Temperature:"))+
  # horizontal lines for lab refrigerator range (0-7 C)
  geom_hline(yintercept = c(0, 7), linetype = "solid", colour = "red")+
  annotate("text", label = "fridge\n range", angle = 90, colour = "red",
           x = first(HT_Hobo_L$Date)+1, y = 3.5)+
  # vertical lines for HT sample dates
  geom_vline(xintercept = c(HT_dates$date_fresh, HT_dates$date_held), 
             linetype = "dashed", colour = "black", size = 0.75) +
  annotate("text", label = c("Hold-time set:\n", paste(HT_dates$HoldTime_set, "\n")), ## set 
           x = c(HT_dates$date_fresh[1]-18, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 27)+
  annotate("text", label = c("Days:\n", paste(HT_dates$lapse, "\n")), ## time lapse
           x = c(HT_dates$date_fresh[1]-8, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 25)+
  theme_bw()+
  labs(y = "Air Temperature (°C)",
       #caption = glue::glue("Mean temperatures during vertical rack hold-time experiments: {A_temp} (set A), {B_temp} (set B), {C_temp} (set C)."),
       x = "") +
  theme(legend.position = "bottom", 
        text = element_text(size = 12)) +
  scale_x_date(date_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_airTemp_megaplot.png", width = 6, height = 5.5, units = "in")

```

# SAMPLES: augment dataframes

Categorize
```{r, mutate}

# create a "first-flush category in rain_season(s)
sampleresults <- sampleresults_df %>% 
  select(-c(DateTime)) %>% 
  mutate(rain_seasons = case_when(
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-20", "2019-03-15") ~ "wet",
    Date %within% interval("2019-03-15", "2019-05-01") ~ "wet", # snow
    Date %within% interval("2019-05-01", "2019-09-13") ~ "dry",
    event_ID == 9 ~ "first flush",
    event_ID %in% 10:18 ~ "wet")) %>% 
  mutate(rain_season = as.character(rain_season)) %>% 
  mutate(sample_type = case_when( # these were late F/P, thus not typical grab samples
    sample == "FP0531" ~ "QA-QC",
    sample == "FP0603" ~ "QA-QC",
    TRUE ~ as.character(sample_type))) %>% 
  mutate(sample_type = factor(sample_type))

# fill in any gaps and save as factors
sampleresults <- within(sampleresults, 
                        rain_seasons <- ifelse(
                          is.na(rain_seasons), rain_season, rain_seasons)) %>% 
  mutate(rain_season = factor(rain_season),
         rain_seasons = factor(rain_seasons))

# further group sites
sampleresults <- sampleresults %>% 
  mutate(site_type = case_when(
    site == "Weeks" ~ "subbasin",   
    site == "ChrisCrk" ~ "subbasin",
    site == "LeechHead"  ~ "subbasin",
    site == "CraggCrk" ~ "subbasin",
    site == "WestLeech" ~ "subbasin",
    site == "Tunnel" ~ "subbasin",
    site == "Lab" ~ "LabQAQC",
    TRUE ~ "synoptic")) %>% 
  mutate(site_type = factor(site_type),
         DateTime_sampled = as.POSIXct(DateTime_sampled, tz = TZ)) 

sampleresults$site <- fct_recode(sampleresults$site, Deception = "Deception-crk",
                                 Deception = "Deception-res")


```

add QA-QC flags to data
```{r}
# HT: flag samples with HoldTime_days >= 30 
# FFHT: flag samples with HoldTime_days >=7 days if rain_seasons == "first flush"
# OK: hold time was less than 30 days

sampleresults <- sampleresults %>% 
  mutate(QAQC_flag = case_when(
    rain_seasons == "first flush" & HoldTime_days >= 7 ~ "FFHT",
    HoldTime_days < 0 ~ "OK",
    between(HoldTime_days, 0, 20) ~ "OK",
    HoldTime_days >= 30 ~ "HT",
    TRUE ~ "OK"))

```

## subset dfs + sample counts
```{r, subsetting-campaign}

# create a subset dataframe for the six install sites for tidier calling
sixfilter <- sampleresults %>% 
  filter(site_type == "subbasin",
         analysis == "DOC",
         sample_type != "QA-QC") %>%
  mutate(site = factor(site, levels = 
                         c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech","Tunnel")),
         QAQC_flag = factor(QAQC_flag))

# make a sixfilter with only QA-QC flag OK samples
sixfilter_ok <- sixfilter %>% filter(QAQC_flag == "OK")

# add air temperatures: 
## 1. replace missing Hobo values with predicted values 
## 2. summarize mean daily air temps
## 3. join mean daily air temps with sample results by date sampled
sixfilter <- within(Hobo_FWx_Tdaily_filled, 
                    Hobo <- ifelse(is.na(Hobo), Predicted, Hobo)) %>% 
  select(site, Date, Hobo_Tmean_airDaily = "Hobo") %>% 
  group_by(site) %>% 
  right_join(sixfilter, by = c("site", "Date")) %>% 
  ungroup()

# now, six filter data has air temperatures estimated before and measured after 2019-08-24

# primary synoptic sampling sites (n > 2)
# 15 sites total
# create a subset dataframe for the synoptically sampled sites for tidier calling
synopticfilter <- sampleresults %>%
  filter(analysis == "DOC", 
         sample_type != "QA-QC") %>% 
  filter(# subbasin sites 
    site == "Weeks"|
      site == "ChrisCrk"|
      site == "LeechHead"|
      site == "CraggCrk"|
      site == "WestLeech"|
      site == "Tunnel"|
      # other sites
      site == "Rithet"|
      site == "Lazar"|
      site == "Jarvis"|
      site == "Judge"|
      site == "Leech-downstreamconf"|
      # site == "Boneyard"| ## not in WSAs - drop
      #site == "West-Jordan"| ## only two samples
      site == "Deception") %>% 
  mutate(site = factor(site, # order as you want to see them in plots
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "Jarvis", "Lazar", "CraggCrk", "WestLeech", "Leech-downstreamconf", "Tunnel", "Rithet", "Judge", "Deception"))) 
# rename funky names
synopticfilter$site <- synopticfilter$site %>% 
  plyr::revalue(c("Leech-downstreamconf" = "Leech-Beach",  ## old = new
                  "Jarvis" = "Jarvis-crk",
                  "Judge" = "Judge-crk", 
                  "Lazar" = "Lazar-crk", 
                  "Rithet" = "Rithet-crk"))

```

add additional categories for plotting groups
```{r}
# subbasin_types
# further categorize site_type
sixfilter <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "headwater",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "mainstem")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

# further categorize subbasin_types
sixfilter_sub <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "mainstem",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "outlet")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

# update stage_samples df to also include c(rain_seasons, site_type, subbasin_type, QAQC_flag)
a <- sixfilter %>% 
  select(site, trip, sample_type, sample, rain_seasons, site_type, subbasin_type, QAQC_flag) %>% 
  group_by(site)

stage_samples <- stage_samples_dat %>% group_by(site) %>% 
  full_join(a, by = c("site", "trip", "sample_type", "sample")) 

```

count samples
```{r}
# sample counts -- all samples

# how many synoptic samples were grabbed?
n_SynopticGrabs <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>%
  #group_by(site = forcats::fct_explicit_na(site)) %>% # to see which sites are included
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% pull()
# how many grab samples were grabbed (<2 per site)?
n_Grabs <- sampleresults %>% 
  dplyr::filter(sample_type == "Grab", analysis == "DOC") %>%
  summarise(grab_sample_count = n()) %>%  pull()
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack"| sample_type == "Grab") %>%
  summarise(number_of_samples = n()) %>% pull()
# Grab samples
n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  summarise(number_of_samples = n()) %>% pull()
# Rack samples
n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# Rack samples -- all including flags
n_installRackSamples_total <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# How many samples were collected overall
n_totalSamples <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                analysis == "DOC") %>%
  summarise(sample_count = n()) %>% pull()
#---
# sample counts -- OK flagged samples

# how many synoptic samples were grabbed?
n_SynopticGrabs_ok <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab" & QAQC_flag == "OK") %>%
  #group_by(site = forcats::fct_explicit_na(site)) %>% # to see which sites are included
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% pull()
# how many grab samples were grabbed (<2 per site)?
n_Grabs_ok <- sampleresults %>% 
  dplyr::filter(sample_type == "Grab", analysis == "DOC", QAQC_flag == "OK") %>%
  summarise(grab_sample_count = n()) %>%  pull()
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples_ok <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  summarise(number_of_samples = n()) %>% pull()
# Grab samples
n_installGrabSamples_ok <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  summarise(number_of_samples = n()) %>% pull()
# Rack samples
n_installRackSamples_ok <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# Rack samples -- all including flags
n_installRackSamples_total_ok <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# How many samples were collected overall
n_totalSamples_ok <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                QAQC_flag == "OK", analysis == "DOC") %>%
  summarise(sample_count = n()) %>% pull()
# ------

# for NOM samples, one file was overwritten by a lab mate (trip 5), find out how many samples were there
# note, all samples were collected at the LWSA subbasins

# trip 5 
# how many synoptic samples were grabbed?
n_SynopticGrabs_5 <- synopticfilter %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Grab") %>%
  #group_by(site = forcats::fct_explicit_na(site)) %>% # to see which sites are included
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% pull()
# how many grab samples were grabbed (<2 per site)?
n_Grabs_5 <- sampleresults %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Grab", analysis == "DOC") %>%
  summarise(grab_sample_count = n()) %>%  pull()
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples_5 <- sixfilter %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  summarise(number_of_samples = n()) %>% pull()
# Grab samples
n_installGrabSamples_5 <- sixfilter %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  summarise(number_of_samples = n()) %>% pull()
# Rack samples
n_installRackSamples_5 <- sixfilter %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# Rack samples -- all including flags
n_installRackSamples_total_5 <- sixfilter %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# Rack samples -- QA-QC OK
n_installRackSamples_5 <- sixfilter %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% pull() 
# How many samples were collected overall
n_totalSamples_5 <- sampleresults %>% filter(trip == 5) %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                analysis == "DOC") %>%
  summarise(sample_count = n()) %>% pull()
# sample counts -- UV-Vis samples

# how many synoptic samples were grabbed for UV analysis?
n_SynopticGrabs_UV <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab", !is.na(pseudo_SUVA)) %>%
  #group_by(site = forcats::fct_explicit_na(site)) %>% # to see which sites are included
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% pull() +n_SynopticGrabs_5
# how many grab samples were grabbed (<2 per site)?
n_Grabs_UV <- sampleresults %>% 
  dplyr::filter(sample_type == "Grab", analysis == "DOC", !is.na(pseudo_SUVA)) %>%
  summarise(grab_sample_count = n()) %>%  pull() + n_Grabs_5
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples_UV <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab", !is.na(pseudo_SUVA)) %>%
  summarise(number_of_samples = n()) %>% pull() + n_subbbasinSamples_5
# Grab samples
n_installGrabSamples_UV <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab", !is.na(pseudo_SUVA)) %>% 
  summarise(number_of_samples = n()) %>% pull() + n_installGrabSamples_5
# Rack samples
n_installRackSamples_UV <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack", !is.na(pseudo_SUVA)) %>% 
  summarise(number_of_samples = n()) %>% pull() + n_installRackSamples_5
# Rack samples -- all including flags
n_installRackSamples_total_UV <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack", !is.na(pseudo_SUVA)) %>% 
  summarise(number_of_samples = n()) %>% pull() + n_installRackSamples_total_5
# How many samples were collected overall
n_totalSamples_UV <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                analysis == "DOC", !is.na(pseudo_SUVA)) %>%
  summarise(sample_count = n()) %>% pull() + n_totalSamples_5

# ------
# sample counts -- UV-Vis samples OK flag

# how many synoptic samples were grabbed?
n_SynopticGrabs_UV_OK <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab", QAQC_flag == "OK", !is.na(E2E3)) %>%
  #group_by(site = forcats::fct_explicit_na(site)) %>% # to see which sites are included
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% pull()
# how many grab samples were grabbed (<2 per site)?
n_Grabs_UV_OK <- sampleresults %>% 
  dplyr::filter(sample_type == "Grab", analysis == "DOC", QAQC_flag == "OK", !is.na(E2E3)) %>%
  summarise(grab_sample_count = n()) %>%  pull()
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples_UV_OK <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab", !is.na(E2E3)) %>%
  summarise(number_of_samples = n()) %>% pull()
# Grab samples
n_installGrabSamples_UV_OK <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Grab", !is.na(E2E3)) %>% 
  summarise(number_of_samples = n()) %>% pull()
# Rack samples
n_installRackSamples_UV_OK <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack", !is.na(E2E3)) %>% 
  summarise(number_of_samples = n()) %>% pull() 
# Rack samples -- all including flags
n_installRackSamples_total_UV_OK <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack", !is.na(E2E3)) %>% 
  summarise(number_of_samples = n()) %>% pull() 
# Rack samples -- QA-QC OK
n_installRackSamples_UV_OK <- sixfilter_ok %>% 
  dplyr::filter(sample_type == "Rack", !is.na(E2E3)) %>% 
  summarise(number_of_samples = n()) %>% pull() 
# How many samples were collected overall
n_totalSamples_UV_OK <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                QAQC_flag == "OK", analysis == "DOC", !is.na(E2E3)) %>%
  summarise(sample_count = n()) %>% pull()

# --- 
# make a summary table:
tibble::tibble(samples = c("synoptic Grabs outside of monitoring sites", 
                           "opportunistic Grabs", 
                           "monitoring sites synoptic Grabs", 
                           "monitoring sites vertical Rack", 
                           "total"),
               total_DOC = c((n_SynopticGrabs - n_installGrabSamples),
                             (n_Grabs - n_SynopticGrabs), 
                             n_installGrabSamples, 
                             n_installRackSamples, 
                             n_totalSamples),
               QAQC_DOC = c((n_SynopticGrabs_ok - n_installGrabSamples_ok),
                            (n_Grabs_ok - n_SynopticGrabs_ok), 
                            n_installGrabSamples_ok, 
                            n_installRackSamples_ok, 
                            n_totalSamples_ok),
               total_UV = c((n_SynopticGrabs_UV - n_installGrabSamples_UV),
                            (n_Grabs_UV - n_SynopticGrabs_UV), 
                            n_installGrabSamples_UV, 
                            n_installRackSamples_UV, 
                            n_totalSamples_UV),
               QAQC_UV = c((n_SynopticGrabs_UV_OK-n_installGrabSamples_UV_OK),
                           (n_Grabs_UV_OK - n_SynopticGrabs_UV_OK),
                           n_installGrabSamples_UV_OK, 
                           n_installRackSamples_UV_OK, 
                           n_totalSamples_UV_OK)) %>% 
  mutate(reduc_DOC = round( (-1*((n_totalSamples_ok-n_totalSamples)/n_totalSamples)*100 ), digits = 1),
         reduc_UV = round( (-1*((n_totalSamples_UV_OK-n_totalSamples_UV)/n_totalSamples_UV)*100 ), digits = 1))  %>% 
  dplyr::select("type of sample collected" = samples, 
                "total collected & analyzed for DOC" = total_DOC,
                "data included in DOC results" = QAQC_DOC,
                "total collected & analyzed for NOM" = total_UV,
                "data included in NOM results" = QAQC_UV) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_samples-count.csv") 

# total DOC data reduction:
T_reduc_DOC = -1*((n_totalSamples_ok-n_totalSamples)/n_totalSamples)*100
T_reduc_UV = -1*((n_totalSamples_UV_OK-n_totalSamples_UV)/n_totalSamples_UV)*100

```

# Wx MegaPlots: FWx + Rv.response

```{r}
# vectors for plots:

# first extract trip start datetimes
trip_df <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Leech-FieldTrip-tracking_forWater-MSc_HMc.csv")
trip_starts <- trip_df %>% filter(!is.na(trip)) %>% pull('trip-start') %>% as.POSIXct(tz = TZ)

# and event timing 
# event times need to be in ten-min intervals to match with stage_sample
event_starts <- round_date(as.POSIXct(events$StartDate, tz = TZ), "10 min") 
event_ends <- round_date(as.POSIXct(events$EndDate, tz = TZ), "10 min")

# event IDs for labels
event_ID_labels <- events$ID 

```

Plot stage, precip, temp and snow and then create a one-page mega plot of all combined.
```{r, Wx-stage-megas-plots}
# 1 - plot snow -- use 'SnowDepth' not 'SnowDep' (clean data)
# LWSA (Chris crk and Martin's Gulch FWx stns)
subasin_snow_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Snow = factor("Snow")) %>% 
  group_by(date, Snow) %>% 
  dplyr::summarise(daily_maxsnow = max(SnowDepth_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24", date <= "2020-02-19") %>% 
  ggplot(aes(x = date, y = daily_maxsnow)) +
  geom_col(aes(colour = Snow), colour = "grey40") +
  labs(x = "", y = "m") +
  theme_bw() +
  scale_x_date(date_breaks = "2 months",
               date_minor_breaks = "1 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Snow, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0.5,0,0,0), "cm")) # top, right, bottom, left

# 2 - plot LWSA temp for the same time span
subasin_meantemp_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Temp = factor("Temp")) %>% 
  group_by(date, Temp) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24", date <= "2020-02-19") %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(aes(colour = Temp), colour = "#E69F00") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = "°C /day") +
  theme_bw() +
  scale_x_date(date_breaks = "2 months",
               date_minor_breaks = "1 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Temp, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)

# 3 - plot rainfall: mean LWSA rain for study period
subbasin_meanrain_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Rain = factor("Rain")) %>% 
  group_by(date, Rain) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24", date <= "2020-02-19") %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(aes(colour = Rain), colour = "#0072B2") +
  scale_y_reverse() +
  labs(x = "", y = "mm /day") +
  theme_bw() +
  scale_x_date(date_breaks = "2 months",
               date_minor_breaks = "1 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Rain, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)

# 4 - plot stage at each of the subbasins
stage_plot <- odyssey_data %>% 
  filter(Date >= "2018-10-24", Date <= "2020-02-19") %>%   
  ggplot(aes(x = DateTime, y = corr_stage_cm))+
  geom_line(colour = "#09A4D2")+
  theme_bw()+
  facet_wrap(~source, ncol = 1, 
             scales = "free_y",
             strip.position = "right")+
  labs(y = "River Stage (cm)", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)

# mega-plot!! 
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subasin_meantemp_plot, subbasin_meanrain_plot, stage_plot, 
                   ncol = 1, 
                   axis = "l", 
                   align = "v",
                   rel_heights = c(1,1,1,5))
# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_megaplot.png",
       width = 6, height = 8.5, units = "in")

```

secondary MegaPlots: with samples
```{r}

# Wx megaplot, with simple sample points
stage_sample_plot <- stage_samples %>% 
  filter(Date >= "2018-10-24", Date <= "2020-02-19") %>%  
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), colour = forWater_colours2["DeepBlue"], size = 0.6)+ 
  theme_bw()+
  geom_point(aes(y = sampleStage_cm), shape = 21, fill = "white", na.rm = TRUE, size = 1)+
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right")+
  labs(y = "River Stage (cm) and Sample Collection", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1), plot.margin = unit(c(0,0,0,0), "cm"),
        legend.position = "none")


# create a second megaplot with sample points included
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subasin_meantemp_plot, subbasin_meanrain_plot, stage_sample_plot, ncol = 1, axis = "l", align = "v", rel_heights = c(1,1,1,6)) 

# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_megaplot2.png",
       width = 6, height = 7.5, units = "in")


# --- baby mega plot
# with precipitation (not temp)
# add event lines 
# and simple sample points
stage_sample_event_plot <- stage_samples %>% 
  filter(Date >= "2018-10-24", Date <= "2020-02-19") %>%  
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), colour = forWater_colours2["DeepBlue"], size = 0.6)+ 
  theme_bw()+
  geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash", 
             xintercept = c(event_starts), size = 0.65, show.legend = TRUE)+ # start event
  #geom_vline(colour = forWater_colours2["SkyBlue"], linetype = "dotted", 
  #           xintercept = c(event_ends), size = 0.65, show.legend = TRUE)+ # end event
  geom_point(aes(y = sampleStage_cm), shape = 21, fill = "white", na.rm = TRUE)+
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right")+
  labs(y = "River Stage (cm) and Sample Collection", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1), plot.margin = unit(c(0,0,0,0), "cm"),
        legend.position = "none")

# create a second megaplot with sample points included
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subbasin_meanrain_plot, stage_sample_event_plot, 
                   ncol = 1, axis = "l", align = "v", rel_heights = c(1,1,6)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-subbasins_megaplot-noTemp.png",
       width = 6, height = 7.5, units = "in")

```


## Ch3 Seasonal megaplot
```{r}
# --- junior megaplot: megaplot 2 with lines indicating seasons

# pull last rain event date from 2018/2019 wet season
last_2018_rainevent <- events %>% 
  filter(ID == 8) %>%
  summarize(eventend = round_date(as.POSIXct(EndDate, tz = TZ), "10 min")) %>% 
  pull()

# pull season start dates
start_wet2018 <- stage_samples %>% ungroup() %>% 
  filter(lubridate::year(DateTime) == 2018,
         rain_seasons == "wet") %>% 
  summarize(start_wet2018 = first(DateTime)) %>% pull()

start_dry2019 <- stage_samples %>% ungroup() %>% 
  filter(lubridate::year(DateTime) == 2019,
         rain_seasons == "dry") %>% 
  summarize(start_dry2019 = first(DateTime)) %>% pull()

start_FF2019 <- stage_samples %>% ungroup() %>% 
  filter(lubridate::year(DateTime) == 2019,
         rain_seasons == "first flush") %>% 
  summarize(start_FF2019 = first(DateTime)) %>% pull()

start_wet2019 <- stage_samples %>% ungroup() %>% 
  filter(lubridate::year(DateTime) == 2019,
         rain_seasons == "wet", 
         lubridate::month(DateTime) > 9) %>% 
  summarize(start_wet2019 = first(DateTime)) %>% pull()

# make the plots

# seasons labels on rain
season_meanrain_plot <- subbasin_meanrain_plot +
  # seasons
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "dashed", 
             xintercept = as.Date(last_2018_rainevent), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_dry2019), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_FF2019), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_wet2019), size = 0.65)+
  # labels
  annotate("text", label = "rain / snow-melt", x = as.Date(last_2018_rainevent)+15, 
           y = 75, colour = "grey45")+
  annotate("text", label = "2018/2019 wet season", x = as.Date(last_2018_rainevent), 
           y = 125)+
  annotate("text", label = "2019 dry season", x = as.Date(start_dry2019)+65, 
           y = 125)+
  annotate("text", label = "first flush", x = as.Date(start_FF2019)+10, 
           y = 80, angle = 90)+
  annotate("text", label = "2019/2020 wet season", x = as.Date(start_wet2019)+75, 
           y = 125)

# update stage plot  
season_stage_sample_plot <- stage_samples %>% 
  filter(Date >= "2018-10-24", Date <= "2020-02-19") %>%  
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), colour = forWater_colours2["DeepBlue"], size = 0.6)+ 
  theme_bw()+
  geom_point(aes(y = sampleStage_cm, shape = sample_type), fill = "white", na.rm = TRUE, size = 1.5)+
  scale_shape_manual(breaks = c("Grab", "Rack"), 
                     values = c("Grab" = 24, "Rack" = 21))+ #triangle, circle
  # seasons
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "dashed", 
             xintercept = last_2018_rainevent, size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = start_dry2019, size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = start_FF2019, size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = start_wet2019, size = 0.65)+
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right")+
  labs(y = "River Stage (cm) and Sample Collection", x = "",
       shape = "sample collection method:")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 20, hjust = 1), plot.margin = unit(c(0,0,0,0), "cm"),
        legend.position = "bottom")

# update snow and temp to include season lines
# snow
season_snow_plot <- subasin_snow_plot +
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "dashed", 
             xintercept = as.Date(last_2018_rainevent), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_dry2019), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_FF2019), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_wet2019), size = 0.65)
# and temp
season_meantemp_plot <- subasin_meantemp_plot +
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "dashed", 
             xintercept = as.Date(last_2018_rainevent), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_dry2019), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_FF2019), size = 0.65)+
  geom_vline(colour = forWater_colours1["MyOrange"], linetype = "solid", 
             xintercept = as.Date(start_wet2019), size = 0.65)

# create a second megaplot with sample points included
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(season_meantemp_plot, season_meanrain_plot, season_snow_plot, season_stage_sample_plot, ncol = 1, axis = "l", align = "v", rel_heights = c(1,1,1,6)) 

# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_season-megaplot2.png", width = 7, height = 9, units = "in")
```

## Ch4 sample stage, rain events, seasons
```{r}

# plot stage, rain events, samples (by sample type) all sites - Rain only
stg_sample_plot <- stage_samples %>% 
  ggplot(aes(x = DateTime))+
  # start of rain events
  geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash", 
             xintercept = c(event_starts), size = 0.45, show.legend = TRUE)+ 
  # river stage
  geom_line(aes(y = corr_stage_cm), size = 0.5) +
  theme_bw()+
  geom_point(aes(y = sampleStage_cm, shape = sample_type, fill = sample_type), 
             na.rm = TRUE, size = 1.5)+
  scale_shape_manual(breaks = c("Grab", "Rack"), 
                     values = c("Grab" = 24, "Rack" = 21))+ #triangle, circle
  scale_fill_manual(breaks = c("Grab", "Rack"), 
                    values = c("Grab" = forWater_colours2[["MyOrange"]], 
                               "Rack" = forWater_colours2[["MyOrange"]]))+
  # seasons
  geom_vline(colour = "magenta", linetype = "solid", 
             xintercept = start_dry2019, size = 0.55)+
  geom_vline(colour = "magenta", linetype = "solid", 
             xintercept = start_FF2019, size = 0.55)+
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right")+
  labs(y = "River Stage (cm)", x = "", shape = "Sample method:")+
  scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme(text = element_text(size = 11), axis.text.x = element_text(angle = 30, hjust = 1),
        legend.position = "bottom")+
  guides(fill = guide_legend("Sample method:"), 
         shape = guide_legend("Sample method:", override.aes = list(size=2.5))) 


# update rain plot
ch3rainplot <- subbasin_meanrain_plot + 
  # start of rain events
  geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash",  
             xintercept = as.Date(c(event_starts)), size = 0.45, show.legend = TRUE)+ 
  # add seasons
  geom_vline(colour = "magenta", linetype = "solid", 
             xintercept = as.Date(start_dry2019), size = 0.55)+
  geom_vline(colour = "magenta", linetype = "solid", 
             xintercept = as.Date(start_FF2019), size = 0.55) +
  # add text labels
  annotate("text", label = "wet season", x = as.Date(start_dry2019)-65, 
           y = 125)+
  annotate("text", label = "dry season", x = as.Date(start_dry2019)+65, 
           y = 125)+
  annotate("text", label = "wet", x = as.Date(start_FF2019)+15, 
           y = 125)


# update snow plot with season lines
ch3snowplot <- subasin_snow_plot + 
  # add seasons
  geom_vline(colour = "magenta", linetype = "solid", 
             xintercept = as.Date(start_dry2019), size = 0.55)+
  geom_vline(colour = "magenta", linetype = "solid", 
             xintercept = as.Date(start_FF2019), size = 0.55) 


# plot grid 
cowplot::plot_grid(ch3snowplot, ch3rainplot, stg_sample_plot, 
                   ncol = 1, align = "v", rel_heights = c(1,1,7))

# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_Wx-stage-subbasins_megaplot_sampletype.png",  width = 6, height = 7, units = "in")
```


# CH3 RESULTS

## boxplots - all sites all samples
```{r}

# all sites -- all samples DOC
a <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>%  
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "sample collection method:")

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_DOC-boxplot_allSites-allSamples.png", width = 6.5, height = 4, units = "in")

# all sites -- all samples SAC254
b <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(SUVA < 9, between(E2E3, 3.6, 15)) %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>%  
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +  # pseudo254
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SAC[254]~(m^-1)), 
       shape = "sample collection method:") 

# all sites -- all samples SUVA
c <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(SUVA < 9, between(E2E3, 3.6, 15)) %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>%  
  ggplot(aes(x = site, y = SUVA, fill = site)) + #  pseudo_SUVA
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SUVA[254]),
       shape = "sample collection method:")

# all sites -- all samples E2E3
d <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>%
  filter(SUVA < 9, between(E2E3, 3.6, 20)) %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>%  
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "bottom",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(E[2]:E[3]), shape = "sample collection method:")

# arrange as combo
syn_box <- cowplot::plot_grid(a,b,d, ncol = 1, align = "v", labels = "AUTO",
                              rel_heights = c(1, 1, 1.4))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_boxplot_allParams-allSites-allSamples.png", width = 5, height = 8, units = "in")


```

### boxplots - wet season all sites
```{r}
dat <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") 

# all sites -- all samples DOC
a <- dat %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "sample collection method:")

# all sites -- all samples SAC254
b <- dat %>%  
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +  # pseudo254
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SAC[254]~(m^-1)), 
       shape = "sample collection method:") 

# all sites -- all samples SUVA
c <- dat %>% 
  ggplot(aes(x = site, y = SUVA, fill = site)) + #  pseudo_SUVA
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SUVA[254]),
       shape = "sample collection method:")

# all sites -- all samples E2E3
d <- dat %>% 
  filter(between(E2E3, 3.6, 20)) %>% 
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "bottom",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(E[2]:E[3]), shape = "sample collection method:")

# arrange as combo
syn_box <- cowplot::plot_grid(a,b,c,d, ncol = 1, align = "v", labels = "AUTO",
                              rel_heights = c(1, 1, 1, 1.5))

# save
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_boxplot_allParams-allSites-allSamples.png", width = 5, height = 8, units = "in")

```

### boxplots - dry season all sites
```{r}
dat <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "dry") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") 

# all sites -- all samples DOC
a <- dat %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "sample collection method:")

# all sites -- all samples SAC254
b <- dat %>%  
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +  # pseudo254
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SAC[254]~(m^-1)), 
       shape = "sample collection method:") 

# all sites -- all samples SUVA
c <- dat %>% 
  ggplot(aes(x = site, y = SUVA, fill = site)) + #  pseudo_SUVA
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_blank())+ #element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SUVA[254]),
       shape = "sample collection method:")

# all sites -- all samples E2E3
d <- dat %>% 
  filter(between(E2E3, 3.6, 20)) %>% 
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "bottom",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(E[2]:E[3]), shape = "sample collection method:")

# arrange as combo
syn_box <- cowplot::plot_grid(a,b,c,d, ncol = 1, align = "v", labels = "AUTO",
                              rel_heights = c(1, 1, 1, 1.5))

# save
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_boxplot_allParams-allSites-allSamples.png", width = 5, height = 8, units = "in")


```

spectral by season
```{r}
# E2E3
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = NPOC_ppm)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = "DOC (mg/L)", y = "")+
  facet_wrap(~rain_season)

# E2E3
synopticfilter %>% 
  filter(between(E2E3, 3.6, 15)) %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = E2E3)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = expression(E[2]:E[3]), y = "")+
  facet_wrap(~rain_season)

# SAC 254
synopticfilter %>% 
  filter(between(E2E3, 3.6, 15)) %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = SAC254_Abs.m)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = expression(SAC[254]~(m^-1)), y = "")+
  facet_wrap(~rain_season)


# what about just those algae samples collected in CraggCrk Nov 2019?
sixfilter %>% 
  filter(site == "CraggCrk", sample == "Algae") %>% 
  select(NPOC_ppm, SAC254_Abs.m, E2E3, SUVA)
# High SAC254, 
```

redundant plot: synoptic ridge, all sites
```{r, synoptic-all-sites}

# all sites
# NPOC
a <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = NPOC_ppm)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = "DOC (mg/L)", y = "")
# SAC254
b <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = SAC254_Abs.m)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = expression(SAC[254]~(m^-1)), y = "")
# SUVA
c <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = SUVA)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = expression(SUVA[254]), y = "")
# E2:E3
d <- synopticfilter %>% 
  filter(between(E2E3, 3.6, 15)) %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = E2E3)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = expression(E[2]:E[3]), y = "")

# arrange?
syn_ridge <- cowplot::plot_grid(a,b,c,d, ncol = 2)

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_ridgeplot_allParams-allSites-allSamples.png")
```


## table: DOC Mean/Min/Max synoptic sites 
```{r, Grab-synoptic-table}

# add identifier
synopticfilter <- synopticfilter %>% 
  mutate(description = case_when(
    site == "Weeks" | site == "ChrisCrk" ~ "headwater of Leech Rv., LWSA",
    site == "LeechHead" | site == "CraggCrk" | site == "WestLeech" ~ "mainstem river, LWSA",
    site == "Tunnel" ~ "inlet of Leech Tunnel, LWSA outlet",
    site == "Jarvis-crk" | site == "Lazar-crk" ~ "headwater of Cragg Crk., LWSA",
    site == "Leech-Beach" ~ "below confluence of WestLeech with Leech Rv.",
    site == "Rithet-crk" | site == "Judge-crk" ~ "key tributary to Sooke Reservoir, SWSA",
    site == "Deception" ~ "outlet of Leech Tunnel, SWSA"
  ))


# synoptic grab samples DOC concs by site
a <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, description) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T))  

# all together  
b <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "all sites", description = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) 

# tag totals summary onto site summary
bind_rows(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_DOC-Synoptic-summary.csv", col_names = T)

```

## table: NOM Mean/Min/Max synoptic sites 
```{r, Grab-synoptic-table}

# synoptic grab samples by site
# SAC254 and E2E3
a <- synopticfilter %>%
  filter(QAQC_flag == "OK",
         !is.na(pseudo254)) %>%
  filter(SUVA < 9, between(E2E3, 3.6, 15)) %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, description) %>% 
  summarize(count = n(), 
            SAC254mean = mean(SAC254_Abs.m, na.rm = T), 
            SAC254sd = sd(SAC254_Abs.m, na.rm = T),
            rsdSAC = round((SAC254sd/SAC254mean)*100, 0),
            SAC254min = min(SAC254_Abs.m, na.rm = T), 
            SAC254max = max(SAC254_Abs.m, na.rm = T),
            # E2E3
            E2E3mean = mean(E2E3, na.rm = T), 
            E2E3sd = sd(E2E3, na.rm = T),
            rsdE2E3 = round((E2E3sd/E2E3mean)*100, 0),
            E2E3min = min(E2E3, na.rm = T), 
            E2E3max = max(E2E3, na.rm = T))  

# all together  
b <- synopticfilter %>% 
  filter(QAQC_flag == "OK",
         !is.na(pseudo254)) %>% 
  filter(SUVA < 9, between(E2E3, 3.6, 15)) %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ungroup() %>% 
  summarize(site = "all sites", description = "summary",
            count = n(), 
            SAC254mean = mean(SAC254_Abs.m, na.rm = T), 
            SAC254sd = sd(SAC254_Abs.m, na.rm = T),
            rsdSAC = (SAC254sd/SAC254mean)*100,
            SAC254min = min(SAC254_Abs.m, na.rm = T), 
            SAC254max = max(SAC254_Abs.m, na.rm = T),
            # E2E3
            E2E3mean = mean(E2E3, na.rm = T), 
            E2E3sd = sd(E2E3, na.rm = T),
            rsdE2E3 = (E2E3sd/E2E3mean)*100,
            E2E3min = min(E2E3, na.rm = T), 
            E2E3max = max(E2E3, na.rm = T)) 

# tag totals summary onto site summary
bind_rows(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_NOM-Synoptic-summary.csv", col_names = T)

```
## nested catchment approach
is rack sampling downstream of a confluence the same as synoptic grab sampling upstream?

first: change synoptic sites to include upstream/downstream grouping for method comparison
```{r, message=FALSE}
# add false sites of the headwaters that only have grab samples (no rack) for plotting
# call them site_method
#1
Weeks_grab <- synopticfilter %>% 
  select(site, trip, sample_type, sample, DateTime_sampled, sampleStage_cm, analysis, NPOC_ppm, SAC254_Abs.m, SUVA, pseudo_SUVA, E2E3, rain_season, HoldTime_days, QAQC_flag, site_type) %>% 
  filter(site == "Weeks" & sample_type == "Grab") 
Weeks_grab$site <- fct_recode(Weeks_grab$site, 'Weeks crk (HW)' = "Weeks")

#2
ChrisCrk_grab <- synopticfilter %>% 
  select(site, trip, sample_type, sample, DateTime_sampled, sampleStage_cm, analysis, NPOC_ppm, SAC254_Abs.m, SUVA, pseudo_SUVA, E2E3, rain_season, HoldTime_days, QAQC_flag, site_type) %>% 
  filter(site == "ChrisCrk" & sample_type == "Grab")
ChrisCrk_grab$site <- fct_recode(ChrisCrk_grab$site, 'Chris crk (HW)' = "ChrisCrk")

#3
LeechHead_grab <- synopticfilter %>% 
  select(site, trip, sample_type, sample, DateTime_sampled, sampleStage_cm, analysis, NPOC_ppm, SAC254_Abs.m, SUVA, pseudo_SUVA, E2E3, rain_season, HoldTime_days, QAQC_flag, site_type) %>% 
  filter(site == "LeechHead" & sample_type == "Grab")
LeechHead_grab$site <- fct_recode(LeechHead_grab$site, 'Leech Head (US)' = "LeechHead")

#4
CraggCrk_grab <- synopticfilter %>% 
  select(site, trip, sample_type, sample, DateTime_sampled, sampleStage_cm, analysis, NPOC_ppm, SAC254_Abs.m, SUVA, pseudo_SUVA, E2E3, rain_season, HoldTime_days, QAQC_flag, site_type) %>% 
  filter(site == "CraggCrk" & sample_type == "Grab")
CraggCrk_grab$site <- fct_recode(CraggCrk_grab$site, 'Cragg crk (US)' = "CraggCrk")

#5
WestLeech_grab <- synopticfilter %>% 
  select(site, trip, sample_type, sample, DateTime_sampled, sampleStage_cm, analysis, NPOC_ppm, SAC254_Abs.m, SUVA, pseudo_SUVA, E2E3, rain_season, HoldTime_days, QAQC_flag, site_type) %>% 
  filter(site == "WestLeech" & sample_type == "Grab")
WestLeech_grab$site <- fct_recode(WestLeech_grab$site, 'West Leech (US)' = "WestLeech")

# then join these pseudo-sites 
pseudo <- full_join(Weeks_grab, ChrisCrk_grab) %>% 
  full_join(LeechHead_grab) %>% 
  full_join(CraggCrk_grab) %>% 
  full_join(WestLeech_grab)

# and join to synopticfilter
pseudo_synopticfilter <- full_join(synopticfilter, pseudo) %>% 
  mutate(site = factor(site, levels = c('Weeks', 'ChrisCrk', 
                                        'Weeks crk (HW)', 
                                        'Chris crk (HW)', 
                                        'Leech Head (US)', 'LeechHead',
                                        'Jarvis-crk', 'Lazar-crk', 
                                        'CraggCrk', 'Cragg crk (US)', 
                                        'WestLeech', 'West Leech (US)',
                                        'Leech-Beach', 'Tunnel', 
                                        'Rithet-crk', 'Judge-crk', 'Deception') ))

# rename
pseudo_synopticfilter$site <- fct_recode(pseudo_synopticfilter$site, 
                                         'Leech Head (DS)' = 'LeechHead',
                                         'Jarvis crk (HW)' = 'Jarvis-crk', 
                                         'Lazar crk (HW)' = 'Lazar-crk',
                                         'Cragg crk (DS)' = 'CraggCrk',
                                         'Tunnel (DS)' = 'Tunnel')

```

### boxplots - upstrm grab to dwnstrm rack + grab
```{r}
# compare synoptic grab sampling upstream to vertical rack sampling below confluence

# for weeks/chris and Leech head
a <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == "Weeks crk (HW)" | site == "Chris crk (HW)" | site == "Leech Head (DS)") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle 
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c("Weeks crk (HW)" = "#440154FF",
                               "Chris crk (HW)" =  "#482677FF",
                               "Leech Head (DS)" = "#404788FF")) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "sample collection method:")

# for Jarvis/Lazar and Cragg
b <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == 'Jarvis crk (HW)' | site == 'Lazar crk (HW)' | site == "Cragg crk (DS)") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c('Jarvis crk (HW)' = "#1F968BFF",
                               'Lazar crk (HW)' =  "#29AF7FFF",
                               "Cragg crk (DS)" = "#55C667FF")) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "sample collection method:")

# for mainstems and Tunnel
c <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == 'Leech Head (US)' | site == 'Cragg crk (US)' | site == 'West Leech (US)' | site == "Tunnel (DS)") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c("Leech Head (US)" = "#404788FF", 
                               "Cragg crk (US)" = "#55C667FF",
                               "West Leech (US)" = "#95D055FF",
                               "Tunnel (DS)" = "#FDE725FF")) +
  theme_bw() +
  theme(legend.position = "right",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24))) +
  labs(x = "", y = "DOC (mg/L)", shape = "sample:")

# arrange the plots together
ab <- cowplot::plot_grid(a, b, nrow = 1, align = "h", 
                         labels = c("A", "B"), label_size = 12)
abc <- cowplot::plot_grid(ab, c, ncol = 1, rel_heights = c(1, 1.25), 
                          labels = c("", "C"), label_size = 12)


# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_DOC-boxplot_up-down_metcompar.png", width = 6, height = 6, units = "in")

```

#### Levene's 

test for homoscedasticity in DOC
--
An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

```{r}
## check variance

#### Weeks / Chris / LeechHead
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "Weeks" ~ "up",
    site == "ChrisCrk" ~ "up",
    site == "LeechHead" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
a <- dat %>% 
  car::leveneTest(NPOC_ppm ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()

#### Jarvis / Lazar / Cragg
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "Jarvis-crk" ~ "up",
    site == "Lazar-crk" ~ "up",
    site == "CraggCrk" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
b <- dat %>% 
  car::leveneTest(NPOC_ppm ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()


#### upstream rivers and Tunnel  
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "LeechHead" | 
           site == "CraggCrk" | 
           site == "WestLeech" | 
           site == "Tunnel") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "LeechHead" ~ "up",
    site == "CraggCrk" ~ "up",
    site == "WestLeech" ~ "up",
    site == "Tunnel" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
c <- dat %>% 
  car::leveneTest(NPOC_ppm ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()
```

##### SAC254 comparison - upstrm grab to dwnstrm rack + grab
```{r}
# compare synoptic grab sampling upstream to vertical rack sampling below confluence

# for weeks/chris and Leech head
a <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == "Weeks crk (HW)" | site == "Chris crk (HW)" | site == "Leech Head (DS)") %>% 
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle 
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c("Weeks crk (HW)" = "#440154FF",
                               "Chris crk (HW)" =  "#482677FF",
                               "Leech Head (DS)" = "#404788FF")) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression( SAC[254] ~ (m^-1) ), shape = "sample collection method:")

# for Jarvis/Lazar and Cragg
b <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == 'Jarvis crk (HW)' | site == 'Lazar crk (HW)' | site == "Cragg crk (DS)") %>% 
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c('Jarvis crk (HW)' = "#1F968BFF",
                               'Lazar crk (HW)' =  "#29AF7FFF",
                               "Cragg crk (DS)" = "#55C667FF")) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression( SAC[254] ~ (m^-1) ), shape = "sample collection method:")

# for mainstems and Tunnel
c <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == 'Leech Head (US)' | site == 'Cragg crk (US)' | site == 'West Leech (US)' | site == "Tunnel (DS)") %>% 
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c("Leech Head (US)" = "#404788FF", 
                               "Cragg crk (US)" = "#55C667FF",
                               "West Leech (US)" = "#95D055FF",
                               "Tunnel (DS)" = "#FDE725FF")) +
  theme_bw() +
  theme(legend.position = "right",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24))) +
  labs(x = "", y = expression( SAC[254] ~ (m^-1) ), shape = "sample:")

# arrange the plots together
ab <- cowplot::plot_grid(a, b, nrow = 1, align = "h", 
                         labels = c("A", "B"), label_size = 12)
abc <- cowplot::plot_grid(ab, c, ncol = 1, rel_heights = c(1, 1.25), 
                          labels = c("", "C"), label_size = 12)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_SAC254-boxplot_up-down_metcompar.png", width = 6, height = 6, units = "in")


#### Levene's 

#test for homoscedasticity in SAC254

#An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

#If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

## check variance

#### Weeks / Chris / LeechHead
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "Weeks" ~ "up",
    site == "ChrisCrk" ~ "up",
    site == "LeechHead" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
a <- dat %>% 
  car::leveneTest(SAC254_Abs.m ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()

#### Jarvis / Lazar / Cragg
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "Jarvis-crk" ~ "up",
    site == "Lazar-crk" ~ "up",
    site == "CraggCrk" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
b <- dat %>% 
  car::leveneTest(SAC254_Abs.m ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()


#### upstream rivers and Tunnel  
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "LeechHead" | 
           site == "CraggCrk" | 
           site == "WestLeech" | 
           site == "Tunnel") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "LeechHead" ~ "up",
    site == "CraggCrk" ~ "up",
    site == "WestLeech" ~ "up",
    site == "Tunnel" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
c <- dat %>% 
  car::leveneTest(SAC254_Abs.m ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()

```

##### E2E3 comparison - upstrm grab to dwnstrm rack + grab
```{r}
# compare synoptic grab sampling upstream to vertical rack sampling below confluence

# for weeks/chris and Leech head
a <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == "Weeks crk (HW)" | site == "Chris crk (HW)" | site == "Leech Head (DS)") %>% 
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle 
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c("Weeks crk (HW)" = "#440154FF",
                               "Chris crk (HW)" =  "#482677FF",
                               "Leech Head (DS)" = "#404788FF")) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression( E[2]:E[3] ), shape = "sample collection method:")

# for Jarvis/Lazar and Cragg
b <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(E2E3 < 20) %>% 
  filter(site == 'Jarvis crk (HW)' | site == 'Lazar crk (HW)' | site == "Cragg crk (DS)") %>% 
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c('Jarvis crk (HW)' = "#1F968BFF",
                               'Lazar crk (HW)' =  "#29AF7FFF",
                               "Cragg crk (DS)" = "#55C667FF")) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression( E[2]:E[3] ), shape = "sample collection method:")

# for mainstems and Tunnel
c <- pseudo_synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(site == 'Leech Head (US)' | site == 'Cragg crk (US)' | site == 'West Leech (US)' | site == "Tunnel (DS)") %>% 
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(shape = sample_type), alpha = 0.6) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  geom_boxplot(alpha = 0.5, outlier.shape = 4) +
  scale_fill_manual(values = c("Leech Head (US)" = "#404788FF", 
                               "Cragg crk (US)" = "#55C667FF",
                               "West Leech (US)" = "#95D055FF",
                               "Tunnel (DS)" = "#FDE725FF")) +
  theme_bw() +
  theme(legend.position = "right",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24))) +
  labs(x = "", y = expression( E[2]:E[3] ), shape = "sample:")

# arrange the plots together
ab <- cowplot::plot_grid(a, b, nrow = 1, align = "h", 
                         labels = c("A", "B"), label_size = 12)
abc <- cowplot::plot_grid(ab, c, ncol = 1, rel_heights = c(1, 1.25), 
                          labels = c("", "C"), label_size = 12)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_E2E3-boxplot_up-down_metcompar.png", width = 6, height = 6, units = "in")

```

```{r}

#### Levene's 

#test for homoscedasticity in SAC254

#An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

#If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

## check variance

#### Weeks / Chris / LeechHead
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "Weeks" ~ "up",
    site == "ChrisCrk" ~ "up",
    site == "LeechHead" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
a <- dat %>% 
  car::leveneTest(E2E3 ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()

#### Jarvis / Lazar / Cragg
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "Jarvis-crk" ~ "up",
    site == "Lazar-crk" ~ "up",
    site == "CraggCrk" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
b <- dat %>% 
  car::leveneTest(E2E3 ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()


#### upstream rivers and Tunnel  
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "LeechHead" | 
           site == "CraggCrk" | 
           site == "WestLeech" | 
           site == "Tunnel") %>% 
  ungroup() %>% 
  mutate(UPDWN = case_when(
    site == "LeechHead" ~ "up",
    site == "CraggCrk" ~ "up",
    site == "WestLeech" ~ "up",
    site == "Tunnel" ~ "down")) %>% 
  mutate(UPDWN = factor(UPDWN))
# check for homoscedasticity
c <- dat %>% 
  car::leveneTest(E2E3 ~ UPDWN, data = .) %>% 
  tidy() %>% 
  pull("p.value") %>% first()

```

### Ch3? spatial variance DOC Samples

*table + boxplot: Mean/Min/Max DOC 

#### table - DOC ranges
tabulate DOC mean/min/max (descriptive stats summary)

Relative standard deviation (RSD) reflects how values range around the mean within a group; it is a ratio of the absolute standard deviation relative to the mean and standard deviation is the square root of the variance.
```{r, all-samples-together}
# grouped-summary by site & sample-type 
a <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() %>%
  bind_rows(
    # grouped-summary by sample-type only  
    sixfilter %>%
      filter(QAQC_flag == "OK") %>% 
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      group_by(sample_type) %>% 
      summarize(site = "All sites",
                count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T), 
                RSD = round((DOCsd/DOCmean)*100, 0),
                DOCmin = min(NPOC_ppm, na.rm = T), 
                DOCmedian = median(NPOC_ppm, na.rm = T), 
                DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
      ungroup()) %>% 
  bind_rows(
    # un-grouped summary
    sixfilter %>%
      filter(QAQC_flag == "OK") %>%
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      summarize(site = "ALL SITES",
                sample_type = "SUMMARY",
                count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T), 
                RSD = round((DOCsd/DOCmean)*100, 0),
                DOCmin = min(NPOC_ppm, na.rm = T), 
                DOCmedian = median(NPOC_ppm, na.rm = T), 
                DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
      select(site, sample_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
      ungroup()) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-sixsite_summary_sample-type.csv", col_names = T)


# calculate range of DOC within each site and between each site for subbasins
# subbasin samples DOC concs (Grab + Rack) -- summarized by subbasin sub-type (nested catchments)
b <- sixfilter_sub %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(subbasin_type = first(subbasin_type),
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() %>% 
  bind_rows( #  grouped by headwaters / mainstem / outlet
    sixfilter_sub %>%
      filter(QAQC_flag == "OK") %>% 
      filter(sample_type == "Grab" | sample_type == "Rack",
             subbasin_type != "outlet") %>% 
      group_by(subbasin_type) %>% 
      summarize(site = "summary",
                count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T),
                RSD = (DOCsd/DOCmean)*100,
                DOCmin = min(NPOC_ppm, na.rm = T), 
                DOCmedian = median(NPOC_ppm, na.rm = T), 
                DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
      select(site, subbasin_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
      ungroup()) %>% 
  bind_rows( # nested catchment summary
    sixfilter_sub %>%
      filter(QAQC_flag == "OK") %>% 
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      filter(subbasin_type != "outlet") %>% 
      summarize(site = "summary",
                subbasin_type = "all nested catchments (sites 1-5)",
                count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T), 
                RSD = (DOCsd/DOCmean)*100,
                DOCmin = min(NPOC_ppm, na.rm = T), 
                DOCmedian = median(NPOC_ppm, na.rm = T), 
                DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
      ungroup()) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Subbasin_summary_CategoryIntegration.csv", col_names = T)

```


#### six-site nested - Levene's test for homoscedasticity in DOC

Q1: is the variance at the watershed outlet greater than the variance in each subbasin?
Q2: is the variance greater within each site or among all sites?

hypo- there is greater variance within each site compared to the variance among all sites 
hypo- the variance within each site is not greater than variance among all sites 

--
An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 

```{r}
# check for normality
sixfilter %>%
  filter(QAQC_flag != "FFHT") %>%
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ site,
             nrow = 3,
             scales = "free_y")
# Weeks is nearly normal, the others are not

# car::leveneTest(response ~ independent variable)
sixfilter %>% filter(QAQC_flag != "FFHT") %>% car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  tidy() %>% pull("p.value") %>% first()
# --> reject Ho, variance is not homogeneous across the LWSA 


# find out where:

# headwaters
# 1-2
WC <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "Weeks" | site == "ChrisCrk") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 1-3
H1 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "Weeks" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 2-3  
H2 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "ChrisCrk" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# all headwaters
Head2Head <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems
# 3-4   
H4 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "CraggCrk" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 3-5 
H5 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "WestLeech" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-5
C5 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "WestLeech" | site == "CraggCrk") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# all mainstems
main2main <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "CraggCrk" | site == "WestLeech" |site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems and outlet
# 3-6
H6 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "LeechHead" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-6 
C6 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "CraggCrk" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 5-6   
W6 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "WestLeech" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()


# write a summary table
Levenes_summary_DOC <- tibble::tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk",
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"), 
  p.value = c(WC, H1, H2, 
              H4, H5, C5, 
              H6, C6, W6)) %>% 
  mutate("Significance" = # (confidence level: ***99%, **95%, *90%)
           case_when(p.value < 0.01 ~ "***",
                     p.value < 0.05 ~ "**",
                     p.value < 0.1 ~ "*",
                     p.value > 0.1 ~ "homoscedastic")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-stats_variance-LeveneTests.csv", col_names = T)

```

#### synoptic nested -- Levene's test for homoscedasticity in DOC

Q1: is the variance at the watershed outlet greater than the variance in each subbasin?
Q2: is the variance greater within each site or among all sites?

hypo- there is greater variance within each site compared to the variance among all sites 
hypo- the variance within each site is not greater than variance among all sites 

--
An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 

```{r}
# check for normality
synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead" | 
           site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk" |
           site == "WestLeech" | site == "Tunnel") %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ site,
             nrow = 3,
             scales = "free_y")
# Weeks is nearly normal, the others are not

# car::leveneTest(response ~ independent variable)
synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead" | 
           site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk" |
           site == "WestLeech" | site == "Tunnel") %>%
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  tidy() %>% pull("p.value") %>% first()
# --> reject Ho, variance is not homogeneous across the LWSA 


# find out where:
dat <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>%
  filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead" | 
           site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk" |
           site == "WestLeech" | site == "Tunnel") 

# headwaters and Leech
HWL <- dat %>% filter(site == "Weeks" | site == "ChrisCrk" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# headwaters and Cragg
# 1-3
HWC <- dat %>% filter(site == "Jarvis-crk" | site == "Lazar-crk" | site == "CraggCrk") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# upstream rivers and Tunnel  
UPDS <- dat %>% filter(site == "LeechHead" | site == "CraggCrk" | site == "WestLeech" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

```

```
# write a summary table
Levenes_DOC <- tibble::tibble(
"Comparison Group" = c("headwaters to Leech", "headwaters to Cragg", "mainstem to outlet"),
"Site Comparison" = c("Weeks & Chris creeks (HW) and LeechHead (DS)", 
"Jarvis & Lazar creeks (HW) and CraggCrk (DS)", 
"LeechHead & CraggCrk & WestLeech (US) and Tunnel (DS)"),
"DOC p-value" = c(HWL, HWC, UPDS)) %>% 
mutate("Significance" = # (confidence level: ***99%, **95%, *90%)
case_when("DOC p-value" < 0.01 ~ "***",
"DOC p-value" < 0.05 ~ "**",
"DOC p-value" < 0.1 ~ "*",
"DOC p-value" > 0.1 ~ "homoscedastic")) 
#write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-stats_variance-LeveneTests.csv", col_names = T)

```

### Temporal

temporal plot: DOC~time subbasin geom_smooth 

#### Loess plots all sites all samples

```{r}
# DOC
synopticfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm)) +
  theme_bw() +
  geom_jitter(aes(fill = site, shape = sample_type), size = 2, alpha = 0.5)+
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24)) + #circle, triangle   
  geom_smooth(linetype = 1, se = FALSE, colour = "#481567FF", size = 0.8)+
  scale_colour_viridis(discrete = TRUE, guide = FALSE) +
  scale_fill_viridis(discrete = TRUE, guide = FALSE) +
  labs(y = "DOC (mg/L)", x = "", shape = "Sample type:") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1), 
        legend.position = "top",
        text = element_text(size = 12))+
  scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_DOC-loess-trend.png", width = 6, height = 4, units = "in")

# E2:E3
d <- synopticfilter %>%
  filter(between(E2E3, 2.5, 15)) %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = E2E3)) +
  theme_bw() +
  geom_jitter(aes(fill = site, shape = sample_type), size = 2, alpha = 0.4)+
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24)) + #circle, triangle     
  geom_smooth(linetype = 1, se = FALSE, colour = "#481567FF", size = 0.8)+
  scale_colour_viridis(discrete = TRUE, guide = FALSE) +
  scale_fill_viridis(discrete = TRUE, guide = FALSE) +
  labs(y = expression(E[2]:E[3]), x = "", shape = "Sample type:") +
  guides(fill = guide_legend("Site:"),
         colour = guide_legend("Site:"))+
  theme(axis.text.x = element_text(angle = 30, hjust = 1), 
        legend.position = "none",
        text = element_text(size = 12))+
  scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_E2E3-loess-trend.png", width = 6, height = 4, units = "in")

# DOC and E2E3 are interesting
# insufficient data for SUVA and SAC254

# how many samples?
n_E2E3 <- synopticfilter %>%
  filter(!is.na(E2E3)) %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Rack" | sample_type == "Grab") %>%
  summarize(count = n())

# how many samples?
n_DOC <- synopticfilter %>%
  filter(!is.na(NPOC_ppm)) %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Rack" | sample_type == "Grab") %>%
  summarize(count = n())


# try arranging them as grid
cowplot::plot_grid(a, d, nrow = 2, align = "v")

```

### Seasonal dynamics 

throw this away, I think:
```
# count dry season samples
n_dry_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "dry") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet season samples
n_wet_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "wet") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# how many total samples?
n_Synoptic_total_OK <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab",
                #!is.na(DOCeq_ppm),
                QAQC_flag == "OK") %>% summarise(samples = n()) %>% pull()
# how many rack samples?
n_Synoptic_rack_OK <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack",
                #!is.na(DOCeq_ppm),
                QAQC_flag == "OK") %>% summarise(samples = n()) %>% pull()
# how many grab samples?
n_Synoptic_grab_OK <- synopticfilter %>% 
  dplyr::filter(sample_type == "Grab",
                #!is.na(DOCeq_ppm),
                QAQC_flag == "OK") %>% summarise(samples = n()) %>% pull()


##  subbasin samples for which DOC and UV surrogate were measured ---

# count samples for both DOC and DOC_eq
n_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                !is.na(DOCeq_ppm),
                QAQC_flag == "OK") %>%
  #group_by(site) %>% 
  summarise(samples = n()) %>% pull()

#count wet samples
n_wet_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                !is.na(DOCeq_ppm),
                QAQC_flag == "OK",
                rain_seasons == "wet") %>%
  #group_by(site) %>% 
  summarise(samples = n()) %>% pull()

# count dry samples 
n_dry_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                !is.na(DOCeq_ppm),
                QAQC_flag == "OK",
                rain_seasons == "dry") %>%
  #group_by(site) %>% 
  summarise(samples = n()) %>% pull()

# count wet = "first flush" samples 
n_ff_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                !is.na(DOCeq_ppm),
                QAQC_flag == "OK",
                rain_seasons == "first flush") %>%
  #group_by(site) %>% 
  summarise(samples = n()) %>% pull()

# make a tibble
tibble("category" = c("total", "wet season", "dry season", "first-flush"),
       "sample count" = c(n_DOCCDOM, n_wet_DOCCDOM, n_dry_DOCCDOM, n_ff_DOCCDOM))

```

#### [1:1] scatter 
```{r}
# how many samples were colelcted by season for which both NPOC and SAC254 data were avaialble and OK?
synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack",
         !is.na(NPOC_ppm) & !is.na(SAC254_Abs.m)) %>% 
  group_by(rain_seasons) %>% 
  summarise(samples = n()) 


# CDOM vs NPOC by season
DOCNPOC <- synopticfilter %>% 
  filter(!is.na(rain_seasons)) %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 1.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  ylim(0, 20) + xlim(0, 20)+
  labs(y = "DOC estimate (ppm eqv.)",
       x = "DOC (mg/L)")+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 9),
        legend.position = "none")

# ---
# SAC254 vs NPOC by season
SAC <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = SAC254_Abs.m)) +
  geom_jitter(aes(fill = rain_seasons, shape = rain_seasons), size = 3.5, alpha = 0.8) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  #geom_smooth(aes(colour = rain_seasons, group = rain_seasons), method = "lm") +
  #scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
  #                             "dry" = forWater_colours2[["MyOrange"]], 
  #                             "first flush" = cbPalette[["grey"]]))+
  # equations
  #ggpmisc::stat_poly_eq(formula = y ~ x, 
  #            aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
  #            parse = TRUE, rr.digits = 4) +
  labs(y = expression(SAC[254]~(m^-1)),
       x = "DOC (mg/L)")+
  theme_bw() +
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 11),
        legend.position = "top")

# correlation coefficients
synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(analysis == "DOC", rain_seasons == "first flush", # "wet" / "dry"
                sample_type == "Grab" | sample_type == "Rack") %>%
  select(NPOC_ppm, SAC254_Abs.m) %>% 
  filter(!is.na(NPOC_ppm), !is.na(SAC254_Abs.m)) %>% 
  cor()
# ---



# inset the SAC254 plot into the NPOC DOCest plot
cowplot::ggdraw() +
  draw_plot(DOCNPOC) +
  draw_plot(plot = SAC,
            x = .1, # x location of inset placement
            y = .575, # y location of inset placement
            width = .3, # Inset width
            height = .3, # Inset height
            scale = 1) # Inset scale (1 = none)
#save image
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch2_DOC-CDOM_seasonal_with-Inset.png", height = 5, width = 5, units = "in")


# inset the DOC est plot into the NPOC-SAC254 plot 
cowplot::ggdraw() +
  draw_plot(SAC) +
  draw_plot(plot = DOCNPOC,
            x = .67, # x location of inset placement
            y = .2, # y location of inset placement
            width = .3, # Inset width
            height = .3, # Inset height
            scale = 1) # Inset scale (1 = none)
#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_DOC-SAC254_seasonal_with-Inset.png",
       height = 4.5, width = 4.5, units = "in")


```

E2:E3 & SUVA

neither are very helpful
```{r}
# E2:E3
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack",
                between(E2E3, 2.5, 15)) %>% 
  ggplot(aes(x = SUVA, y = E2E3 )) +
  geom_jitter(aes(fill = rain_seasons, shape = rain_seasons), alpha = 0.8, size = 3.5) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  theme_bw() +
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 11),
        legend.position = "top") 

# that's not very helpful --- not sure how to look at this

# ---
# SUVA vs NPOC by season
synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(analysis == "DOC", 
         sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = SUVA)) +
  geom_jitter(aes(fill = rain_seasons, shape = rain_seasons), size = 3.5, alpha = 0.8) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  ylim(0.2, 4.5) +
  labs(y = expression(paste("SUVA "[254])),
       x = "DOC (mg/L)")+
  theme_bw() +
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 11),
        legend.position = "top")
#save image
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_SUVA-NPOC.png", height = 3.5, width = 5, units = "in")
```


##### Seasonal Sample Method

For DOC
```{r}
# Concentration
# how many samples were collected seasonally?
conc_seas <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(rain_season) %>% 
  summarize(conc_count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            #DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (sd(NPOC_ppm, na.rm = T)/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>%
  ungroup() %>% 
  bind_rows( synopticfilter %>%
               filter(QAQC_flag == "OK") %>%
               filter(sample_type == "Grab" | sample_type == "Rack") %>% 
               summarize(rain_season = "overall",
                         conc_count = n(), 
                         DOCmean = mean(NPOC_ppm, na.rm = T), 
                         #DOCsd = sd(NPOC_ppm, na.rm = T), 
                         RSD = (sd(NPOC_ppm, na.rm = T)/DOCmean)*100,
                         DOCmin = min(NPOC_ppm, na.rm = T), 
                         DOCmedian = median(NPOC_ppm, na.rm = T), 
                         DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
               ungroup()) %>%
  mutate(mean_RSD = paste0(round(DOCmean, 2), " ± ", round(RSD, 0), "%")) %>% 
  select(rain_season, conc_count, mean_RSD, DOCmin, DOCmedian, DOCmax) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_seasonal-samples-DOC-summary.csv")


# Character
# how many samples were collected seasonally?
char_seas <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack",
         !is.na(SAC254_Abs.m)) %>% 
  group_by(rain_season) %>% 
  summarize(char_count = n(),
            SACmean = mean(SAC254_Abs.m, na.rm = T), 
            SACRSD = (sd(SAC254_Abs.m, na.rm = T)/SACmean)*100,
            SACmin = min(SAC254_Abs.m, na.rm = T), 
            SACmedian = median(SAC254_Abs.m, na.rm = T), 
            SACmax = max(SAC254_Abs.m, na.rm = T) #,
            # E2E3count = length(!is.na(E2E3)), # same as SAC254
            #E2E3mean = mean(E2E3, na.rm = T), 
            #E2E3RSD = (sd(E2E3, na.rm = T) /E2E3mean)*100,
            #E2E3min = min(E2E3, na.rm = T), 
            #E2E3median = median(E2E3, na.rm = T), 
            #E2E3max = max(E2E3, na.rm = T)
  ) %>%
  ungroup() %>% 
  bind_rows(synopticfilter %>%
              filter(QAQC_flag == "OK") %>%
              filter(sample_type == "Grab" | sample_type == "Rack",
                     !is.na(SAC254_Abs.m)) %>% 
              summarize(rain_season = "overall",
                        char_count = n(), 
                        SACmean = mean(SAC254_Abs.m, na.rm = T), 
                        SACRSD = (sd(SAC254_Abs.m, na.rm = T) /SACmean)*100,
                        SACmin = min(SAC254_Abs.m, na.rm = T), 
                        SACmedian = median(SAC254_Abs.m, na.rm = T), 
                        SACmax = max(SAC254_Abs.m, na.rm = T) #,
                        #E2E3mean = mean(E2E3, na.rm = T), 
                        #E2E3RSD = (sd(E2E3, na.rm = T) /SACmean)*100, 
                        #E2E3min = min(E2E3, na.rm = T), 
                        #E2E3median = median(E2E3, na.rm = T), 
                        #E2E3max = max(E2E3, na.rm = T)
              ) %>% 
              ungroup()) %>%
  mutate(mean_RSD_SAC = paste0(round(SACmean, 2), " ± ", round(SACRSD, 0), "%") #,
         #mean_RSD_E2E3 = paste0(round(E2E3mean, 2), " ± ", round(E2E3RSD, 0), "%")
  ) %>% 
  select( rain_season, char_count, 
          mean_RSD_SAC, SACmin, SACmedian, SACmax #, 
          # mean_RSD_E2E3, E2E3min, E2E3median, E2E3max
  ) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_seasonal-samples-NOM-summary.csv")


# --- THIS IS THE ONE

# Join conc & character
full_join(conc_seas, char_seas, by = "rain_season") %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_seasonal-summary_conc-char.csv")


```


###### wet season & monitoring sites only

```{r}
# Concentration

# --- overall 

# in only the wet season & LWSA monitoring sites...
a <- sixfilter %>%
  filter(QAQC_flag == "OK",
         rain_season == "wet") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(sample_type) %>% 
  summarize(conc_count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>%
  ungroup() %>% 
  bind_rows(sixfilter %>%
      filter(QAQC_flag == "OK",
             rain_season == "wet") %>%
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      summarize(sample_type = "all",
                conc_count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T), 
                RSD = round((DOCsd/DOCmean)*100, 0),
                DOCmin = min(NPOC_ppm, na.rm = T), 
                DOCmedian = median(NPOC_ppm, na.rm = T), 
                DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
      ungroup() ) %>% 
  mutate(mean_RSD = paste0(round(DOCmean, 2), " ± ", round(RSD, 0), "%")) %>% 
  select(sample_type, conc_count, mean_RSD, DOCmin, DOCmedian, DOCmax) 

# Character
# in only the wet season in LWSA monitoring sites...
b <- sixfilter %>%
  filter(QAQC_flag == "OK",
         rain_season == "wet") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(!is.na(SAC254_Abs.m)) %>% 
  group_by(sample_type) %>% 
  summarize(char_count = n(), 
            SACmean = mean(SAC254_Abs.m, na.rm = T), 
            SACsd = sd(SAC254_Abs.m, na.rm = T), 
            RSD = round((SACsd/SACmean)*100, 0),
            SACmin = min(SAC254_Abs.m, na.rm = T), 
            SACmedian = median(SAC254_Abs.m, na.rm = T), 
            SACmax = max(SAC254_Abs.m, na.rm = T)) %>%
  ungroup() %>% 
  bind_rows(sixfilter %>%
      filter(QAQC_flag == "OK",
             rain_season == "wet",
             !is.na(SAC254_Abs.m)) %>%
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      summarize(sample_type = "all",
                char_count = n(), 
                SACmean = mean(SAC254_Abs.m, na.rm = T), 
                SACsd = sd(SAC254_Abs.m, na.rm = T), 
                RSD = round((SACsd/SACmean)*100, 0),
                SACmin = min(SAC254_Abs.m, na.rm = T), 
                SACmedian = median(SAC254_Abs.m, na.rm = T), 
                SACmax = max(SAC254_Abs.m, na.rm = T)) %>% 
      ungroup()) %>% 
  mutate(mean_RSD_SAC = paste0(round(SACmean, 2), " ± ", round(RSD, 0), "%") ) %>% 
  select(sample_type, char_count, 
          mean_RSD_SAC, SACmin, SACmedian, SACmax) 

# Join conc & character
full_join(a, b, by = c("sample_type") ) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_wet-season-summary_conc-char_overall.csv")

# -- each site


# Concentration
# samples by site and sample_type in the wet season only
conc_wet <- sixfilter %>%
  filter(QAQC_flag == "OK",
         rain_season == "wet") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, sample_type) %>% 
  summarize(conc_count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            RSD = (sd(NPOC_ppm, na.rm = T)/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>%
  ungroup() %>% 
  mutate(mean_RSD = paste0(round(DOCmean, 2), " ± ", round(RSD, 0), "%")) %>% 
  select(site, sample_type, conc_count, mean_RSD, DOCmin, DOCmedian, DOCmax) 


# Character
# samples by site and sample_type in the wet season only
char_wet <- sixfilter %>%
  filter(QAQC_flag == "OK",
         rain_season == "wet") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack",
         !is.na(SAC254_Abs.m)) %>% 
  group_by(site, sample_type) %>% 
  summarize(char_count = n(),
            SACmean = mean(SAC254_Abs.m, na.rm = T), 
            SACRSD = (sd(SAC254_Abs.m, na.rm = T)/SACmean)*100,
            SACmin = min(SAC254_Abs.m, na.rm = T), 
            SACmedian = median(SAC254_Abs.m, na.rm = T), 
            SACmax = max(SAC254_Abs.m, na.rm = T)) %>%
  ungroup() %>% 
  mutate(mean_RSD_SAC = paste0(round(SACmean, 2), " ± ", round(SACRSD, 0), "%")) %>% 
  select( site, sample_type, char_count, 
          mean_RSD_SAC, SACmin, SACmedian, SACmax) 


# --- THIS IS THE ONE

# Join conc & character
full_join(conc_wet, char_wet, by = c("site", "sample_type") ) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_wet-season-summary_conc-char_by-site.csv")
```

# TRASSH?

```
# Concentration
# in only the wet season & LWSA monitoring sites...
a <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(rain_season == "wet") %>% 
  group_by(sample_type) %>% 
  summarize(conc_count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>%
  ungroup() %>% 
  bind_rows(
    synopticfilter %>%
      filter(QAQC_flag == "OK") %>%
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      summarize(sample_type = "all",
                conc_count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T), 
                RSD = round((DOCsd/DOCmean)*100, 0),
                DOCmin = min(NPOC_ppm, na.rm = T), 
                DOCmedian = median(NPOC_ppm, na.rm = T), 
                DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
      ungroup()) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_wet-InstallSamples-DOC-summary.csv")

# by monitoring site & wet season
sixfilter %>%
  ungroup() %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(rain_season == "wet") %>%
  group_by(site, sample_type) %>% 
  summarize(conc_count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_wet-site-InstallSamples-DOC-summary.csv")


# Character
# in only the wet season in LWSA monitoring sites...
b <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(rain_season == "wet", 
         !is.na(SAC254_Abs.m)) %>% 
  group_by(sample_type) %>% 
  summarize(char_count = n(), 
            SACmean = mean(SAC254_Abs.m, na.rm = T), 
            SACsd = sd(SAC254_Abs.m, na.rm = T), 
            RSD = round((SACsd/SACmean)*100, 0),
            SACmin = min(SAC254_Abs.m, na.rm = T), 
            SACmedian = median(SAC254_Abs.m, na.rm = T), 
            SACmax = max(SAC254_Abs.m, na.rm = T),
            E2E3mean = mean(E2E3, na.rm = T), 
            E2E3sd = sd(E2E3, na.rm = T), 
            RSD = round((E2E3sd/E2E3mean)*100, 0),
            E2E3min = min(E2E3, na.rm = T), 
            E2E3median = median(E2E3, na.rm = T), 
            E2E3max = max(E2E3, na.rm = T)) %>%
  ungroup() %>% 
  bind_rows(
    synopticfilter %>%
      filter(QAQC_flag == "OK",
             !is.na(SAC254_Abs.m)) %>%
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      summarize(sample_type = "all",
                char_count = n(), 
                SACmean = mean(SAC254_Abs.m, na.rm = T), 
                SACsd = sd(SAC254_Abs.m, na.rm = T), 
                RSD = round((SACsd/SACmean)*100, 0),
                SACmin = min(SAC254_Abs.m, na.rm = T), 
                SACmedian = median(SAC254_Abs.m, na.rm = T), 
                SACmax = max(SAC254_Abs.m, na.rm = T),
                E2E3mean = mean(E2E3, na.rm = T), 
                E2E3sd = sd(E2E3, na.rm = T), 
                RSD = round((E2E3sd/E2E3mean)*100, 0),
                E2E3min = min(E2E3, na.rm = T), 
                E2E3median = median(E2E3, na.rm = T), 
                E2E3max = max(E2E3, na.rm = T)) %>% 
      ungroup()) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_wet-InstallSamples-NOM-summary.csv")

# by site
sixfilter %>%
  ungroup() %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(rain_season == "wet",
         !is.na(SAC254_Abs.m)) %>%
  group_by(site, sample_type) %>% 
  summarize(char_count = n(), 
            SACmean = mean(SAC254_Abs.m, na.rm = T), 
            SACsd = sd(SAC254_Abs.m, na.rm = T), 
            RSD = round((SACsd/SACmean)*100, 0),
            SACmin = min(SAC254_Abs.m, na.rm = T), 
            SACmedian = median(SAC254_Abs.m, na.rm = T), 
            SACmax = max(SAC254_Abs.m, na.rm = T),
            E2E3mean = mean(E2E3, na.rm = T), 
            E2E3sd = sd(E2E3, na.rm = T), 
            RSD = round((E2E3sd/E2E3mean)*100, 0),
            E2E3min = min(E2E3, na.rm = T), 
            E2E3median = median(E2E3, na.rm = T), 
            E2E3max = max(E2E3, na.rm = T)) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_wet-site-InstallSamples-NOM-summary.csv")

```




ridge plots of G/R wet season only  
```{r}
# wrap by sample_type -- wet season only
label1 <- c(Grab = "Grab sample concentration, wet season", 
            Rack = "Rack samples concentration, wet season")
label2 <- c(Grab = "Grab sample character, wet season", 
            Rack = "Rack sample character, wet season")

# --- Concentration
# density ridge plot
a <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(y = fct_rev(site), x = NPOC_ppm, fill = site)) +
  geom_density_ridges(alpha = 0.5) +
  #geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  facet_wrap(~sample_type, ncol = 1,
             labeller = labeller(sample_type = label1)) +  
  labs(y = "", x = "DOC (mg/L)")


# --- character
# density ridge plot
b <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(y = fct_rev(site), x = SAC254_Abs.m, fill = site)) +
  geom_density_ridges(alpha = 0.5) +
  #geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.y = element_blank(),
        text = element_text(size = 12)) +
  facet_wrap(~sample_type, ncol = 1,
             labeller = labeller(sample_type = label2)) +  
  labs(y = "", x = expression(SAC[254]~(m^-1)) )


# --- both side by each
cowplot::plot_grid(a, b, nrow = 1, align = "h", rel_widths = c(2, 1.6))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_subbasin_GvsR_WETseason-ridgeplot.png", width = 7, height = 4.5, unit = "in") 

```


sample counts and DOC mean/min/max (wet season only)
```{r}
# --- wet season only
# how many of each sample_type are there at the 6 main sites?
a <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                rain_season == "wet") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()

b <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "wet") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

c <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "wet") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

# bind & save to outputs
bind_rows(a, b, c) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_wet-season_subbasins-SampleCount.csv")

# Grab samples only
wet_n_installGrabSamples <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "wet") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples)

# Rack samples only
wet_n_installRackSamples <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "wet") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples) 


```





Trash ? table: subbasin Rack DOC linear trends by event & site

I think this is garbage and that the peak DOC-stage analysis I did makes more sense. The trends weren't really linear... so these linear trends don't seem to elucidate much
```
# calculate trend with linear model
DOC_rack_trends_lm <- sixfilter %>%
filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
sample_type == "Rack", 
sample != "Algae",      # remove sample containing whole algae (high DOC)
QAQC_flag == "OK",      # remove samples with extended hold-time  
sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
!is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
NPOC_ppm != 0) %>%  # drop NAs
group_by(site, trip) %>% 
summarise(yint_DOC = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[1],
slope = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[2],
r_sq = summary(lm(formula = NPOC_ppm ~ sampleStage_cm))$r.squared,
n = n(),
range_DOC = max(NPOC_ppm, na.rm = TRUE) - min(NPOC_ppm, na.rm = TRUE),
DOC_min = sample[which.min(NPOC_ppm)],
DOC_max = sample[which.max(NPOC_ppm)],
first_event = first(event_ID),
last_event = last(event_ID),
first_rack = first(sample, order_by = DateTime_sampled),
last_rack = last(sample, order_by = DateTime_sampled)) 

```



###### plot: rack DOC by event
```{r, rackDOC}
# rising limb
sixfilter %>% 
  filter(sample_type == "Rack", rain_season == "wet") %>%
  filter(event_ID != "NA") %>% 
  group_by(site, event_ID) %>% 
  mutate(RisingLimb = NumberXtract(sample),
         RisingLimb = factor(RisingLimb, levels = c(1:9))) %>%
  ggplot(aes(x = DateTime_sampled, y = RisingLimb))+
  geom_point(aes(size = NPOC_ppm, colour = event_ID))+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 12),
        legend.position = "left")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  labs(y = "Sampling Rack Position", x = "", size = "DOC (ppm)", colour = "Rain Event")+
  facet_wrap(~site, ncol = 1,
             strip.position = "right",
             scales = "free_y")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_rack-trends.png", 
       height = 8, width = 6, unit ="in")


# what if x axis was event rather than time?
# rising limb
sixfilter %>% 
  filter(sample_type == "Rack") %>%
  filter(event_ID != "NA") %>% 
  group_by(site, event_ID) %>% 
  mutate(RisingLimb = NumberXtract(sample),
         RisingLimb = factor(RisingLimb, levels = c(1:9))) %>%
  ggplot(aes(x = event_ID, y = RisingLimb))+
  geom_point(aes(colour = NPOC_ppm, size = NPOC_ppm))+
  #scale_size_continuous(breaks = c(2, 6, 10, 14, 18), values = c(1,2,3,4,5))+ # ???
  scale_colour_viridis(option = "plasma")+
  theme_bw()+
  theme(#axis.text.x = element_text(angle = 45, hjust = 1),
    text = element_text(size = 11),
    legend.position = "top")+
  labs(y = "Sampling Rack Position", x = "Rain event ID", size = "DOC (mg/L):", colour = "")+
  facet_wrap(~site, ncol = 1, strip.position = "right", scales = "free_y")
#+
# guides(size = guide_legend("DOC (mg/L)"), colour = guide_legend("DOC (mg/L)"))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_rack-trends.png", 
       height = 7, width = 5, unit ="in")
```


# CH4 RESULTS

## normalize

```{r}

# min-max normalized stage data 
# (because the stage is arbitrarily references to the stilling well and it's the fluctuation that's important)
stage_samples_norm <- stage_samples %>%
  ungroup() %>% 
  filter(QAQC_flag == "OK") %>% 
  group_by(site) %>% 
  dplyr::mutate(norm_stg = (corr_stage_cm - min(corr_stage_cm, na.rm=T)) / (max(corr_stage_cm, na.rm=T) - min(corr_stage_cm, na.rm=T) ),
                norm_NPOC_ppm = (NPOC_ppm - min(NPOC_ppm, na.rm=T)) / (max(NPOC_ppm, na.rm=T) - min(NPOC_ppm, na.rm=T) ),
                norm_SAC254_Abs.m = (SAC254_Abs.m - min(SAC254_Abs.m, na.rm=T)) / (max(SAC254_Abs.m, na.rm=T) - min(SAC254_Abs.m, na.rm=T) ),
                norm_SUVA = (SUVA - min(SUVA, na.rm=T)) / (max(SUVA, na.rm=T) - min(SUVA, na.rm=T) ),
                norm_E2E3 = (E2E3 - min(E2E3, na.rm=T)) / (max(E2E3, na.rm=T) - min(E2E3, na.rm=T)) ) %>% 
  ungroup() %>% 
  # some are seasons missing, fix that:
  mutate(rain_season = case_when(
    Date < "2018-10-27" ~ "wet",
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-20", "2019-03-01") ~ "wet",
    Date %within% interval("2019-03-01", "2019-04-30") ~ "wet", # snow",
    Date %within% interval("2019-05-01", "2019-09-12") ~ "dry",
    event_ID %in% 9:18 ~ "wet")) 
```

## Events

```{r}
# events_table

# for wet season filter out ID = NA
eventsample_table <- right_join(events_table,
                                sixfilter %>% 
                                  filter(QAQC_flag == "OK") %>%
                                  filter(!is.na(event_ID)) %>% 
                                  group_by(event_ID) %>% 
                                  summarise("Samples collected" = n(),
                                            "mean DOC (mg/L)" = mean(NPOC_ppm, na.rm = T),
                                            mean_SAC254 = mean(SAC254_Abs.m, na.rm = T),
                                            "mean SUVA" = mean(SUVA, na.rm = T) ,
                                            "mean E2E3" = mean(E2E3, na.rm = T), 
                                            mean_pseudo254 = mean(pseudo254, na.rm = T)
                                            #mean_pseudoSUVA = mean(pseudo_SUVA, na.rm = T)
                                  ) %>%  
                                  mutate(mean_pseudo254 = as.character(mean_pseudo254)) %>% 
                                  mutate(mean_SAC254 = case_when(
                                    event_ID == "1" ~ mean_pseudo254[[1]],
                                    event_ID == "2" ~ mean_pseudo254[[2]],
                                    event_ID == "3" ~ mean_pseudo254[[3]],
                                    TRUE ~ as.character(mean_SAC254)  )) %>%
                                  mutate(mean_SAC254 = as.numeric(mean_SAC254)),
                                # attach to event table
                                by = c("Major event no." = "event_ID" )) %>% 
  # rename things
  select(-c("Storm number", mean_pseudo254)) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/CH4_events-n-samples.csv")


```

## DOC spatial boxplot

LWSA monitoring sites DOC 
```{r}
# Boxplots with jitter scatter

# DOC by site (all sites) 
# grab and rack combined 
sixfilter_sub %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  scale_fill_brewer(palette="Set2") +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  guides(shape = guide_legend("Sample method:", override.aes = list(size=2.5)))+
  labs(x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_DOC_subbasin_boxplots.png",
       width = 5, height = 4, units = "in")

```

### seasonal

*boxplot
wet vs dry season (number of samples is so different)
```{r}
# count samples
sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>%
  group_by(rain_season) %>% 
  summarize(n = n())

# wrap by sample_type with nice labels
label <- c(dry = "Dry season samples", wet = "Wet season samples")

# plot with adjusted strip label
sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.4)+
  geom_jitter(aes(shape = sample_type), alpha = 0.5) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle  
  facet_wrap(labeller = labeller(rain_season = label),
             ~rain_season, nrow = 1) +
  scale_fill_brewer(palette="Set2", guide = FALSE) +
  theme_bw() +
  labs(y = "DOC (mg/L)", shape = "Sample type:", 
       x = "") +
  theme(legend.position = "top",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 30, hjust = 1)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_DOC-seasonal-subbasin_boxplots.png", width = 6, height = 4, units = "in")

```

##### table: seasonal sample count and summary
```{r}
# how many samples were collected seasonally?
# what were the mean +/- sd values at each site?
a <- sixfilter %>%
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, rain_season) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T)) %>%
  ungroup() %>% 
  bind_rows(
    sixfilter %>%
      filter(QAQC_flag == "OK") %>%
      filter(sample_type == "Grab" | sample_type == "Rack") %>% 
      group_by(rain_season) %>% 
      summarize(site = "all sites",
                count = n(), 
                DOCmean = mean(NPOC_ppm, na.rm = T), 
                DOCsd = sd(NPOC_ppm, na.rm = T)) %>% 
      ungroup()) 


# SAC254 and E2E3
b <- sixfilter %>%
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  #filter(SUVA < 9, between(E2E3, 3.6, 15)) %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, rain_season) %>% 
  summarize(#NOMcount = n(),
    # SAC254
    SAC254mean = mean(SAC254_Abs.m, na.rm = T), 
    SAC254sd = sd(SAC254_Abs.m, na.rm = T),
    # SUVA
    SUVAmean = mean(SUVA, na.rm = T), 
    SUVAsd = sd(SUVA, na.rm = T),
    # E2E3
    E2E3mean = mean(E2E3, na.rm = T), 
    E2E3sd = sd(E2E3, na.rm = T))


# all together  
c <- sixfilter %>% 
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  #filter(SUVA < 9, between(E2E3, 3.6, 15)) %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(rain_season) %>% 
  summarize(site = "all sites", 
            #NOMcount = n(),
            # SAC254
            SAC254mean = mean(SAC254_Abs.m, na.rm = T), 
            SAC254sd = sd(SAC254_Abs.m, na.rm = T),
            # SUVA
            SUVAmean = mean(SUVA, na.rm = T), 
            SUVAsd = sd(SUVA, na.rm = T),
            # E2E3
            E2E3mean = mean(E2E3, na.rm = T), 
            E2E3sd = sd(E2E3, na.rm = T))

# tag totals summary onto site summary
left_join(a, bind_rows(b, c), by = c("site", "rain_season")) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_NOM-seasonal-summary.csv", col_names = T)

```

### wet season only
```{r}
# wrap by sample_type -- wet season only
label <- c(Grab = "Grab samples, wet season", Rack = "Rack samples, wet season")

# Boxplot with jitter scatter 
# site vs DOC, facet wrap by sample type
sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 40, hjust = 1),
        text = element_text(size = 12)) +
  facet_wrap(~sample_type, ncol = 2, nrow = 1,
             labeller = labeller(sample_type = label)) +  
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "Sample collection method:")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_subbasin_GvsR_WETseason-boxplot.png",  width = 5, height = 4, unit = "in") 

```

### boxplots: all parameters split by seasons
```{r}

# wrap by season
label <- c(dry = "Dry season", wet = "Wet season")

# all parameters together
a <- sixfilter %>%
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        axis.text.x = element_blank(),
        text = element_text(size = 11)) +
  facet_wrap(~rain_season, ncol = 2, nrow = 1,
             labeller = labeller(rain_season = label),
             scales = "free_y") +  
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "DOC (mg/L)", shape = "Sample collection method:")


#### NOM wet season only

# SAC254
b <- sixfilter %>%
  filter(QAQC_flag == "OK",
         sample != "Algae") %>%  
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        text = element_text(size = 11),
        strip.background = element_blank(),
        strip.text.x = element_blank()) +
  facet_wrap(~rain_season, ncol = 2, nrow = 1,
             labeller = labeller(rain_season = label),
             scales = "free_y") +  
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression( SAC[254]~(m^-1) ), shape = "Sample collection method:")

# make an inset that doesn't include Weeks
# change colours manually: brewer.pal(n = 6, name = 'Set2')
bb <- sixfilter %>%
  filter(site != "Weeks") %>% 
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  filter(rain_season == "dry") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values = c("#FC8D62", "#8DA0CB", "#E78AC3", "#A6D854", "#FFD92F")) +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        text = element_text(size = 10))+
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"),
        plot.background = element_rect(inherit.blank = TRUE, fill = NA)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "", shape = "Sample collection method:")

# just Cragg, West and Tunnel  
bbb <- sixfilter %>%
  filter(site != "Weeks" & site != "ChrisCrk" & site != "LeechHead") %>% 
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  filter(rain_season == "dry") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = SAC254_Abs.m, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values = c("#E78AC3", "#A6D854", "#FFD92F")) +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        text = element_text(size = 10))+
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"),
        plot.background = element_rect(inherit.blank = TRUE, fill = NA)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "", shape = "Sample collection method:")


# inset 
B <- cowplot::ggdraw() +
  draw_plot(b) +
  draw_plot(plot = bb,
            x = .2, # x location of inset placement
            y = .3, # y location of inset placement
            width = .3, # Inset width
            height = .62, # Inset height
            scale = 1) # Inset scale (1 = none)
# inset on the inset!
BB <- cowplot::ggdraw() +
  draw_plot(B) +
  draw_plot(plot = bbb,
            x = .3, # x location of inset placement
            y = .5, # y location of inset placement
            width = .2, # Inset width
            height = .42, # Inset height
            scale = 1) # Inset scale (1 = none)


# SUVA
c <- sixfilter %>%
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  filter(SUVA < 9) %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = SUVA, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        text = element_text(size = 11),
        strip.background = element_blank(),
        strip.text.x = element_blank()) +
  facet_wrap(~rain_season, ncol = 2, nrow = 1,
             labeller = labeller(rain_season = label),
             scales = "free_y") +  
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(SUVA[254]), shape = "Sample collection method:")

# make an inset that doesn't include Weeks
# change colours manually: brewer.pal(n = 6, name = 'Set2')
cc <- sixfilter %>%
  filter(site != "Weeks") %>% 
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  filter(rain_season == "dry") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = SUVA, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values = c("#FC8D62", "#8DA0CB", "#E78AC3", "#A6D854", "#FFD92F")) +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        text = element_text(size = 10))+
  theme(plot.margin = unit(c(0, 0, 0, 0), "cm"),
        plot.background = element_rect(inherit.blank = TRUE, fill = NA)) +
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = "", shape = "Sample collection method:")


# inset 
C <- cowplot::ggdraw() +
  draw_plot(c) +
  draw_plot(plot = cc,
            x = .2, # x location of inset placement
            y = .4, # y location of inset placement
            width = .3, # Inset width
            height = .52, # Inset height
            scale = 1) # Inset scale (1 = none)

# E2E3
d <- sixfilter %>%
  filter(QAQC_flag == "OK",
         sample != "Algae") %>% 
  filter(E2E3 > 3.6) %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = E2E3, fill = site)) +
  geom_jitter(aes(fill = site, shape = sample_type), alpha = 0.8) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24))+ #circle, triangle
  geom_boxplot(alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 40, hjust = 1),
        text = element_text(size = 11),
        strip.background = element_blank(),
        strip.text.x = element_blank()) +
  facet_wrap(~rain_season, ncol = 2, nrow = 1,
             labeller = labeller(rain_season = label),
             scales = "free_y") +  
  guides(fill = FALSE,
         shape = guide_legend(override.aes = c("Grab" = 21, "Rack" = 24), size = 1.5))+
  labs(x = "", y = expression(E[2]:E[3]), shape = "Sample collection method:")

# plot grid
cowplot::plot_grid(a, B, C, d, ncol = 1, axis = "tb", 
                   rel_widths = c(1,1,1,1),
                   rel_heights = c(3,2,2,3))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_NOM-DOC_boxplots-by-season.png",  width = 6, height = 7.5, unit = "in") 

# Drop SUVA 254
# plot grid
cowplot::plot_grid(a, B, d, ncol = 1, axis = "tb", 
                   rel_widths = c(1,1,1),
                   rel_heights = c(3,2,3),
                   labels = "AUTO")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_NOM-DOC_boxplots-by-season.png",  
       width = 6, height = 6, unit = "in") 

```

* table: wet G/R DOC means/min/max
```{r, summaryDOC-table}
# DOC summary table -- Grab vs Rack by site
a <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack",
                rain_season == "wet") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(),
            DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() 

# DOC summary table -- Grab vs Rack
b <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack",
                rain_season == "wet") %>% 
  group_by(sample_type) %>% 
  summarize(site = "All",
            count = n(),
            DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() 

# make table
bind_rows(a, b)  %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_DOC_wet-season_subbasin_MeanMinMax-SampleType.csv", col_names = TRUE)

```


## normalized stage
```{r}

# min-max normalized stage data 
# (because the stage is arbitrarily references to the stilling well and it's the fluctuation that's important)
odyssey_norm <- odyssey_data %>%
  group_by(source) %>% 
  dplyr::mutate(norm_stg = (stage_cm-min(stage_cm))/(max(stage_cm)-min(stage_cm))) %>% 
  ungroup()


# plot normalized stage 
# The stage was normalized (min-max norm) to compare relative rises
# lines over time
a <-odyssey_norm %>%
  ggplot(aes(x = DateTime, y = norm_stg))+
  geom_line(colour = "#0072B2") +
  #viridis::scale_colour_viridis(discrete = TRUE) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(y = "River stage (normalized)", x = "") +
  facet_wrap(~source, ncol = 1, strip.position = "right")  
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_subbasins.png", width = 8.5, height = 11, units = "in")

# ridge plot ---
# plot stage, density ridges -- could be cool -- fix aesthetics 
b <- odyssey_norm %>%
  ggplot(aes(x = norm_stg, y = fct_rev(source)))+
  ggridges::geom_density_ridges(aes(fill = source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  scale_y_discrete() +
  theme(legend.position = "none")+
  labs(x = "River Stage (normalized)", y = "",
       caption = "Density distribution of min-max normalized stage at six subbasins")
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_ridgeplot_subbasins.png")

```

### stage: temporal Synchrony tests
```{r}
# reshape odyssey data to wide flat file matrix
## sites as columns, timestep as rows
# note: Tunnel was not installed & recording until "2018-12-06 19:30:00"
# to check for synchrony, all timesteps should be of equal length with no NAs
six_wide_stage <- odyssey_data %>%
  group_by(source) %>% 
  filter(rain_season == "wet") %>%  # remove baseflow
  filter(Date >= "2018-12-06", Date <= "2020-01-31") %>% # overlapping date ranges
  mutate(DateTimeRound = lubridate::round_date(DateTime, unit = "10 mins")) %>% # round to remove NAs
  select(c(DateTimeRound, source, stage_cm)) %>% 
  distinct(DateTimeRound, .keep_all = TRUE) %>%   # keep only unique time stamps
  ungroup() %>% 
  pivot_wider(names_from = source,
              values_from = stage_cm) %>% 
  unnest(cols = c(Weeks, ChrisCrk, LeechHead, CraggCrk, WestLeech, Tunnel)) %>% 
  arrange(DateTimeRound) %>% 
  mutate(timestep = row_number(DateTimeRound))

# synchrony tests
# community-wide & significance via Monte Carlo randomizations
# 1 == perfect synchrony

## concordance (Kendall's W) [0:1]
# isolate sites only (drop time and timestep now that it's sorted)
dat <- six_wide_stage %>% select(-c(DateTimeRound, timestep))
stage_synch_kendall.w <- synchrony::kendall.w(data = dat) # nrands = 1050, type = 2)
stage_synch_kendall.w_1 <- synchrony::kendall.w(data = dat) #, nrands = 9999, type = 1)
# results are the same for type 1 and type 2:
## Kendall's W (uncorrected for ties): 0.9721
## Kendall's W (corrected for ties): 0.9721
## Spearman's ranked correlation: 0.9666
## Kendall's W p-value (one-tailed test [greater]): 0.0009515 (nrands = 1050)


## PEAKS
# Determine the proportion of concurrent local extrema (Peaks)
# isolate time series matrix for each site where col 1 is timestep and col 2 is stage
# site 1
six_wide_stage_Weeks <- six_wide_stage %>% 
  select(c(timestep, Weeks)) %>% 
  as.matrix()
# site 2
six_wide_stage_Chris <- six_wide_stage %>% 
  select(c(timestep, ChrisCrk)) %>% 
  as.matrix()
# site 3
six_wide_stage_Head <- six_wide_stage %>% 
  select(c(timestep, LeechHead)) %>% 
  as.matrix()
# site 4
six_wide_stage_Cragg <- six_wide_stage %>% 
  select(c(timestep, CraggCrk)) %>% 
  as.matrix()
# site 5
six_wide_stage_West <- six_wide_stage %>% 
  select(c(timestep, WestLeech)) %>%
  as.matrix()
# site 6
six_wide_stage_Tunnel <- six_wide_stage %>% 
  select(c(timestep, Tunnel)) %>%
  as.matrix()

### tests by site (number) (RAM intensive with nrands -- hash out after use)
# note, check p-value difference with nrands = 10000 and it's similar enough that I think 999 is fine.
peaks_1to2 <- synchrony::peaks(six_wide_stage_Weeks, six_wide_stage_Chris, type = 2) #, nrands = 999)
peaks_1to3 <- synchrony::peaks(six_wide_stage_Weeks, six_wide_stage_Head, type = 2) #, nrands = 999)
peaks_2to3 <- synchrony::peaks(six_wide_stage_Chris, six_wide_stage_Head, type = 2) #, nrands = 999)
peaks_3to4 <- synchrony::peaks(six_wide_stage_Head, six_wide_stage_Cragg, type = 2) #, nrands = 999)
peaks_3to5 <- synchrony::peaks(six_wide_stage_Head, six_wide_stage_West, type = 2) #, nrands = 999)
peaks_4to5 <- synchrony::peaks(six_wide_stage_Cragg, six_wide_stage_West, type = 2) #, nrands = 999)
peaks_3to6 <- synchrony::peaks(six_wide_stage_Head, six_wide_stage_Tunnel, type = 2) #, nrands = 999)
peaks_4to6 <- synchrony::peaks(six_wide_stage_Cragg, six_wide_stage_Tunnel, type = 2) #, nrands = 999)
peaks_5to6 <- synchrony::peaks(six_wide_stage_West, six_wide_stage_Tunnel, type = 2) #, nrands = 999)

# combine
synch_PeaksSumm_stage <- tibble(      
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk", 
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"),
  "Proportion of common peaks" = c(peaks_1to2$obs, peaks_1to3$obs, peaks_2to3$obs, peaks_3to4$obs, peaks_3to5$obs, peaks_4to5$obs, peaks_3to6$obs, peaks_4to6$obs, peaks_5to6$obs)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/stage-stats_synchrony-peaks_wet-season.csv", col_names = T)

# where proportion of coincident peaks = a fraction of the maximum number of peaks in the two series
```




# Random Forest

## RF data

* add antecedent conditions data
* combine analytical results with stage and weather
* load watershed characteristics and join all 

```{r}
# first, calculate antecedent rain conditions at the cumulative rain for 7 days up to and including date sampled
# NOTE this is not antecedent 'wetness' because it doesn't account for snow or snowmelt

# get antecedent mean air temp (average) and cumulative rain (daily totals)
antecedent_Wx <- LWSA_meanWx %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(Date) %>% 
  summarise(daily_rain = sum(Rn15_mean, na.rm = TRUE),
            daily_mean_T = mean(Temp_mean, na.rm = TRUE)) %>%  # temp too, why not
  ungroup() %>% 
  arrange(Date) %>% 
  # add a 7 day antecedent rain for each day
  mutate(antecedent_30day_rain = as.double(zoo::rollsum(daily_rain, k = 30, align = "right", fill = NA)),
         antecedent_7day_rain = as.double(zoo::rollsum(daily_rain, k = 7, align = "right", fill = NA)),
         antecedent_3day_rain = as.double(zoo::rollsum(daily_rain, k = 3, align = "right", fill = NA)),
         antecedent_30day_temp = as.double(zoo::rollmean(daily_mean_T, k = 30, align = "right", fill = NA)),
         antecedent_7day_temp = as.double(zoo::rollmean(daily_mean_T, k = 7, align = "right", fill = NA))
  )
# note: align right sets the date to the right side of box (k values wide) & sums all values in the box 

# join sample results with normalized stage and antecedent 7 day rain
sixfilter_RF <- sixfilter %>%
  group_by(site) %>% 
  # add normalized stage (better than absolute for RF)
  left_join(., ( odyssey_norm %>% group_by(source) %>% select(-c(stage_cm)) ), 
            by = c("DateTime_sampled" = "DateTime", "site" = "source", "trip" = "interval", 
                   "corr_stage_cm", "rain_season", "event_ID")) %>% 
  filter(!is.na(analysis),  # drop empty TOC samples (unfiltered on shimadzu)
         QAQC_flag == "OK") %>% 
  select(-c(Date.x, Date.y, analysis, collection, Date_collected, two_seasons, corr_stage_cm)) %>% # drop un-needed items 
  group_by(site, trip, sample) %>% 
  left_join(., antecedent_Wx, by = c("Date_sampled" = "Date")) %>% ungroup() %>%  
  select(-c("Date_sampled")) %>% 
  # rename norm_stg & trip
  rename(sampling_trip = "trip",
         sampleStage_normalized = "norm_stg")

# load watershed characteristics for each site
physiographic <- read_csv("R-inputs_UBC-forWater-MSc_HMc/subbasin_characteristics_RandomForests.csv", col_names = TRUE) %>% 
  mutate(site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")))

# combine 
sixfilter_physiographic <- left_join(sixfilter_RF, physiographic, by = c("site")) %>%
  ungroup() %>% 
  # filter so all that's left is NPOC and any predictor variables, no NAs
  filter(!is.na(DateTime_sampled),
         !is.na(sampleStage_normalized)) %>% 
  # drop unneccessary variables
  select(-c("QAQC_flag", "Hobo_Tmean_airDaily", "sampling_trip", "subbasin_type", "daily_rain", "daily_mean_T")) %>% 
  mutate(event_ID = as.numeric(event_ID)) %>%  # RF don't want no factors
  # create a Leech River formation variable 
  mutate(geo_LeechRiverFormation_percent = geo_Metagreywacke_percent + geo_ArgilliteMetagreywacke_percent)

```

### RF & plots
```{r}

# named colour vector
fills <- c("Conditions" = forWater_colours2[["SkyBlue"]], 
           "Parent material" = forWater_colours2[["Gray"]], 
           "Surface characteristics" = forWater_colours2[["Green"]])

# all tests and plots by predictant follow:

```

### Individually grouped predictors

```{r}
# named colour vector for different groups
fills <- c("Conditions" = forWater_colours2[["SkyBlue"]], 
           "Parent material" = forWater_colours2[["Gray"]], 
           "Surface characteristics" = forWater_colours2[["Green"]])
```

separated conditions from characteristics - show combo plot in appendix
dynamic and static conditions appear to be treated for regression & categorically (respectively). Numeric isn't the defining factor, it's whether the predictant is changing (or not) with the predictor, that seems to be what may create bias in combined RF VIM. 

#### DOC
```{r}
# --- DOC
# dynamic values: conditions only
dynamicVariables_DOC <- sixfilter_physiographic %>% 
  filter(!is.na(NPOC_ppm)) %>%
  select(c(NPOC_ppm, # predict DOC
           sampleStage_normalized, 
           antecedent_30day_rain,  
           antecedent_7day_temp 
  ))  #%>%     
 #add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
DOC_dynamic_RF <- randomForest::randomForest(NPOC_ppm ~ ., 
                                             data = dynamicVariables_DOC, 
                                             replace = FALSE, # improve VIM
                                             na.action = randomForest::na.roughfix,
                                             mtry = ceiling(length(data)/2), # no. of features
                                             ntree = 5000,  
                                             importance = TRUE,
                                             proximity = TRUE,
                                             corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_dynamic_RelImp1_MSE <- randomForest::importance(DOC_dynamic_RF, type = 1  ) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # "IncNodePurity") %>%  # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain event number" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "sampling stage" = "sampleStage_normalized" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "forest cover" | 
      predictor == "slope (median, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  



# VIM plot -- dynamic
RFplot_dynamic_DOC <- RF_DOC_dynamic_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "none", text = element_text(size = 12))+
  labs(y = "", # expression('Relative importance in predicting DOC (%)'), 
       x = "",
       fill = "Predictor variable group", 
       subtitle = "A) Sampling Conditions") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# ---
# static values: watershed characteristics only
staticVariables_DOC <- sixfilter_physiographic %>% 
  filter(!is.na(NPOC_ppm)) %>%
  select(c(NPOC_ppm, # predict DOC
           geo_metamorphic_percent,
           geo_igneous_percent,
           drainage_area_km2,
           slope_median_degrees,
           tree_age_average,
           logging_percent_1980to2011)) # %>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(staticVariables_DOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
DOC_static_RF <- randomForest::randomForest(NPOC_ppm ~ ., 
                                            data = staticVariables_DOC, 
                                            replace = FALSE, # improve VIM
                                            na.action = randomForest::na.roughfix,
                                            mtry = ceiling(length(data)/2), # no. of features
                                            ntree = 5000,  
                                            importance = TRUE,
                                            proximity = TRUE,
                                            corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_static_RelImp1_MSE <- randomForest::importance(DOC_static_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>%  #"IncNodePurity") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                #"QA-QC (random numbers)" = "QA_RandNum",
                                "drainage area" = "drainage_area_km2",
                                "tree age (average, yrs)" = 'tree_age_average',
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_median_degrees",
                                "logging history (1980-2011)" = "logging_percent_1980to2011", 
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "slope (median, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  


# VIM plot --- Static (characteristics)
RFplot_static_DOC <- RF_DOC_static_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "none", text = element_text(size = 12))+
  labs(y = 'Relative importance in predicting DOC (%)', 
       x = "",
       fill = "Predictor variable group",
       subtitle = "B) Watershed Characteristics") +
  guides(fill = guide_legend(nrow = 2, byrow=TRUE))

# DOC dynamic and static adjacent to eachother
RFsep_DOC <- cowplot::plot_grid(RFplot_dynamic_DOC, RFplot_static_DOC, ncol= 1, align = "v")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RFplot_sep-DOC.png", 
       width = 6, height = 6, units = "in")

```

#### E2E3
```{r}

# --- E2E3
# dynamic values: conditions only
dynamicVariables_E2E3 <- sixfilter_physiographic %>% 
  filter(!is.na(E2E3)) %>%
  select(c(E2E3, # predict SAC254
           sampleStage_normalized, 
           antecedent_30day_rain, # relatively more important than 7-day -- correlated with stage tho 
           antecedent_7day_temp # no real diff in VIM for 7 vs 30 day
  ))  #%>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(dynamicVariables_E2E3))


## Run RF
E2E3_dynamic_RF <- randomForest::randomForest(E2E3 ~ ., 
                                              data = dynamicVariables_E2E3, 
                                              replace = FALSE, # improve VIM
                                              na.action = randomForest::na.roughfix,
                                              mtry = ceiling(length(data)/2), # no. of features
                                              ntree = 5000,  
                                              importance = TRUE,
                                              proximity = TRUE,
                                              corr.bias = TRUE) # experimental 


## relative importance of features in predicting E2E3
## type 1 = mean square error (MSE) as decrease in accuracy
RF_E2E3_dynamic_RelImp1_MSE <- randomForest::importance(E2E3_dynamic_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain event number" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "sampling stage" = "sampleStage_normalized" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "forest cover" | 
      predictor == "slope (median, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  

# VIM plot - dynamic
RFplot_dynamic_E2E3 <- RF_E2E3_dynamic_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "none", text = element_text(size = 12))+
  labs(y = "", #expression('Relative importance in predicting'~E[2]:E[3]~'(%)'), 
       x = "",
       fill = "Predictor variable group",
       subtitle = "A) Sampling Conditions") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))


# --- dynamic
# static values: watershed characteristics only
staticVariables_E2E3 <- sixfilter_physiographic %>% 
  filter(!is.na(E2E3)) %>%
  select(c(E2E3, # predict SAC254
           geo_metamorphic_percent,
           geo_igneous_percent,
           drainage_area_km2,
           slope_median_degrees,
           tree_age_average,
           logging_percent_1980to2011))  # %>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(AllVariables_SAC254))


## Run RF
E2E3_static_RF <- randomForest::randomForest(E2E3 ~ ., 
                                             data = staticVariables_E2E3, 
                                             replace = FALSE, # improve VIM
                                             na.action = randomForest::na.roughfix,
                                             mtry = ceiling(length(data)/2), # no. of features
                                             ntree = 5000,  
                                             importance = TRUE,
                                             proximity = TRUE,
                                             corr.bias = TRUE) # experimental 


## relative importance of features in predicting E2E3
## type 1 = mean square error (MSE) as decrease in accuracy
RF_E2E3_static_RelImp1_MSE <- randomForest::importance(E2E3_static_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "drainage area" = "drainage_area_km2",
                                "tree age (average, yrs)" = 'tree_age_average',
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_median_degrees",
                                "logging history (1980-2011)" = "logging_percent_1980to2011", 
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "slope (median, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  


# VIM plot -- static
RFplot_static_E2E3 <- RF_E2E3_static_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "none", text = element_text(size = 12))+
  labs(y = expression('Relative importance in predicting'~E[2]:E[3]~'(%)'), 
       x = "",
       fill = "Predictor variable group",
       subtitle = "B) Watershed Characteristics") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# DOC dynamic and static adjacent to eachother
RFsep_E2E3 <- cowplot::plot_grid(RFplot_dynamic_E2E3, RFplot_static_E2E3, ncol= 1, align = "v")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RFplot_sep-E2E3.png", 
       width = 6, height = 6, units = "in")

```

#### SAC254
```{r}

# --- SAC254
# dynamic values: conditions only
dynamicVariables_SAC254 <- sixfilter_physiographic %>% 
  filter(!is.na(SAC254_Abs.m)) %>%
  select(c(SAC254_Abs.m, # predict SAC254
           sampleStage_normalized, 
           antecedent_30day_rain, # relatively more important than 7-day -- correlated with stage tho 
           antecedent_7day_temp # no real diff in VIM for 7 vs 30 day
  )) #  %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(AllVariables_SAC254))


## Run RF
SAC254_dynamic_RF <- randomForest::randomForest(SAC254_Abs.m ~ ., 
                                                data = dynamicVariables_SAC254, 
                                                replace = FALSE, # improve VIM
                                                na.action = randomForest::na.roughfix,
                                                mtry = ceiling(length(data)/2), # no. of features
                                                ntree = 5000,  
                                                importance = TRUE,
                                                proximity = TRUE,
                                                corr.bias = TRUE) # experimental 

## relative importance of features in predicting SAC254
## type 1 = mean square error (MSE) as decrease in accuracy
RF_SAC254_dynamic_RelImp1_MSE <- randomForest::importance(SAC254_dynamic_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain event number" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "sampling stage" = "sampleStage_normalized" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "forest cover" | 
      predictor == "slope (median, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  


# VIM plot
RFplot_dynamic_SAC254 <- RF_SAC254_dynamic_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "none", text = element_text(size = 12))+
  labs(y = "", #expression('Relative importance in predicting'~SAC[254]~'(%)'), 
       x = "",
       fill = "Predictor variable group",
       subtitle = "A) Sampling Conditions") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))


# --- static
# static values: watershed characteristics only
staticVariables_SAC254 <- sixfilter_physiographic %>% 
  filter(!is.na(SAC254_Abs.m)) %>%
  select(c(SAC254_Abs.m, # predict SAC254
           geo_metamorphic_percent,
           geo_igneous_percent,
           drainage_area_km2,
           slope_median_degrees,
           tree_age_average,
           logging_percent_1980to2011)) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(AllVariables_SAC254))


## Run RF
SAC254_static_RF <- randomForest::randomForest(SAC254_Abs.m ~ ., 
                                               data = staticVariables_SAC254, 
                                               replace = FALSE, # improve VIM
                                               na.action = randomForest::na.roughfix,
                                               mtry = ceiling(length(data)/2), # no. of features
                                               ntree = 5000,  
                                               importance = TRUE,
                                               proximity = TRUE,
                                               corr.bias = TRUE) # experimental 


## relative importance of features in predicting SAC254
## type 1 = mean square error (MSE) as decrease in accuracy
RF_SAC254_static_RelImp1_MSE <- randomForest::importance(SAC254_static_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "drainage area" = "drainage_area_km2",
                                "tree age (average, yrs)" = 'tree_age_average',
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_median_degrees",
                                "logging history (1980-2011)" = "logging_percent_1980to2011", 
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "slope (median, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  


# VIM plot -- static
RFplot_static_SAC254 <- RF_SAC254_static_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "none", text = element_text(size = 12))+
  labs(y = expression('Relative importance in predicting'~SAC[254]~'(%)'), 
       x = "",
       fill = "Predictor variable group",
       subtitle = "B) Watershed Characteristics") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))


# DOC dynamic and static adjacent to eachother
RFsep_SAC254 <- cowplot::plot_grid(RFplot_dynamic_SAC254, RFplot_static_SAC254, ncol= 1, align = "v")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RFplot_sep-SAC254.png", 
       width = 6, height = 6, units = "in")


```

##### RF summary plot (separate variables)
```{r}
# stack DOC, E2E3, SAC254 plots
cowplot::plot_grid(RFsep_DOC, RFsep_E2E3, RFsep_SAC254,
                   ncol = 3, rel_widths = c(1,1,1) )

# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RFplot-summary_DOC-E2E3-SAC254.png", 
       width = 9, height = 6, units = "in")
```

### All variables together

#### DOC all vars
```{r}

# select surface & subsurface predictor variables -- some removed due to cross-correlation
# values removed were cross-correlated at 0.65 or greater
AllVariables_NPOC <- sixfilter_physiographic %>% 
  select(c(#event_ID, 
    #antecedent_7day_rain,
    # antecedent_30day_temp,
    #geo_metasedimentary_percent,  # correlated to meta and logging!? 
    #geo_metaSedimentaryVolcanic_percent, # correlated to meta etc 
    #rain_season, 
    #wetland_percent, # correlated to slope + forest
    #forest_percent, # correlated with wetland and open water (all land-cover) + slope
    #HoldTime_days,
    geo_metamorphic_percent,
    geo_igneous_percent, # ------
    #"geo_ArgilliteMetagreywacke_percent", 
    # geo_ChertArgilliteVolcanic_percent",
    #"geo_MetchosinVolcanics_percent",
    # geo_LeechRiverFormation_percent, # cross correlation
    NPOC_ppm, # predict DOC
    sampleStage_normalized, 
    antecedent_30day_rain, # relatively more important than 7-day -- correlated with stage tho 
    #antecedent_3day_rain,
    antecedent_7day_temp, # no real diff in VIM for 7 vs 30 day
    drainage_area_km2,
    # slope_median_degrees, # only 3 unique values
    slope_mean_degrees, # 6 unique values
    tree_age_average,
    #geo_WarkGneiss_percent,
    #geo_Metagreywacke_percent,
    #COLL_O.HFP_percent, 
    #TILL_DU.HFP_percent, 
    #TILL_O.HFP_percent,
    #FLUV_DU.HFP_percent,
    #GLFL_DU.HFP_percent,
    #UNDO_T.M_percent,
    logging_percent_1980to2011))  # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(AllVariables_NPOC, method = "spearman")) # ? should I Spear, man?
# view(cor(AllVariables_NPOC))

# ---

# subsurface only 
SSVariables_NPOC <- AllVariables_NPOC %>% 
  select(NPOC_ppm, geo_metamorphic_percent, geo_igneous_percent)
# view(cor(SSVariables_NPOC))

# surface only 
SVariables_NPOC <- AllVariables_NPOC %>% 
  select(-c(geo_metamorphic_percent, geo_igneous_percent) )

# ---

## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
DOC_allVars_RF <- randomForest::randomForest(NPOC_ppm ~ ., 
                                             data = AllVariables_NPOC, 
                                             replace = FALSE, # improve VIM
                                             na.action = randomForest::na.roughfix,
                                             mtry = ceiling(length(data)/2), # no. of features
                                             ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                             importance = TRUE,
                                             proximity = TRUE,
                                             corr.bias = TRUE) # experimental 

# ---

## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_allChrc_RelImp1_MSE <- randomForest::importance(DOC_allVars_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain event number" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "sampling stage" = "sampleStage_normalized",
                                "drainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "tree age (average, yrs)" = 'tree_age_average',
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_median_degrees",
                                "slope (mean, degrees)" = "slope_mean_degrees",
                                "logging history (1980-2011)" = "logging_percent_1980to2011", 
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "igneous (%)" = "geo_igneous_percent",
                                "colluvial (O-HFP, %)" = "COLL_O.HFP_percent",
                                "till (DU-HFP, %)" = "TILL_DU.HFP_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "slope (mean, degrees)"  | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)" |
      predictor == "colluvial (O-HFP, %)" |
      predictor == "till (DU-HFP, %)" ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group)) 



# VIM plot
RFplot_all_DOC <- RF_DOC_allChrc_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "top", text = element_text(size = 12))+
  labs(y = "Relative importance in predicting DOC (%)", x = "", fill = "Predictor variable group") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Appendix-Ch4_RFplot_all_DOC.png", width = 6, height = 6, units = "in")

```

##### surface sep. subsurface
```{r}
# ---

# subsurface only
DOC_SSVars_RF <- randomForest::randomForest(NPOC_ppm ~ ., 
                                            data = SSVariables_NPOC, 
                                            replace = FALSE, 
                                            na.action = randomForest::na.roughfix,
                                            mtry = ceiling(length(data)/2), 
                                            ntree = 5000,  
                                            importance = TRUE,
                                            proximity = TRUE,
                                            corr.bias = TRUE) 

# surface only
DOC_SVars_RF <- randomForest::randomForest(NPOC_ppm ~ ., 
                                           data = SVariables_NPOC, 
                                           replace = FALSE, 
                                           na.action = randomForest::na.roughfix,
                                           mtry = ceiling(length(data)/2), 
                                           ntree = 5000,  
                                           importance = TRUE,
                                           proximity = TRUE,
                                           corr.bias = TRUE)
# --- segregated dynamic from static values

# subsurface RF
RF_DOC_SSChrc_RelImp1_MSE <- randomForest::importance(DOC_SSVars_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE))

# surface RF
RF_DOC_SChrc_RelImp1_MSE <- randomForest::importance(DOC_SVars_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE))

#--- segregated plots
# subsurface VIM  plots
RFplot_SS_DOC <- RF_DOC_SSChrc_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  theme_bw() +
  theme(legend.position = "top", text = element_text(size = 12))+
  labs(y = "Relative importance in predicting DOC (%)", x = "", fill = "Predictor variable group") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# surface VIM plots
RFplot_S_DOC <- RF_DOC_SChrc_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  theme_bw() +
  theme(legend.position = "top", text = element_text(size = 12))+
  labs(y = "Relative importance in predicting DOC (%)", x = "", fill = "Predictor variable group") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# ---


```


#### E2E3 all vars
```{r}

# select surface & subsurface predictor variables
AllVariables_E2E3 <- sixfilter_physiographic %>% 
  filter(!is.na(E2E3)) %>% 
  select(c(E2E3, # predict E2E3
           geo_metamorphic_percent,
           geo_igneous_percent,
           #"geo_ArgilliteMetagreywacke_percent", 
           # geo_ChertArgilliteVolcanic_percent",
           #"geo_MetchosinVolcanics_percent",
           sampleStage_normalized, 
           antecedent_30day_rain, # relatively more important than 7-day -- correlated with stage tho 
           antecedent_7day_temp, # no real diff in VIM for 7 vs 30 day
           drainage_area_km2,
           # slope_median_degrees, # only 3 unique values
           slope_mean_degrees,
           tree_age_average,
           #geo_WarkGneiss_percent,
           #geo_Metagreywacke_percent,
           logging_percent_1980to2011))  #%>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(AllVariables_E2E3))


## Run RF
E2E3_allVars_RF <- randomForest::randomForest(E2E3 ~ ., 
                                              data = AllVariables_E2E3, 
                                              replace = FALSE, # improve VIM
                                              na.action = randomForest::na.roughfix,
                                              mtry = ceiling(length(data)/2), # no. of features
                                              ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                              importance = TRUE,
                                              proximity = TRUE,
                                              corr.bias = TRUE) # experimental 


## relative importance of features in predicting E2E3
## type 1 = mean square error (MSE) as decrease in accuracy
RF_E2E3_allChrc_RelImp1_MSE <- randomForest::importance(E2E3_allVars_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "sampling stage" = "sampleStage_normalized",
                                "drainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "tree age (average, yrs)" = 'tree_age_average',
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_median_degrees",
                                "slope (mean, degrees)" = "slope_mean_degrees",
                                "logging history (1980-2011)" = "logging_percent_1980to2011", 
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "slope (mean, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  


# VIM plot
RFplot_all_E2E3 <- RF_E2E3_allChrc_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "top", text = element_text(size = 12))+
  labs(y = expression('Relative importance in predicting'~E[2]:E[3]~'(%)'), 
       x = "",
       fill = "Predictor variable group") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Appendix-Ch4_RFplot_all_E2E3.png", 
       width = 6, height = 6, units = "in")

```

#### SAC254 all vars
```{r}

# select surface & subsurface predictor variables
AllVariables_SAC254 <- sixfilter_physiographic %>% 
  filter(!is.na(SAC254_Abs.m)) %>%
  select(c(SAC254_Abs.m, # predict SAC254
           geo_metamorphic_percent,
           geo_igneous_percent,
           #"geo_ArgilliteMetagreywacke_percent", 
           # geo_ChertArgilliteVolcanic_percent",
           #"geo_MetchosinVolcanics_percent",
           sampleStage_normalized, 
           antecedent_30day_rain, # relatively more important than 7-day -- correlated with stage tho 
           antecedent_7day_temp, # no real diff in VIM for 7 vs 30 day
           drainage_area_km2,
           # slope_median_degrees, # only 3 unique values
           slope_mean_degrees,
           tree_age_average,
           #geo_WarkGneiss_percent,
           #geo_Metagreywacke_percent,
           logging_percent_1980to2011))  #%>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(AllVariables_SAC254))


## Run RF
SAC254_allVars_RF <- randomForest::randomForest(SAC254_Abs.m ~ ., 
                                                data = AllVariables_SAC254, 
                                                replace = FALSE, # improve VIM
                                                na.action = randomForest::na.roughfix,
                                                mtry = ceiling(length(data)/2), # no. of features
                                                ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                importance = TRUE,
                                                proximity = TRUE,
                                                corr.bias = TRUE) # experimental 


## relative importance of features in predicting SAC254
## type 1 = mean square error (MSE) as decrease in accuracy
RF_SAC254_allChrc_RelImp1_MSE <- randomForest::importance(SAC254_allVars_RF, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain event number" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "sampling stage" = "sampleStage_normalized",
                                "drainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "tree age (average, yrs)" = 'tree_age_average',
                                "slope (median, degrees)" = "slope_median_degrees",
                                "slope (mean, degrees)" = "slope_mean_degrees",
                                "logging history (1980-2011)" = "logging_percent_1980to2011", 
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # add category for plot colouring:
  mutate(variable_group = case_when(
    # conditions:
    predictor == "rain event number" | 
      predictor == "antecedent 7-day air temp" |
      predictor == "antecedent 30-day rain" | 
      predictor == "sampling stage" ~ "Conditions",
    # surface characteristics
    predictor == "tree age (average, yrs)" |
      predictor ==  "drainage area" | 
      predictor == "sample site elevation" | 
      predictor == "slope (mean, degrees)" | 
      predictor == "logging history (1980-2011)" ~ "Surface characteristics",
    # subsurface characteristics (parent material):
    predictor == "metamorphic (%)" |
      predictor == "igneous (%)"  ~ "Parent material") ) %>%
  mutate(variable_group = factor(variable_group))  


# VIM plot
RFplot_all_SAC254 <- RF_SAC254_allChrc_RelImp1_MSE %>% 
  ggplot(aes(x = predictor, y = MSE_percent)) +
  coord_flip()+
  geom_bar(aes(fill = variable_group), alpha = 0.8,
           stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1) +
  scale_fill_manual(values = fills,
                    breaks = c("Conditions", 
                               "Surface characteristics", 
                               "Parent material")) +
  theme_bw() +
  theme(legend.position = "top", text = element_text(size = 12))+
  labs(y = expression('Relative importance in predicting'~SAC[254]~'(%)'), 
       x = "",
       fill = "Predictor variable group") +
  guides(fill = guide_legend(nrow = 3, byrow=TRUE))

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Appendix-Ch4_RFplot_all_SAC254.png", 
       width = 6, height = 6, units = "in")


```

##### RF summary plot (all variables together)
```{r}
# stack DOC, E2E3, SAC254 plots
cowplot::plot_grid(RFplot_all_DOC, 
                   (RFplot_all_SAC254 + theme(legend.position = "none") ),
                   (RFplot_all_E2E3 + theme(legend.position = "none") ),
                   ncol = 1, rel_heights = c(2, 1.3, 1.3) )

# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Appendix-Ch4_RFplot-summary_DOC-E2E3-SAC254.png", 
       width = 6, height = 7.5, units = "in")
```


## 1:1 Plots: predictors VS predictants

```{r}
# plot antecedent rain with stage
# is this a surrogate?

sixfilter_physiographic %>% 
  mutate(rain_season = factor(rain_season, levels = c("wet", "dry"))) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = sampleStage_normalized)) +
  ylim(min = 0, max = 1) +
  theme_bw() +
  geom_point(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  facet_wrap(~site)+
  labs(x = "Antecedent 30-day rain (mm)", y = "Normalized stage (a.u.)" ) 

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4-A_RF_ant.rain-norm.stage.png", width = 4, height = 4, units = "in")


```


## new (by predictor)

### sampling stage
```{r}
stage_DOC <- sixfilter_physiographic %>% 
  ggplot(aes(x = sampleStage_normalized, y = NPOC_ppm)) +
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  #facet_wrap(~site, scales = "free_y")+
  labs(x = "", y = "DOC (mg/L)" )


stage_SAC254 <- sixfilter_physiographic %>% 
  ggplot(aes(x = sampleStage_normalized, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(mg/L)) )


stage_E2E3 <- sixfilter_physiographic %>% 
  filter(E2E3 > 2.5) %>% 
  ggplot(aes(x = sampleStage_normalized, y = E2E3)) +
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Sampling stage (normalized)", y = expression(E[2]:E[3]) )

# together
cowplot::plot_grid(stage_DOC, stage_SAC254, stage_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_stage.png",
       width = 6, height = 6, units = "in")

```


### temp (7 day ant)
```{r}
temp_DOC <- sixfilter_physiographic %>% 
  mutate(rain_season = factor(rain_season, levels = c("wet", "dry"))) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = NPOC_ppm)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  facet_wrap(~rain_season, scales = "free_x") +
  labs(x = "", y = "DOC (mg/L)" ) 


temp_SAC254 <- sixfilter_physiographic %>% 
  ggplot(aes(x = antecedent_7day_temp, y = SAC254_Abs.m)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(m^-1) ) ) 


temp_E2E3 <-  sixfilter_physiographic %>% 
  ggplot(aes(x = antecedent_7day_temp, y = E2E3)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Antecedent 7-day air temp. (°C)", y = expression(E[2]:E[3])) 

# together
cowplot::plot_grid(temp_DOC, temp_SAC254, temp_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_temp.png",
       width = 6, height = 6, units = "in")

```


### rain (30 day ant)
```{r}
rain_DOC <- sixfilter_physiographic %>% 
  #filter(rain_season == "wet") %>% 
  ggplot(aes(x = antecedent_30day_rain, y = NPOC_ppm)) + 
  theme_bw() +
  geom_point(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  facet_wrap(~site, scales = "free_x") +
  labs(x = "", y = "DOC (mg/L)" )

rain_SAC254 <- sixfilter_physiographic %>% 
  ggplot(aes(x = antecedent_30day_rain, y = SAC254_Abs.m)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  #facet_wrap(~site, scales = "free_x") +
  labs(x = "", y = expression(SAC[254]~(mg/L)) ) 

rain_E2E3 <- sixfilter_physiographic %>% 
  filter(E2E3 > 2.5) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = E2E3)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Antecedent 30-day rain (mm)", y = expression(E[2]:E[3]) ) 

# together
cowplot::plot_grid(rain_DOC, rain_SAC254, rain_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_rain.png",
       width = 6, height = 6, units = "in")

```

### metamorphic
```{r}
metamorphic_DOC <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_metamorphic_percent, y = NPOC_ppm)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "", y = "DOC (mg/L)")

metamorphic_SAC254 <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_metamorphic_percent, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(m^-1)) )

metamorphic_E2E3 <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_metamorphic_percent, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Metamorphic parent material (%)", y = expression(E[2]:E[3]) )

# together
cowplot::plot_grid(metamorphic_DOC, metamorphic_SAC254, metamorphic_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_metamorphic.png",
       width = 6, height = 6, units = "in")

```


### slope
```{r}
slope_DOC <- sixfilter_physiographic %>% 
  ggplot(aes(x = slope_mean_degrees, y = NPOC_ppm)) + 
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5,
               varwidth = TRUE) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "", y = "DOC (mg/L)")


slope_SAC254 <- sixfilter_physiographic %>% 
  ggplot(aes(x = slope_mean_degrees, y = NPOC_ppm)) + 
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5,
               varwidth = TRUE) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(m^-1)) )


slope_E2E3 <- sixfilter_physiographic %>% 
  ggplot(aes(x = slope_mean_degrees, y = NPOC_ppm)) + 
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5,
               varwidth = TRUE) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Slope, mean (degrees)", y = expression(E[2]:E[3]))

# together
cowplot::plot_grid(slope_DOC, slope_SAC254, slope_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_slope.png",
       width = 6, height = 6, units = "in")

```


### logging (1980-2011)
```{r}
logging_DOC <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = logging_percent_1980to2011, y = NPOC_ppm)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "", y = "DOC (mg/L)" )


logging_SAC254 <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = logging_percent_1980to2011, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(m^-1)) )


logging_E2E3 <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = logging_percent_1980to2011, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Area harvested between 1980 and 2011 (%)", y = expression(E[2]:E[3]) )


# together
cowplot::plot_grid(logging_DOC, logging_SAC254, logging_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_logging.png",
       width = 6, height = 6, units = "in")
```


### tree age
```{r}
tree_DOC <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = tree_age_average, y = NPOC_ppm)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "", y = "DOC(mg/L)" )


tree_SAC254 <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = tree_age_average, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(m^-1)) )


tree_E2E3 <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = tree_age_average, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "Tree age, average (years)", y = expression(E[2]:E[3]) )

# together
cowplot::plot_grid(tree_DOC, tree_SAC254, tree_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_tree-age.png",
       width = 6, height = 6, units = "in")

```


### drainage area -- not very interesting...
```{r}
area_DOC <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = drainage_area_km2, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "", y = "DOC(mg/L)" )


area_SAC254 <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = drainage_area_km2, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "", y = expression(SAC[254]~(m^-1)) )


area_E2E3 <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = drainage_area_km2, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = expression(Drainage~Area~(km^2), y = expression(E[2]:E[3]) ) )

# together
cowplot::plot_grid(area_DOC, area_SAC254, area_E2E3,
                   ncol = 1, align = "v", rel_heights = c(2, 1.3, 1.3))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_drainage-area.png",
       width = 6, height = 6, units = "in")
```


## Old (by predictant)
### DOC
```
{r}

# 1 DOC with 7-day temp
a <- sixfilter_physiographic %>% 
  mutate(rain_season = factor(rain_season, levels = c("wet", "dry"))) %>% 
  #filter(rain_season == "wet") %>% 
  ggplot(aes(x = antecedent_7day_temp, y = NPOC_ppm)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  facet_wrap(~rain_season, scales = "free_x") +
  labs(x = "Antecedent 7-day air temp. (°C)", y = "DOC (mg/L)" ) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_DOC-predictor-1-temp.png",
       width = 4, height = 4, units = "in")

# 2 DOC with 30-day rain
b <- sixfilter_physiographic %>% 
  #filter(rain_season == "wet") %>% 
  ggplot(aes(x = antecedent_30day_rain, y = NPOC_ppm)) + 
  theme_bw() +
  geom_point(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  facet_wrap(~site, scales = "free_x") +
  labs(x = "Antecedent 30-day rain (mm)", y = "DOC (mg/L)" )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_DOC-predictor-2-rain.png",
       width = 4, height = 4, units = "in")

# 3 DOC with slope -- box
c <- sixfilter_physiographic %>% 
  ggplot(aes(x = slope_mean_degrees, y = NPOC_ppm)) + 
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5,
               varwidth = TRUE) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Slope, mean (degrees)", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_DOC-predictor-3-slope.png",
       width = 4, height = 4, units = "in")

# 3 again DOC & slope -- ridge plot
c <- sixfilter_physiographic %>% 
  mutate(site = fct_rev(site) ) %>% 
  ggplot(aes(y = slope_mean_degrees, x = NPOC_ppm)) + 
  theme_bw() +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(y = "Slope, mean (degrees)", x = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_DOC-predictor-3-slope_ridge.png",
       width = 4, height = 4, units = "in")


# 4 DOC with metamorphic parent material
d <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_metamorphic_percent, y = NPOC_ppm)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Metamorphic parent material (%)", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_DOC-predictor-4-gneiss.png",
       width = 4, height = 4, units = "in")

# ?4? DOC with Leech River formation parent material
d <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_LeechRiverFormation_percent, y = NPOC_ppm)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Leech River Formation parent material (%)", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_DOC-predictor-4.1-LeechRvForm.png",
       width = 4, height = 4, units = "in")



```

###  SAC254

```
{r}
# 1 SAC254 with sampling stage
aa <- sixfilter_physiographic %>% 
  ggplot(aes(x = sampleStage_normalized, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Sampling stage (normalized)", y = expression(SAC[254]~(mg/L)) )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_SAC254-predictor-1-stage.png",
       width = 4, height = 4, units = "in")

# 2 SAC254 with 7-day temp
bb <- sixfilter_physiographic %>% 
  ggplot(aes(x = antecedent_7day_temp, y = SAC254_Abs.m)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  # facet_wrap(~rain_season, scales = "free_x") + # doesn't clarify much
  labs(x = "Antecedent 7-day air temp. (°C)", y = expression(SAC[254]~(mg/L)) ) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_SAC254-predictor-2-temp.png",
       width = 4, height = 4, units = "in")

# 3 SAC254 with 30-day rain
cc <- sixfilter_physiographic %>% 
  ggplot(aes(x = antecedent_30day_rain, y = SAC254_Abs.m)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  #facet_wrap(~site, scales = "free_x") +
  labs(x = "Antecedent 30-day rain (mm)", y = expression(SAC[254]~(mg/L)) ) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_SAC254-predictor-3-rain.png",
       width = 4, height = 4, units = "in")


# 4 SAC254 with metamorphic parent material
dd <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_metamorphic_percent, y = SAC254_Abs.m)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Metamorphic parent material (%)", y = expression(SAC[254]~(mg/L)) )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_SAC254-predictor-4-metamorphic.png",
       width = 4, height = 4, units = "in")
```


### E2E3

```
{r}
# 1 E2E3 with 30-day rain
aaa <- sixfilter_physiographic %>% 
  filter(E2E3 > 2.5) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = E2E3)) + 
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Antecedent 30-day rain (mm)", y = expression(E[2]:E[3]) ) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_E2E3-predictor-1-rain.png",
       width = 4, height = 4, units = "in")

# 2 E2E3 with sampling stage
bbb <- sixfilter_physiographic %>% 
  filter(E2E3 > 2.5) %>% 
  ggplot(aes(x = sampleStage_normalized, y = E2E3)) +
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Sampling stage (normalized)", y = expression(E[2]:E[3]) )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_E2E3-predictor-2-stage.png", width = 4, height = 4, units = "in")


# 3 E2E3 with Tree age
ccc <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = tree_age_average, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Tree age, average (years)", y = expression(E[2]:E[3]) )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_E2E3-predictor-3-TreeAge.png",
       width = 4, height = 4, units = "in")

# 4 E2E3 with logging history
ddd <- sixfilter_physiographic %>% 
  filter(E2E3 > 3.5) %>% 
  ggplot(aes(x = logging_percent_1980to2011, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Area harvested between 1980 and 2011 (%)", y = expression(E[2]:E[3]) )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_E2E3-predictor-4-31yrLogging.png",
       width = 4, height = 4, units = "in")

## stack ccc and ddd
cowplot::plot_grid(ccc,
                   ddd + theme(legend.position = "none"),
                   ncol = 1, rel_heights = c(1.25, 1))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_E2E3-predictor-3n4-Trees-Logging.png",
       width = 4, height = 6, units = "in")


# 5 E2E3 with metamorphic parent material
eee <- sixfilter_physiographic %>% 
  ggplot(aes(x = geo_metamorphic_percent, y = E2E3)) +
  theme_bw() +
  geom_boxplot(aes(fill = site), alpha = 0.5) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "Metamorphic parent material (%)", y = expression(E[2]:E[3]) )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_RF_E2E3-predictor-5-metamorphic.png",
       width = 4, height = 4, units = "in")

```
# Hysteresis

```{r}

# antecedent weather (like RF but a bit different)
antecedent_Wx <- LWSA_meanWx %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(Date) %>% 
  summarise(daily_rain = sum(Rn15_mean, na.rm = TRUE),
            daily_mean_T = mean(Temp_mean, na.rm = TRUE)) %>%  # temp too, why not
  ungroup() %>% 
  arrange(Date) %>% 
  # add a 7 day antecedent rain for each day
  mutate(antecedent_30day_rain = as.double(zoo::rollsum(daily_rain, k = 30, align = "right", fill = NA)),
         antecedent_15day_rain = as.double(zoo::rollsum(daily_rain, k = 15, align = "right", fill = NA)),
         antecedent_7day_rain = as.double(zoo::rollsum(daily_rain, k = 7, align = "right", fill = NA)),
         antecedent_30day_temp = as.double(zoo::rollmean(daily_mean_T, k = 30, align = "right", fill = NA)),
         antecedent_22day_temp = as.double(zoo::rollmean(daily_mean_T, k = 22, align = "right", fill = NA)),
         antecedent_14day_temp = as.double(zoo::rollmean(daily_mean_T, k = 14, align = "right", fill = NA)),
         antecedent_7day_temp = as.double(zoo::rollmean(daily_mean_T, k = 7, align = "right", fill = NA)),
         antecedent_5day_temp = as.double(zoo::rollmean(daily_mean_T, k = 5, align = "right", fill = NA)),
         antecedent_3day_temp = as.double(zoo::rollmean(daily_mean_T, k = 3, align = "right", fill = NA))  )
# note: align right sets the date to the right side of box (k values wide) & sums all values in the box 

# make a big ol nugget of a dataframe
hyst_df <- sixfilter %>%
  group_by(site) %>% 
  # add normalized stage
  left_join(., ( odyssey_norm %>% group_by(source) %>% select(-c(stage_cm, Date)) ), 
            by = c("DateTime_sampled" = "DateTime", "site" = "source", "trip" = "interval", 
                   "corr_stage_cm", "rain_season", "event_ID")) %>% 
  filter(!is.na(analysis),  # drop empty TOC samples (unfiltered on shimadzu)
         QAQC_flag == "OK") %>%
  ungroup() %>% 
  # drop un-needed items 
  select(-c(analysis, collection, Date_collected, two_seasons, corr_stage_cm, rain_seasons, E4E6, SlopeRatio)) %>% 
  group_by(site, trip, sample) %>% 
  left_join(., antecedent_Wx, by = c("Date_sampled" = "Date")) %>% ungroup() %>%  
  select(-c("Date_sampled")) %>% 
  # rename norm_stg & trip
  rename(sampling_trip = "trip",
         sampleStage_normalized = "norm_stg") %>% 
  # add a month-year grouping variable
  mutate(mo = lubridate::month(DateTime_sampled),
         yr = lubridate::year(DateTime_sampled),
         moyr = paste(mo, yr, sep = "-") ) %>% 
  mutate(moyr = factor(moyr, 
                       levels = c("10-2018", "10-2019", 
                                  "11-2018", "11-2019", 
                                  "12-2018", "12-2019", 
                                  "1-2019", "1-2020",
                                  "2-2019", "2-2020", 
                                  "3-2019", "4-2019", "5-2019", "6-2019", "7-2019", "8-2019", "9-2019"))) %>% 
  mutate(hyst_season = case_when(moyr == "10-2018" |
                                   moyr == "11-2018" |
                                   moyr == "12-2018" ~ "2018 fall (early wet season)",
                                 moyr == "1-2019" |
                                   moyr == "2-2019" |
                                   moyr == "3-2019" |
                                   moyr == "4-2019" |
                                   moyr == "5-2019" ~ "2018/2019 winter (late wet season)",
                                 moyr == "6-2019" |
                                   moyr == "7-2019" |
                                   moyr == "8-2019" ~ "2019 dry season",
                                 moyr == "9-2019" |
                                   moyr == "10-2019" |
                                   moyr == "11-2019" |
                                   moyr == "12-2019" ~ "2019 fall (early wet season)",
                                 moyr == "1-2020" |
                                   moyr == "2-2020" ~ "2019/2020 winter (late wet season)"))

```

## stage sample plot events 10 & 11

```{r}
# insufficient data in events 4, 5, 6, 8, 13, 14, 15, 17
#### --- events 10 & 11 were interesting for DOC with rain 
# also the most sampled events --> eventsample_table


# plot events 10 & 11
stage_samples %>% 
  filter(event_ID == 10 | event_ID == 11) %>%
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), size = 0.6, colour = forWater_colours2["DeepBlue"])+
  theme_bw()+
  geom_point(aes(y = sampleStage_cm, shape = sample_type), 
             size = 2, na.rm = TRUE, fill = forWater_colours2[["Gray"]]) +
  scale_shape_manual(values = c("Grab" = 21, "Rack" = 24),  #circle, triangle
                     breaks = c("Grab", "Rack"))+ 
  geom_vline(xintercept = event_starts[10], linetype = 1, colour = forWater_colours2["MyOrange"] ) + 
  geom_vline(xintercept = event_starts[11], linetype = 1, colour = forWater_colours2["MyOrange"] ) + 
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right") +
  labs(y = "River Stage (cm)", x = "", caption = "Events 10 & 11", shape = "Sampling method:")+
  scale_x_datetime(breaks = "4 day")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        legend.position = "top") 
# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_sampling-events_10-11.png",
       width = 6, height = 6.5, units = "in")

```

```{r}
# trying things...
# plot antecedent rain with datetime_sampled to relate the direction of the hysteresis loop to the conditions and thus the hydrograph

sixfilter_physiographic %>% 
  ggplot(aes(x = antecedent_7day_rain, y = sampleStage_normalized)) +
  theme_bw() +
  geom_jitter(aes(fill = site), shape = 21, size = 2) +
  geom_smooth(colour = "black", size = 0.7) +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 11)) +
  labs(x = "antecedent 7-day rain (mm)", y = "Sampling stage (normalized)" )
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_hysteresis_rain-stage.png", width = 4, height = 4, units = "in")

```



### DOC 

7-day temp 

```{r}

## --- 7 day antecedent temp
# event 10
e10temp_DOC <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = NPOC_ppm, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11)) +
  labs(x = "antecedent 7-day temp (°C)", y = "DOC (mg/L)") + ggtitle("A) Event 10")

# event 11
e11temp_DOC <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = NPOC_ppm, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "antecedent 7-day temp (°C)", y = "") + ggtitle("B) Event 11")

# side by side
#hystPlot_DOC_3temp <-
hystPlot_DOC_7temp <- cowplot::plot_grid(e10temp_DOC, e11temp_DOC, ncol = 2)

```

30-day rain

```{r}

# add the lowflow points to both events... ??
#hyst_1011df_shared <- 
e_ten <- hyst_df %>%
  select(c(site, Date, event_ID, DateTime_sampled, antecedent_30day_rain, NPOC_ppm, SAC254_Abs.m, E2E3)) %>% 
  filter(event_ID == "10") %>% 
  mutate(shared_lowflow_eventID = event_ID )

e_eleven <- hyst_df %>%
  select(c(site, Date, event_ID, DateTime_sampled, antecedent_30day_rain, NPOC_ppm, SAC254_Abs.m, E2E3)) %>% 
  filter(event_ID == "10" | event_ID == "11",
         Date > lubridate::as_date("2019-11-10")) %>% 
  mutate(shared_lowflow_eventID = case_when(Date > lubridate::as_date("2019-11-10") ~ "11") )

# join both so they share the low-flow date points
hyst_1011df_shared <- full_join(e_ten, e_eleven,
                                by = c("site", "Date", "event_ID", "DateTime_sampled", 
                                       "antecedent_30day_rain", 
                                       "NPOC_ppm", "SAC254_Abs.m", "E2E3",  
                                       "shared_lowflow_eventID")) %>% 
  mutate(shared_lowflow_eventID = factor(shared_lowflow_eventID, levels = c("10", "11")) )

# tried it with shared low-flow and it was whacky -- better to use the actual events

# 10 == clockwise hysteresis
# 11 == counter clockwise

## --- 30 day antecedent rain
# event 10
e10rain_DOC <- hyst_1011df_shared %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = NPOC_ppm)) + #, colour = site
  geom_point(na.rm = TRUE, colour = forWater_colours2["DeepBlue"], size = 2)+
  geom_path(arrow = arrow(angle = 20, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  #scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11)) +
  labs(x = "antecedent 30-day rain (mm)", y = "DOC (mg/L)") + ggtitle("A) Event 10")

# event 11
e11rain_DOC <- hyst_1011df_shared %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = NPOC_ppm)) +  # , colour = site
  geom_point(na.rm = TRUE, colour = forWater_colours2["DeepBlue"], size = 2)+
  geom_path(arrow = arrow(angle = 20, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  #scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw() +  
  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "antecedent 30-day rain (mm)", y = "") + ggtitle("B) Event 11")

# side by side
hystPlot_DOC_30rain <-cowplot::plot_grid(e10rain_DOC, e11rain_DOC, ncol = 2)


```

stage

```{r}

## --- stage
# event 10
e10stg_DOC <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x =  sampleStage_cm, y = NPOC_ppm, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11)) +
  labs(x = "sampling stage (cm)", y = "DOC (mg/L)") + ggtitle("A) Event 10")

# event 11
e11stg_DOC <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = sampleStage_cm, y = NPOC_ppm, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "sampling stage (cm)", y = "") + ggtitle("B) Event 11")

# side by side
hystPlot_DOC_stg <- cowplot::plot_grid(e10stg_DOC, e11stg_DOC, ncol = 2)

```

### SAC254

stage

```{r}
# event 10
e10SAC254_stg <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = sampleStage_cm, y = SAC254_Abs.m, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11))+
  labs(x = "Sample Stage (cm)", y = expression(SAC[254]~(m^-1)) ) + ggtitle("A) Event 10")

# event 11
e11SAC254_stg <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = sampleStage_cm, y = SAC254_Abs.m, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "Sample Stage (cm)", y = "") + ggtitle("B) Event 11")

# side by side
hystPlot_SAC254_stg <-cowplot::plot_grid(e10SAC254_stg, e11SAC254_stg, ncol = 2)

```

30-day rain
```{r}

# event 10
e10SAC254_rain <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = SAC254_Abs.m, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11))+
  labs(x = "antecedent 30-day rain (mm)", y = expression(SAC[254]~(m^-1)) ) + ggtitle("A) Event 10")

# event 11
e11SAC254_rain <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = SAC254_Abs.m, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "antecedent 30-day rain (mm)", y = "") + ggtitle("B) Event 11")

# side by side
hystPlot_1011_SAC_rain <- cowplot::plot_grid(e10SAC254_rain, e11SAC254_rain, ncol = 2)

```

7-day temp 

```{r}

## --- 7 day antecedent temp
# event 10
e10temp_SAC254 <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = SAC254_Abs.m, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11)) +
  labs(x = "antecedent 7-day temp (°C)", y = expression(SAC[254]~ (m^1)) ) + ggtitle("A) Event 10")

# event 11
e11temp_SAC254 <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = SAC254_Abs.m, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "antecedent 7-day temp (°C)", y = expression(SAC[254]~ (m^1))) + ggtitle("B) Event 11")

# side by side
#hystPlot_DOC_3temp <-
hystPlot_1011_SAC_temp <- cowplot::plot_grid(e10temp_SAC254, e11temp_SAC254, ncol = 2)

```

### E2E3

30-day rain

```{r}

# event 10
e10E2E3_rain <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = E2E3, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11))+
  labs(x = "antecedent 30-day rain (mm)", y = expression(E[2]:E[3]) ) + ggtitle("A) Event 10")

# event 11
e11E2E3_rain <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_30day_rain, y = E2E3, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "antecedent 30-day rain (mm)", y = "") + ggtitle("B) Event 11")

# side by side
hystPlot_E2E3_rain <-cowplot::plot_grid(e10E2E3_rain, e11E2E3_rain, ncol = 2)


```

stage

```{r}
# event 10
e10E2E3_stg <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = sampleStage_cm, y = E2E3, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11))+
  labs(x = "Sample Stage (cm)", y = expression(E[2]:E[3]) ) + ggtitle("A) Event 10")

# event 11
e11E2E3_stg <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = sampleStage_cm, y = E2E3, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "Sample Stage (cm)", y = "") + ggtitle("B) Event 11")

# side by side
hystPlot_E2E3_stg <-cowplot::plot_grid(e10E2E3_stg, e11E2E3_stg, ncol = 2)

```

7-day temp 

```{r}

## --- 7 day antecedent temp
# event 10
e10temp_E2E3 <- hyst_df %>%
  filter(event_ID == "10") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = E2E3, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+
  theme(legend.position = "none", strip.background.x = element_blank(), strip.text = element_blank(), 
        text = element_text(size = 11)) +
  labs(x = "antecedent 7-day temp (°C)", y = expression(E[2]:E[3]) ) + ggtitle("A) Event 10")

# event 11
e11temp_E2E3 <- hyst_df %>%
  filter(event_ID == "11") %>% 
  filter(!is.na(DateTime_sampled)) %>% 
  ggplot(aes(x = antecedent_7day_temp, y = E2E3, colour = site)) + 
  geom_point(na.rm = TRUE)+
  geom_path(arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches") ),
            na.rm = TRUE, linetype = 1) +
  scale_colour_brewer(palette = "Dark2") +
  facet_wrap(~site, scales = "free", ncol = 1, strip.position = "right")+
  theme_bw()+  theme(legend.position = "none", text = element_text(size = 11)) +
  labs(x = "antecedent 7-day temp (°C)", y = expression(E[2]:E[3]) ) + ggtitle("B) Event 11")

# side by side
#hystPlot_DOC_3temp <-
hystPlot_E2E3_temp <- cowplot::plot_grid(e10temp_E2E3, e11temp_E2E3, ncol = 2)

```

## hysteresis plots summary
```
# compare DOC to spectral ps

# wetness -- 30 day rain was a predictor variable that all 3 were sensitive to
# DOC has a better plot -- 10 was clockwise, 11 was counter clockwise
hystPlot_1011_SAC_rain # similar pattern
hystPlot_E2E3_rain  # similar pattern but missing values make it whacky

```

```{r}
# Save the DOC hysteresis plot as representative 
hystPlot_DOC_30rain
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_hysteresis_DOC-wetness.png",
       width = 6, height = 6, units = "in" )
```


```
# --- other variables? Plots are not as clear
# temp 
hystPlot_DOC_7temp # ugly
hystPlot_1011_SAC_temp # ugly

hystPlot_DOC_7temp # ugly
hystPlot_E2E3_temp # ugly

# stage
hystPlot_DOC_stg     # messy but more clear
hystPlot_SAC254_stg  # messy

hystPlot_DOC_stg
hystPlot_E2E3_stg

```

## events 10 & 11 similarity tests:

how did events 10-11 compare to other sampled events, is this subset representative?
```{r}

# were trips 10 & 11 results representative of most events?
# compare samples from these results to others
# use statistics -- Wilcoxon tests by parameter and site

# stage
narrow_stage <- stage_samples %>% filter(QAQC_flag == "OK") %>% 
  filter(interval == 10 | interval == 11) 

rest_stage <- stage_samples %>% filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet", # remove summer baseflow
         interval != 10, interval != 11) 

# sample results
narrow_results <- sixfilter %>% filter(QAQC_flag == "OK") %>% 
  filter(event_ID == 10 | event_ID == 11) 

rest_results <- sixfilter %>% filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet", # remove summer baseflow
         event_ID != 10, event_ID != 11) 


# density distribution normality 
# stage of the isolated events
narrow_stage %>% 
  ggplot(aes(corr_stage_cm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 
# stage of the rest
rest_stage %>% 
  ggplot(aes(corr_stage_cm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 

# DOC of the isolated events
narrow_results %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 
# stage of the rest
rest_results %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 


# run tests and compile results
# ---
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis
# p-value < 0.05 --> reject the null hypothesis 
subbset_Wilcoxon_tests <- bind_rows(
  ## stage ---
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "Weeks"],
                   rest_stage$corr_stage_cm[rest_stage$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "ChrisCrk"],
                   rest_stage$corr_stage_cm[rest_stage$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "LeechHead"],
                   rest_stage$corr_stage_cm[rest_stage$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "CraggCrk"],
                   rest_stage$corr_stage_cm[rest_stage$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "WestLeech"],
                   rest_stage$corr_stage_cm[rest_stage$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "Tunnel"],
                   rest_stage$corr_stage_cm[rest_stage$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "stage"),
  
  ## NPOC ---
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "Weeks"],
                   rest_results$NPOC_ppm[rest_results$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "ChrisCrk"],
                   rest_results$NPOC_ppm[rest_results$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "LeechHead"],
                   rest_results$NPOC_ppm[rest_results$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "CraggCrk"],
                   rest_results$NPOC_ppm[rest_results$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "WestLeech"],
                   rest_results$NPOC_ppm[rest_results$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "Tunnel"],
                   rest_results$NPOC_ppm[rest_results$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "NPOC_ppm"),
  
  ## UV-254 ---
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "Weeks"],
                   rest_results$SAC254_Abs.m[rest_results$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "ChrisCrk"],
                   rest_results$SAC254_Abs.m[rest_results$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "LeechHead"],
                   rest_results$SAC254_Abs.m[rest_results$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "CraggCrk"],
                   rest_results$SAC254_Abs.m[rest_results$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "WestLeech"],
                   rest_results$SAC254_Abs.m[rest_results$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "Tunnel"],
                   rest_results$SAC254_Abs.m[rest_results$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "SAC254_Abs.m"),
  
  ## E2E3 ---
  tidy(wilcox.test(narrow_results$E2E3[narrow_results$site == "Weeks"],
                   rest_results$E2E3[rest_results$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "E2E3"),
  
  tidy(wilcox.test(narrow_results$E2E3[narrow_results$site == "ChrisCrk"],
                   rest_results$E2E3[rest_results$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "E2E3"),
  
  tidy(wilcox.test(narrow_results$E2E3[narrow_results$site == "LeechHead"],
                   rest_results$E2E3[rest_results$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "E2E3"),
  
  tidy(wilcox.test(narrow_results$E2E3[narrow_results$site == "CraggCrk"],
                   rest_results$E2E3[rest_results$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "E2E3"),
  
  tidy(wilcox.test(narrow_results$E2E3[narrow_results$site == "WestLeech"],
                   rest_results$E2E3[rest_results$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "E2E3"),
  
  tidy(wilcox.test(narrow_results$E2E3[narrow_results$site == "Tunnel"],
                   rest_results$E2E3[rest_results$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "E2E3")  ) %>% 
  
  select(Parameter = "Analysis", site, p.value) %>% 
  
  # pull p-values to summarize
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
                              p.value < 0.05 ~ "**",# CL = 95%
                              p.value > 0.05 ~ "NA")) # not significantly different (means are equal)
# check it out
subbset_Wilcoxon_tests

# also
# compare storm intensity and duration for these events
narrow_events_summary <- majEvents_summary %>% 
  filter(ID == 10 | ID == 11) %>% 
  select(c(ID, startDate, endDate, rain, duration_days, intensity_mmhr))

rest_events_summary <- majEvents_summary %>% 
  filter(ID != 10, ID != 11) %>% 
  select(c(ID, startDate, endDate, rain, duration_days, intensity_mmhr))

# compare with tests & summarize results
subbset_Wilcoxon_tests_rain <- bind_rows(
  tidy(wilcox.test(narrow_events_summary$rain, rest_events_summary$rain)) %>% 
    mutate(Parameter = "Rain (mm)"),
  tidy(wilcox.test(narrow_events_summary$duration_days, rest_events_summary$duration_days)) %>% 
    mutate(Parameter = "Duration (days)"),
  tidy(wilcox.test(narrow_events_summary$intensity_mmhr, rest_events_summary$intensity_mmhr)) %>%
    mutate(Parameter = "Intensity (mm/hr)")) %>% 
  select(Parameter, p.value) %>% 
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
                              p.value < 0.05 ~ "**",# CL = 95%
                              p.value > 0.05 ~ "NA"))  # means are equal 

# make a summary table
subbset_Wilcoxon_tests$Parameter <- fct_recode(subbset_Wilcoxon_tests$Parameter, 
                                               "DOC (mg/L)" = "NPOC_ppm", 
                                               "SAC254 (/m)" = "SAC254_Abs.m",
                                               "Stream stage" = "stage")
# on average?
avP <- subbset_Wilcoxon_tests %>% 
  group_by(Parameter) %>% 
  summarise(p.value = mean(p.value)) %>% 
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
                              p.value < 0.05 ~ "**",# CL = 95%
                              p.value > 0.05 ~ "NA"))  # means are equal
# add weather
full_join(avP, (subbset_Wilcoxon_tests_rain %>% mutate(site = "all") %>% 
                  filter(Parameter != "Duration (days)") ) ) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch4_events10-11_rep_wilcoxon.csv")

# add weather
full_join(subbset_Wilcoxon_tests, (subbset_Wilcoxon_tests_rain %>%
                                     filter(Parameter != "Duration (days)") ) ) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch4_events10-11_rep-by-site_wilcoxon.csv")

```

## events 10 & 11 conc changes

```{r}
percent_diff <- hyst_df %>% 
  filter(event_ID == 10 | event_ID == 11) %>% 
  group_by(site, event_ID) %>% 
  summarise(DOC_max = max(NPOC_ppm, na.rm = TRUE),
            DOC_min = min(NPOC_ppm, na.rm = TRUE),
            DOC_diff = ((DOC_max - DOC_min)/((DOC_max + DOC_min)/2))*100,
            SAC_max = max(SAC254_Abs.m, na.rm = TRUE),
            SAC_min = min(SAC254_Abs.m, na.rm = TRUE),
            SAC_diff = ((SAC_max - SAC_min)/((SAC_max + SAC_min)/2))*100,
            E2E3_max = max(E2E3, na.rm = TRUE),
            E2E3_min = min(E2E3, na.rm = TRUE),
            E2E3_diff = ((E2E3_max - E2E3_min)/((E2E3_max + E2E3_min)/2))*100 ) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch4_events10-11_values-difference.csv")



```





# River Stage & NOM dynamics

## stage variance:  Levene's test for homoscedasticity

An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 

```{r}
# check for normality
dat <- odyssey_data %>%
  group_by(source) %>% 
  filter(rain_season == "wet", # remove baseflow
         !is.na(corr_stage_cm)) %>%  
  filter(Date >= "2018-12-06", Date <= "2020-01-31") # overlapping date ranges


# check for normality
dat %>% 
  ggplot(aes(corr_stage_cm))+
  geom_density(aes(colour = source))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~source, nrow = 3, scales = "free_y")

# car::leveneTest(response ~ independent variable)
car::leveneTest(stage_cm ~ source, data = dat) %>% tidy() %>% pull("p.value") %>% first()
# --> reject Ho, variance is not homogeneous across the LWSA 

# find out where:

# headwaters
# 1-2
WC <- dat %>%
  filter(source == "Weeks" | source == "ChrisCrk") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 1-3
H1 <- dat %>%
  filter(source == "Weeks" | source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 2-3  
H2 <- dat %>%
  filter(source == "ChrisCrk" | source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems
# 3-4   
H4 <- dat %>%
  filter(source == "CraggCrk" | source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 3-5 
H5 <- dat %>%
  filter(source == "WestLeech" | source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-5
C5 <- dat %>%
  filter(source == "WestLeech" | source == "CraggCrk") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems and outlet
# 3-6
H6 <- dat %>%
  filter(source == "LeechHead" | source == "Tunnel") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-6 
C6 <- dat %>%
  filter(source == "CraggCrk" | source == "Tunnel") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 5-6   
W6 <- dat %>%
  filter(source == "WestLeech" | source == "Tunnel") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()


# write a summary table
Levenes_summary_stage <- tibble::tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk",
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"), 
  p.value = c(WC, H1, H2, 
              H4, H5, C5, 
              H6, C6, W6)) %>% 
  mutate("Significance" = # (confidence level: ***99%, **95%, *90%)
           case_when(p.value < 0.01 ~ "***",
                     p.value < 0.05 ~ "**",
                     p.value < 0.1 ~ "*",
                     p.value > 0.1 ~ "homoscedastic")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/stage-stats_variance-LeveneTests.csv", col_names = T)

```


## stage & params

### plot density of stage (norm) + sample results

* normalized parameters also

```{r}

# plot stage vs DOC
d <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = norm_NPOC_ppm))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  scale_x_continuous(breaks = c(0.5, 1)) +
  facet_wrap(~site, scales = "free_x", ncol = 1)+
  theme(legend.position = "none", text = element_text(size=12),
        strip.background = element_blank(), strip.text = element_blank())+
  labs(y = "Normalized Stage", x = "DOC (mg/L)")


# plot stage vs UV254
u <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = norm_SAC254_Abs.m))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  scale_x_continuous(breaks = c(0.5, 1)) +
  facet_wrap(~site, scales = "free_x", ncol = 1)+
  theme(legend.position = "none", text = element_text(size=12),
        strip.background = element_blank(), strip.text = element_blank())+
  labs(y = "", x = expression(SAC[254]) )

# plot stage vs UV254
s <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = norm_SUVA))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  scale_x_continuous(breaks = c(0.5, 1)) +
  facet_wrap(~site, scales = "free_x", ncol = 1, strip.position = "right")+
  theme(legend.position = "none", text = element_text(size=12),
        strip.background = element_blank(), strip.text = element_blank())+
  labs(y = "", x = expression(SUVA[254]))

# plot stage vs E2E3
e <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = norm_E2E3))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  scale_x_continuous(breaks = c(0.5, 1)) +
  facet_wrap(~site, scales = "free_x", ncol = 1, strip.position = "right")+
  theme(legend.position = "none", text = element_text(size=12))+
  labs(y = "", x = expression(E[2]:E[3]))

# group
cowplot::plot_grid(d,u,e, nrow = 1, rel_widths = c(1,1,1.075))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch4_StageNorm_DOC-NOM.png",
       width = 6, height = 7.5, units = "in")

```

## temporal - loess plot

```{r DOC_overtime-by-site}

# brewer.pal(n = 6, name = "PuOr") # orange to purple (2 orange for headwaters)
# brewer.pal(n = 6, name = "PRGn") # purple to green (1 purple for tunnel + 3 green for mainstems)
timetrendcolours1 <- c(brewer.pal(n = 11, name = "PiYG")[3], brewer.pal(n = 11, name = "PiYG")[2], # orange
                       brewer.pal(n = 11, name = "RdBu")[8], brewer.pal(n = 11, name = "RdBu")[9], brewer.pal(n = 11, name = "RdYlBu")[10], # three blue for mainstem
                       brewer.pal(n = 8, name = "Set2")[6]) # purple for tunnel

### this one is more clear:
# DOC over time at each of the six sites 
sixfilter_sub %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm)) +
  theme_bw() +
  geom_jitter(aes(fill = site), size = 2, shape = 21, alpha = 0.4)+
  geom_smooth(aes(group = site, colour = site), linetype = 1, se = FALSE)+ 
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  labs(y = "DOC (mg/L)", fill = "Sample type:", x = "") +
  guides(fill = guide_legend("Site:"),
         colour = guide_legend("Site:"))+
  facet_wrap(~subbasin_type, ncol = 1, strip.position = "right", scales = "free_y")+
  theme(axis.text.x = element_text(angle = 30, hjust = 1), 
        legend.position = "top",
        text = element_text(size = 12))+
  scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_trend_bassin-type-facet_loess.png", width = 6, height = 6, units = "in") 

# samples: n_installGrabSamples+n_installRackSamples  
# Grab samples: n_installGrabSamples 
# Rack samples: n_installRackSamples

```





# half-attempted -- maybe come back to this
```
# do the same but for stage
# at all of the six sites (DOC over time) -- not a very good plot
odyssey_data %>%
ggplot(aes(x = DateTime, y = corr_stage_cm)) +
theme_bw() +
geom_smooth(aes(group = source, 
colour = source, 
linetype = subbasin_type), se = FALSE)+ 
scale_colour_manual(values = timetrendcolours1)+
scale_linetype_manual(values = c(3, 1, 2))+
labs(y = "DOC (mg/L)", fill = "Sample type:", x = "") +
theme(axis.text.x = element_text(angle = 45, hjust = 1), 
text = element_text(size = 11), 
legend.position = "top", legend.box="vertical")+
scale_x_datetime(date_labels = "%Y %b %d",
date_breaks = "2 months",
date_minor_breaks = "1 months")+
guides(colour = guide_legend("Site:"),
linetype = guide_legend("Basin type:", override.aes = list(colour = "black")))  
# --- yeah no.
```



TRASH?
```
# check with seasons

# with seasons
d2 <- stage_samples_norm %>% 
ggplot(aes(y = norm_stg, x = NPOC_ppm))+
theme_bw()+
geom_point(aes(fill = rain_season), shape = 21, na.rm = TRUE, alpha = 0.8)+
geom_density_2d(aes(colour = rain_season))+
scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
"dry" = forWater_colours2[["MyOrange"]]),
aesthetics = c("fill", "colour"))+
#scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
scale_y_continuous(breaks = c(0.5, 1))+
facet_wrap(~site, scales = "free_x", ncol = 1)+
theme(legend.position = "none", text = element_text(size=11),
strip.background = element_blank(), strip.text = element_blank())+
labs(y = "Normalized Stage", x = "DOC (mg/L)")

# seasons
u2 <- stage_samples_norm %>% 
ggplot(aes(y = norm_stg, x = SAC254_Abs.m))+
theme_bw()+
geom_point(aes(fill = rain_season), shape = 21, na.rm = TRUE, alpha = 0.8)+
geom_density_2d(aes(colour = rain_season))+
scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
"dry" = forWater_colours2[["MyOrange"]]),
aesthetics = c("fill", "colour"))+
#scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
scale_y_continuous(breaks = c(0.5, 1))+
#scale_x_discrete(position = "top") +
facet_wrap(~site, scales = "free_x", ncol = 1)+
theme(legend.position = "none", text = element_text(size=11),
strip.background = element_blank(), strip.text = element_blank())+
labs(y = "", x = "Abs. at 254nm")  

# season
s2 <- stage_samples_norm %>% 
ggplot(aes(y = norm_stg, x = SUVA))+
theme_bw()+
geom_point(aes(fill = rain_season), shape = 21, na.rm = TRUE, alpha = 0.8)+
geom_density_2d(aes(colour = rain_season))+
scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
"dry" = forWater_colours2[["MyOrange"]]),
aesthetics = c("fill", "colour"))+
#scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
scale_y_continuous(breaks = c(0.5, 1))+
#scale_x_discrete(position = "top") +
facet_wrap(~site, scales = "free_x", ncol = 1, strip.position = "right")+
theme(legend.position = "none", text = element_text(size=11))+
labs(y = "", x = expression(paste("SUVA " [254])))

cowplot::plot_grid(d2,u2,s2, ncol = 3)
# nope
```



## Synchrony: Stage & DOC 

### DOC-stage extrema
```{r}
# --- MAXIMUMS ---

# summarize data for coinciding maxima of DOC and stage at each site
coincident_peaks <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm), NPOC_ppm != 0) %>%  # drop NAs
  select(c(site, trip, event_ID, DateTime_sampled, sample, NPOC_ppm, sampleStage_cm, HoldTime_days, QAQC_flag, Hobo_Tmean_airDaily)) %>% 
  mutate(sample = as.character(sample)) %>% 
  group_by(site, trip, event_ID) %>% 
  summarise(max_stage = max(sampleStage_cm), # maximum stage sampled
            # sample associated with max stage that was sampled:
            sample_max_stage = sample[last(which.max(sampleStage_cm))],
            # DOC associated with max stage that was sampled:
            npoc_max_stage = NPOC_ppm[last(which.max(sampleStage_cm))],
            # eventID 
            max_DOC = max(NPOC_ppm),  # maximum DOC sampled
            # sample associated with max DOC that was sampled:
            sample_max_DOC = (sample[last(which.max(NPOC_ppm))]),
            # stage associated with max DOC that was sampled:
            stage_max_DOC = sampleStage_cm[last(which.max(NPOC_ppm))]) %>% 
  mutate(
    # TRUE if the sample ID for peak stage matched with the sample-ID of peak DOC:
    coincident_sample = (sample_max_stage == sample_max_DOC), 
    # TRUE if the [DOC] for peak stage matched with the peak [DOC] sampled:
    coincident_DOC = (npoc_max_stage == max_DOC),
    # TRUE if the maximum stage sampled matched with the stage associated with max [DOC]:
    coincident_stage = (max_stage == stage_max_DOC)) %>% 
  ungroup()

# calculate the percent of samples for which peak-DOC-sample coincided with peak-stage-sample
# for each site
coincident_proportion_sites <- coincident_peaks %>% 
  group_by(site) %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  group_by(site) %>% 
  # calculate the proportion of common peaks
  summarise(common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))

# overall -- not grouped by site
coincident_proportion_all <- coincident_peaks %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  summarise(site = "all sites",
            common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))
### key:
# common sample = sample ID associated with peak-stage matched with the sample ID of peak-DOC
# common_npoc = sample DOC concentration associated with max.stage sampled corresponds to the maximum DOC measured for that event
# common_stage = peak stage sampled corresponds to the stage associate with peak DOC

# combine as a tibble (merge with minima and write as csv (next chunk))
maxima_tibble <- bind_rows(coincident_proportion_sites, coincident_proportion_all) %>%
  select(c(site, common_npoc)) %>% 
  rename("Site" = "site", 
         "Proportion of common maxima" = "common_npoc")

# -----


# ----- MINIMUMS ----

# summarize data for coinciding minima of DOC and stage at each site
coincident_valleys <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
         NPOC_ppm != 0) %>%  # drop NAs
  select(c(site, trip, event_ID, DateTime_sampled, sample, NPOC_ppm, sampleStage_cm, HoldTime_days, QAQC_flag, Hobo_Tmean_airDaily)) %>% 
  mutate(sample = as.character(sample)) %>% 
  group_by(site, trip, event_ID) %>% 
  summarise(min_stage = min(sampleStage_cm), # minimum stage sampled
            # sample associated with min stage that was sampled:
            sample_min_stage = sample[first(which.min(sampleStage_cm))],
            # DOC associated with min stage that was sampled:
            npoc_min_stage = NPOC_ppm[first(which.min(sampleStage_cm))],
            # eventID 
            min_DOC = min(NPOC_ppm),  # minimum DOC sampled
            # sample associated with min DOC that was sampled:
            sample_min_DOC = (sample[first(which.min(NPOC_ppm))]),
            # stage associated with min DOC that was sampled:
            stage_min_DOC = sampleStage_cm[first(which.min(NPOC_ppm))]) %>% 
  mutate(
    # TRUE if the sample ID for peak stage matched with the sample-ID of peak DOC:
    coincident_sample = (sample_min_stage == sample_min_DOC), 
    # TRUE if the [DOC] for peak stage matched with the peak [DOC] sampled:
    coincident_DOC = (npoc_min_stage == min_DOC),
    # TRUE if the maximum stage sampled matched with the stage associated with max [DOC]:
    coincident_stage = (min_stage == stage_min_DOC)) %>% 
  ungroup()

# calculate the percent of samples for which peak-DOC-sample coincided with peak-stage-sample
# for each site
coincident_valley_proportion_sites <- coincident_valleys %>% 
  group_by(site) %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  group_by(site) %>% 
  # calculate the proportion of common peaks
  summarise(common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))

# overall -- not grouped by site
coincident_valley_proportion_all <- coincident_valleys %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  summarise(site = "all sites",
            common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))
# woops -- in trip 20 there were two grab samples collected at Chris Crk which resulted in 'common_sample' differing from 'common_npoc' and 'common_stage', which did agree

### key:
# common sample = sample ID associated with min-stage matched with the sample ID of min-DOC
# common_npoc = sample DOC concentration associated with min.stage sampled corresponds to the minimum DOC measured for that event
# common_stage = min. stage sampled corresponds to the stage associate with min. DOC

# combine as a table
minima_tibble <- bind_rows(coincident_valley_proportion_sites, 
                           coincident_valley_proportion_all) %>%
  select(c(site, common_npoc)) %>% 
  rename("Site" = "site", 
         "Proportion of common minima" = "common_npoc")

# -----


# ----- TABLE: COINCIDENCE OF EXTREMA
# join with maxima and write a csv
full_join(maxima_tibble, minima_tibble) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/synchrony_DOC-stage_extrema-simultaneous.csv", col_names = T)

```


### Stage response

* find peaks for stage for each event
* calculate time to peak for each storm
* calculate magnitude of stage cahnge
* calculate rate of stream response 

```{r}
# isolate max for each site by event
max_stage <- stage_samples %>%
  filter(!is.na(DateTime)) %>% 
  select(c(site, trip = "interval", DateTime, corr_stage_cm, event_ID)) %>% 
  group_by(site, event_ID) %>% 
  slice(which.max(corr_stage_cm)) %>% 
  rename(DateTime_stage_max = "DateTime",
         stage_max = "corr_stage_cm")
# minimum stage
min_stage <- stage_samples %>%
  filter(!is.na(DateTime)) %>% 
  select(c(site, trip = "interval", DateTime, corr_stage_cm, event_ID)) %>% 
  group_by(site, event_ID) %>% 
  slice(which.min(corr_stage_cm))%>% 
  rename(DateTime_stage_min = "DateTime",
         stage_min = "corr_stage_cm")

# join and calculate time to peak / magnitude of stage change / rate of response
stage_response <- full_join(max_stage, min_stage, by = c("site", "trip", "event_ID")) %>% 
  ungroup() %>% 
  mutate(time_to_peak_hr = as.double(difftime(DateTime_stage_max, DateTime_stage_min, units = "hours")),
         stage_change_cm = (stage_max - stage_min),
         stage_response_cmhr = (stage_change_cm)/time_to_peak_hr) %>% 
  group_by(site) %>% 
  # add the rain events summary
  left_join(., (majEvents_summary %>% 
                  select(ID, intensity_mmhr) ), by = c("event_ID" = "ID")  )


# summarize all
stage_response %>% 
  ungroup() %>% 
  filter(!is.na(stage_change_cm), time_to_peak_hr > 0) %>%
  select(c(site, stage_max, stage_min, time_to_peak_hr, stage_change_cm, stage_response_cmhr)) %>% 
  group_by(site) %>% 
  summarise_all(list(~mean(.), ~sd(.), ~max(.), ~min(.))) %>% 
  select(c(site,  
           time_to_peak_hr_min, time_to_peak_hr_max,  
           stage_change_cm_min, stage_change_cm_max,  
           stage_response_cmhr_min, stage_response_cmhr_max)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Ch3_response_stage-summary.csv")

```


```{r}
# plot rate of stream response with storm intensity -- not very interesting
stage_response %>%
  mutate(event_ID = factor(event_ID, levels = c(1:18))) %>% 
  filter(!is.na(event_ID), event_ID != 17, event_ID != 18) %>% 
  ggplot(aes(x = intensity_mmhr, y = stage_response_cmhr))+
  geom_point(aes(colour = site)) +
  theme_bw()+
  theme(legend.position = "top")+
  scale_color_brewer(palette = "Dark2")

# join to stage data to check visually -- stage plot with max and min
left_join(odyssey_data, max_stage, by = c("source" = "site", "interval" = "trip", "event_ID", "DateTime" = "DateTime_stage_max")) %>% 
  left_join(min_stage, by = c("source" = "site", "interval" = "trip", "event_ID", "DateTime" = "DateTime_stage_min")) %>% 
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm))+
  geom_point(aes(y = stage_max), shape = 21, fill = "red", na.rm = TRUE)+
  geom_point(aes(y = stage_min), shape = 21, fill = "blue",  na.rm = TRUE)+
  theme_bw()+
  facet_wrap(~source, ncol = 1, strip.position = "right", scales = "free_y")+
  labs(x = "", y = "River Stage (cm)")

```

### magnitude of DOC change

calculate percent difference within storm flow 

diff = max[DOC] - min[DOC] = magnitude of change

percent difference = [diff/((max+min)/2)]*100

```{r}
# calculate difference
max_DOC <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
         NPOC_ppm != 0) %>%  # drop NAs
  select(c(site, trip, event_ID, DateTime_sampled, NPOC_ppm)) %>% 
  group_by(site, event_ID) %>% 
  slice(which.max(NPOC_ppm)) %>% 
  rename(DateTime_DOC_max = DateTime_sampled,
         DOC_max = NPOC_ppm)

# minimum DOC
min_DOC <- sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
         NPOC_ppm != 0) %>%  # drop NAs
  select(c(site, trip, event_ID, DateTime_sampled, NPOC_ppm)) %>% 
  group_by(site, event_ID) %>% 
  slice(which.min(NPOC_ppm)) %>% 
  rename(DateTime_DOC_min = DateTime_sampled,
         DOC_min = NPOC_ppm)

# join and calculate magnitude of change (DOC diff) / percent difference
DOC_change <- full_join(max_DOC, min_DOC, by = c("site", "trip", "event_ID")) %>% 
  ungroup() %>% 
  group_by(site) %>% 
  mutate(time_to_max_hr = as.double(difftime(DateTime_DOC_max, DateTime_DOC_min, units = "hours")),
         DOC_change_mgL = DOC_max - DOC_min,
         DOC_percentDiff = DOC_change_mgL/((DOC_max+DOC_min)/2)*100 ) %>% 
  # filter out single sample events and NULL values
  filter(!is.na(DOC_change_mgL), DOC_change_mgL != 0)

# summarize all
DOC_change %>% 
  ungroup() %>% 
  select(c(site, DOC_max, DOC_min, DOC_change_mgL, DOC_percentDiff)) %>% 
  group_by(site) %>% 
  summarise_all(list(~max(.), ~min(.))) %>% 
  select(c(site,  
           DOC_min_min, DOC_max_max,  
           DOC_change_mgL_min, DOC_change_mgL_max,  
           DOC_percentDiff_min, DOC_percentDiff_max)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/response_DOC-summary.csv")



# --- I'm not sure how useful this is:

# join the DOC slice set to stage and filter for empty and missing or null values
response_full <- left_join(DOC_change, stage_response, by = c("site", "trip", "event_ID")) %>% 
  filter(!is.na(DOC_change_mgL), !is.na(time_to_peak_hr), DOC_change_mgL != 0) %>% 
  select(c(site, trip, event_ID, rain_intensity_mmhr = "intensity_mmhr", 
           DOC_change_mgL, DOC_percentDiff, 
           time_to_peakStage_hr = "time_to_peak_hr", stage_change_cm)) %>% 
  ungroup()

# summarize 
response_full %>% 
  select(-c(site, trip)) %>% 
  group_by(event_ID) %>% 
  summarize_all(list(mean = mean)) %>% 
  mutate(event_ID = factor(event_ID, levels = c(1:18))) %>% 
  arrange(event_ID)

```

#### subset -ERROR
```
{r}
# repeat the above for the subset samples

# subset stage response
stage_response_subset <- stage_response %>% 
ungroup() %>% 
filter(!is.na(stage_change_cm), time_to_peak_hr > 0,
event_ID == 9 | event_ID == 10 | event_ID == 11 | event_ID == 12) %>%
select(c(site, event_ID, intensity_mmhr, stage_max, stage_min, time_to_peak_hr, stage_change_cm, stage_response_cmhr)) %>% 
group_by(site) %>% 
summarise_all(list(~max(.), ~min(.))) %>% 
select(c(site, intensity_mmhr_min, intensity_mmhr_max,   
time_to_peak_hr_min, time_to_peak_hr_max,  
stage_change_cm_min, stage_change_cm_max,  
stage_response_cmhr_min, stage_response_cmhr_max)) %>% 
ungroup() %>% 
#mutate(event_ID = factor(event_ID, levels = c(1:18))) %>% 
arrange(site) %>% 
write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/response_stage-summary_subset.csv")

# subset DOC differences
DOC_response_subset <- DOC_change %>% 
ungroup() %>% 
filter(event_ID == 9 | event_ID == 10 | event_ID == 11 | event_ID == 12) %>% 
select(c(site, DOC_max, DOC_min, DOC_change_mgL, DOC_percentDiff)) %>% 
group_by(site) %>% 
summarise_all(list(~max(.), ~min(.))) %>% 
select(c(site,   
DOC_min_min, DOC_max_max,  
DOC_change_mgL_min, DOC_change_mgL_max,  
DOC_percentDiff_min, DOC_percentDiff_max)) %>%
#mutate(event_ID = factor(event_ID, levels = c(1:18))) %>% 
arrange(site) %>% 
write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/response_DOC-summary_subset.csv")


```



Subset grouping --- not sure this is necessary

plot peak-DOC w/ stage-samples 

narrow in on specific (well-sampled) events
```
{r}
# for plots, add max_DOC by trip and event to stage_sample dataframe

# Maxima
peaksss1 <- stage_samples %>% 
filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
sample_type == "Grab" | sample_type == "Rack", 
sample != "Algae",      # remove sample containing whole algae (high DOC)
QAQC_flag == "OK",      # remove samples with extended hold-time  
sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5", # unique only
!is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm)) %>%  # drop NAs
group_by(site, trip, event_ID) %>% 
# summarize maxima
summarise(maxDOC_stage = sampleStage_cm[which.max(NPOC_ppm)],
sample = sample[which.max(NPOC_ppm)],
sampleStage_cm = sampleStage_cm[which.max(NPOC_ppm)]) %>% 
full_join(stage_samples %>% group_by(site, trip), by = c("site", "trip", "sampleStage_cm", "sample",  "event_ID")) %>% 
arrange(DateTime) %>% ungroup()

# Minima joined to Maxima for full extrema set
# peaks in stage_sample = peaksSS
peaksss <- stage_samples %>% 
filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
sample_type == "Grab" | sample_type == "Rack", 
sample != "Algae",      # remove sample containing whole algae (high DOC)
QAQC_flag == "OK",      # remove samples with extended hold-time  
sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5", # unique only
!is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm)) %>%  # drop NAs
group_by(site, trip, event_ID) %>%
# summarize minima
summarise(minDOC_stage = sampleStage_cm[which.min(NPOC_ppm)],
sample = sample[which.min(NPOC_ppm)],
sampleStage_cm = sampleStage_cm[which.min(NPOC_ppm)]) %>% 
full_join(peaksss1 %>% group_by(site, trip), by = c("site", "trip", "sampleStage_cm", "sample", "event_ID")) %>% 
arrange(DateTime) %>% 
ungroup()

# -----
# trip 17-21 -- stage and samples at each site by sampling event
subset_event_starts <- (events %>% filter(ID == 9 | ID == 10 | ID == 11 | ID == 12))$StartDate

# plot
peaksss %>% 
filter(interval == 17 | interval == 18 | interval == 19 | interval == 20 | interval == 21) %>%
ggplot(aes(x = DateTime))+
#geom_vline(xintercept = c(trip_starts), size = 0.7, colour = forWater_colours2["Green"])+
#geom_vline(colour = forWater_colours2["SkyBlue"], linetype = "dotted", xintercept = c(event_ends), size = 0.65, show.legend = TRUE)+ # events end
geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash", 
xintercept = c(subset_event_starts), size = 0.65, show.legend = TRUE)+ # events start

#annotate("text", x = c(subset_event_starts), y = 60, label = c("9", "10", "11", "12")) +

geom_line(aes(y = corr_stage_cm), size = 0.6, colour = forWater_colours2["DeepBlue"])+
theme_bw()+
geom_point(aes(y = sampleStage_cm, colour = "sample", fill = "sample"), 
shape = 21, size = 2, na.rm = TRUE) +
geom_point(aes(y = maxDOC_stage, colour = "max DOC", fill = "max DOC"), 
shape = 24, size = 2, na.rm = TRUE) +
geom_point(aes(y = minDOC_stage, colour = "min DOC", fill = "min DOC"), 
shape = 22, size = 2, na.rm = TRUE) +
# geom_text(aes(x = DateTime, y = sampleStage_cm, label = round(NPOC_ppm, 2)), na.rm = TRUE) +
scale_fill_manual(values = c(forWater_colours2["MyOrange"], 
forWater_colours2["Green"], 
"grey")) + # manual matches alphabetically (max, min, sample)
facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right") +
labs(y = "River Stage (cm)", x = "", caption = "Events 9-12")+
scale_x_datetime(breaks = "3 day")+
theme(text = element_text(size = 12),
axis.text.x = element_text(angle = 60, hjust = 1),
legend.position = "top") +
scale_color_manual(breaks = c("max DOC", "min DOC", "sample"),
values = c("black", "black", "black"))+ # alphabetical matching
guides(colour = guide_legend("key:"),
fill = guide_legend("key:", override.aes = list(shape = c(24, 22, 21), fill = c(forWater_colours2["MyOrange"], forWater_colours2["Green"], "grey"))))
# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/narrow_events_9-12_peakDOC-stage.png",
width = 6.5, height = 6.5, units = "in")

# --- 
# big plot with lines showing subbset
# assign lines
narrow_trips_start <- peaksss %>% 
filter(interval == 17) %>%  
summarise(event = first(event_ID),
start = first(DateTime)) %>% pull()

narrow_trips_end <- peaksss %>% 
filter(interval == 21) %>%  
summarise(event = last(event_ID),
end = last(DateTime)) %>% pull()

# big plot with lines
stage_sample_plot +
geom_vline(xintercept = narrow_trips_start, size = 0.7)+
geom_vline(xintercept = narrow_trips_end, size = 0.7)
# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/stage-samples-with_narrow_events_9-12.png",
width = 6.5, height = 7, units = "in")

# OR --- big plto with all max and min and lines for subset
# -----
# stage and sample extrema at each site by sampling event
peaksss %>% 
ggplot(aes(x = DateTime))+
geom_line(aes(y = corr_stage_cm), size = 0.6, colour = forWater_colours2["DeepBlue"])+
theme_bw()+
geom_point(aes(y = sampleStage_cm, colour = "sample", fill = "sample"), shape = 21, size = 2.5, na.rm = TRUE) +
geom_point(aes(y = minDOC_stage, colour = "min DOC", fill = "min DOC"), shape = 22, size = 2.5, na.rm = TRUE) +
geom_point(aes(y = maxDOC_stage, colour = "max DOC", fill = "max DOC"), shape = 24, size = 2, na.rm = TRUE) +
geom_vline(xintercept = narrow_trips_start, size = 0.7)+
geom_vline(xintercept = narrow_trips_end, size = 0.7) +
# change colour of points -- matches alphabetically (max, min, sample)
scale_fill_manual(values = c(forWater_colours2["MyOrange"], forWater_colours2["Green"], "grey")) + 
facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right") +
labs(y = "River Stage (cm)", x = "")+
scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months") +
theme(text = element_text(size = 12),
axis.text.x = element_text(angle = 30, hjust = 1),
legend.position = "top") +
# colour for point outlines:
scale_color_manual(breaks = c("max DOC", "min DOC", "sample"), values = c("black", "black", "black"))+ 
# legend:
guides(colour = guide_legend("key:"),
fill = guide_legend("key:", override.aes = list(shape = c(24, 22, 21), fill = c(forWater_colours2["MyOrange"], forWater_colours2["Green"], "grey"))))
# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/extrema_peakDOC-stage_plot.png",
width = 7.5, height = 8, units = "in")

```


subset similarity tests:

how did events 17-21 compare to other sampled events, is this subset representative?
```
{r}

# were trips 17-21 results representative of most events?
# compare samples from these results to others
# use statistics -- Wilcoxon tests by parameter and site

# stage
narrow_stage <- stage_samples %>% 
filter(QAQC_flag == "OK") %>% 
filter(interval == 17 | interval == 18 | interval == 19 | interval == 20 | interval == 21) 

rest_stage <- stage_samples %>% 
filter(QAQC_flag == "OK") %>% 
filter(rain_season == "wet", # remove summer baseflow
interval != 17, interval != 18, interval != 19, interval != 20, interval != 21) 

# sample results
narrow_results <- sixfilter %>% 
filter(QAQC_flag == "OK") %>% 
filter(trip == 17 | trip == 18 | trip == 19 | trip == 20 | trip == 21) 

rest_results <- sixfilter %>% 
filter(QAQC_flag == "OK") %>% 
filter(trip != 17, trip != 18, trip != 19, trip != 20, trip != 21) 


# density distribution normality 
# stage of the isolated events
narrow_stage %>% 
ggplot(aes(corr_stage_cm))+
geom_density(aes(colour = site))+
theme_bw()+
theme(legend.position = "top") 
# stage of the rest
rest_stage %>% 
ggplot(aes(corr_stage_cm))+
geom_density(aes(colour = site))+
theme_bw()+
theme(legend.position = "top") 

# DOC of the isolated events
narrow_results %>% 
ggplot(aes(NPOC_ppm))+
geom_density(aes(colour = site))+
theme_bw()+
theme(legend.position = "top") 
# stage of the rest
rest_results %>% 
ggplot(aes(NPOC_ppm))+
geom_density(aes(colour = site))+
theme_bw()+
theme(legend.position = "top") 


# run tests and compile results
# ---
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis
# p-value < 0.05 --> reject the null hypothesis 
subbset_Wilcoxon_tests <- bind_rows(
## stage ---
tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "Weeks"],
rest_stage$corr_stage_cm[rest_stage$site == "Weeks"])) %>% 
mutate(site = "Weeks", Analysis = "stage"),

tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "ChrisCrk"],
rest_stage$corr_stage_cm[rest_stage$site == "ChrisCrk"])) %>% 
mutate(site = "ChrisCrk", Analysis = "stage"),

tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "LeechHead"],
rest_stage$corr_stage_cm[rest_stage$site == "LeechHead"])) %>% 
mutate(site = "LeechHead", Analysis = "stage"),

tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "CraggCrk"],
rest_stage$corr_stage_cm[rest_stage$site == "CraggCrk"])) %>% 
mutate(site = "CraggCrk", Analysis = "stage"),

tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "WestLeech"],
rest_stage$corr_stage_cm[rest_stage$site == "WestLeech"])) %>% 
mutate(site = "WestLeech", Analysis = "stage"),

tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "Tunnel"],
rest_stage$corr_stage_cm[rest_stage$site == "Tunnel"])) %>% 
mutate(site = "Tunnel", Analysis = "stage"),

## NPOC ---
tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "Weeks"],
rest_results$NPOC_ppm[rest_results$site == "Weeks"])) %>% 
mutate(site = "Weeks", Analysis = "NPOC_ppm"),

tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "ChrisCrk"],
rest_results$NPOC_ppm[rest_results$site == "ChrisCrk"])) %>% 
mutate(site = "ChrisCrk", Analysis = "NPOC_ppm"),

tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "LeechHead"],
rest_results$NPOC_ppm[rest_results$site == "LeechHead"])) %>% 
mutate(site = "LeechHead", Analysis = "NPOC_ppm"),

tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "CraggCrk"],
rest_results$NPOC_ppm[rest_results$site == "CraggCrk"])) %>% 
mutate(site = "CraggCrk", Analysis = "NPOC_ppm"),

tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "WestLeech"],
rest_results$NPOC_ppm[rest_results$site == "WestLeech"])) %>% 
mutate(site = "WestLeech", Analysis = "NPOC_ppm"),

tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "Tunnel"],
rest_results$NPOC_ppm[rest_results$site == "Tunnel"])) %>% 
mutate(site = "Tunnel", Analysis = "NPOC_ppm"),

## UV-254 ---
tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "Weeks"],
rest_results$SAC254_Abs.m[rest_results$site == "Weeks"])) %>% 
mutate(site = "Weeks", Analysis = "SAC254_Abs.m"),

tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "ChrisCrk"],
rest_results$SAC254_Abs.m[rest_results$site == "ChrisCrk"])) %>% 
mutate(site = "ChrisCrk", Analysis = "SAC254_Abs.m"),

tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "LeechHead"],
rest_results$SAC254_Abs.m[rest_results$site == "LeechHead"])) %>% 
mutate(site = "LeechHead", Analysis = "SAC254_Abs.m"),

tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "CraggCrk"],
rest_results$SAC254_Abs.m[rest_results$site == "CraggCrk"])) %>% 
mutate(site = "CraggCrk", Analysis = "SAC254_Abs.m"),

tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "WestLeech"],
rest_results$SAC254_Abs.m[rest_results$site == "WestLeech"])) %>% 
mutate(site = "WestLeech", Analysis = "SAC254_Abs.m"),

tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "Tunnel"],
rest_results$SAC254_Abs.m[rest_results$site == "Tunnel"])) %>% 
mutate(site = "Tunnel", Analysis = "SAC254_Abs.m")) %>% 

select(Parameter = "Analysis", site, p.value) %>% 

# pull p-values to summarize
mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
p.value < 0.05 ~ "**",# CL = 95%
p.value > 0.05 ~ "NA")) # not significantly different (means are equal)
# check it out
subbset_Wilcoxon_tests

# also
# compare storm intensity and duration
narrow_events_summary <- majEvents_summary %>% 
filter(ID == 10 | ID == 11 | ID == 12) %>% 
select(c(ID, startDate, endDate, rain, duration_days, intensity_mmhr))

rest_events_summary <- majEvents_summary %>% 
filter(ID != 10, ID != 11, ID != 12) %>% 
select(c(ID, startDate, endDate, rain, duration_days, intensity_mmhr))

# compare with tests & summarize results
subbset_Wilcoxon_tests_rain <- bind_rows(
tidy(wilcox.test(narrow_events_summary$rain, rest_events_summary$rain)) %>% 
mutate(Parameter = "Rain (mm)"),
tidy(wilcox.test(narrow_events_summary$duration_days, rest_events_summary$duration_days)) %>% 
mutate(Parameter = "Duration (days)"),
tidy(wilcox.test(narrow_events_summary$intensity_mmhr, rest_events_summary$intensity_mmhr)) %>%
mutate(Parameter = "Intensity (mm/hr)")) %>% 
select(Parameter, p.value) %>% 
mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
p.value < 0.05 ~ "**",# CL = 95%
p.value > 0.05 ~ "NA"))  # means are equal 

# make a summary table

# stage and UV 254 are not comparable but DOC is
narrow_wilcox_DOC <- subbset_Wilcoxon_tests %>% 
filter(Parameter == "NPOC_ppm") %>% 
mutate(Parameter = "DOC (mg/L)")
# join with rain summary
full_join(narrow_wilcox_DOC, (subbset_Wilcoxon_tests_rain %>%
filter(Parameter != "Duration (days)") %>% 
mutate(site = "LWSA"))) %>% 
select(c(site, Parameter, p.value)) %>%
write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/narrow-subbset_wilcoxon.csv")



# compare hold-time days
narrow_results %>% 
group_by(site, trip) %>% 
summarise(HT_mean = mean(HoldTime_days, na.rm = T),
HT_min = min(HoldTime_days, na.rm = T),
HT_max = max(HoldTime_days, na.rm = T))

```




# APPENDIX PLOTS

## Malahat Wx

Longer data record from the Malahat weather station (for comparison).

```{r, malahat-wx}

# malahat weather
malahat_data <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Malahat_station-data-11596.csv", 
                         skip = 16,
                         col_names = TRUE,
                         col_types = list("f", "c", "d", "d")) %>% 
  mutate(Datetime = lubridate::ymd_hms(Datetime, tz = TZ, truncated = 1),
         Date = lubridate::as_date(Datetime),
         Year = lubridate::year(Datetime))

# summary: malahat_data precip + air temp 
malahat_data %>% 
  filter(Analysis == "Precipitation Amount (mm)", 
         between(Year, 2014, 2019)) %>% 
  group_by(Year) %>%
  summarise(total_precip = sum(Value, na.rm = TRUE)) %>% 
  ungroup() %>% 
  right_join((
    malahat_data %>% 
      dplyr::filter(Analysis == "Temperature (Mean) (celsius)", 
                    between(Year, 2014, 2019)) %>% 
      group_by(Year) %>%
      summarise(annual_mean_temp = mean(Value, na.rm = TRUE),
                temp_sd = sd(Value))) %>% 
      ungroup(), 
    by = "Year") %>%
  filter(Year != "2013", Year != "2020") %>% 
  dplyr::rename("year" = Year, 
                "annual precip. (mm)" = total_precip, 
                "mean air temp. (°C)" = annual_mean_temp, 
                "std.dev. (± °C)" = temp_sd) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_malahat-summary.csv")


# plots
# plot malahat rain and highlight my study period
malahat_rn <- malahat_data %>% 
  filter(Analysis == "Precipitation Amount (mm)") %>% 
  ggplot(aes(x = Datetime, y = Value)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain (mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
  theme(legend.position = "none") +
  gghighlight::gghighlight(Datetime > "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))

# plot malahat temperature and highlight my study period
malahat_temp <- malahat_data %>% 
  filter(Analysis == "Temperature (Mean) (celsius)") %>% 
  ggplot(aes(x = Datetime, y = Value)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = expression('Mean daily air temp ('*~degree*C*')')) +
  theme_bw() +
  scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(Datetime > "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))

# stack with cowplot
cowplot::plot_grid(malahat_rn, malahat_temp, ncol = 1, align = "v")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat.png")


### lag-years: Wilcoxon's rank sum test
#{r}
# check for normality
# The central limit theorem:
## sampling distribution tends to be normal if the sample is large enough (n > 30)
malahat_data %>% 
  filter(!is.na(Value),
         Analysis == "Precipitation Amount (mm)" | Analysis == "Temperature (Mean) (celsius)") %>% 
  group_by(Year, Analysis) %>% 
  summarise(count = n())
# could assume normal distribution because each year has daily values (>>30)

# visually check for normality 
malahat_data %>% 
  filter(Year != 2013, Year != 2020,  # incomplete data sets
         !is.na(Value),
         Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                   color = "Year", 
                   palette = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" ),
                   facet.by = "Analysis")
## Precipitation was not normally distributed (seasonality)

# tidy wilcoxon tests: lag-year 
## solution from:
## https://stackoverflow.com/questions/32477863/r-run-t-test-on-previous-years-by-group-using-dplyr

# t-test comparing each year to the last year
Malahat_test_lagyear <- malahat_data %>% 
  filter(Year != 2013, Year != 2020,  # incomplete data sets
         !is.na(Value)) %>%  # remove missing values 
  select(Analysis, Year) %>% 
  arrange(Analysis, Year) %>% 
  distinct() %>% 
  group_by(Analysis) %>% 
  mutate(lag_year = lag(Year)) %>% 
  filter(!is.na(lag_year)) %>% 
  group_by(Analysis, Year, lag_year) %>% 
  do(tidy(wilcox.test(malahat_data$Value[malahat_data$Year == .$Year & malahat_data$Analysis == .$Analysis],
                      malahat_data$Value[malahat_data$Year == .$lag_year & malahat_data$Analysis == .$Analysis])))

# identify signficantly different years
Malahat_test_lagyear %>% 
  filter(p.value < 0.10)

# 2015 was an incredible drought year, so it makes sense that 2015-2016 would differ


#### Wx pre & during MSc

# group
malahat_test_data <- malahat_data %>% 
  filter(!is.na(Value),
         Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data 
  mutate(set = case_when(Year == 2016 | Year == 2017 ~ "pre",
                         Year == 2018 | Year == 2019 ~ "MSc"),
         set = as_factor(set)) %>% 
  filter(!is.na(set)) 

# subset for tests
pre_MSc <- malahat_test_data %>% filter(set == "pre")
MSc <- malahat_test_data %>% filter(set == "MSc")



##### plots
# plot sets
malahat_test_data %>% 
  ggplot(aes(x = set, y = Value, fill = set))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    labels = c(pre = "2016-2017", MSc = "2018-2019"),
                    name = "Year span")+
  labs(y = "value", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~Analysis)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat_plot_pre-MSc-2years.png")

# looks like precip is not normally distributed because of seasons
# Tests for normality 
# Pre-MSc
pre_MSc %>% 
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                   color = "Year", palette = c("#648326", "#f4AB0E", "#62ACC8", "#535353"),
                   facet.by = "Analysis")

# during
MSc %>% 
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                   color = "Year", palette = c("#648326", "#f4AB0E"),
                   facet.by = "Analysis")



##### tests
# t-tests or Wilcoxon to compare 2014-2017 to 2018-2019
# ggpubr::ggqqplot() to check for normality
## if points fall approximately along the reference line, assume normality

# t-tests for temperature (normally distributed)
# Wilcoxon signed rank test for Precip (not normally distributed)
# make a tibble for tidiness
# note: snow data was only available 2017-2019 -- not included
Malahat_testMSc_Wx <- bind_rows(
  # rain
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Precipitation Amount (mm)"], 
                   MSc$Value[MSc$Analysis == "Precipitation Amount (mm)"],
  )) %>% 
    mutate(Parameter = "rain"),
  # air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Mean) (celsius)"], 
                   MSc$Value[MSc$Analysis == "Temperature (Mean) (celsius)"])) %>% 
    mutate(Parameter = "temp_mean"),
  # Min air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Min.) (celsius)"], 
                   MSc$Value[MSc$Analysis == "Temperature (Min.) (celsius)"])) %>% 
    mutate(Parameter = "temp_min"),
  # Max air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Max.) (celsius)"], 
                   MSc$Value[MSc$Analysis == "Temperature (Max.) (celsius)"])) %>% 
    mutate(Parameter = "temp_max")) %>% 
  # pull values of interest to summarize
  select(Parameter, p.value) %>% 
  mutate(signifcance = case_when(p.value < 0.01 ~ "at 99%",
                                 p.value < 0.05 ~ "at 95%",
                                 p.value < 0.1 ~ "at 90%",
                                 p.value > 0.1 ~ "NA")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Malahat_Wilcoxtest_pre-MSc-2years.csv")

# interpretation
# null hypothesis = both means are equal
# if the p-value is less than the significance level critical value, reject the null hypothesis 

```



## Nitrate & DOC
```{r}
# nitrate and DOC
a <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 1.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "none",
        text = element_text(size = 11)) +
  labs(x = "DOC (mg/L)", y = "Nitrate (mg/L)", fill = "Sample type:")+
  stat_poly_eq(formula = y ~ x, 
               aes(label =  (..rr.label..)), 
               parse = TRUE, rr.digits = 4)

# nitrate and DOC
b <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = DOCeq_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 1.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "right",
        text = element_text(size = 11),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
  labs(x = "DOC eqiv. (estimated mg/L)", y = "", fill = "Sample type:")+
  stat_poly_eq(formula = y ~ x, 
               aes(label =  (..rr.label..)), 
               parse = TRUE, rr.digits = 4)

# stack
cowplot::plot_grid(a, b, nrow = 1, rel_widths = c(1,1.3))
#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOC_scatter.png",
       width = 6, height = 4, units = "in") 

```

## Metals 

plot: ug/L metals+DOC in solution
```{r}
# filter out the parameters with insufficient data
# plot DOC against metals concentrations 

# ug/L
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"
  ) %>%
  mutate(metal_parameters = factor(metal_parameters, # order as you want to see them in plots
                                   levels = c("Total Mercury (Hg)",
                                              "Total Iron (Fe)",
                                              "Total Manganese (Mn)",
                                              "Total Aluminum (Al)",
                                              "Total Barium (Ba)",
                                              "Total Copper (Cu)",
                                              "Total Arsenic (As)",
                                              "Total Strontium (Sr)",
                                              "Total Silicon (Si)"
                                   ))) %>% 
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE, colour = "red")+ ## to check MAC
  facet_wrap(~metal_parameters, scales = "free") +
  theme_bw() +
  theme(text = element_text(size = 12)) +
  labs(y = "metals concentrations (μg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_ugL_scatterplots.png")

```

plot: mg/L metals+DOC in solution
```{r}
# mg/L
metalslab %>% 
  filter(metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)") %>%
  # order as you want to see them in plots
  mutate(metal_parameters = factor(metal_parameters, 
                                   levels = c("Total Magnesium (Mg)",
                                              "Total Potassium (K)",
                                              "Total Hardness (CaCO3)",
                                              "Total Calcium (Ca)",
                                              "Total Sodium (Na)"
                                   ))) %>%
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE)  ## to check MAC
  facet_wrap(~metal_parameters, scales = "free", ncol = 3) +
  theme_bw() +
  labs(y = "metals concentrations (mg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_mgL_scatterplots.png")
```

table: correlation metals/DOC 
```{r}
# make a summary table of Metals regression
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"|
           metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)"
  ) %>%
  group_by(metal_parameters) %>% 
  filter(!is.na(metals_values)) %>% 
  summarise(unit = first(UNITS), 
            count = n(), 
            slope = coefficients(lm(formula = metals_values ~ NPOC_ppm))[2],
            yint_DOC = coefficients(lm(formula = metals_values ~ NPOC_ppm))[1],
            r_sq = summary(lm(formula = metals_values ~ NPOC_ppm))$r.squared) %>% 
  dplyr::arrange(desc(r_sq)) %>%  # strongest correlation to weakest
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/metals-doc_correlations.csv")

```

## Treatability
```{r}

# add date, timing, update site names
treatdat_UW <- treatdat_UW %>% 
  filter(source == "02") %>%   ## turns out, everything was included in second report
  mutate(day = substr(Sample_ID, 1, 2),
         site = substr(Sample_ID, 20, 22)) %>% 
  mutate(Date = case_when(
    day == "12" ~ as_date("2019-11-12"),
    day == "18" ~ as_date("2020-02-18"))) %>% 
  mutate(Collection = case_when(
    day == "12" ~ "Nov 2019",
    day == "18" ~ "Feb 2020")) %>% 
  mutate(Collection = factor(Collection, levels = c("Nov 2019", "Feb 2020"))) %>% 
  mutate(site = case_when(
    site == "DCP" ~ "Deception-res",
    site == "TUN" ~ "Tunnel",
    site == "JDG" ~ "Judge",
    site == "RTH" ~ "Rithet")) %>% 
  mutate(site = factor(site))

# isolate and join to my UBC lab results for treatability samples
treatdat <- sampleresults %>% 
  filter(sample == "Treatability") %>% 
  full_join(treatdat_UW, by = c("Date", "site")) %>% 
  mutate(site = factor(site))

# pivot long
treatdat_long <- treatdat_UW %>%
  filter(source == "02") %>% 
  select(-c(source, Sample_ID, pH, Turbidity_NTU, Zeta_Potential_mV, TBM, DBCM, MCAA, MBAA, DBAA, Free_Chlorine_Final_mgL, day, Date)) %>%
  tidyr::pivot_longer(names_to = "DBP", cols = c(THMs:TCAA),
                      values_to = "DBPfp_ugL") %>% 
  mutate(DBP = factor(DBP, levels = c(
    "THMs", "TCM", "BDCM", "HAAs", "DCAA", "TCAA")))
```

## plot; DOC/UV254 + DBP-FPs
```{r}

# plot DOC
a <- treatdat_long %>% 
  ggplot(aes(x = DOC_ppm, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 2.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, ncol = 1, strip.position = "right", 
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "none",
        strip.text.y = element_blank(),
        strip.background = element_blank())+
  labs(x = "DOC \n(ppm)", 
       y = "DBP-FPs (ppb)",
       colour = "Sampling site:")+
  guides(shape = FALSE,
         colour = FALSE)

# plot UV-254
b <- treatdat_long %>% 
  ggplot(aes(x = `UV254_cm-1`, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 2.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "none",
        strip.text.y = element_blank(),
        strip.background = element_blank(),
        axis.text.y = element_blank())+
  labs(x = expression(atop(SAC[254], (m^-1)) ), 
       y = "",
       shape = "Collection:")+
  guides(colour = FALSE,
         shape = FALSE)

# plot SUVA-254
c <- treatdat_long %>% 
  rename(UV254_cm = `UV254_cm-1`) %>% 
  mutate(SUVA254_m = ( (UV254_cm*100) / DOC_ppm)) %>% 
  ggplot(aes(x = SUVA254_m, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 2.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "right",
        axis.text.y = element_blank())+
  labs(x = expression(atop(SUVA[254], (L~{mg^-1}~{m}^-1)) ), 
       y = "",
       shape = "Collection:")+
  guides(#colour = ,
    shape = guide_legend(nrow = 2))

# join side by side
cowplot::plot_grid(a, b, c, 
                   ncol = 3, align = "h", rel_widths = c(1.25, 1, 2.15)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/appendix_treatability_DOC-UV254-SUVA.png",
       width = 6, height = 6.5, units = "in")
```

# Garbage I think

##### Wx questionable objects
```{r, Wx-Stn_summaries}
# I want to know precip totals over the study period
# by month and by season
# use rain to define storm events

# calculate total rainfall at each of the wx-stns (survey mountain went in in late)
rn_MScTotal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime),
         year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx",
         date >= "2018-10-23") %>% 
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_MSc_mm = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup() 

# rain seasons rainfalls
rn_seasonal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(month = lubridate::month(DateTime),
         year = lubridate::year(DateTime)) %>%
  group_by(StationName, year, rain_season) %>% 
  dplyr::summarise(rain_seasonal = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# annual rainfalls
rn_annual <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(year = lubridate::year(DateTime)) %>%
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_monthly = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# water-year rainfalls (Oct 1 - Sept 30)
rn_wateryr <- LWSA_meanWx %>%
  mutate(Year = lubridate::year(DateTime),
         month = lubridate::month(DateTime),
         water_year = case_when(
           between(month, 1, 9) & Year == "2018" ~ "2018",
           between(month, 10, 12) & Year == "2018" ~ "2019",
           between(month, 1, 9) & Year == "2019" ~ "2019",
           between(month, 10, 12) & Year == "2019" ~ "2020",
           between(month, 1, 9) & Year == "2020" ~ "2020")) %>%
  #filter(water_year != "2018") %>% 
  group_by(water_year) %>% 
  dplyr::summarise(annual_precip_mm = sum(Rn_1_mean, na.rm = TRUE),
                   max_snow_m = max(SnowDep_mean, na.rm = TRUE),
                   annual_mean_temp = mean(Temp_mean, na.rm = TRUE),
                   temp_sd = sd(Temp_mean, na.rm = TRUE)) %>% 
  ungroup() #%>% 
#write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA_WaterYear-summary.csv", col_names = TRUE)

```


RF can generate biased VIM (variable importance measure) when different types of predictant data are used (e.g. numeric and categorical). 

Watershed characteristics data is mostly categorical (even though they're numbers they are static percent covers in each sampling basin), therefore separate characteristic data from analytical and measured data (conditions) 

RF : DOC conditions variables
```{r}
# select only condition variables
conditions_NPOC <- sixfilter_physiographic %>% 
  select(c("NPOC_ppm", # predict DOC
           "event_ID",               # when
           "sampleStage_normalized", # what depth -- this is correlated (0.6) with rain*
           "antecedent_30day_rain",   # how wet --- this is correlated (0.6) with stage*
           "antecedent_7day_temp",   # how warm
           "HoldTime_days")) #%>%     # held how long
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_conditions_NPOC))


# --- RF
# NPOC_ppm is dependent variable
# mtry = (length(RF_conditions)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (un-pruned)

## Run RF
RF_DOC_cond <- randomForest::randomForest(NPOC_ppm ~ ., data = conditions_NPOC, 
                                          na.action = randomForest::na.roughfix,
                                          mtry = ceiling(length(data)/2), # no. of features
                                          ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                          importance = TRUE,
                                          proximity = TRUE,
                                          corr.bias = TRUE) # experimental 


# Variable importance measure (VIM)
## relative importance of features in predicting DOC

## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_cond_RelImp1_MSE <- randomForest::importance(RF_DOC_cond, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "Rain event" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "Hold-time days" = "HoldTime_days",
                                "sampling stage" = "sampleStage_normalized"),  
         MSE_percent = MSE/sum(MSE)*100,  # percent MSE 
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) # arrange by MSE%

# make a VIM plot ---
RFplot_condit <- RF_DOC_cond_RelImp1_MSE %>% 
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1, 
           fill = forWater_colours2["SkyBlue"],
           alpha = 0.8) +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  labs(y = "variable importance in predicting DOC (%)", x = "")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_conditions_DOC.png", 
       width = 6, height = 5, units = "in")

```

same thing but using type=2 method (heavily weights random numbers as important)
```{r}

# VIM type 2 = mean decrease in node impurity by sum of square errors
# plot relative importance of RSS_percent -- more sensitive to correlated values --- Gini index (random numbers high!)
RF_DOC_cond_RelImp2_RSE <- randomForest::importance(RF_DOC_cond, type = 2) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  select(predictor = rowname,
         RSS = IncNodePurity) %>% # residual sum of squares
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "Rain event" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "Hold-time days" = "HoldTime_days",
                                "sampling stage" = "sampleStage_normalized"),  
         RSS_percent = RSS/sum(RSS)*100, # percent RSS 
         predictor = fct_reorder(predictor, RSS, .desc=FALSE)) %>% 
  ggplot(aes(predictor, RSS_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], 
           fill = forWater_colours2["SkyBlue"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save this one too 
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3A_RF_DOC_cond_RelImp2_RSE.png", width = 6, height = 5, units = "in")

```

E2E3 conditions variables
```{r}

# select only condition variables
conditions_E2E3 <- sixfilter_physiographic %>% 
  filter(!is.na(E2E3)) %>% 
  select(c("E2E3", # predict E2E3
           "event_ID",               # when
           "sampleStage_normalized", # what depth -- this is correlated (0.6) with rain*
           "antecedent_30day_rain",   # how wet --- this is correlated (0.6) with stage*
           "antecedent_7day_temp",   # how warm
           "HoldTime_days")) #%>%     # held how long
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_conditions_E2E3))


# --- RF
# E2E3 is dependent variable
# mtry = (length(RF_conditions)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (un-pruned)

## Run RF
RF_E2E3_cond <- randomForest::randomForest(E2E3 ~ ., data = conditions_E2E3, 
                                           na.action = randomForest::na.roughfix,
                                           mtry = ceiling(length(data)/2), # no. of features
                                           ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                           importance = TRUE,
                                           proximity = TRUE,
                                           corr.bias = TRUE) # experimental 


# Variable importance measure (VIM)
## relative importance of features in predicting E2E3

## type 1 = mean square error (MSE) as decrease in accuracy
RF_E2E3_cond_RelImp1_MSE <- randomForest::importance(RF_E2E3_cond, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "Rain event" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "Hold-time days" = "HoldTime_days",
                                "sampling stage" = "sampleStage_normalized"),  
         MSE_percent = MSE/sum(MSE)*100,  # percent MSE 
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) # arrange by MSE%

# make a VIM plot ---
RFplot_condit_E2E3 <- RF_E2E3_cond_RelImp1_MSE %>% 
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1, 
           fill = forWater_colours2["SkyBlue"],
           alpha = 0.8) +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  labs(y = "variable importance in predicting E2:E3 (%)", x = "")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_conditions_E2E3.png", 
       width = 6, height = 5, units = "in")

```


DOC RF conditions -- seasonal
```{r}
# wet season only ------------------------------------------------------------
# select only condition variables 
conditions_NPOC_wet <- sixfilter_physiographic %>% 
  filter(rain_season == "wet") %>% 
  select(c("NPOC_ppm", # predict DOC
           "event_ID",               
           "sampleStage_normalized", 
           "antecedent_30day_rain",   
           "antecedent_7day_temp",   
           "HoldTime_days")) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# --- RF
# NPOC_ppm is dependent variable
# mtry = (length(RF_conditions)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (un-pruned)

## Run RF
RF_DOC_condWET <- randomForest::randomForest(NPOC_ppm ~ ., data = conditions_NPOC_wet, 
                                             na.action = randomForest::na.roughfix,
                                             mtry = ceiling(length(data)/2), # no. of features
                                             ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                             importance = TRUE,
                                             proximity = TRUE,
                                             corr.bias = TRUE) # experimental 


# Variable importance measure (VIM)
## relative importance of features in predicting DOC

## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_cond_RelImp1_MSE__WETseason <- randomForest::importance(RF_DOC_condWET, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "Rain event" = "event_ID",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "Hold-time days" = "HoldTime_days",
                                "sampling stage" = "sampleStage_normalized"),  
         MSE_percent = MSE/sum(MSE)*100,  # percent MSE 
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% # arrange by MSE%
  # make a VIM plot ---
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["DeepBlue"], size = 1,
           fill = forWater_colours2["SkyBlue"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RF_DOC_cond_RelImp1_MSE__WETseason.png", width = 6, height = 5, units = "in")





# dry season only ------------------------------------------------------------
# select only condition variables 
conditions_NPOC_dry <- sixfilter_physiographic %>% 
  filter(rain_season == "dry") %>% 
  select(c("NPOC_ppm", # predict DOC
           "sampleStage_normalized", 
           "antecedent_30day_rain",   
           "antecedent_7day_temp",   
           "HoldTime_days")) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# --- RF
# NPOC_ppm is dependent variable
# mtry = (length(RF_conditions)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (un-pruned)

## Run RF
RF_DOC_condDRY <- randomForest::randomForest(NPOC_ppm ~ ., data = conditions_NPOC_dry, 
                                             na.action = randomForest::na.roughfix,
                                             mtry = ceiling(length(data)/2), # no. of features
                                             ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                             importance = TRUE,
                                             proximity = TRUE,
                                             corr.bias = TRUE) # experimental 


# Variable importance measure (VIM)
## relative importance of features in predicting DOC

## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_cond_RelImp1_MSE__DRYseason <- randomForest::importance(RF_DOC_condDRY, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "antecedent 7-day air temp" = "antecedent_7day_temp",
                                "antecedent 30-day rain" = "antecedent_30day_rain",
                                "Hold-time days" = "HoldTime_days",
                                "sampling stage" = "sampleStage_normalized"),  
         MSE_percent = MSE/sum(MSE)*100,  # percent MSE 
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% # arrange by MSE%
  # make a VIM plot ---
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["MyOrange"], size = 1, 
           fill = forWater_colours2["SkyBlue"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RF_DOC_cond_RelImp1_MSE__DRYseason.png", width = 6, height = 5, units = "in")


# --- 
# put these seasonal plots together to compare (not direct)
# seasons
# s <- cowplot::plot_grid(RF_DOC_cond_RelImp1_MSE__WETseason, RF_DOC_cond_RelImp1_MSE__DRYseason, ncol = 2 )

```

RF : characteristics variables --- failures
Surface DOC
```{r}

# select only watershed characteristic variables (essentially categorical (numeric) variables)
surfaceCharacteristics_NPOC <- sixfilter_physiographic %>% 
  # change rain season to numbers {1 = wet, 0 = dry}
  mutate(rain_season = case_when(rain_season == "wet" ~ 1, rain_season == "dry" ~ 0)) %>% 
  select(c(NPOC_ppm, # predict DOC
           rain_season, 
           drainage_area_km2, 
           slope_med_degrees,
           forest_percent, # correlated with wetland and open water (all landcover)
           #wetland_percent, 
           #openWater_percent,
           logging_percent_FROMnineteeneightyTOtwentyeleven = "logging_percent_nineteeneighty-twentyeleven")) # %>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_surfaceCharacteristics_NPOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_DOC_chrc_surf <- randomForest::randomForest(NPOC_ppm ~ ., 
                                               data = surfaceCharacteristics_NPOC, 
                                               replace = FALSE, # improve VIM
                                               na.action = randomForest::na.roughfix,
                                               mtry = ceiling(length(data)/2), # no. of features
                                               ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                               importance = TRUE,
                                               proximity = TRUE,
                                               corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_surfchar_RelImp1_MSE <- randomForest::importance(RF_DOC_chrc_surf, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain season" = "rain_season",
                                "darainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_med_degrees",
                                "logging history (1980-2011)" = "logging_percent_FROMnineteeneightyTOtwentyeleven" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) 

# VIM plot
RFplot_surface <- RF_DOC_surfchar_RelImp1_MSE %>% 
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1,
           fill = forWater_colours2["Green"],
           alpha = 0.8) +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  labs(y = "variable importance in predicting DOC (%)", x = "")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_surface_DOC.png", 
       width = 6, height = 5, units = "in")

```

same but with type=2 
```{r}

# --- RSS
## relative importance of features in predicting DOC
# type 2 = mean decrease in node impurity
# plot relative importance of RSS_percent -- more sensitive to correlated values
RF_DOC_surfchar_RelImp2_RSE <- randomForest::importance(RF_DOC_chrc_surf, type = 2) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         RSS = IncNodePurity) %>% # percent increase in residual sum of squares
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain season" = "rain_season",
                                "darainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_med_degrees",
                                "logging history (1980-2011)" = "logging_percent_FROMnineteeneightyTOtwentyeleven" ),
         RSS_percent = RSS/sum(RSS)*100,  # add a percent RSS variable
         predictor = fct_reorder(predictor, RSS_percent, .desc=FALSE)) %>% 
  # ----- VIM plot
  # make a plot
  ggplot(aes(predictor, RSS_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1,
           fill = forWater_colours2["Green"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3A_RF_DOC_surfchar_RelImp2_RSE.png", 
       width = 6, height = 5, units = "in")

```

E2E3 Surface
```{r}

# select only watershed characteristic variables (essentially categorical (numeric) variables)
surfaceCharacteristics_E2E3 <- sixfilter_physiographic %>% 
  filter(!is.na(E2E3)) %>% 
  # change rain season to numbers {1 = wet, 0 = dry}
  mutate(rain_season = case_when(rain_season == "wet" ~ 1, rain_season == "dry" ~ 0)) %>% 
  select(c(E2E3, # predict E2E3
           rain_season, 
           drainage_area_km2, 
           slope_med_degrees,
           forest_percent, # correlated with wetland and open water (all landcover)
           #wetland_percent, 
           #openWater_percent,
           logging_percent_FROMnineteeneightyTOtwentyeleven = "logging_percent_nineteeneighty-twentyeleven")) # %>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_surfaceCharacteristics_E2E3))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_E2E3_chrc_surf <- randomForest::randomForest(E2E3 ~ ., 
                                                data = surfaceCharacteristics_E2E3, 
                                                replace = FALSE, # improve VIM
                                                na.action = randomForest::na.roughfix,
                                                mtry = ceiling(length(data)/2), # no. of features
                                                ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                importance = TRUE,
                                                proximity = TRUE,
                                                corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_E2E3_surfchar_RelImp1_MSE <- randomForest::importance(RF_E2E3_chrc_surf, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "rain season" = "rain_season",
                                "darainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_med_degrees",
                                "logging history (1980-2011)" = "logging_percent_FROMnineteeneightyTOtwentyeleven" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) 

# VIM plot
RFplot_surface_E2E3 <- RF_E2E3_surfchar_RelImp1_MSE %>% 
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1,
           fill = forWater_colours2["Green"],
           alpha = 0.8) +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  labs(y = "variable importance in predicting E2:E3 (%)", x = "")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_surface_E2E3.png", 
       width = 6, height = 5, units = "in")

```

DOC RF surface -- seasonal 
```{r}
# wet season only -------------------------------------------------------
# select only watershed characteristic variables (essentially categorical (numeric) variables)
surfaceCharacteristics_NPOC_WET <- sixfilter_physiographic %>% 
  filter(rain_season == "wet") %>% 
  select(c("NPOC_ppm", # predict DOC
           drainage_area_km2, 
           slope_med_degrees,
           forest_percent, # correlated with wetland and open water (all landcover)
           #wetland_percent, 
           #openWater_percent,
           logging_percent_FROMnineteeneightyTOtwentyeleven = "logging_percent_nineteeneighty-twentyeleven")) # %>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_surfaceCharacteristics_NPOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_DOC_chrc_surf_WET <- randomForest::randomForest(NPOC_ppm ~ ., 
                                                   data = surfaceCharacteristics_NPOC_WET, 
                                                   replace = FALSE, # improve VIM
                                                   na.action = randomForest::na.roughfix,
                                                   mtry = ceiling(length(data)/2), # no. of features
                                                   ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                   importance = TRUE,
                                                   proximity = TRUE,
                                                   corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_surfchar_RelImp1_MSE_WET <- randomForest::importance(RF_DOC_chrc_surf_WET, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "darainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_med_degrees",
                                "logging history (1980-2011)" = "logging_percent_FROMnineteeneightyTOtwentyeleven" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # ----- VIM plot
  # make a plot
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["DeepBlue"], size = 1,
           fill = forWater_colours2["Green"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RF_DOC_surfchar_RelImp1_MSE_WETseason.png", width = 6, height = 5, units = "in")



# dry season only -------------------------------------------------------
# select only watershed characteristic variables (essentially categorical (numeric) variables)
surfaceCharacteristics_NPOC_DRY <- sixfilter_physiographic %>% 
  filter(rain_season == "dry") %>% 
  select(c("NPOC_ppm", # predict DOC
           drainage_area_km2, 
           slope_med_degrees,
           forest_percent, # correlated with wetland and open water (all landcover)
           #wetland_percent, 
           #openWater_percent,
           logging_percent_FROMnineteeneightyTOtwentyeleven = "logging_percent_nineteeneighty-twentyeleven")) # %>%     
# add a column of random values as as QA -- this should not be found to be important
#mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_surfaceCharacteristics_NPOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_DOC_chrc_surf_DRY <- randomForest::randomForest(NPOC_ppm ~ ., 
                                                   data = surfaceCharacteristics_NPOC_DRY, 
                                                   replace = FALSE, # improve VIM
                                                   na.action = randomForest::na.roughfix,
                                                   mtry = ceiling(length(data)/2), # no. of features
                                                   ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                   importance = TRUE,
                                                   proximity = TRUE,
                                                   corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_surfchar_RelImp1_MSE_DRY <- randomForest::importance(RF_DOC_chrc_surf_DRY, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "darainage area" = "drainage_area_km2",
                                "sample site elevation"= "elevation_masl",
                                "forest cover" = "forest_percent",
                                "wetland cover" = "wetland_percent",
                                "open water" ="openWater_percent",
                                "slope (median, degrees)" = "slope_med_degrees",
                                "logging history (1980-2011)" = "logging_percent_FROMnineteeneightyTOtwentyeleven" ),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # ----- VIM plot
  # make a plot
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["MyOrange"], size = 1,
           fill = forWater_colours2["Green"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RF_DOC_surfchar_RelImp1_MSE_DRYseason.png", width = 6, height = 5, units = "in")

```

Subsurface DOC
```{r}
# select subsurface predictor variables
RF_subSurfaceCharacteristics_NPOC <- sixfilter_physiographic %>% 
  select(c("NPOC_ppm", # predict DOC
           #geo_WarkGneiss_percent, 
           geo_metamorphic_percent,
           #geo_ArgilliteMetagreywacke_percent, 
           #geo_Metagreywacke_percent,
           geo_metasedimentary_percent, 
           #geo_ChertArgilliteVolcanic_percent,
           geo_metaSedimentaryVolcanic_percent, 
           #geo_MetchosinVolcanics_percent,
           #geo_SookeGabbro_percent, 
           geo_igneous_percent )) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_subSurfaceCharacteristics_NPOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_DOC_chrc_SubSurf <- randomForest::randomForest(NPOC_ppm ~ ., 
                                                  data = RF_subSurfaceCharacteristics_NPOC, 
                                                  replace = FALSE, # improve VIM
                                                  na.action = randomForest::na.roughfix,
                                                  mtry = ceiling(length(data)/2), # no. of features
                                                  ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                  importance = TRUE,
                                                  proximity = TRUE,
                                                  corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_chrc_SubSurf_RelImp1_MSE <- randomForest::importance(RF_DOC_chrc_SubSurf, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "meta-sedimentary (%)" = "geo_metasedimentary_percent", 
                                "meta-sedimentary-volcanic (%)" = "geo_metaSedimentaryVolcanic_percent", 
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) 

# VIM plot
RFplot_subsurface <- RF_DOC_chrc_SubSurf_RelImp1_MSE %>% 
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1,
           fill = forWater_colours2["Gray"],
           alpha = 0.8) +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  labs(y = "variable importance in predicting DOC (%)", x = "")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_subsurface_DOC.png", 
       width = 6, height = 5, units = "in")

```

same but with type=2
```{r}

## relative importance of features in predicting DOC
# type 2 = mean decrease in node impurity
# plot relative importance of RSS_percent -- more sensitive to correlated values
RF_DOC_chrc_SubSurf_RelImp2_RSE <- randomForest::importance(RF_DOC_chrc_SubSurf, type = 2) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         RSS = IncNodePurity) %>% # percent increase in residual sum of squares
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "meta-sedimentary (%)" = "geo_metasedimentary_percent", 
                                "meta-sedimentary-volcanic (%)" = "geo_metaSedimentaryVolcanic_percent", 
                                "igneous (%)" = "geo_igneous_percent"),
         RSS_percent = RSS/sum(RSS)*100,  # add a percent RSS variable
         predictor = fct_reorder(predictor, RSS_percent, .desc=FALSE)) %>% 
  # ----- VIM plot
  # make a plot
  ggplot(aes(predictor, RSS_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1,
           fill = forWater_colours2["Gray"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3A_RF_DOC_chrc_SubSurf_RelImp2_RSE.png", width = 6, height = 5, units = "in")


```

E2E3 Subsurface
```{r}
# select subsurface predictor variables
RF_subSurfaceCharacteristics_E2E3 <- sixfilter_physiographic %>%
  filter(!is.na(E2E3)) %>% 
  select(c(E2E3, # predict E2E3
           geo_metamorphic_percent,
           geo_metasedimentary_percent, 
           geo_metaSedimentaryVolcanic_percent, 
           geo_igneous_percent )) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_subSurfaceCharacteristics_E2E3))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_E2E3_chrc_SubSurf <- randomForest::randomForest(E2E3 ~ ., 
                                                   data = RF_subSurfaceCharacteristics_E2E3, 
                                                   replace = FALSE, # improve VIM
                                                   na.action = randomForest::na.roughfix,
                                                   mtry = ceiling(length(data)/2), # no. of features
                                                   ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                   importance = TRUE,
                                                   proximity = TRUE,
                                                   corr.bias = TRUE) # experimental 


## relative importance of features in predicting E2E3
## type 1 = mean square error (MSE) as decrease in accuracy
RF_E2E3_chrc_SubSurf_RelImp1_MSE <- randomForest::importance(RF_E2E3_chrc_SubSurf, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "meta-sedimentary (%)" = "geo_metasedimentary_percent", 
                                "meta-sedimentary-volcanic (%)" = "geo_metaSedimentaryVolcanic_percent", 
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) 

# VIM plot
RFplot_subsurface_E2E3 <- RF_E2E3_chrc_SubSurf_RelImp1_MSE %>% 
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["Gray"], size = 1,
           fill = forWater_colours2["Gray"],
           alpha = 0.8) +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  labs(y = "variable importance in predicting E2:E3 (%)", x = "")

# save it
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_subsurface_E2E3.png", 
       width = 6, height = 5, units = "in")

```

DOC RF subsurface - seasonal
```{r}

# wet season only -------
# select subsurface predictor variables
subSurfaceChrc_NPOC_Wet <- sixfilter_physiographic %>% 
  filter(rain_season == "wet") %>% 
  select(c(NPOC_ppm, # predict DOC
           geo_metamorphic_percent,
           geo_metasedimentary_percent, 
           geo_metaSedimentaryVolcanic_percent, 
           geo_igneous_percent )) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_subSurfaceCharacteristics_NPOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_DOC_chrc_SubSurf_WET <- randomForest::randomForest(NPOC_ppm ~ ., 
                                                      data = subSurfaceChrc_NPOC_Wet, 
                                                      replace = FALSE, # improve VIM
                                                      na.action = randomForest::na.roughfix,
                                                      mtry = ceiling(length(data)/2), # no. of features
                                                      ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                      importance = TRUE,
                                                      proximity = TRUE,
                                                      corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_chrc_SubSurf_RelImp1_MSE_WET <- randomForest::importance(RF_DOC_chrc_SubSurf_WET, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "meta-sedimentary (%)" = "geo_metasedimentary_percent", 
                                "meta-sedimentary-volcanic (%)" = "geo_metaSedimentaryVolcanic_percent", 
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # ----- VIM plot
  # make a plot
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["DeepBlue"], size = 1,
           fill = forWater_colours2["Gray"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RF_DOC_chrc_SubSurf_RelImp1_MSE_WETseason.png", width = 6, height = 5, units = "in")



# dry season only -------
# select subsurface predictor variables
subSurfaceChrc_NPOC_Dry <- sixfilter_physiographic %>% 
  filter(rain_season == "dry") %>% 
  select(c("NPOC_ppm", # predict DOC
           geo_metamorphic_percent,
           geo_metasedimentary_percent, 
           geo_metaSedimentaryVolcanic_percent, 
           geo_igneous_percent )) # %>%     
# add a column of random values as as QA -- this should not be found to be important
# mutate(QA_RandNum = sample(200, size = nrow(.), replace = TRUE))  # -- remove after checking 

# check for correlations
# view(cor(RF_subSurfaceCharacteristics_NPOC))


## Run RF
# mtry = (length(sixfilter_physiographic)-1)/3 = number of features/3 ~= 10 (or = num.features)
# mtry : at each node, mtry variables are selected at random and are searched through for best split then the largest tree possible is grown (unpruned)
RF_DOC_chrc_SubSurf_DRY <- randomForest::randomForest(NPOC_ppm ~ ., 
                                                      data = subSurfaceChrc_NPOC_Dry, 
                                                      replace = FALSE, # improve VIM
                                                      na.action = randomForest::na.roughfix,
                                                      mtry = ceiling(length(data)/2), # no. of features
                                                      ntree = 5000,  # ntree default = 500 (but Breiman says "Don't be stingy")
                                                      importance = TRUE,
                                                      proximity = TRUE,
                                                      corr.bias = TRUE) # experimental 


## relative importance of features in predicting DOC
## type 1 = mean square error (MSE) as decrease in accuracy
RF_DOC_chrc_SubSurf_RelImp1_MSE_DRY <- randomForest::importance(RF_DOC_chrc_SubSurf_DRY, type = 1) %>% 
  as.data.frame() %>%  # rather than matrix
  rownames_to_column() %>% 
  select(predictor = rowname,
         MSE = "%IncMSE") %>% # percent increase in mean square error
  mutate(predictor = fct_recode(predictor,
                                "QA-QC (random numbers)" = "QA_RandNum",
                                "metamorphic (%)" = "geo_metamorphic_percent",
                                "meta-sedimentary (%)" = "geo_metasedimentary_percent", 
                                "meta-sedimentary-volcanic (%)" = "geo_metaSedimentaryVolcanic_percent", 
                                "igneous (%)" = "geo_igneous_percent"),
         MSE_percent = MSE/sum(MSE)*100,  # add a percent MSE variable
         predictor = fct_reorder(predictor, MSE_percent, .desc=FALSE)) %>% 
  # ----- VIM plot
  # make a plot
  ggplot(aes(predictor, MSE_percent)) +
  coord_flip()+
  geom_bar(stat = "identity", position = "dodge",
           colour = forWater_colours2["MyOrange"], size = 1,
           fill = forWater_colours2["Gray"],
           alpha = 0.8) +
  theme_bw() +
  labs(y = "variable importance (%)", x = "", size = 12)

# save it
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RF_DOC_chrc_SubSurf_RelImp1_MSE_DRYseason.png", width = 6, height = 5, units = "in")


# compare both 
# cowplot::plot_grid(RF_DOC_chrc_SubSurf_RelImp1_MSE_WET, RF_DOC_chrc_SubSurf_RelImp1_MSE_DRY, nrow = 1)

```

```
# maybe don't need all these:
# DOC ---
# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_all.png":
RFplot_all_DOC

# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_conditions.png":
a <- RFplot_condit +
labs(y = "")

# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_surface.png":
b <- RFplot_surface +
labs(y = "")

# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_subsurface.png":
c <- RFplot_subsurface

# stack conditions, surface and subsurface plots
RFplot_summary <- cowplot::plot_grid(a, b, c, 
ncol = 1, align = "v",
labels = c("A. Conditions", 
"B. Surface Characteristics",
"C. Subsurface Characteristics"), 
label_size = 11, hjust = 0, label_fontface = "plain")

# save
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplots_variable-groups_DOC.png", width = 6, height = 5, units = "in")

# add with all?
bigboi <- cowplot::plot_grid(RFplot_all_DOC, RFplot_summary, ncol = 2)

# save for landscape page layout
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_summary-by_variable-groups_DOC.png", width = 9, height = 6, units = "in")

# --- E2E3
# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_all.png":
RFplot_all_E2E3

# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_conditions.png":
a <- RFplot_condit_E2E3 +
labs(y = "")

# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_surface.png":
b <- RFplot_surface_E2E3 +
labs(y = "")

# "R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_subsurface.png":
c <- RFplot_subsurface_E2E3

# stack conditions, surface and subsurface plots
RFplot_summary_E2E3 <- cowplot::plot_grid(a, b, c, 
ncol = 1, align = "v",
labels = c("A. Conditions", 
"B. Surface Characteristics",
"C. Subsurface Characteristics"), 
label_size = 11, hjust = 0, label_fontface = "plain")

# save
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplots_variable-groups_E2E3.png", width = 6, height = 5, units = "in")

# add with all?
bigboi <- cowplot::plot_grid(RFplot_all_E2E3, RFplot_summary_E2E3, ncol = 2)

# save for landscape page layout
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Ch3_RFplot_summary-by_variable-groups_E2E3.png", width = 9, height = 6, units = "in")

```


# end

```{r}
# empty code chunk
# sometimes RStudio cuts off the last bit of the view, this holds place :)
```
