---
title: "Reproducible data analysis: thesis data visualization and analysis"
subtitle: "Pacific Maritime forWater Masters Project (NSERC forWater)"
author: "Hannah J McSorley"
output: bookdown::word_document2
---

___Data Visualization and Summaries___
This RMD file generates summary tables and figures but is not included in the final bookdown product (tables and figures will be added to applicable sections by reading them in).

# Set-up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message = FALSE)
```

## Packages
```{r, package.startup.message = FALSE}

# load packages
library(tidyverse)  # includes: dplyr, ggplot2, purrr, readr, forcats
library(lubridate)  # dates and times
library(broom)      # tidy up
library(glue)       # glue() is an object-integrated 'paste'-like function
library(knitr)      # tidy tables
library(RColorBrewer) # Brewer palette for plots
library(viridis)    # nice colours for plots gradient fills
library(cowplot)    # add-on to ggplot for layout (nice grid)
library(directlabels) # add labels to ggplots
library(gghighlight)# plot highlighting
library(gridExtra)  # for plot & table layout options
library(ggpmisc)    # linear regression line values (ggplot)
library(ggpubr)     # Q-Q plots
library(car)        # stats: Companion to Applied Regression
library(synchrony)  # stats for autocorrelated & non-independent data :)
library(randomForest)

```

## define colours
```{r vectorize-colours}
# use forWater defined colours (hexadecimal codes) for plots
# all colours defined by forWater admin, except 'MyOrange' which I made
forWater_colours1 <- c(MainBlue = "#09A4D2", 
                       MainGreen = "#668536", 
                       AccentBlue = "#5B99CC", 
                       DarkGrey = "#3B3838", 
                       MyOrange = "#f4AB0E")

# colours updated late 2019 :\
forWater_colours2 <- c(DeepBlue = "#0A5EA6", 
                       Green = "#648326", 
                       SkyBlue = "#62ACC8", 
                       Gray = "#535353", 
                       MyOrange = "#f4AB0E")

# colour-blind friendly pallet with grey (no black)
cbPalette <- c(grey = "#999999", 
               orange = "#E69F00", 
               lightblue = "#56B4E9", 
               green = "#009E73", 
               yellow = "#F0E442", 
               darkblue = "#0072B2", 
               red = "#D55E00", 
               pink = "#CC79A7")
```

## define functions
Define function for number extraction from alphanumerics.
```{r NumberXtract}
# define functions

# ---- Alpha-numeric extraction function ---- #
# from http://stla.github.io/stlapblog/posts/Numextract.html
NumberXtract <- function(alphnum){
  unlist(regmatches(alphnum, gregexpr("[[:digit:]]+\\.*[[:digit:]]*", alphnum)))
}

```

# Load datasets
```{r, input-files, message=FALSE}
# assign timezone
TZ <- "Etc/GMT+8"

# File Inputs
#Results of data wrangling (01) were saved as .csv files for tidy loading. 
# read all compiled data files & format

# --- field data:

# Wrangled Hobo TidibiT logger data with rain events and trip IDs
Hobo_df <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Hobo_trip-event.csv", 
                    col_names = TRUE) %>% 
  mutate(location = factor(location),
         site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         trip = factor(trip), 
         event_ID = factor(event_ID), 
         rain_season = factor(rain_season),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ)) %>% 
  rename(TidbiT_location = "location")

# subbasin_Hobos -- I DON'T THINK I USE THIS...
subbasin_dailyHobo <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Subbasin_Results_complete.csv", col_names = TRUE) %>% 
  mutate(trip = factor(trip),
         event_ID = factor(event_ID), 
         rain_season = factor(rain_season),
         site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         TidbiT_location = factor(TidbiT_location))


# odyssey_data df
# stage data compiled with interval/trip
odyssey_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Odyssey-RackCorrected-stage.csv", col_names = TRUE) %>% 
  mutate(source = factor(source, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")),
         interval = factor(interval),
         event_ID = factor(event_ID),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ))

# precip_data df
# 2018-2020 weather station data compiled and formatted
precip_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/FWx-PrecipTemp_compiled.csv", col_names = TRUE, col_types = list("c", "T", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d", "D", "d", "c")) %>%
  mutate(StationName = factor(StationName),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         event_ID = factor(event_ID),
         rain_season = factor(rain_season))    

# LWSA mean precip data (FWx-mean-LWSA df)
# 2018-2020 weather station data compiled and formatted
LWSA_meanWx <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/FWx-Mean-LWSA_PrecipTemp.csv", col_names = TRUE, col_types = list("T", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d")) %>% 
  mutate(DateTime = lubridate::ymd_hms(DateTime, tz = TZ))    


# rain events defined with Rainmaker::RMevents()
# mean 15-minute rainfall record from Chris Crk and Martin's gulch FWx stns
# inter-event period = 14 hrs, threshold for major event = 50mm 
events <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Wx-RainEvents.csv", 
                   col_names = TRUE) %>% 
  mutate(ID = factor(ID),
         StartDate = ymd_hms(StartDate, tz = TZ),
         EndDate = ymd_hms(EndDate, tz = TZ))


# --- sample data:

# results df
# compiled sample analyses results (wide)
# including DateTime of Rack sample collection
sampleresults_df <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Results_complete.csv", col_names = TRUE) %>%   
  mutate(DateTime = lubridate::ymd_hms(DateTime, tz = TZ), 
         DateTime_sampled = lubridate::ymd_hms(DateTime_sampled, tz = TZ),
         collection = lubridate::ymd_hms(collection, tz = TZ),
         site = factor(site),
         trip = factor(trip),
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         rain_season = factor(rain_season),
         pseudoSUVA = pseudo254/NPOC_ppm,
         event_ID = factor(event_ID))

# metalslab df
# metals sample analyses results with OC (long)
metalslab <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/metals-DOCgrab-sample_results-long.csv", col_names = TRUE) %>% 
  mutate(dt_sampled = lubridate::ymd_hms(dt_sampled, tz = TZ),
         Trip = factor(Trip),
         site = factor(site), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         metal_parameters = factor(Parameters))

# stage_samples
# subbasin sample results with stage, timestamps, and precip event ID
stage_samples <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/subbasins_matched-chemohydro-samples.csv", col_names = TRUE) %>% 
  select(-c(stage_cm)) %>% 
  mutate(site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")),
         interval = factor(interval), # stage chunk that corresponds to field trip
         trip = factor(trip),  # field trip
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),  # season estimated by month
         rain_season = factor(rain_season),  # season assigned by rain events
         event_ID = factor(event_ID),  # rain events defined by precip >50mm & 14hrs btwn events
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ), # continuous stage
         DateTime_sampled = lubridate::ymd_hms(DateTime_sampled, tz = TZ)) # sample collection

# Treatability data from U.Waterloo (Fariba Amiri)
treatdat_UW <- 
  list.files("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", pattern = "*.csv") %>% 
  set_names(str_extract(., "([0-9]{2,}+)")) %>%
  purrr::map_dfr(~ read_csv(
    file.path("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", .), 
    col_names = TRUE, skip = 15), .id = "source") 

# Character data from U.Alberta (Julia Orlova)
NOMcharacter_UA <- read_csv("R-inputs_UBC-forWater-MSc_HMc/NOM-character-results_UofA/Orlova-J_UofA-results_PM_Hannah_Nov2019-Feb2020.csv", col_names = TRUE)

```

# WEATHER - FWx

## CC+MG plots: rain/snow/temp
At Chris Creek and Martin's Gulch FWx stations
```{r, FWx-plots}

# Rn15 is 15-minute rainfall (mm) 
# Prec_1 is hourly accummulated precipitation (mm)
# Temp is 15 minute intervals (degrees C)
rainplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n (mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)

# plot LWSA snow
snowplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  
  dplyr::summarise(daily_Snowmean = mean(SnowDep, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = "Snow accum.\n (m /day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)+
  theme(strip.background = NULL, 
        strip.text = element_blank()) 

# plot LWSA temperature
tempplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0, 
             linetype = "dotted") +
  labs(x = "", y = "Daily air temp\n(°C)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1) +
  theme(strip.background = NULL, 
        strip.text = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))


# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(rainplot, snowplot, tempplot, ncol = 1, align = "v",
                   rel_heights = c(1.25,1,1.75))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA.png",
       width = 6, height = 5, units = "in")
```


## table: annual precip, max snow, mean temp 

FWx means
```{r, FWx-table}
# precip_data summary
precip_data %>%
  mutate(Year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017) %>%   #, Year != 2020
  mutate(year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan-Feb 2020")) %>% 
  group_by(year, StationName) %>%
  summarise(total_precip_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDep, na.rm = TRUE), # not sure how to report
            annual_mean_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>% 
  dplyr::rename("Year" = year, 
                "station name" = StationName, 
                "annual precip. (mm)" = total_precip_mm,
                "max snow (m)" = max_snow_m,
                "mean air temp. (°C)" = annual_mean_temp, 
                "stdev air temp. (± °C)" = temp_sd,
                "mean max. temp. (°C)" = annual_min_temp,
                "mean min. temp. (°C)" = annual_max_temp) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-summary.csv")
```


### Mean Wx LWSA 

Arithmetic means from ChrisCrk and MartinsGulch.
*Too few stations to do Theissen polygons (2 point polygon = straight line) or isohyetal lines.*

```{r}
# add seasons to mean weather df
LWSA_meanWx <- precip_data %>% 
  select(DateTime, rain_season) %>% 
  right_join(LWSA_meanWx, by = "DateTime") %>% 
  mutate(Year = lubridate::year(DateTime),
         year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan-Feb 2020")) 

# check seasons visually
LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(date >= "2018-10-23") %>% 
  ggplot(aes(x = DateTime, y = Rn_1_mean)) +
  geom_col(aes(colour = rain_season)) +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme(text = element_text(size = 11),
        axis.text.x = element_text(angle = 60, hjust = 1))

```


#### plot mean FWx 
```{r, mean-Wx_plot}
# mean precip plot
mean_rainplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "2 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  geom_vline(xintercept = as_date("2018-10-23"), 
             colour = brewer.pal(8, "Dark2")[4],
             linetype = "dashed", size = 0.75) +
  annotate("text", label = "Project start", angle = 90, colour = brewer.pal(8, "Dark2")[8],
           x = as_date("2018-10-23")-20, y = 170)

# plot LWSA snow
mean_snowplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Snowmean = mean(SnowDep_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = 'Snow depth\n(m/day)') +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "2 months", date_minor_breaks = "1 months", labels = NULL)+ 
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  geom_vline(xintercept = as_date("2018-10-23"), 
             colour = brewer.pal(8, "Dark2")[4],
             linetype = "dashed", size = 0.75)

# plot LWSA temperature
mean_tempplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = 'Daily air temp\n(°C)') +
  theme_bw()+
  theme(legend.position = "none",
        text = element_text(size = 11),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_date(date_breaks = "2 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))+
  geom_vline(xintercept = as_date("2018-10-23"), 
             colour = brewer.pal(8, "Dark2")[4],
             linetype = "dashed", size = 0.75)

# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(mean_rainplot, mean_snowplot, mean_tempplot, 
                   ncol = 1,# align = "vh", greedy = FALSE,
                   rel_heights = c(3,3,4))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA-means.png", 
       width = 6, 
       height = 6, 
       units = "in")
```

#### table: mean Wx

```{r, table_mean-FWx_summary}
# mean weather summary
precip_data %>%
  mutate(Year = lubridate::year(DateTime),
         year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan & Feb 2020")) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017) %>%  
  group_by(Year, year, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDep, na.rm = TRUE),
            annual_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>%
  ungroup() %>% 
  group_by(year) %>%
  summarise(mean_rain_mm = mean(total_rain_mm, na.rm = TRUE),
            sd_rain_mm = sd(total_rain_mm, na.rm = TRUE),
            mean_max_snow_m = mean(max_snow_m, na.rm = TRUE),
            annual_mean_temp = mean(annual_temp, na.rm = TRUE),
            temp_sd = sd(annual_temp, na.rm = TRUE),
            annual_min_temp2 = mean(annual_min_temp, na.rm = TRUE),
            #TMin_sd = sd(annual_min_temp, na.rm = TRUE),
            annual_max_temp2 = mean(annual_max_temp, na.rm = TRUE)) %>%
  #TMax_sd = sd(annual_max_temp, na.rm = TRUE)) %>% 
  ungroup() %>% 
  dplyr::rename("mean annual rain (mm)" = mean_rain_mm,
                "stdev rain. (±mm)" = sd_rain_mm,
                "mean snow accum. (m)" = mean_max_snow_m,
                "mean temp. (°C)" = annual_mean_temp, 
                "st.dev temp. (±°C)" = temp_sd,
                "min. temp. (°C)" = annual_min_temp2,
                #"stdev TMin. (±°C)" = TMin_sd,
                "max. temp. (°C)" = annual_max_temp2) %>%
  #"stdev TMax. (±°C)" = TMax_sd) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-mean-summary.csv")
```

##### questionable objects
```{r, Wx-Stn_summaries}
# I want to know precip totals over the study period
# by month and by season
# use rain to define storm events

# calculate total rainfall at each of the wx-stns (survey mountain went in in late)
rn_MScTotal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime),
         year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx",
         date >= "2018-10-23") %>% 
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_MSc_mm = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup() 

# rain seasons rainfalls
rn_seasonal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(month = lubridate::month(DateTime),
         year = lubridate::year(DateTime)) %>%
  group_by(StationName, year, rain_season) %>% 
  dplyr::summarise(rain_seasonal = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# annual rainfalls
rn_annual <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(year = lubridate::year(DateTime)) %>%
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_monthly = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# water-year rainfalls (Oct 1 - Sept 30)
rn_wateryr <- LWSA_meanWx %>%
  mutate(month = lubridate::month(DateTime),
         water_year = case_when(
           between(month, 1, 9) & Year == "2018" ~ "2018",
           between(month, 10, 12) & Year == "2018" ~ "2019",
           between(month, 1, 9) & Year == "2019" ~ "2019",
           between(month, 10, 12) & Year == "2019" ~ "2020",
           between(month, 1, 9) & Year == "2020" ~ "2020")) %>%
  #filter(water_year != "2018") %>% 
  group_by(water_year) %>% 
  dplyr::summarise(annual_precip_mm = sum(Rn_1_mean, na.rm = TRUE),
                   max_snow_m = max(SnowDep_mean, na.rm = TRUE),
                   annual_mean_temp = mean(Temp_mean, na.rm = TRUE),
                   temp_sd = sd(Temp_mean, na.rm = TRUE)) %>% 
  ungroup() #%>% 
#write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA_WaterYear-summary.csv", col_names = TRUE)

```

## RAIN EVENTS
```{r}
majEvents_summary <- events %>%
  mutate(duration = difftime(EndDate, StartDate, units = "hours"),
         duration_days = as.numeric(difftime(EndDate, StartDate, units = "days")),
         duration_hours = as.numeric(NumberXtract(duration)),
         intensity_mmhr = rain/duration_hours,
         startDate = as_date(StartDate),
         endDate = as_date(EndDate)) %>% 
  mutate(ID = as_factor(ID))

# make a table
majEvents_summary %>% 
  mutate(duration_days = round(as.numeric(duration_days), 1)) %>% 
  select('Storm number' = stormnum,
         'Major event no.' = ID,
         'Start Date' = startDate,
         'Duration (days)' = duration_days,
         'Rainfall (mm)' = rain,
         'Intensity (mm/hr)' = intensity_mmhr) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Events.csv",
            col_names = TRUE) 

# summarize all  
events_summary <- majEvents_summary %>% 
  mutate(year = year(StartDate)) %>% 
  group_by(year) %>% 
  summarise(duration_min_days = min(duration_days),
            duration_max_days = max(duration_days),
            rain_min_mm = min(rain),
            rain_max_mm = max(rain),
            intensity_min_mmhr = min(intensity_mmhr),
            intensity_max_mmhr = max(intensity_mmhr),
            ID_duration_min = ID[which(duration_days == duration_min_days)],
            ID_duration_max = ID[which(duration_days == duration_max_days)],
            ID_rain_min = ID[which(rain == rain_min_mm)],
            ID_rain_max = ID[which(rain == rain_max_mm)],
            ID_intensity_min = ID[which(intensity_mmhr == intensity_min_mmhr)],
            ID_intensity_max = ID[which(intensity_mmhr == intensity_max_mmhr)])

# make a table
events_summary %>% 
  select(year, 
         'min. duration (days)' = duration_min_days,
         'max. duration (days)' = duration_max_days,
         'min rain (mm)' = rain_min_mm, 
         'max rain (mm)' = rain_max_mm, 
         'min intensity (mm/hr)' = intensity_min_mmhr,
         'max intensity (mm/hr)' = intensity_max_mmhr) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Events-annual_min-max.csv",
            col_names = TRUE) 

```

## Malahat Wx

Longer data record from the Malahat weather station (for comparison).

```
#{r, malahat-wx}

# malahat weather
malahat_data <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Malahat_station-data-11596.csv", 
skip = 16,
col_names = TRUE,
col_types = list("f", "c", "d", "d")) %>% 
mutate(Datetime = lubridate::ymd_hms(Datetime, tz = TZ, truncated = 1),
Date = lubridate::as_date(Datetime),
Year = lubridate::year(Datetime))

# summary: malahat_data precip + air temp 
malahat_data %>% 
filter(Analysis == "Precipitation Amount (mm)", 
between(Year, 2014, 2019)) %>% 
group_by(Year) %>%
summarise(total_precip = sum(Value, na.rm = TRUE)) %>% 
ungroup() %>% 
right_join((
malahat_data %>% 
dplyr::filter(Analysis == "Temperature (Mean) (celsius)", 
between(Year, 2014, 2019)) %>% 
group_by(Year) %>%
summarise(annual_mean_temp = mean(Value, na.rm = TRUE),
temp_sd = sd(Value))) %>% 
ungroup(), 
by = "Year") %>%
filter(Year != "2013", Year != "2020") %>% 
dplyr::rename("year" = Year, 
"annual precip. (mm)" = total_precip, 
"mean air temp. (°C)" = annual_mean_temp, 
"std.dev. (± °C)" = temp_sd) %>% 
write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_malahat-summary.csv")

```


```
### plots: Malahat Wx
#{r, malahat-plots}
# plots
# plot malahat rain and highlight my study period
malahat_rn <- malahat_data %>% 
filter(Analysis == "Precipitation Amount (mm)") %>% 
ggplot(aes(x = Datetime, y = Value)) +
geom_col(colour = "#09A4D2") +
scale_y_reverse() +
labs(x = "", y = "Rain (mm/day)") +
theme_bw() +
scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
theme(legend.position = "none") +
gghighlight::gghighlight(Datetime > "2018-10-23",
unhighlighted_params = list(colour = "#3B3838"))

# plot malahat temperature and highlight my study period
malahat_temp <- malahat_data %>% 
filter(Analysis == "Temperature (Mean) (celsius)") %>% 
ggplot(aes(x = Datetime, y = Value)) +
geom_line(colour = "#f4AB0E") +
geom_hline(yintercept = 0,
linetype = "dotted") +
labs(x = "", y = expression('Mean daily air temp ('*~degree*C*')')) +
theme_bw() +
scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
gghighlight::gghighlight(Datetime > "2018-10-23",
unhighlighted_params = list(colour = "#3B3838"))

# stack with cowplot
cowplot::plot_grid(malahat_rn, malahat_temp, ncol = 1, align = "v")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat.png")

```



```
### lag-years: Wilcoxon's rank sum test
#{r}
# check for normality
# The central limit theorem:
## sampling distribution tends to be normal if the sample is large enough (n > 30)
malahat_data %>% 
filter(!is.na(Value),
Analysis == "Precipitation Amount (mm)" | Analysis == "Temperature (Mean) (celsius)") %>% 
group_by(Year, Analysis) %>% 
summarise(count = n())
# could assume normal distribution because each year has daily values (>>30)

# visually check for normality 
malahat_data %>% 
filter(Year != 2013, Year != 2020,  # incomplete data sets
!is.na(Value),
Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data
mutate(Year = as_factor(Year)) %>% 
ggpubr::ggqqplot(data = ., x = "Value", 
color = "Year", 
palette = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" ),
facet.by = "Analysis")
## Precipitation was not normally distributed (seasonality)

# tidy wilcoxon tests: lag-year 
## solution from:
## https://stackoverflow.com/questions/32477863/r-run-t-test-on-previous-years-by-group-using-dplyr

# t-test comparing each year to the last year
Malahat_test_lagyear <- malahat_data %>% 
filter(Year != 2013, Year != 2020,  # incomplete data sets
!is.na(Value)) %>%  # remove missing values 
select(Analysis, Year) %>% 
arrange(Analysis, Year) %>% 
distinct() %>% 
group_by(Analysis) %>% 
mutate(lag_year = lag(Year)) %>% 
filter(!is.na(lag_year)) %>% 
group_by(Analysis, Year, lag_year) %>% 
do(tidy(wilcox.test(malahat_data$Value[malahat_data$Year == .$Year & malahat_data$Analysis == .$Analysis],
malahat_data$Value[malahat_data$Year == .$lag_year & malahat_data$Analysis == .$Analysis])))

# identify signficantly different years
Malahat_test_lagyear %>% 
filter(p.value < 0.10)

# 2015 was an incredible drought year, so it makes sense that 2015-2016 would differ

```


```
#{r}
#### Wx pre & during MSc

# group
malahat_test_data <- malahat_data %>% 
filter(!is.na(Value),
Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data 
mutate(set = case_when(Year == 2016 | Year == 2017 ~ "pre",
Year == 2018 | Year == 2019 ~ "MSc"),
set = as_factor(set)) %>% 
filter(!is.na(set)) 

# subset for tests
pre_MSc <- malahat_test_data %>% filter(set == "pre")
MSc <- malahat_test_data %>% filter(set == "MSc")
```


```
#{r}
##### plots
# plot sets
malahat_test_data %>% 
ggplot(aes(x = set, y = Value, fill = set))+
geom_boxplot(alpha = 0.8)+
scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
labels = c(pre = "2016-2017", MSc = "2018-2019"),
name = "Year span")+
labs(y = "value", x = "")+
theme_bw()+
theme(legend.position = "top")+
facet_wrap(~Analysis)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat_plot_pre-MSc-2years.png")

# looks like precip is not normally distributed because of seasons
# Tests for normality 
# Pre-MSc
pre_MSc %>% 
mutate(Year = as_factor(Year)) %>% 
ggpubr::ggqqplot(data = ., x = "Value", 
color = "Year", palette = c("#648326", "#f4AB0E", "#62ACC8", "#535353"),
facet.by = "Analysis")

# during
MSc %>% 
mutate(Year = as_factor(Year)) %>% 
ggpubr::ggqqplot(data = ., x = "Value", 
color = "Year", palette = c("#648326", "#f4AB0E"),
facet.by = "Analysis")

```


```
#{r}

##### tests
# t-tests or Wilcoxon to compare 2014-2017 to 2018-2019
# ggpubr::ggqqplot() to check for normality
## if points fall approximately along the reference line, assume normality

# t-tests for temperature (normally distributed)
# Wilcoxon signed rank test for Precip (not normally distributed)
# make a tibble for tidiness
# note: snow data was only available 2017-2019 -- not included
Malahat_testMSc_Wx <- bind_rows(
# rain
tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Precipitation Amount (mm)"], 
MSc$Value[MSc$Analysis == "Precipitation Amount (mm)"],
)) %>% 
mutate(Parameter = "rain"),
# air temp
tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Mean) (celsius)"], 
MSc$Value[MSc$Analysis == "Temperature (Mean) (celsius)"])) %>% 
mutate(Parameter = "temp_mean"),
# Min air temp
tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Min.) (celsius)"], 
MSc$Value[MSc$Analysis == "Temperature (Min.) (celsius)"])) %>% 
mutate(Parameter = "temp_min"),
# Max air temp
tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Max.) (celsius)"], 
MSc$Value[MSc$Analysis == "Temperature (Max.) (celsius)"])) %>% 
mutate(Parameter = "temp_max")) %>% 
# pull values of interest to summarize
select(Parameter, p.value) %>% 
mutate(signifcance = case_when(p.value < 0.01 ~ "at 99%",
p.value < 0.05 ~ "at 95%",
p.value < 0.1 ~ "at 90%",
p.value > 0.1 ~ "NA")) %>% 
write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Malahat_Wilcoxtest_pre-MSc-2years.csv")

# interpretation
# null hypothesis = both means are equal
# if the p-value is less than the significance level critical value, reject the null hypothesis 

```

## STAGE: River Stage 

```{r}
# min-max normalized stage data 
# (because the stage is arbitrarily references to the stilling well and it's the fluctuation that's important)
odyssey_norm <- odyssey_data %>%
  group_by(source) %>% 
  dplyr::mutate(norm_stg = (stage_cm-min(stage_cm))/(max(stage_cm)-min(stage_cm))) %>% 
  ungroup()
```

### plot: normalized stage 

The stage was normalized (min-max norm) to compare relative rises
```{r, stage-line-plots}

# plot stage, lines over time
odyssey_norm %>%
  ggplot(aes(x = DateTime, y = norm_stg))+
  geom_line(colour = "#0072B2") +
  #viridis::scale_colour_viridis(discrete = TRUE) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(y = "River stage (normalized)", x = "") +
  facet_wrap(~source, ncol = 1, strip.position = "right")  
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_subbasins.png",
       width = 8.5,
       height = 11,
       units = "in")
```

### plot: norm stage ridge
```{r, ridgey}

# plot stage, density ridges -- could be cool -- fix aesthetics 
odyssey_norm %>%
  ggplot(aes(x = norm_stg, y = fct_rev(source)))+
  ggridges::geom_density_ridges(aes(fill = source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  scale_y_discrete() +
  theme(legend.position = "none")+
  labs(x = "River Stage (normalized)", y = "",
       caption = "Density distribution of min-max normalized stage at six subbasins")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_ridgeplot_subbasins.png")

```

### Synchrony tests
```{r}

# reshape odyssey data to wide flat file matrix
## sites as columns, timestep as rows
# note: Tunnel was not installed & recording until "2018-12-06 19:30:00"
# to check for synchrony, all timesteps should be of equal length with no NAs
six_wide_stage <- odyssey_data %>%
  group_by(source) %>% 
  filter(rain_season == "wet") %>%  # remove baseflow
  filter(Date >= "2018-12-06", Date <= "2020-01-31") %>% # overlapping date ranges
  mutate(DateTimeRound = lubridate::round_date(DateTime, unit = "10 mins")) %>% # round to remove NAs
  select(c(DateTimeRound, source, stage_cm)) %>% 
  distinct(DateTimeRound, .keep_all = TRUE) %>%   # keep only unique time stamps
  ungroup() %>% 
  pivot_wider(names_from = source,
              values_from = stage_cm) %>% 
  unnest(cols = c(Weeks, ChrisCrk, LeechHead, CraggCrk, WestLeech, Tunnel)) %>% 
  arrange(DateTimeRound) %>% 
  mutate(timestep = row_number(DateTimeRound))

# synchrony tests
# community-wide & significance via Monte Carlo randomizations
# 1 == perfect synchrony

## concordance (Kendall's W) [0:1]
# isolate sites only (drop time and timestep now that it's sorted)
dat <- six_wide_stage %>% select(-c(DateTimeRound, timestep))
stage_synch_kendall.w <- synchrony::kendall.w(data = dat) #, nrands = 999, type = 2)
stage_synch_kendall.w_1 <- synchrony::kendall.w(data = dat) #, nrands = 999, type = 1)
# results are the same for type 1 and type 2:
## Kendall's W (uncorrected for ties): 0.9721
## Kendall's W (corrected for ties): 0.9721
## Spearman's ranked correlation: 0.9666
## Kendall's W p-value (one-tailed test [greater]): 0.001


## PEAKS
# Determine the proportion of concurrent local extrema (Peaks)
# isolate time series matrix for each site where col 1 is timestep and col 2 is stage
# site 1
six_wide_stage_Weeks <- six_wide_stage %>% 
  select(c(timestep, Weeks)) %>% 
  as.matrix()
# site 2
six_wide_stage_Chris <- six_wide_stage %>% 
  select(c(timestep, ChrisCrk)) %>% 
  as.matrix()
# site 3
six_wide_stage_Head <- six_wide_stage %>% 
  select(c(timestep, LeechHead)) %>% 
  as.matrix()
# site 4
six_wide_stage_Cragg <- six_wide_stage %>% 
  select(c(timestep, CraggCrk)) %>% 
  as.matrix()
# site 5
six_wide_stage_West <- six_wide_stage %>% 
  select(c(timestep, WestLeech)) %>%
  as.matrix()
# site 6
six_wide_stage_Tunnel <- six_wide_stage %>% 
  select(c(timestep, Tunnel)) %>%
  as.matrix()

### tests by site (number) (RAM intensive with nrands -- hash out after use)
# note, check p-value difference with nrands = 10000 and it's similar enough that I think 999 is fine.
peaks_1to2 <- synchrony::peaks(six_wide_stage_Weeks, six_wide_stage_Chris, type = 2) #, nrands = 999)
peaks_1to3 <- synchrony::peaks(six_wide_stage_Weeks, six_wide_stage_Head, type = 2) #, nrands = 999)
peaks_2to3 <- synchrony::peaks(six_wide_stage_Chris, six_wide_stage_Head, type = 2) #, nrands = 999)
peaks_3to4 <- synchrony::peaks(six_wide_stage_Head, six_wide_stage_Cragg, type = 2) #, nrands = 999)
peaks_3to5 <- synchrony::peaks(six_wide_stage_Head, six_wide_stage_West, type = 2) #, nrands = 999)
peaks_4to5 <- synchrony::peaks(six_wide_stage_Cragg, six_wide_stage_West, type = 2) #, nrands = 999)
peaks_3to6 <- synchrony::peaks(six_wide_stage_Head, six_wide_stage_Tunnel, type = 2) #, nrands = 999)
peaks_4to6 <- synchrony::peaks(six_wide_stage_Cragg, six_wide_stage_Tunnel, type = 2) #, nrands = 999)
peaks_5to6 <- synchrony::peaks(six_wide_stage_West, six_wide_stage_Tunnel, type = 2) #, nrands = 999)

# combine
synch_PeaksSumm_stage <- tibble(      
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk", 
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"),
  "Proportion of common peaks" = c(peaks_1to2$obs, peaks_1to3$obs, peaks_2to3$obs, peaks_3to4$obs, peaks_3to5$obs, peaks_4to5$obs, peaks_3to6$obs, peaks_4to6$obs, peaks_5to6$obs)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/stage-stats_synchrony-peaks_wet-season.csv", col_names = T)

# where proportion of coincident peaks = a fraction of the maximum number of peaks in the two series
```

## Levene's test for homoscedasticity in stage:

An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 

```{r}
# check for normality
dat <- odyssey_data %>%
  group_by(source) %>% 
  filter(rain_season == "wet") %>%  # remove baseflow
  filter(Date >= "2018-12-06", Date <= "2020-01-31") %>%  # overlapping date ranges
  ungroup()

# check for normality
dat %>% 
  ggplot(aes(corr_stage_cm))+
  geom_density(aes(colour = source))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~source, nrow = 3, scales = "free_y")

# car::leveneTest(response ~ independent variable)
car::leveneTest(corr_stage_cm ~ source, data = dat) %>% tidy() %>% pull("p.value") %>% first()
# --> reject Ho, variance is not homogeneous across the LWSA 

# find out where:

# headwaters
# 1-2
WC <- dat %>%
  filter(source == "Weeks" |
           source == "ChrisCrk") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 1-3
H1 <- dat %>%
  filter(source == "Weeks" |
           source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 2-3  
H2 <- dat %>%
  filter(source == "ChrisCrk" |
           source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems
# 3-4   
H4 <- dat %>%
  filter(source == "CraggCrk" |
           source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 3-5 
H5 <- dat %>%
  filter(source == "WestLeech" |
           source == "LeechHead") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-5
C5 <- dat %>%
  filter(source == "WestLeech" |
           source == "CraggCrk") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems and outlet
# 3-6
H6 <- dat %>%
  filter(source == "LeechHead" |
           source == "Tunnel") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-6 
C6 <- dat %>%
  filter(source == "CraggCrk" |
           source == "Tunnel") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 5-6   
W6 <- dat %>%
  filter(source == "WestLeech" |
           source == "Tunnel") %>% 
  car::leveneTest(corr_stage_cm ~ source, data = .) %>% tidy() %>% pull("p.value") %>% first()


# write a summary table
Levenes_summary_stage <- tibble::tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk",
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"), 
  p.value = c(WC, H1, H2, 
              H4, H5, C5, 
              H6, C6, W6)) %>% 
  mutate("Significance" = # (confidence level: ***99%, **95%, *90%)
           case_when(p.value < 0.01 ~ "***",
                     p.value < 0.05 ~ "**",
                     p.value < 0.1 ~ "*",
                     p.value > 0.1 ~ "homoscedastic")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/stage-stats_variance-LeveneTests.csv", col_names = T)

```

#### trash? peak stage by event & site
Don't really know what to do with this...
```{r}
# isolate max for each site by year
max_stage <- stage_samples %>%
  filter(!is.na(DateTime)) %>% 
  mutate(year = lubridate::year(DateTime)) %>% 
  select(c(site, year, trip = "interval", DateTime, corr_stage_cm, event_ID)) %>% 
  group_by(site, year) %>% 
  slice(which.max(corr_stage_cm))

# determine the rate of stage rise for each event at each site
# odyssey_data

# note: Tunnel was not installed & recording until "2018-12-06 19:30:00"
# to check for synchrony, all timesteps should be of equal length

# summarize max and min with timesteps for each site
stepped_normStage <- odyssey_norm %>% 
  mutate(Date = as_date(DateTime)) %>% # add a Date 
  mutate(rain_season = case_when( # some are seasons missing, fix that:
    Date < "2018-10-27" ~ "wet",
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-20", "2019-03-01") ~ "wet",
    Date %within% interval("2019-03-01", "2019-04-30") ~ "wet", # snow",
    Date %within% interval("2019-05-01", "2019-09-12") ~ "dry",
    event_ID %in% 9:18 ~ "wet")) %>% 
  # isolate span of Tunnel logger life
  filter(DateTime >= "2018-12-06 19:30:00", DateTime <= "2020-02-01 02:30:00") %>%  
  select(c(site = source, event_ID, corr_stage_cm, norm_stg, DateTime)) %>% 
  #filter(!is.na(event_ID)) %>% 
  group_by(site) %>%
  mutate(timestep = row_number(DateTime)) %>%  # each site gets timesteps
  ungroup() 


# find peak for stage
pks_stage <- stepped_normStage %>% 
  group_by(site, event_ID) %>%
  summarise(DateTime_peak_stage = DateTime[which.max(norm_stg)],
            timestep_peak_stage = timestep[which.max(norm_stg)],
            peak_stage = max(norm_stg))
# reshape to wide (for visual inspection)
pks_stage_wide <- pks_stage %>%
  filter(!is.na(event_ID)) %>% 
  select(-c(DateTime_peak_stage, peak_stage)) %>% 
  pivot_wider(names_from = site,
              values_from = c(timestep_peak_stage)) %>% 
  mutate(LHtoT = Tunnel - LeechHead,
         CtoT = Tunnel - CraggCrk,
         WtoT = Tunnel - WestLeech)

```

## Stage (norm) & samples

### plot density of stage + sample results 
```{r}
# min-max normalized stage data 
# (because the stage is arbitrarily references to the stilling well and it's the fluctuation that's important)
stage_samples_norm <- stage_samples %>%
  group_by(site) %>% 
  dplyr::mutate(norm_stg = (corr_stage_cm - min(corr_stage_cm))/(max(corr_stage_cm) - min(corr_stage_cm))) %>% 
  ungroup() %>% 
  # some are seasons missing, fix that:
  mutate(rain_season = case_when(
    Date < "2018-10-27" ~ "wet",
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-20", "2019-03-01") ~ "wet",
    Date %within% interval("2019-03-01", "2019-04-30") ~ "wet", # snow",
    Date %within% interval("2019-05-01", "2019-09-12") ~ "dry",
    event_ID %in% 9:18 ~ "wet")) 

# plot stage vs DOC
d <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = NPOC_ppm))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  facet_wrap(~site, scales = "free_x", ncol = 1)+
  theme(legend.position = "none", text = element_text(size=11),
        strip.background = element_blank(), strip.text = element_blank())+
  labs(y = "Normalized Stage", x = "DOC (mg/L)")


# plot stage vs UV254
u <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = SAC254_Abs.m))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  #scale_x_discrete(position = "top") +
  facet_wrap(~site, scales = "free_x", ncol = 1)+
  theme(legend.position = "none", text = element_text(size=11),
        strip.background = element_blank(), strip.text = element_blank())+
  labs(y = "", x = "Abs. at 254nm")

# plot stage vs UV254
s <- stage_samples_norm %>% 
  ggplot(aes(y = norm_stg, x = SUVA))+
  theme_bw()+
  geom_point(aes(fill = site), shape = 21, na.rm = TRUE, alpha = 0.8)+
  geom_density_2d(aes(colour = site))+
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  scale_y_continuous(breaks = c(0.5, 1))+
  #scale_x_discrete(position = "top") +
  facet_wrap(~site, scales = "free_x", ncol = 1, strip.position = "right")+
  theme(legend.position = "none", text = element_text(size=11))+
  labs(y = "", x = expression(paste("SUVA " [254])))

# group
cowplot::plot_grid(d,u,s, ncol = 3)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/StageNorm_DOC-abs-SUVA.png",
       width = 6, height = 8, units = "in")

```

```
# check with seasons

# with seasons
d2 <- stage_samples_norm %>% 
ggplot(aes(y = norm_stg, x = NPOC_ppm))+
theme_bw()+
geom_point(aes(fill = rain_season), shape = 21, na.rm = TRUE, alpha = 0.8)+
geom_density_2d(aes(colour = rain_season))+
scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
"dry" = forWater_colours2[["MyOrange"]]),
aesthetics = c("fill", "colour"))+
#scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
scale_y_continuous(breaks = c(0.5, 1))+
facet_wrap(~site, scales = "free_x", ncol = 1)+
theme(legend.position = "none", text = element_text(size=11),
strip.background = element_blank(), strip.text = element_blank())+
labs(y = "Normalized Stage", x = "DOC (mg/L)")

# seasons
u2 <- stage_samples_norm %>% 
ggplot(aes(y = norm_stg, x = SAC254_Abs.m))+
theme_bw()+
geom_point(aes(fill = rain_season), shape = 21, na.rm = TRUE, alpha = 0.8)+
geom_density_2d(aes(colour = rain_season))+
scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
"dry" = forWater_colours2[["MyOrange"]]),
aesthetics = c("fill", "colour"))+
#scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
scale_y_continuous(breaks = c(0.5, 1))+
#scale_x_discrete(position = "top") +
facet_wrap(~site, scales = "free_x", ncol = 1)+
theme(legend.position = "none", text = element_text(size=11),
strip.background = element_blank(), strip.text = element_blank())+
labs(y = "", x = "Abs. at 254nm")  

# season
s2 <- stage_samples_norm %>% 
ggplot(aes(y = norm_stg, x = SUVA))+
theme_bw()+
geom_point(aes(fill = rain_season), shape = 21, na.rm = TRUE, alpha = 0.8)+
geom_density_2d(aes(colour = rain_season))+
scale_colour_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
"dry" = forWater_colours2[["MyOrange"]]),
aesthetics = c("fill", "colour"))+
#scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
scale_y_continuous(breaks = c(0.5, 1))+
#scale_x_discrete(position = "top") +
facet_wrap(~site, scales = "free_x", ncol = 1, strip.position = "right")+
theme(legend.position = "none", text = element_text(size=11))+
labs(y = "", x = expression(paste("SUVA " [254])))

cowplot::plot_grid(d2,u2,s2, ncol = 3)
# nope
```

## Wx MEGAPLOT: FWx+RiverStage
Plot stage, precip, temp and snow and then create a one-page mega plot of all combined.
```{r, Wx-stage-megas-plots}

# 1 plot snow
# LWSA (Chris crk and Martin's Gulch FWx stns)
subasin_snow_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Snow = factor("Snow")) %>% 
  group_by(date, Snow) %>% 
  dplyr::summarise(daily_meansnow = mean(SnowDep_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24", date <= "2020-02-19") %>% 
  ggplot(aes(x = date, y = daily_meansnow)) +
  geom_col(aes(colour = Snow), colour = "grey40") +
  labs(x = "", y = "m /day") +
  theme_bw() +
  scale_x_date(date_breaks = "2 months",
               date_minor_breaks = "1 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Snow, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0.5,0,0,0), "cm")) # top, right, bottom, left


# 2 plot 
# LWSA temp for the same time span
subasin_meantemp_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Temp = factor("Temp")) %>% 
  group_by(date, Temp) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24", date <= "2020-02-19") %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(aes(colour = Temp), colour = "#E69F00") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = "°C /day") +
  theme_bw() +
  scale_x_date(date_breaks = "2 months",
               date_minor_breaks = "1 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Temp, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)


# 3 plot rainfall
# mean LWSA rain for study period
subbasin_meanrain_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Rain = factor("Rain")) %>% 
  group_by(date, Rain) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24", date <= "2020-02-19") %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(aes(colour = Rain), colour = "#0072B2") +
  scale_y_reverse() +
  labs(x = "", y = "mm /day") +
  theme_bw() +
  scale_x_date(date_breaks = "2 months",
               date_minor_breaks = "1 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Rain, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)


# 4 plot stage
# stage at each of the subbasins
stage_plot <- odyssey_data %>% 
  filter(Date >= "2018-10-24", Date <= "2020-02-19") %>%   
  ggplot(aes(x = DateTime, y = corr_stage_cm))+
  geom_line(colour = "#09A4D2")+
  theme_bw()+
  facet_wrap(~source, ncol = 1, 
             scales = "free_y",
             strip.position = "right")+
  labs(y = "River Stage (cm)", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)



# mega-plot!! 
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subasin_meantemp_plot, subbasin_meanrain_plot, stage_plot, 
                   ncol = 1, 
                   axis = "l", 
                   align = "v",
                   rel_heights = c(1,1,1,5))
# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_megaplot.png",
       width = 8.5,
       height = 11,
       units = "in")

```



# TEMPERATURE (Hobo)
```{r}
# update Hobo wet temperatures 
# most sites were wet by mid-September (2019) 
# all sites water loggers were wet by Oct 15
Hobo <- Hobo_df %>% 
  mutate(Temp_C_fullwet = Temp_C)

# Cragg Creek
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & site == "CraggCrk" &
                                  Date < as_date("2019-09-15"), "NA", Temp_C_fullwet)) 
# Tunnel  
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & site == "Tunnel" & 
                                  Date < as_date("2019-10-15"), "NA", Temp_C_fullwet))

# Temp_C is numeric, update from character
Hobo <- Hobo %>% 
  mutate(Temp_C = as.numeric(Temp_C)) 

```

## plot: Hobo air/water temps over time
```{r}
Hobo %>% 
  group_by(site, TidbiT_location, Date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date, y = T_daily))+
  geom_line(aes(colour = site), size = 0.6)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  geom_hline(yintercept = 0, linetype = "dashed", colour = "darkgrey", size = 0.4)+
  facet_wrap(~TidbiT_location, ncol = 1,
             scales = "free_y",
             strip.position = "left")+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Site:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs_line-by-time_daily.png", 
       width = 6, height = 6, units = "in")
```

## plot: Hobo A/W over space
```{r}
# update the water temperature logger time frames to be equal
# all sites water loggers were submerged by 2019-10-15  
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & 
                                  Date < as_date("2019-10-15"), "NA", Temp_C_fullwet)) 

# Temp_C is numeric, update from character
Hobo <- Hobo %>% 
  mutate(Temp_C = as.numeric(Temp_C)) 

## Boxplot
Hobo %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, TidbiT_location, date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = site, y = T_daily, fill = site))+
  geom_jitter(aes(fill = site), alpha = 0.6, shape = 21)+
  geom_boxplot(alpha = 0.4)+
  scale_fill_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~TidbiT_location, 
             ncol = 1,
             scales = "free_y",
             strip.position = "left")+
  labs(x = "", y = "Mean Daily Temperature (°C)")+
  theme(legend.position = "none", 
        text = element_text(size = 12))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs_box-by-location_daily.png", 
       width = 5.5, height = 5.5, units = "in") 
```

## Compare: Hobo / LWSA
```{r}

# find overlapping ranges
Hobo %>% 
  group_by(site) %>% 
  summarize(count = n(),
            earliest = first(Date),
            latest = last(Date)) %>% 
  arrange(count)

# join the air temp from subbasins with the mean LWSA temperature data to compare
# augment Hobo df to include full range of DateTime to match to FWx df

# need FWx for each site before Hobo TidbiTs were installed
# range: start = "2018-10-23" & end = "2019-08-23"
project_start <- ymd_hms("2018-10-23 01:00:00", tz = TZ) # first overlapping field day
Hobo_start <- ymd_hms("2019-08-24 01:00:00", tz = TZ)  # all TidbiTs deployed
project_end <- ymd_hms("2020-02-18 15:00:00", tz = TZ) # last overlapping field day

# create a dataframe of full DateTimes
Hobo_FWx_joiner <- 
  # FWx data came in ever 15 minutes (Hobo ever 30 min)
  tidyr::tibble(DateTime = seq(project_start, project_end, by = "15 min")) %>% 
  # and join to wide Hobo air temp data
  full_join(Hobo %>% 
              filter(TidbiT_location == "air",
                     !is.na(site),
                     DateTime < project_end) %>% 
              select(site, DateTime, Temp_C) %>% 
              pivot_wider(names_from = site, values_from = Temp_C), 
            by = c("DateTime")) %>% 
  # then, pivot longer again so each site has a full DateTime range
  pivot_longer(cols = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"), names_to = "site", values_to = "Temp_C") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  group_by(site) 

# join FWx and Hobo
# 30 minute temp intervals from start of project to end
Hobo_WxLWSA_full <- LWSA_meanWx %>%
  select(c(DateTime, Temp_mean, rain_season)) %>%
  filter(DateTime < project_end,
         DateTime >= project_start) %>% 
  full_join(Hobo_FWx_joiner, by = c("DateTime")) %>% 
  rename(FWx = "Temp_mean", Hobo = "Temp_C") %>%
  filter(lubridate::minute(DateTime) != 15,
         lubridate::minute(DateTime) != 45) %>%  # drops 15 minute Hobo nulls
  group_by(site) %>% 
  distinct() %>% # drop duplicate rows
  mutate(Date = as_date(DateTime)) %>% 
  select(c(site, Date, DateTime, Hobo, FWx, rain_season))  # reorganize for viewing


# isolate overlapping date ranges of Hobo and FWx
Hobo_WxLWSA <- Hobo_WxLWSA_full %>% 
  filter(DateTime >= Hobo_start) 
```

### plot: [1:1] FWx vs HOBO
```{r}

## plot: 1:1 scatter of temperatures -- dry season
adry <- Hobo_WxLWSA %>% 
  filter(rain_season == "dry") %>% 
  ggplot(aes(x = FWx, y = Hobo))+
  geom_point(alpha = 0.35)+
  theme_bw()+
  facet_wrap(~ site)+
  labs(y = "Site temperature (°C)", x = "")+
  #labs(y = "Site temperature (°C)", x = "Mean LWSA temperature (°C)") +
  theme(text = element_text(size = 10))+
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) +
  ## to get equations include this line:
  #stat_poly_eq(formula = y ~ x, aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), parse = TRUE, rr.digits = 4)+
  stat_poly_eq(formula = y ~ x, aes(label = ..rr.label..), parse = TRUE, rr.digits = 4)

## plot: 1:1 scatter of temperatures -- wet season
awet <- Hobo_WxLWSA %>% 
  filter(rain_season == "wet") %>% 
  ggplot(aes(x = FWx, y = Hobo))+
  geom_point(alpha = 0.35)+
  theme_bw()+
  facet_wrap(~ site)+
  labs(y = "", x = "")+
  #labs(y = "Site temperature (°C)", x = "Mean LWSA temperature (°C)") +
  theme(text = element_text(size = 10))+
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) +
  ## to get equations include this line:
  #stat_poly_eq(formula = y ~ x, aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), parse = TRUE, rr.digits = 4)+
  stat_poly_eq(formula = y ~ x, aes(label = ..rr.label..), parse = TRUE, rr.digits = 4)

# grid adjacent
a <- cowplot::plot_grid(adry, awet, nrow = 1)

## plot: 1:1 scatter of temperatures -- all season
b <- Hobo_WxLWSA %>% 
  ggplot(aes(x = FWx, y = Hobo))+
  geom_point(alpha = 0.35)+
  theme_bw()+
  facet_wrap(~ site)+
  labs(y = "Site temperature (°C)", x = "Mean LWSA temperature (°C)") +
  theme(text = element_text(size = 11))+
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) +
  ## to get equations include this line:
  #stat_poly_eq(formula = y ~ x, aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), parse = TRUE, rr.digits = 4)+
  stat_poly_eq(formula = y ~ x, aes(label = ..rr.label..), parse = TRUE, rr.digits = 4)

# grid vertical -- I dunno, seems unneccessary
cowplot::plot_grid(a, b, ncol = 1)

# save
ggsave(plot = b, filename = "R-outputs_UBC-forWater-MSc_HMc/figures/Temp_TidbiTs-FWx_lm-scatter.png", 
       width = 8, height = 6, units = "in")

```

#### visual checks
```{r}
# take dataframe with both FWx and Hobo data
# pivot longer
Hobo_Fwx <- Hobo_WxLWSA %>%
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx"),
               names_to = "data_source",
               values_to = "Temp_C") %>% 
  mutate(data_source = factor(data_source))

# check daily temp overlap
Hobo_Fwx %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(site, data_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  filter(data_source == "FWx") %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = site), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Daily mean air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# perfect :)

```

### air temp over time
```{r}
# compare temps from FWx to HOBO at each site
Hobo_Fwx %>% 
  group_by(site, data_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = data_source), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~site, ncol = 1,
             scales = "free_y",
             strip.position = "right")+
  labs(x = "", y = "Air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d", date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_subbasin_daily-temps.png", 
       width = 6, height = 7, units = "in")

```

### air temp over space
```{r}
# set FWx like it's a site
HoboFWx_sites <- Hobo %>% 
  filter(TidbiT_location == "air",
         DateTime < project_end, DateTime >= Hobo_start) %>%
  select(site, DateTime, Temp_C, rain_season) %>% 
  pivot_wider(names_from = site, values_from = Temp_C) %>%
  
  left_join(
    LWSA_meanWx %>% select(c(DateTime, Temp_mean)) %>% filter(DateTime < project_end, DateTime >= Hobo_start), by = c("DateTime")) %>% 
  rename(FWx = "Temp_mean") %>% 
  # then, pivot longer again so each site has a full DateTime range
  pivot_longer(cols = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel", "FWx"), names_to = "site", values_to = "Temp_C") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel", "FWx"))) 

# --- this is not better than the plot above
# compare temps from FWx to HOBO at each site
HoboFWx_sites %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(site, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = site), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d", date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# ---


# boxplot
# compare temps from FWx to HOBO at each site
HoboFWx_sites %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, date, rain_season) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = site, y = T_daily, fill = site))+
  geom_jitter(alpha = 0.6, shape = 21)+
  geom_boxplot(alpha = 0.4)+
  scale_fill_brewer(palette = "Dark2")+
  theme_bw() +
  labs(x = "", y = "Mean Daily Air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "none", 
        text = element_text(size = 12)) # + facet_wrap(~rain_season)

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_box-air-by-site.png", 
       width = 6, height = 7, units = "in")

```

### Stats: FWx-Hobo differences 

#### Normality tests (ADD TO APPENDIX)
```{r}
# make a comparison between subbasin hobos and the LWSA FWx data
# Test temps for normality

# density by weather station source
# these should be the same 
## -- they came from the same source & are limited to the same date range
Hobo_Fwx %>% 
  ggplot(aes(Temp_C))+
  geom_density(aes(colour = site))+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~ data_source)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_DensityNormalityCheck-subbasins.png", 
       width = 4, height = 4, units = "in")

# density ridges by TidbiT site
Hobo_Fwx %>% 
  ggplot(aes(x = Temp_C, y = fct_rev(site)))+
  ggridges::geom_density_ridges(aes(fill = data_source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw()+
  theme(legend.position = "top")+
  labs(x = "Air temperature (°C)",
       y = "",
       fill = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_ridgeplot-subbasins.png", 
       width = 4, height = 4, units = "in")

```

#### Wilcoxon tests
```{r}
# Wilcoxon tests (not normally distributed)

# null hypothesis: there is no difference between the means
# p-value > 0.05 --> cannot reject null hypothesis (accept that there is no sig.diff)
# p-value < 0.05 --> reject the null hypothesis

# tests
test <- Hobo_Fwx$Temp_C
stn <- Hobo_Fwx$data_source
site <- Hobo_Fwx$site

# compare temperatures from FWx versus Hobo on-site loggers
# run tests and compile results
Temp_Wilcoxon_tests <- bind_rows(
  tidy(wilcox.test(test[stn == "FWx" & site == "Weeks"], test[stn == "Hobo" & site == "Weeks"])) %>% 
    mutate(site = "Weeks"),
  tidy(wilcox.test(test[stn == "FWx" & site == "ChrisCrk"], test[stn == "Hobo" & site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk"),
  tidy(wilcox.test(test[stn == "FWx" & site == "LeechHead"], test[stn == "Hobo" & site == "LeechHead"])) %>% 
    mutate(site = "LeechHead"),
  tidy(wilcox.test(test[stn == "FWx" & site == "CraggCrk"], test[stn == "Hobo" & site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk"),
  tidy(wilcox.test(test[stn == "FWx" & site == "WestLeech"], test[stn == "Hobo" & site == "WestLeech"])) %>% 
    mutate(site = "WestLeech"),
  tidy(wilcox.test(test[stn == "FWx" & site == "Tunnel"], test[stn == "Hobo" & site == "Tunnel"])) %>% 
    mutate(site = "Tunnel"))

# summarize p-values
Wilcoxon_Temp_summary <- Temp_Wilcoxon_tests %>% 
  select(c(site, p.value)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/TidbiT-FWx_Wilcoxon-pvalues.csv", col_names = TRUE)

```

### Linear Regression

Relate subbasins to FWx & use linear regression to estimate temperature for each subbasin 
```{r}
# lm(y ~ x) == lm(dependent ~ independent) 
# save summary object
# use wide dataframe (Hobo_WxLWSA) rather than long(Hobo_Fwx)
sites_lm <- Hobo_WxLWSA %>% 
  filter(Date > "2019-08-23") %>% # overlapping range
  group_by(site) %>% 
  summarise(slope = coefficients(lm(formula = Hobo ~ FWx))[2],
            yint_DOC = coefficients(lm(formula = Hobo ~ FWx))[1],
            r_sq = summary(lm(formula = Hobo ~ FWx))$r.squared) 

# use linear regression to calculate earlier temperatures
Hobo_FWx_filled <- Hobo_WxLWSA_full %>% 
  group_by(site) %>% 
  mutate(Predicted = case_when(# y = m*x + b
    site == "Weeks" ~ sites_lm[[1,2]]*FWx + sites_lm[[1,3]], # [[row, column]]
    site == "ChrisCrk" ~ sites_lm[[2,2]]*FWx + sites_lm[[2,3]], 
    site == "LeechHead" ~ sites_lm[[3,2]]*FWx + sites_lm[[3,3]], 
    site == "CraggCrk" ~ sites_lm[[4,2]]*FWx + sites_lm[[4,3]], 
    site == "WestLeech" ~ sites_lm[[5,2]]*FWx + sites_lm[[5,3]], 
    site == "Tunnel" ~ sites_lm[[6,2]]*FWx + sites_lm[[6,3]]
  )) %>% 
  filter(!is.na(site))
```

#### table: error for overlap Hobo + estimates
```{r}
# isolate overlapping date range & summarize percent error
Hobo_overlapPredictionErrors <- Hobo_FWx_filled %>% 
  filter(Date > as_date(Hobo_start), Date < as_date(project_end)) %>% 
  group_by(site) %>% 
  mutate(error = ((Hobo - Predicted)/Hobo)*100) %>%  # positive error = regression under-estimated subbasin temp
  group_by(site) %>% 
  summarise(error_mean = mean(error, na.rm = TRUE),
            #Hobo_mean = mean(Hobo, na.rm = TRUE),
            #sd_Hobo = sd(Hobo, na.rm = TRUE), 
            Hobo_median = median(Hobo, na.rm = TRUE),
            Predicted_median = median(Predicted, na.rm = TRUE),
            #Predicted_mean = mean(Predicted, na.rm = TRUE),
            #sd_Predicted = sd(Predicted, na.rm = TRUE), 
            min_Hobo = min(Hobo, na.rm = TRUE),
            min_Predicted = min(Predicted, na.rm = TRUE),
            max_Hobo = max(Hobo, na.rm = TRUE),
            max_Predicted = max(Predicted, na.rm = TRUE)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/TidbiT-FWx_lm_prediction-errors.csv", col_names = TRUE)

```

#### plot: lines of estimated earlier +FWx +Hobo temps
```{r}

# take the study period data frame with temp estimates at each site
# pivot longer
HoboFWx_filled_L <- Hobo_FWx_filled %>%
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx", "Predicted"),
               names_to = "Temp_source",
               values_to = "Temp_C") %>% 
  mutate(Temp_source = factor(Temp_source))

# visualize and compare each site
HoboFWx_filled_L %>% 
  group_by(site, Temp_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = Temp_source), size = 0.5)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~site, ncol = 1,
             scales = "free_y",
             strip.position = "right")+
  labs(x = "", y = "Air temperature (°C)",
       colour = "Temp source:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d", date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Temp_TidbiTs-FWx-predicted_lm.png", 
       width = 5.5, height = 7, units = "in")


# line plot of all, not separated by site
HoboFWx_filled_L %>% 
  group_by(site, Temp_source, Date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date, y = T_daily))+
  geom_line(aes(colour = Temp_source))+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Temperature:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
               date_breaks = "1 months")


```

# QA-QC ANALYSIS 
```{r}
QAQC <- sampleresults_df %>% 
  filter(sample_type == "QA-QC") %>% 
  select(-c(DateTime))

# subset for calibration verification 
# extract cal-ver concentrations from sample name (with 'str_extract()')
calver <- QAQC %>% 
  filter(site == "Lab") %>% 
  select(c(site, sample_type, sample, analysis, NPOC_ppm, SAC254_Abs.m, DOCeq_ppm)) %>% 
  mutate(cal_ver = str_extract(sample, "([0-9]{1,}+\\.[0-9]{1,}+)"),
         cal_ver = as.numeric(cal_ver),
         rn = row_number(cal_ver)) %>% 
  mutate(sample_type = case_when(
    !is.na(cal_ver) ~ "cal_ver",
    is.na(cal_ver) ~ "RO" )) 
```


## Hold-time experiments (Tunnel rack)
```{r}
# three cycles of hold time experiments (A, B , C)
# each time, 5 samples were collected (grab) while 5 were placed on the rack with siphon lids
# the held samples (rack) were collected later after sitting out
# compare results between fresh and held samples

# subset QAQC df for holdtime samples
# extract set and rep values and group sets
HT <- QAQC %>% 
  filter(site == "Tunnel",
         !is.na(NPOC_ppm)) %>% 
  select(-c(sampleStage_cm, corr_stage_cm)) %>% 
  mutate(HoldTime_set = substr(sample, 10, 10),
         HoldTime_rep = substr(sample, 11, 12),
         HoldTime_group = case_when(
           HoldTime_rep == c(1:5) ~ "G",  # 'fresh' grab samples
           HoldTime_rep == c(6:10) ~ "R", # 'held' rack samples
         )) %>% 
  # groups
  mutate(group = case_when(
    HoldTime_set == "A" & HoldTime_rep == c(1:5) ~ "AG", # first set grabs, 2019-10-12 (trip 16)
    HoldTime_set == "A" & HoldTime_rep == c(6:10) ~ "AR", # first set rack, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(1:5) ~ "BG", # second set grabs, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(6:10) ~ "BR", # second set rack, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(1:5) ~ "CG", # third set grabs, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(6:10) ~ "CR", # third set rack, 2019-12-16 (trip 20)
  ))

# how many days passed between collecting fresh and held samples?
a <- HT %>% 
  group_by(HoldTime_set, Date) %>% 
  summarise(group = first(group)) %>%
  group_by(HoldTime_set) %>% 
  summarize(lapse = diff.Date(Date))

# mutate lapse to HT df
HT <- full_join(HT, a, by = "HoldTime_set") %>% 
  mutate(HoldTime_set = factor(HoldTime_set, levels = c("A", "B", "C")), 
         HoldTime_rep= as_factor(HoldTime_rep), 
         HoldTime_group = as_factor(HoldTime_group), 
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR"))) %>% 
  mutate(HT_set_labels = HoldTime_set,
         HT_group_labels = HoldTime_group)


# Join Tunnel HOBO TidbiT data with HT data
HT_Hobo <- Hobo %>% 
  filter(site == "Tunnel",
         TidbiT_location == "air") %>% 
  mutate(Date = as_date(DateTime)) %>% 
  full_join(HT, by = c("site", "trip", "event_ID", "rain_season", "Date")) %>% 
  mutate(site = factor(site),
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR")))

```

### HT plots
```{r}

# create labels for plots
HT$HT_group_labels <- fct_recode(HT$HT_group_labels, Fresh = "G", Held = "R")
HT$HT_set_labels <- fct_recode(HT$HT_set_labels, "A (11 days)" = "A", "B (20 days)" = "B", "C (34 days)" = "C")

# plot sets
a <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = NPOC_ppm, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "DOC (mg/L)", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~HoldTime_set)

b <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = SAC254_Abs.m, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "UV abs at 254nm (a.u.)", x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HoldTime_set)

c <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = DOCeq_ppm, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "Est. DOC (mg/L)", x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HoldTime_set)

# with Estimated DOC
#cowplot::plot_grid(a, b, c, align = "v", ncol = 1, rel_heights = c(2, 1.6, 1.6))  

# without estimated DOC
cowplot::plot_grid(a, b, align = "v", ncol = 1, rel_heights = c(2, 1.6))  
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_boxplots.png")

```

### HT tests: Wilcoxon
```{r}

# density distribution normality 
# NPOC
HT %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "NPOC_ppm",
                 color = "HoldTime_set")

# Tests UV254 abs for normality 
HT %>% 
  ggplot(aes(SAC254_Abs.m))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "SAC254_Abs.m",
                 color = "HoldTime_set")

# Tests DOC estimate abs for normality 
HT %>% 
  ggplot(aes(DOCeq_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "DOCeq_ppm",
                 color = "HoldTime_set")
# ---
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis
# p-value < 0.05 --> reject the null hypothesis 

# run tests and compile results
# paired (before and after)
HT_Wilcoxon_tests <- bind_rows(
  ## NPOC ---
  # set A
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "AG"], HT$NPOC_ppm[HT$group == "AR"], paired = TRUE)) %>% 
    mutate(Set = "A", Analysis = "NPOC_ppm"),
  # set B 
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "BG"], HT$NPOC_ppm[HT$group == "BR"], paired = TRUE)) %>% 
    mutate(Set = "B", Analysis = "NPOC_ppm"),
  # set C
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "CG"], HT$NPOC_ppm[HT$group == "CR"], paired = TRUE)) %>% 
    mutate(Set = "C", Analysis = "NPOC_ppm"),
  ## UV-254 ---
  # set A
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "AG"], HT$SAC254_Abs.m[HT$group == "AR"], paired = TRUE)) %>% 
    mutate(Set = "A", Analysis = "SAC254_Abs.m"),
  # set B
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "BG"], HT$SAC254_Abs.m[HT$group == "BR"], paired = TRUE)) %>% 
    mutate(Set = "B", Analysis = "SAC254_Abs.m"),
  # set C
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "CG"], HT$SAC254_Abs.m[HT$group == "CR"], paired = TRUE)) %>% 
    mutate(Set = "C", Analysis = "SAC254_Abs.m")) %>% 
  select(Analysis, Set, p.value) %>% 
  # pull values of interest to summarize
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***",
                              p.value < 0.05 ~ "**",
                              p.value < 0.1 ~ "*",
                              p.value > 0.1 ~ "NA")) 

## view
# HT_Wilcoxon_tests
# cowplot::plot_grid(a, b, align = "v", ncol = 1, rel_heights = c(2, 1.6)) 

```

#### table: conc results summary
```{r}
# summarize
HT_summ <- HT %>% 
  group_by(group) %>% 
  summarise(set = first(HoldTime_set),
            lapse = first(lapse),
            count = n(),
            mean_DOC = mean(NPOC_ppm),
            sd_DOC = sd(NPOC_ppm),
            RSD_DOC = (sd_DOC/mean_DOC)*100,
            mean_UV254 = mean(SAC254_Abs.m),
            sd_UV254 = sd(SAC254_Abs.m)) 
# save results
HT_summ %>% 
  select(-set) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_sample-summary.csv")

```


#### table: HT summary
```{r}
# summarize percent change (DOC & UV254) for each set
# vector
HTDOCresult <- HT_summ$mean_DOC
HTUVresult <- HT_summ$mean_UV254
# summarize
change <- 
  tibble(set = c("A", "B", "C"),
         percent_change_DOC = c(
           round((((HTDOCresult[2]-HTDOCresult[1])/HTDOCresult[1])*100),0),
           round((((HTDOCresult[4]-HTDOCresult[3])/HTDOCresult[3])*100),0),
           round((((HTDOCresult[6]-HTDOCresult[5])/HTDOCresult[5])*100),0)),
         percent_change_UV254 = c(
           round((((HTUVresult[2]-HTUVresult[1])/HTUVresult[1])*100),0),
           round((((HTUVresult[4]-HTUVresult[3])/HTUVresult[3])*100),0),
           round((((HTUVresult[6]-HTUVresult[5])/HTUVresult[5])*100),0)))


# pull & set values for plot + table
# set dates
HT_range <- HT %>% 
  group_by(HoldTime_set) %>% 
  summarise(start = first(Date),
            end = last(Date))

# set sample dates
HT_dates <- HT %>% 
  group_by(HoldTime_set) %>% 
  mutate(lapse = as.numeric(lapse)) %>% 
  summarise(date_fresh = as_date(first(DateTime_sampled)),
            date_held = as_date(last(DateTime_sampled)),
            lapse = mean(lapse),
            half_lapse = lapse*0.5)


# summarize mean temp +/- sd for each hold-time set
A_temp <- HT_Hobo %>% 
  filter(Date %within% interval(HT_range$start[1], HT_range$end[1])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(A_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

B_temp <- HT_Hobo %>% 
  filter(Date %within% interval(HT_range$start[2], HT_range$end[2])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(B_temp = paste(format(round(.$set_temp, 1), nsmall = 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

C_temp <- HT_Hobo %>% 
  filter(Date %within% interval(HT_range$start[3], HT_range$end[3])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(C_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()


#---
# join statistical results with Hobo results
HT_tests_summary <- HT_Wilcoxon_tests %>% 
  pivot_wider(names_from = Analysis, values_from = c("p.value", "sig.diff")) %>% 
  mutate(lapse = (HT_Hobo %>% 
                    filter(!is.na(group)) %>% 
                    group_by(HoldTime_set) %>% 
                    summarise(lapse = last(lapse)))$lapse) %>% 
  full_join(change, by = c("Set" = "set")) %>% 
  mutate("Temp range" = c(A_temp, B_temp, C_temp)) %>% 
  select(Set, "Days held" = lapse, 
         "Temp range", 
         "DOC change (%)" = percent_change_DOC, # rename: new = old
         "sig.diff (DOC)" = sig.diff_NPOC_ppm,  
         "p-value (DOC)" = p.value_NPOC_ppm,
         "UV 254 change (%)" = percent_change_UV254,
         "sig.diff (UV 254)" = sig.diff_SAC254_Abs.m, 
         "p-value (UV 254)" = p.value_SAC254_Abs.m) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_results-summary.csv")

```

### plot HT megaplot
```{r}

# pivot long
HT_Hobo_L <- HT_Hobo %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(Date) %>% 
  summarise(daily_mean_T = mean(Temp_C)) %>% 
  full_join(HT_Hobo) %>% 
  pivot_longer(cols = c(daily_mean_T, Temp_C),
               values_to = "degrees_C",
               names_to = "Temp") %>% 
  mutate(Temp = factor(Temp, levels = c("Temp_C", "daily_mean_T")))

# plot it  
HT_air_plot <- HT_Hobo_L %>% 
  ggplot(aes(x = Date, y = degrees_C))+
  geom_line(aes(colour = Temp, size = Temp))+
  scale_colour_manual(values = c(forWater_colours2[["SkyBlue"]], ## 30 minute 
                                 forWater_colours2[["DeepBlue"]]), ## daily average
                      labels = c("30 minute measurement", "Daily mean"))+
  scale_size_manual(values = c(1, 1.5), labels = c("30 minute measurement", "Daily mean"))+
  guides(colour = guide_legend("Temperature:"), size = guide_legend("Temperature:"))+
  # horizontal lines for lab refrigerator range (0-7 C)
  geom_hline(yintercept = c(0, 7), linetype = "solid", colour = "red")+
  annotate("text", label = "fridge\n range", angle = 90, colour = "red",
           x = first(HT_Hobo_L$Date)+1, y = 3.5)+
  # vertical lines for HT sample dates
  geom_vline(xintercept = c(HT_dates$date_fresh, HT_dates$date_held), 
             linetype = "dashed", colour = "black", size = 0.75) +
  annotate("text", label = c("Hold-time set:\n", paste(HT_dates$HoldTime_set, "\n")), ## set 
           x = c(HT_dates$date_fresh[1]-18, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 27)+
  annotate("text", label = c("Days:\n", paste(HT_dates$lapse, "\n")), ## time lapse
           x = c(HT_dates$date_fresh[1]-8, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 25)+
  theme_bw()+
  labs(y = "Air Temperature (°C)",
       #caption = glue::glue("Mean temperatures during vertical rack hold-time experiments: {A_temp} (set A), {B_temp} (set B), {C_temp} (set C)."),
       x = "") +
  theme(legend.position = "bottom", 
        text = element_text(size = 12)) +
  scale_x_date(date_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_airTemp.png", width = 6.5, height = 6, units = "in")

# --- 
# plot rain for the same period
HT_rain_plot <- LWSA_meanWx %>% 
  filter(DateTime >= first(HT_Hobo_L$DateTime),
         DateTime <= last(HT_Hobo_L$DateTime)) %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(fill = forWater_colours1[["DarkGrey"]]) +
  scale_y_reverse() +
  labs(x = "", y = "Rain (mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(labels = NULL, 
               date_breaks = "1 months")
# stack and save
cowplot::plot_grid(HT_rain_plot, HT_air_plot, align = "v", ncol = 1, rel_heights = c(1,3.5))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_airTemp_withRain.png", width = 7, height = 7, units = "in")

```

## LAB 
```{r}

### blanks --------
# check lab blanks
# this is a difficult measure of precision because the RO water is not the most reliably stable
calver %>% 
  filter(sample_type == "RO",
         sample == "RO" | sample == "RO_pH<2",
         NPOC_ppm != 0) %>% 
  group_by(sample) %>% 
  summarise(count = n(),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            RSD = (sd_DOC/DOC_mean)*100)

### cal vers -------
# percent error calculated as 'measured' minus 'actual'
# negative error indicates the method was under-estimating DOC concentration 
# positive error indicates the method was over-estimating DOC concentration

# check cal vers for shimadzu
a <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(NPOC_ppm),
         rn != 7,  # error -- did not add standard 
         cal_ver != 5.7) %>%  # true concs were not calculated
  group_by(rn) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            percent_error = ((DOC_mean - calc)/ calc)*100) %>% 
  ungroup() %>% 
  summarise(count = sum(count),
            error_percent = mean(percent_error))

# check cal vers for spectrolyser
b <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(DOCeq_ppm)) %>% 
  group_by(rn) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOCeq_mean = mean(DOCeq_ppm, na.rm = TRUE),
            sd_DOCeq = sd(DOCeq_ppm, na.rm = T),
            percent_error = ((DOCeq_mean - calc)/ calc)*100) %>% 
  ungroup() %>%  
  summarise(count = sum(count),
            error_percent = mean(percent_error))

# total cal-vers included
n_calvers_total <- calver %>% 
  filter(sample_type == "cal_ver") %>% 
  summarise(n = n())

# cal-vers included
n_calvers <- a[1,1]+b[1,1]

# percent error from shimadzu
error_shimadzu <- a %>% pull(error_percent)

# percent error from spectrolyser
error_spectrolyser <- b %>% pull(error_percent)

# average percent error from both methods:
error_overall <- (error_shimadzu + error_spectrolyser)/2

```




# SAMPLES: augment dataframes

## Categorize
```{r, mutate}

# create a "first-flush category in rain_season(s)
sampleresults <- sampleresults_df %>% 
  select(-c(DateTime)) %>% 
  mutate(rain_seasons = case_when(
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-21", "2019-03-01") ~ "wet",
    Date %within% interval("2019-03-01", "2019-04-30") ~ "wet", # snow",
    Date %within% interval("2019-05-01", "2019-09-11") ~ "dry",
    event_ID == 9 ~ "first flush",
    event_ID %in% 10:18 ~ "wet")) %>% 
  mutate(rain_season = as.character(rain_season))

# fill in any gaps and save as factors
sampleresults <- within(sampleresults, 
                        rain_seasons <- ifelse(
                          is.na(rain_seasons), rain_season, rain_seasons)) %>% 
  mutate(rain_season = factor(rain_season),
         rain_seasons = factor(rain_seasons))

# further group sites
sampleresults <- sampleresults %>% 
  mutate(site_type = case_when(
    site == "Weeks" ~ "subbasin",   
    site == "ChrisCrk" ~ "subbasin",
    site == "LeechHead"  ~ "subbasin",
    site == "CraggCrk" ~ "subbasin",
    site == "WestLeech" ~ "subbasin",
    site == "Tunnel" ~ "subbasin",
    site == "Lab" ~ "LabQAQC",
    TRUE ~ "synoptic")) %>% 
  mutate(site_type = factor(site_type),
         DateTime_sampled = as.POSIXct(DateTime_sampled, tz = TZ))


```

## QA-QC flags
```{r}
# HT: flag samples with HoldTime_days >= 30 
# FFHT: flag samples with HoldTime_days >=7 days if rain_seasons == "first flush"
# OK: hold time was less than 30 days

sampleresults <- sampleresults %>% 
  mutate(QAQC_flag = case_when(
    rain_seasons == "first flush" & HoldTime_days >= 7 ~ "FFHT",
    HoldTime_days <= 20 ~ "OK",
    HoldTime_days >= 30 ~ "HT",
    TRUE ~ "OK"))

```

## subset dfs + sample counts
```{r, subsetting-campaign}

# create a subset dataframe for the six install sites for tidier calling
sixfilter <- sampleresults %>% 
  filter(site_type == "subbasin",
         analysis == "DOC") %>% 
  filter(sample_type != "QA-QC") %>%
  mutate(site = factor(site, levels = 
                         c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech","Tunnel")),
         QAQC_flag = factor(QAQC_flag))

# add air temperatures: 
## 1. replace missing Hobo values with predicted values 
## 2. summarize mean daily air temps
## 3. join mean daily air temps with sample results by date sampled
sixfilter <- within(Hobo_FWx_filled, 
                    Hobo <- ifelse(is.na(Hobo), Predicted, Hobo)) %>% 
  group_by(site, Date) %>% 
  summarise(Tmean_airDaily = mean(Hobo)) %>% 
  select(site, Date, Tmean_airDaily) %>% 
  right_join(sixfilter, by = c("site", "Date")) %>% 
  ungroup()

# primary synoptic sampling sites (n > 1)
# 15 sites total

# how many synoptic samples were grabbed?
# save value as object to implant in text
n_SynopticGrabs <- sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab") %>%
  filter(sample_type != "QA-QC") %>%
  group_by(site = forcats::fct_explicit_na(site)) %>% 
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% 
  mutate(what = "synoptic grab count") %>% 
  ungroup() %>%  # drop the following code to see samples by sites
  group_by(what) %>% 
  summarise(total = sum(grab_sample_count)) %>% 
  pull(total)

# create a subset dataframe for the synoptically sampled sites for tidier calling
synopticfilter <- sampleresults %>% 
  filter(sample_type != "QA-QC") %>% 
  filter(# subbasin sites 
    site == "Weeks"|
      site == "ChrisCrk"|
      site == "LeechHead"|
      site == "CraggCrk"|
      site == "WestLeech"|
      site == "Tunnel"|
      # other sites
      site == "Rithet"|
      site == "Lazar"|
      site == "Jarvis"|
      site == "Judge"|
      site == "Leech-downstreamconf"|
      site == "Boneyard"|
      #site == "Deception-crk"|  ## only two samples
      #site == "West-Jordan"| ## only two samples
      site == "Deception-res",
    analysis == "DOC"
  ) %>% 
  mutate(site = factor(site, # order as you want to see them in plots
                       levels = c("West-Jordan", "Weeks", "ChrisCrk", "LeechHead", "Jarvis", "Lazar", "CraggCrk", "WestLeech", "Leech-downstreamconf", "Tunnel", "Rithet", "Judge", "Deception-res", "Deception-crk", "Boneyard" ))) 
# rename funky names
synopticfilter$site <- synopticfilter$site %>% 
  plyr::revalue(c("Leech-downstreamconf" = "Leech-Beach",  ## old = new
                  "Jarvis" = "Jarvis-crk",
                  "Judge" = "Judge-crk", 
                  "Lazar" = "Lazar-crk", 
                  #"West-Jordan" = "W.Jordan-Trib",
                  #"Deception-crk" = "Deception-Gluch",
                  "Rithet" = "Rithet-crk"))

# ------
# sample counts
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()
# save to outputs
write_csv(n_subbbasinSamples, "R-outputs_UBC-forWater-MSc_HMc/tables/summary_subbasins-SampleCount.csv", na = "NA") 

# how many of each type total?
# save values as objects to implant in text

# Grab samples
n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  summarise(number_of_samples = n()) %>% 
  summarize(total = sum(number_of_samples)) %>% 
  pull(total)

# Rack samples
n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% 
  summarize(total = sum(number_of_samples)) %>% 
  pull(total) 

# How many samples were collected overall
n_totalSamples <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                analysis == "DOC") %>%
  #group_by(sample_type) %>% 
  summarise(sample_count = n()) %>% 
  ungroup() %>% 
  pull(sample_count)


# 15 synoptic sites (including the install sites)
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>%
  group_by(site = forcats::fct_explicit_na(site)) %>% 
  summarise(grab_sample_count = n()) %>% 
  ungroup() 


# make a summary table:
tibble::tibble(
  "synoptic samples outside of subbasin sites" = n_SynopticGrabs-n_installGrabSamples,
  "opportunistic grab samples" = n_totalSamples-(n_SynopticGrabs+n_installRackSamples),
  "sub-basin synoptic grab samples" = n_installGrabSamples,
  "sub-basin rack samples" = n_installRackSamples,
  "total" = n_totalSamples) %>% 
  pivot_longer(everything(),
               names_to = "sample category", values_to = "count") %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_AllSamples_Count.csv")

```

### subbasin_types
```{r}

# further categorize site_type
sixfilter <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "headwater",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "mainstem")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

# further categorize subbasin_types
sixfilter_sub <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "mainstem",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "outlet")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

# update stage_samples df also
stage_samples <- left_join(stage_samples, sixfilter) %>% 
  mutate(trip = factor(trip),
         sample_type = factor(sample_type),
         event_ID = factor(event_ID),
         rain_season = factor(rain_season))

```

# SUBBASINS

## unused table: DOC subbasin sites, Mean/Min/Max 
```{r, all-samples-together}

# grouped-summary (site and sample-type and all)
a <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()  # %>%
# for a site summary of each, include this:
rbind(sixfilter %>%
        filter(sample_type == "Grab" | sample_type == "Rack") %>% 
        group_by(site) %>% 
        summarize(sample_type = "All",
                  count = n(), 
                  DOCmean = mean(NPOC_ppm, na.rm = T), 
                  DOCsd = sd(NPOC_ppm, na.rm = T), 
                  RSD = round((DOCsd/DOCmean)*100, 0),
                  DOCmin = min(NPOC_ppm, na.rm = T), 
                  DOCmedian = median(NPOC_ppm, na.rm = T), 
                  DOCmax = max(NPOC_ppm, na.rm = T))) %>% 
  ungroup() %>% 
  arrange(site)

# un-grouped summary
b <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "ALL SITES",
            sample_type = "SUMMARY",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, sample_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# tag totals summary onto site summary
rbind(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Subbasin_summary_GvsR.csv", col_names = T)

```

## Tunnel as outlet - nested catchments - DOC ranges

Q: is the variance at the watershed outlet greater than the variance in each subbasin?
Q2: is the variance greater within each site or among all sites?

Ha: there is greater variance within each site compared to the variance among all sites 
Ho: the variance within each site is not greater than variance among all sites 

### *DOC mean/min/max (descriptive stats summary)
```{r}
# calculate range of DOC within each site and between each site for subbasins
# this code was copied -- needs to be modified and updated


# subbasin samples DOC concs (Grab + Rack)
a <- sixfilter_sub %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(subbasin_type = first(subbasin_type),
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped by headwaters / mainstem / outlet
b <- sixfilter_sub %>%
  filter(sample_type == "Grab" | sample_type == "Rack",
         subbasin_type != "outlet") %>% 
  group_by(subbasin_type) %>% 
  summarize(site = "SUMMARY",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, subbasin_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# nested catchment summary
c <- sixfilter_sub %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  filter(subbasin_type != "outlet") %>% 
  summarize(site = "SUMMARY",
            subbasin_type = "all nested catchments",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# combine 
rbind(a,b) %>%
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Subbasin_summary_CategoryIntegration.csv", col_names = T)

# ###########################
# Boxplots with jitter scatter

# DOC by site (all sites) 
# grab and rack combined 
site_subbasin_box <- sixfilter_sub %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin_boxplots.png")

```

## Levene's test for homoscedasticity in DOC:

An alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). 

If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 

```{r}
# check for normality
sixfilter %>%
  filter(QAQC_flag != "FFHT") %>%
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ site,
             nrow = 3,
             scales = "free_y")
# Weeks is nearly normal, the others are not

# car::leveneTest(response ~ independent variable)
car::leveneTest(NPOC_ppm ~ site, data = sixfilter)
# --> reject Ho, variance is not homogeneous across the LWSA 

# find out where:

# headwaters
# 1-2
WC <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "Weeks" | site == "ChrisCrk") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 1-3
H1 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "Weeks" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 2-3  
H2 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "ChrisCrk" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems
# 3-4   
H4 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "CraggCrk" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 3-5 
H5 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "WestLeech" | site == "LeechHead") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-5
C5 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "WestLeech" | site == "CraggCrk") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()

# mainstems and outlet
# 3-6
H6 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "LeechHead" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 4-6 
C6 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "CraggCrk" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()
# 5-6   
W6 <- sixfilter %>% filter(QAQC_flag != "FFHT") %>%
  filter(site == "WestLeech" | site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% tidy() %>% pull("p.value") %>% first()


# write a summary table
Levenes_summary_DOC <- tibble::tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk",
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"), 
  p.value = c(WC, H1, H2, 
              H4, H5, C5, 
              H6, C6, W6)) %>% 
  mutate("Significance" = # (confidence level: ***99%, **95%, *90%)
           case_when(p.value < 0.01 ~ "***",
                     p.value < 0.05 ~ "**",
                     p.value < 0.1 ~ "*",
                     p.value > 0.1 ~ "homoscedastic")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-stats_variance-LeveneTests.csv", col_names = T)

```


### Synchrony tests

#### trash 
```{r}

# -- synchrony::peaks WET

# reshape sixfilter data to wide flat file matrix
## sites as columns, timestep as rows
# values should be abundance
six_wide_NPOC_wet <- sixfilter %>% 
  filter(rain_season == "wet") %>% 
  select(c(DateTime_sampled, site, NPOC_ppm)) %>% 
  pivot_wider(names_from = site,
              values_from = NPOC_ppm) %>% 
  unnest(cols = c(WestLeech, Tunnel, CraggCrk, LeechHead, Weeks, ChrisCrk)) %>% 
  arrange(DateTime_sampled) %>% 
  mutate(timestep = row_number(DateTime_sampled))

# synchrony tests
# community-wide & significance via Monte Carlo randomizations
# 1 == perfect synchrony
six_wide_NPOC_matrix <- six_wide_NPOC_wet %>% select(-DateTime_sampled) %>% as.matrix()

summary(synchrony::community.sync(six_wide_NPOC_matrix, type = 2))

# synchrony tests
# Determine the proportion of concurrent local extrema (Peaks)
# 1
six_wide_NPOC_Weeks <- six_wide_NPOC_wet %>% 
  select(c(timestep, NPOC_Weeks = "Weeks")) %>% 
  filter(!is.na(NPOC_Weeks)) %>% 
  as.matrix()

# 2
six_wide_NPOC_Chris <- six_wide_NPOC_wet %>% 
  select(c(timestep, NPOC_ChrisCrk = "ChrisCrk")) %>% 
  filter(!is.na(NPOC_ChrisCrk)) %>% 
  as.matrix()

# 3
six_wide_NPOC_Head <- six_wide_NPOC_wet %>% 
  select(c(timestep, NPOC_LeechHead = "LeechHead")) %>% 
  filter(!is.na(NPOC_LeechHead)) %>% 
  as.matrix()

# 4
six_wide_NPOC_Cragg <- six_wide_NPOC_wet %>% 
  select(c(timestep, NPOC_CraggCrk = "CraggCrk")) %>% 
  filter(!is.na(NPOC_CraggCrk)) %>% 
  as.matrix()

# 5
six_wide_NPOC_West <- six_wide_NPOC_wet %>% 
  select(c(timestep, NPOC_WestLeech = "WestLeech")) %>%
  filter(!is.na(NPOC_WestLeech)) %>% 
  as.matrix()

# 6
six_wide_NPOC_Tunnel <- six_wide_NPOC_wet %>% 
  select(c(timestep, NPOC_Tunnel = "Tunnel")) %>%
  filter(!is.na(NPOC_Tunnel)) %>% 
  as.matrix()

# tests by site (number)
peaks_1to2 <- synchrony::peaks(six_wide_NPOC_Weeks, six_wide_NPOC_Chris, type = 2) #, nrands = 999)
peaks_1to3 <- synchrony::peaks(six_wide_NPOC_Weeks, six_wide_NPOC_Head, type = 2) #, nrands = 999)
peaks_2to3 <- synchrony::peaks(six_wide_NPOC_Chris, six_wide_NPOC_Head, type = 2) #, nrands = 999)
peaks_3to4 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_Cragg, type = 2) #, nrands = 999)
peaks_3to5 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_West, type = 2) #, nrands = 999)
peaks_4to5 <- synchrony::peaks(six_wide_NPOC_Cragg, six_wide_NPOC_West, type = 2) #, nrands = 999)
peaks_3to6 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)
peaks_4to6 <- synchrony::peaks(six_wide_NPOC_Cragg, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)
peaks_5to6 <- synchrony::peaks(six_wide_NPOC_West, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)

# combine
synch_PeaksSumm_wet <- tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk", 
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"),
  "Proportion of common DOC peaks" = c(peaks_1to2$obs, peaks_1to3$obs, peaks_2to3$obs, peaks_3to4$obs, peaks_3to5$obs, peaks_4to5$obs, peaks_3to6$obs, peaks_4to6$obs, peaks_5to6$obs))  #,
#"p-value" = c(peaks_1to2$pval, peaks_1to3$pval, peaks_2to3$pval, peaks_3to4$pval, peaks_3to5$pval, peaks_4to5$pval, peaks_3to6$pval, peaks_4to6$pval, peaks_5to6$pval)) 



# DRY SEASON --- 
# reshape sixfilter data to wide flat file matrix
## sites as columns, timestep as rows
# values should be abundance
six_wide_NPOC_dry <- sixfilter %>% 
  filter(rain_season == "dry") %>% 
  select(c(DateTime_sampled, site, NPOC_ppm, rain_season)) %>% 
  pivot_wider(names_from = site,
              values_from = NPOC_ppm) %>% 
  unnest(cols = c(WestLeech, Tunnel, CraggCrk, LeechHead, Weeks, ChrisCrk)) %>% 
  arrange(DateTime_sampled) %>% 
  mutate(timestep = row_number(DateTime_sampled)) %>% 
  select(-rain_season)

# synchrony tests
# community-wide & significance via Monte Carlo randomizations
# 1 == perfect synchrony
six_wide_NPOC_matrix <- six_wide_NPOC_dry %>% select(-DateTime_sampled) %>% as.matrix()

summary(synchrony::community.sync(six_wide_NPOC_matrix, type = 2))

# synchrony tests
# Determine the proportion of concurrent local extrema (Peaks)
# 1
six_wide_NPOC_Weeks <- six_wide_NPOC_dry %>% 
  select(c(timestep, NPOC_Weeks = "Weeks")) %>% 
  filter(!is.na(NPOC_Weeks)) %>% 
  as.matrix()

# 2
six_wide_NPOC_Chris <- six_wide_NPOC_dry %>% 
  select(c(timestep, NPOC_ChrisCrk = "ChrisCrk")) %>% 
  filter(!is.na(NPOC_ChrisCrk)) %>% 
  as.matrix()

# 3
six_wide_NPOC_Head <- six_wide_NPOC_dry %>% 
  select(c(timestep, NPOC_LeechHead = "LeechHead")) %>% 
  filter(!is.na(NPOC_LeechHead)) %>% 
  as.matrix()

# 4
six_wide_NPOC_Cragg <- six_wide_NPOC_dry %>% 
  select(c(timestep, NPOC_CraggCrk = "CraggCrk")) %>% 
  filter(!is.na(NPOC_CraggCrk)) %>% 
  as.matrix()

# 5
six_wide_NPOC_West <- six_wide_NPOC_dry %>% 
  select(c(timestep, NPOC_WestLeech = "WestLeech")) %>%
  filter(!is.na(NPOC_WestLeech)) %>% 
  as.matrix()

# 6
six_wide_NPOC_Tunnel <- six_wide_NPOC_dry %>% 
  select(c(timestep, NPOC_Tunnel = "Tunnel")) %>%
  filter(!is.na(NPOC_Tunnel)) %>% 
  as.matrix()

# tests by site (number)
peaks_1to2 <- synchrony::peaks(six_wide_NPOC_Weeks, six_wide_NPOC_Chris, type = 2) #, nrands = 999)
peaks_1to3 <- synchrony::peaks(six_wide_NPOC_Weeks, six_wide_NPOC_Head, type = 2) #, nrands = 999)
peaks_2to3 <- synchrony::peaks(six_wide_NPOC_Chris, six_wide_NPOC_Head, type = 2) #, nrands = 999)
peaks_3to4 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_Cragg, type = 2) #, nrands = 999)
peaks_3to5 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_West, type = 2) #, nrands = 999)
peaks_4to5 <- synchrony::peaks(six_wide_NPOC_Cragg, six_wide_NPOC_West, type = 2) #, nrands = 999)
peaks_3to6 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)
peaks_4to6 <- synchrony::peaks(six_wide_NPOC_Cragg, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)
peaks_5to6 <- synchrony::peaks(six_wide_NPOC_West, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)

# combine
synch_PeaksSumm_dry <- tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk", 
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"),
  "Proportion of common DOC peaks" = c(peaks_1to2$obs, peaks_1to3$obs, peaks_2to3$obs, peaks_3to4$obs, peaks_3to5$obs, peaks_4to5$obs, peaks_3to6$obs, peaks_4to6$obs, peaks_5to6$obs))  #,
#"p-value" = c(peaks_1to2$pval, peaks_1to3$pval, peaks_2to3$pval, peaks_3to4$pval, peaks_3to5$pval, peaks_4to5$pval, peaks_3to6$pval, peaks_4to6$pval, peaks_5to6$pval)) 


#### trash -- synchrony::peaks all

# reshape sixfilter data to wide flat file matrix
## sites as columns, timestep as rows
# values should be abundance
six_wide_NPOC <- sixfilter %>% 
  select(c(DateTime_sampled, site, NPOC_ppm)) %>% 
  pivot_wider(names_from = site,
              values_from = NPOC_ppm) %>% 
  unnest(cols = c(WestLeech, Tunnel, CraggCrk, LeechHead, Weeks, ChrisCrk)) %>% 
  arrange(DateTime_sampled) %>% 
  mutate(timestep = row_number(DateTime_sampled))

# synchrony tests
# community-wide & significance via Monte Carlo randomizations
# 1 == perfect synchrony
six_wide_NPOC_matrix <- six_wide_NPOC %>% select(-DateTime_sampled) %>% as.matrix()

summary(synchrony::community.sync(six_wide_NPOC_matrix, type = 2))

# synchrony tests
# Determine the proportion of concurrent local extrema (Peaks)
# 1
six_wide_NPOC_Weeks <- six_wide_NPOC %>% 
  select(c(timestep, NPOC_Weeks = "Weeks")) %>% 
  filter(!is.na(NPOC_Weeks)) %>% 
  as.matrix()

# 2
six_wide_NPOC_Chris <- six_wide_NPOC %>% 
  select(c(timestep, NPOC_ChrisCrk = "ChrisCrk")) %>% 
  filter(!is.na(NPOC_ChrisCrk)) %>% 
  as.matrix()

# 3
six_wide_NPOC_Head <- six_wide_NPOC %>% 
  select(c(timestep, NPOC_LeechHead = "LeechHead")) %>% 
  filter(!is.na(NPOC_LeechHead)) %>% 
  as.matrix()

# 4
six_wide_NPOC_Cragg <- six_wide_NPOC %>% 
  select(c(timestep, NPOC_CraggCrk = "CraggCrk")) %>% 
  filter(!is.na(NPOC_CraggCrk)) %>% 
  as.matrix()

# 5
six_wide_NPOC_West <- six_wide_NPOC %>% 
  select(c(timestep, NPOC_WestLeech = "WestLeech")) %>%
  filter(!is.na(NPOC_WestLeech)) %>% 
  as.matrix()

# 6
six_wide_NPOC_Tunnel <- six_wide_NPOC %>% 
  select(c(timestep, NPOC_Tunnel = "Tunnel")) %>%
  filter(!is.na(NPOC_Tunnel)) %>% 
  as.matrix()

# tests by site (number)
peaks_1to2 <- synchrony::peaks(six_wide_NPOC_Weeks, six_wide_NPOC_Chris, type = 2) #, nrands = 999)
peaks_1to3 <- synchrony::peaks(six_wide_NPOC_Weeks, six_wide_NPOC_Head, type = 2) #, nrands = 999)
peaks_2to3 <- synchrony::peaks(six_wide_NPOC_Chris, six_wide_NPOC_Head, type = 2) #, nrands = 999)
peaks_3to4 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_Cragg, type = 2) #, nrands = 999)
peaks_3to5 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_West, type = 2) #, nrands = 999)
peaks_4to5 <- synchrony::peaks(six_wide_NPOC_Cragg, six_wide_NPOC_West, type = 2) #, nrands = 999)
peaks_3to6 <- synchrony::peaks(six_wide_NPOC_Head, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)
peaks_4to6 <- synchrony::peaks(six_wide_NPOC_Cragg, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)
peaks_5to6 <- synchrony::peaks(six_wide_NPOC_West, six_wide_NPOC_Tunnel, type = 2) #, nrands = 999)

# combine
synch_PeaksSumm_all <- tibble(
  "Comparison Group" = c(rep("headwaters", 3), rep("mainstems", 3), rep("mainstem to outlet", 3)),
  "Site Comparison" = c("Weeks & ChrisCrk", "LeechHead & Weeks", "LeechHead & ChrisCrk", 
                        "LeechHead & CraggCrk", "LeechHead & WestLeech", "CraggCrk & WestLeech",
                        "LeechHead & Tunnel", "CraggCrk & Tunnel", "WestLeech & Tunnel"),
  "Proportion of common DOC peaks" = c(peaks_1to2$obs, peaks_1to3$obs, peaks_2to3$obs, peaks_3to4$obs, peaks_3to5$obs, peaks_4to5$obs, peaks_3to6$obs, peaks_4to6$obs, peaks_5to6$obs))  #,
#"p-value" = c(peaks_1to2$pval, peaks_1to3$pval, peaks_2to3$pval, peaks_3to4$pval, peaks_3to5$pval, peaks_4to5$pval, peaks_3to6$pval, peaks_4to6$pval, peaks_5to6$pval)) 

# ---
# join wet, dry and all
full_join(
  synch_PeaksSumm_dry %>% rename(`Dry season common peak proportion` = `Proportion of common DOC peaks`),
  synch_PeaksSumm_wet %>% rename(`Wet season common peak proportion` = `Proportion of common DOC peaks`)) %>% 
  full_join(synch_PeaksSumm_all%>% rename(`Proportion of total common DOC peaks` = `Proportion of common DOC peaks`)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-stats_synchrony-peaks_all.csv", col_names = T)

```


#### temporal plot: DOC~time subbasin geom_smooth -- site & subbasin type

```{r DOC_overtime-by-site}

# brewer.pal(n = 6, name = "PuOr") # orange to purple (2 orange for headwaters)
# brewer.pal(n = 6, name = "PRGn") # purple to green (1 purple for tunnel + 3 green for mainstems)
timetrendcolours1 <- c(brewer.pal(n = 11, name = "PiYG")[3], brewer.pal(n = 11, name = "PiYG")[2], # orange
                       brewer.pal(n = 11, name = "RdBu")[8], brewer.pal(n = 11, name = "RdBu")[9], brewer.pal(n = 11, name = "RdYlBu")[10], # three blue for mainstem
                       brewer.pal(n = 8, name = "Set2")[6]) # purple for tunnel

# at all of the six sites (DOC over time)
sixfilter_sub %>%
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm)) +
  theme_bw() +
  geom_smooth(aes(group = site, 
                  colour = site, 
                  linetype = subbasin_type), se = FALSE)+ 
  scale_colour_manual(values = timetrendcolours1)+
  scale_linetype_manual(values = c(3, 1, 2))+
  labs(y = "DOC (mg/L)", fill = "Sample type:", x = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        text = element_text(size = 11), 
        legend.position = "top", legend.box="vertical")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  guides(colour = guide_legend("Site:"),
         linetype = guide_legend("Basin type:", override.aes = list(colour = "black")))  
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_trend_bassin-type_loess.png", 
         width = 6, height = 5, units = "in") 
# ---
### this one seems more clear:
# at each of the six sites (DOC over time)
sixfilter_sub %>%
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm)) +
  theme_bw() +
  geom_jitter(aes(fill = site), size = 2, shape = 21, alpha = 0.4)+
  geom_smooth(aes(group = site, colour = site), linetype = 1, se = FALSE)+ 
  scale_colour_brewer(palette = "Dark2", aesthetics = c("fill", "colour"))+
  labs(y = "DOC (mg/L)", fill = "Sample type:", x = "") +
  guides(fill = guide_legend("Site:"),
         colour = guide_legend("Site:"))+
  facet_wrap(~subbasin_type, ncol = 1, strip.position = "right", scales = "free_y")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "top",
        text = element_text(size = 12))+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_trend_bassin-type-facet_loess.png", 
         width = 6, height = 6, units = "in") 

# samples: n_installGrabSamples+n_installRackSamples  
# Grab samples: n_installGrabSamples 
# Rack samples: n_installRackSamples

```


### synchrony: Stage & DOC 

#### events

```{r}

# first extract trip start datetimes
trip_df <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Leech-FieldTrip-tracking_forWater-MSc_HMc.csv")
trip_starts <- trip_df %>% filter(!is.na(trip)) %>% pull('trip-start') %>% as.POSIXct(tz = TZ)

# event times need to be in ten-min intervals to match with stage_sample
event_starts <- round_date(as.POSIXct(events$StartDate, tz = TZ), "10 min") 
event_ends <- round_date(as.POSIXct(events$EndDate, tz = TZ), "10 min")

```

#### plot stage, event, samples all sites
plot stage at each site with samples collected (stage and time), and add lines for rain events

```{r}
# plot stage with sample dots
# stage at each of the subbasins
stage_samples %>% 
  ggplot(aes(x = DateTime))+
  #geom_vline(xintercept = c(trip_starts), size = 0.7, colour = forWater_colours2["Green"])+ 
  geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash", 
             xintercept = c(event_starts), size = 0.65, show.legend = TRUE)+ # start event
  geom_vline(colour = forWater_colours2["SkyBlue"], linetype = "dotted", 
             xintercept = c(event_ends), size = 0.65, show.legend = TRUE)+ # end event
  geom_line(aes(y = corr_stage_cm), size = 0.6)+ #, colour = forWater_colours2["DeepBlue"])+
  theme_bw()+
  geom_point(aes(y = sampleStage_cm, shape = sample_type, fill = sample_type), na.rm = TRUE)+
  scale_shape_manual(breaks = c("Grab", "Rack"), values = c("Grab" = 24, "Rack" = 21))+
  scale_fill_manual(breaks = c("Grab", "Rack"), values = c("Grab" = "white", 
                                                           #"Rack" = forWater_colours2[["MyOrange"]],
                                                           "Rack" = "white"))+
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right")+
  labs(y = "River Stage (cm)", x = "", shape = "Sample Type:")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        legend.position = "top")+
  guides(fill = guide_legend("Sample type:"), 
         shape = guide_legend("Sample type:", override.aes = list(size=2.5)))  
#save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/stage-with-samples_trip-event-lines.png",
         width = 6, height = 7, units = "in")

```

##### second MegaPlot
```{r}

# Wx megaplot, with simple sample points
stage_sample_plot <- stage_samples %>% 
  filter(Date >= "2018-10-24", Date <= "2020-02-19") %>%  
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), colour = forWater_colours2["DeepBlue"], size = 0.6)+ 
  theme_bw()+
  geom_point(aes(y = sampleStage_cm), shape = 21, fill = "white", na.rm = TRUE)+
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right")+
  labs(y = "River Stage (cm) and Sample Collection", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1), plot.margin = unit(c(0,0,0,0), "cm"),
        legend.position = "none")


# create a second megaplot with sample points included
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subasin_meantemp_plot, subbasin_meanrain_plot, stage_sample_plot, ncol = 1, axis = "l", align = "v", rel_heights = c(1,1,1,6)) 

# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_megaplot2.png",
         width = 8.5, height = 11, units = "in")
```


### synchrony: DOC-stage extrema

#### peak DOC & stage 
```{r}
# summarize data for coinciding maxima of DOC and stage at each site
coincident_peaks <- sixfilter %>%
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
         NPOC_ppm != 0) %>%  # drop NAs
  select(c(site, trip, event_ID, DateTime_sampled, sample, NPOC_ppm, sampleStage_cm, HoldTime_days, QAQC_flag, Tmean_airDaily)) %>% 
  mutate(sample = as.character(sample)) %>% 
  group_by(site, trip, event_ID) %>% 
  summarise(max_stage = max(sampleStage_cm), # maximum stage sampled
            # sample associated with max stage that was sampled:
            sample_max_stage = sample[last(which.max(sampleStage_cm))],
            # DOC associated with max stage that was sampled:
            npoc_max_stage = NPOC_ppm[last(which.max(sampleStage_cm))],
            # eventID 
            max_DOC = max(NPOC_ppm),  # maximum DOC sampled
            # sample associated with max DOC that was sampled:
            sample_max_DOC = (sample[last(which.max(NPOC_ppm))]),
            # stage associated with max DOC that was sampled:
            stage_max_DOC = sampleStage_cm[last(which.max(NPOC_ppm))]) %>% 
  mutate(
    # TRUE if the sample ID for peak stage matched with the sample-ID of peak DOC:
    coincident_sample = (sample_max_stage == sample_max_DOC), 
    # TRUE if the [DOC] for peak stage matched with the peak [DOC] sampled:
    coincident_DOC = (npoc_max_stage == max_DOC),
    # TRUE if the maximum stage sampled matched with the stage associated with max [DOC]:
    coincident_stage = (max_stage == stage_max_DOC)) %>% 
  ungroup()

# calculate the percent of samples for which peak-DOC-sample coincided with peak-stage-sample
# for each site
coincident_proportion_sites <- coincident_peaks %>% 
  group_by(site) %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  group_by(site) %>% 
  # calculate the proportion of common peaks
  summarise(common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))

# overall -- not grouped by site
coincident_proportion_all <- coincident_peaks %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  summarise(site = "all sites",
            common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))
### key:
# common sample = sample ID associated with peak-stage matched with the sample ID of peak-DOC
# common_npoc = sample DOC concentration associated with max.stage sampled corresponds to the maximum DOC measured for that event
# common_stage = peak stage sampled corresponds to the stage associate with peak DOC

# combine as a tibble (merge with minima and write as csv (next chunk))
maxima_tibble <- bind_rows(coincident_proportion_sites, coincident_proportion_all) %>%
  select(c(site, common_npoc)) %>% 
  rename("Site" = "site", 
         "Proportion of common maxima" = "common_npoc")

```

#### valley DOC & stage 
```{r}
# summarize data for coinciding minima of DOC and stage at each site
coincident_valleys <- sixfilter %>%
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
         NPOC_ppm != 0) %>%  # drop NAs
  select(c(site, trip, event_ID, DateTime_sampled, sample, NPOC_ppm, sampleStage_cm, HoldTime_days, QAQC_flag, Tmean_airDaily)) %>% 
  mutate(sample = as.character(sample)) %>% 
  group_by(site, trip, event_ID) %>% 
  summarise(min_stage = min(sampleStage_cm), # minimum stage sampled
            # sample associated with min stage that was sampled:
            sample_min_stage = sample[first(which.min(sampleStage_cm))],
            # DOC associated with min stage that was sampled:
            npoc_min_stage = NPOC_ppm[first(which.min(sampleStage_cm))],
            # eventID 
            min_DOC = min(NPOC_ppm),  # minimum DOC sampled
            # sample associated with min DOC that was sampled:
            sample_min_DOC = (sample[first(which.min(NPOC_ppm))]),
            # stage associated with min DOC that was sampled:
            stage_min_DOC = sampleStage_cm[first(which.min(NPOC_ppm))]) %>% 
  mutate(
    # TRUE if the sample ID for peak stage matched with the sample-ID of peak DOC:
    coincident_sample = (sample_min_stage == sample_min_DOC), 
    # TRUE if the [DOC] for peak stage matched with the peak [DOC] sampled:
    coincident_DOC = (npoc_min_stage == min_DOC),
    # TRUE if the maximum stage sampled matched with the stage associated with max [DOC]:
    coincident_stage = (min_stage == stage_min_DOC)) %>% 
  ungroup()

# calculate the percent of samples for which peak-DOC-sample coincided with peak-stage-sample
# for each site
coincident_valley_proportion_sites <- coincident_valleys %>% 
  group_by(site) %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  group_by(site) %>% 
  # calculate the proportion of common peaks
  summarise(common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))

# overall -- not grouped by site
coincident_valley_proportion_all <- coincident_valleys %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>% 
  summarise(site = "all sites",
            common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))
# woops -- in trip 20 there were two grab samples collected at Chris Crk which resulted in 'common_sample' differing from 'common_npoc' and 'common_stage', which did agree

### key:
# common sample = sample ID associated with min-stage matched with the sample ID of min-DOC
# common_npoc = sample DOC concentration associated with min.stage sampled corresponds to the minimum DOC measured for that event
# common_stage = min. stage sampled corresponds to the stage associate with min. DOC

# combine as a table
minima_tibble <- bind_rows(coincident_valley_proportion_sites, 
                           coincident_valley_proportion_all) %>%
  select(c(site, common_npoc)) %>% 
  rename("Site" = "site", 
         "Proportion of common minima" = "common_npoc")

# join with maxima and write a csv
full_join(maxima_tibble, minima_tibble) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/synchrony_DOC-stage_extrema-simultaneous.csv", col_names = T)

```

##### ?run the same tests on narrower sample group
```{r}
# subset for narrower window of well-sampled rain events -- not very useful?
# trips 17-18* & 19-20 collected racks for all and 2 grabs on falling limb
## *note that trip 18 had a major fall algae bloom in Cragg Crk (remove sample = Algae)
## note that trip 21 exists only for CraggCrk and was actually a rain event that occured on trip 20 between first and second visit to site 4 
# trips: 17-21 --> event_ID: 10-12

# narrow window by site
coincident_proportion_narrow_sites <- coincident_peaks %>% 
  #filter(event_ID == 10 | event_ID == 11 | event_ID == 12) %>% 
  filter(trip == 17 | trip == 18 | trip == 19 | trip == 20 | trip == 21) %>%
  group_by(site) %>% 
  summarise(sample_count = length(which(coincident_sample == TRUE | coincident_sample == FALSE)),
            sample_match_true = length(which(coincident_sample == TRUE)),
            npoc_count = length(which(coincident_DOC == TRUE | coincident_DOC == FALSE)),
            npoc_match_true = length(which(coincident_DOC == TRUE)),
            stage_count = length(which(coincident_stage == TRUE | coincident_stage == FALSE)),
            stage_match_true = length(which(coincident_stage==TRUE))) %>%
  group_by(site) %>%
  summarise(common_sample = (sample_match_true/sample_count),
            common_npoc = (npoc_match_true/npoc_count),
            common_stage = (stage_match_true/stage_count))
# all sites together
coincident_proportion_narrow_all <- coincident_proportion_narrow_sites %>% 
  summarise(common_sample = mean(common_sample),
            common_npoc = mean(common_npoc),
            common_stage = mean(common_stage))
# check them out (not very interesting)
coincident_proportion_narrow_sites
coincident_proportion_narrow_all

```

#### plot peak-DOC w/ stage-samples 
narrow in on specific (well-sampled) events
```{r}
# for plots, add max_DOC by trip and event to stage_sample dataframe
# DOC peaks in stage_sample = peaksSS
peaksss1 <- stage_samples %>% 
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5", # unique only
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm)) %>%  # drop NAs
  group_by(site, trip, event_ID) %>% # or by event_ID
  summarise(maxDOC_stage = sampleStage_cm[which.max(NPOC_ppm)],
            sample = sample[which.max(NPOC_ppm)],
            sampleStage_cm = sampleStage_cm[which.max(NPOC_ppm)]) %>% 
  full_join(stage_samples %>% group_by(site, trip), by = c("site", "trip", "sampleStage_cm", "sample")) %>% 
  arrange(DateTime) %>% 
  ungroup()

peaksss <- stage_samples %>% 
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Grab" | sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5", # unique only
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm)) %>%  # drop NAs
  group_by(site, trip, event_ID) %>% # or by event_ID
  summarise(minDOC_stage = sampleStage_cm[which.min(NPOC_ppm)],
            sample = sample[which.min(NPOC_ppm)],
            sampleStage_cm = sampleStage_cm[which.min(NPOC_ppm)]) %>% 
  full_join(peaksss1 %>% group_by(site, trip), by = c("site", "trip", "sampleStage_cm", "sample")) %>% 
  arrange(DateTime) %>% 
  ungroup()


# ---- 
# trip 4 -- stage and samples at each site by sampling event
tripfour <- peaksss %>% 
  filter(interval == "4", site != "Tunnel") %>% # Tunnel wasn't installed yet
  ggplot(aes(x = DateTime))+
  geom_vline(xintercept = c(trip_starts), size = 0.7, colour = forWater_colours2["Green"])+ 
  geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash", 
             xintercept = c(event_starts), size = 0.65, show.legend = TRUE)+ # events start
  geom_vline(colour = forWater_colours2["SkyBlue"], linetype = "dotted", 
             xintercept = c(event_ends), size = 0.65, show.legend = TRUE)+ # events end
  geom_line(aes(y = corr_stage_cm), size = 0.6, colour = forWater_colours2["DeepBlue"])+
  theme_bw()+
  geom_point(aes(y = sampleStage_cm, colour = "sample", fill = "sample" ), 
             shape = 21, size = 2, na.rm = TRUE) +
  geom_point(aes(y = maxDOC_stage, colour = "max DOC", fill = "max DOC"), 
             shape = 24, size = 2, na.rm = TRUE) +  
  scale_fill_manual(values = c(forWater_colours2["MyOrange"], "grey")) +
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right") +
  labs(y = "River Stage (cm)", x = "", caption = "Event 3 - 7")+
  scale_x_datetime(breaks = "1 day")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        legend.position = "top") +
  scale_color_manual(breaks = c("max DOC", "sample"),
                     values = c("black", "black"))+ # alphabetical matching
  guides(colour = guide_legend("key:"),
         fill = guide_legend("key:", override.aes = list(shape = c(24, 21), fill = c(forWater_colours2["MyOrange"], "grey"))))

# -----
# trip 17-21 -- stage and samples at each site by sampling event
peaksss %>% 
  filter(interval == 17 | interval == 18 | interval == 19 | interval == 20 | interval == 21) %>%
  ggplot(aes(x = DateTime))+
  #geom_vline(xintercept = c(trip_starts), size = 0.7, colour = forWater_colours2["Green"])+
  #geom_vline(colour = forWater_colours2["SkyBlue"], linetype = "dotted", xintercept = c(event_ends), size = 0.65, show.legend = TRUE)+ # events end
  #geom_vline(colour = forWater_colours1["MainBlue"], linetype = "twodash", xintercept = c(event_starts), size = 0.65, show.legend = TRUE)+ # events start
  geom_line(aes(y = corr_stage_cm), size = 0.6, colour = forWater_colours2["DeepBlue"])+
  theme_bw()+
  geom_point(aes(y = sampleStage_cm, colour = "sample", fill = "sample"), 
             shape = 21, size = 2, na.rm = TRUE) +
  geom_point(aes(y = maxDOC_stage, colour = "max DOC", fill = "max DOC"), 
             shape = 24, size = 2, na.rm = TRUE) +
  geom_point(aes(y = minDOC_stage, colour = "min DOC", fill = "min DOC"), 
             shape = 22, size = 2, na.rm = TRUE) +
  # geom_text(aes(x = DateTime, y = sampleStage_cm, label = round(NPOC_ppm, 2)), na.rm = TRUE) +
  scale_fill_manual(values = c(forWater_colours2["MyOrange"], 
                               forWater_colours2["Green"], 
                               "grey")) + # manual matches alphabetically (max, min, sample)
  facet_wrap(~site, ncol = 1, scales = "free_y", strip.position = "right") +
  labs(y = "River Stage (cm)", x = "", caption = "Events 9-12")+
  scale_x_datetime(breaks = "3 day")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        legend.position = "top") +
  scale_color_manual(breaks = c("max DOC", "min DOC", "sample"),
                     values = c("black", "black", "black"))+ # alphabetical matching
  guides(colour = guide_legend("key:"),
         fill = guide_legend("key:", override.aes = list(shape = c(24, 22, 21), fill = c(forWater_colours2["MyOrange"], forWater_colours2["Green"], "grey"))))
# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/narrow_events_9-12_peakDOC-stage.png",
       width = 6.5, height = 6.5, units = "in")

# --- 
# big plot with lines showing subbset
# assign lines
narrow_trips_start <- peaksss %>% 
  filter(interval == 17) %>%  
  summarise(event = first(event_ID),
            start = first(DateTime)) %>% pull()

narrow_trips_end <- peaksss %>% 
  filter(interval == 21) %>%  
  summarise(event = last(event_ID),
            end = last(DateTime)) %>% pull()

# big plot with lines
stage_sample_plot +
  geom_vline(xintercept = narrow_trips_start, size = 0.7)+
  geom_vline(xintercept = narrow_trips_end, size = 0.7)
# save 
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/stage-samples-with_narrow_events_9-12.png",
       width = 6.5, height = 7, units = "in")

```


##### representation test

how did events 17-21 compare to other sampled events, is this subset representative?
```{r}

# were trips 17-21 results representative of most events?
# compare samples from these results to others
# use statistics -- Wilcoxon tests by parameter and site

# stage
narrow_stage <- stage_samples %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(interval == 17 | interval == 18 | interval == 19 | interval == 20 | interval == 21) 

rest_stage <- stage_samples %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet", # remove summer baseflow
         interval != 17, interval != 18, interval != 19, interval != 20, interval != 21) 

# sample results
narrow_results <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(trip == 17 | trip == 18 | trip == 19 | trip == 20 | trip == 21) 

rest_results <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(trip != 17, trip != 18, trip != 19, trip != 20, trip != 21) 


# density distribution normality 
# stage of the isolated events
narrow_stage %>% 
  ggplot(aes(corr_stage_cm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 
# stage of the rest
rest_stage %>% 
  ggplot(aes(corr_stage_cm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 

# DOC of the isolated events
narrow_results %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 
# stage of the rest
rest_results %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = site))+
  theme_bw()+
  theme(legend.position = "top") 


# run tests and compile results
# ---
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis
# p-value < 0.05 --> reject the null hypothesis 
subbset_Wilcoxon_tests <- bind_rows(
  ## stage ---
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "Weeks"],
                   rest_stage$corr_stage_cm[rest_stage$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "ChrisCrk"],
                   rest_stage$corr_stage_cm[rest_stage$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "LeechHead"],
                   rest_stage$corr_stage_cm[rest_stage$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "CraggCrk"],
                   rest_stage$corr_stage_cm[rest_stage$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "WestLeech"],
                   rest_stage$corr_stage_cm[rest_stage$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "stage"),
  
  tidy(wilcox.test(narrow_stage$corr_stage_cm[narrow_stage$site == "Tunnel"],
                   rest_stage$corr_stage_cm[rest_stage$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "stage"),
  
  ## NPOC ---
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "Weeks"],
                   rest_results$NPOC_ppm[rest_results$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "ChrisCrk"],
                   rest_results$NPOC_ppm[rest_results$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "LeechHead"],
                   rest_results$NPOC_ppm[rest_results$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "CraggCrk"],
                   rest_results$NPOC_ppm[rest_results$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "WestLeech"],
                   rest_results$NPOC_ppm[rest_results$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "NPOC_ppm"),
  
  tidy(wilcox.test(narrow_results$NPOC_ppm[narrow_results$site == "Tunnel"],
                   rest_results$NPOC_ppm[rest_results$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "NPOC_ppm"),
  
  ## UV-254 ---
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "Weeks"],
                   rest_results$SAC254_Abs.m[rest_results$site == "Weeks"])) %>% 
    mutate(site = "Weeks", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "ChrisCrk"],
                   rest_results$SAC254_Abs.m[rest_results$site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "LeechHead"],
                   rest_results$SAC254_Abs.m[rest_results$site == "LeechHead"])) %>% 
    mutate(site = "LeechHead", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "CraggCrk"],
                   rest_results$SAC254_Abs.m[rest_results$site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "WestLeech"],
                   rest_results$SAC254_Abs.m[rest_results$site == "WestLeech"])) %>% 
    mutate(site = "WestLeech", Analysis = "SAC254_Abs.m"),
  
  tidy(wilcox.test(narrow_results$SAC254_Abs.m[narrow_results$site == "Tunnel"],
                   rest_results$SAC254_Abs.m[rest_results$site == "Tunnel"])) %>% 
    mutate(site = "Tunnel", Analysis = "SAC254_Abs.m")) %>% 
  
  select(Parameter = "Analysis", site, p.value) %>% 
  
  # pull p-values to summarize
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
                              p.value < 0.05 ~ "**",# CL = 95%
                              p.value > 0.05 ~ "NA")) # not significantly different (means are equal)
# check it out
subbset_Wilcoxon_tests

# also
# compare storm intensity and duration
narrow_events_summary <- majEvents_summary %>% 
  filter(ID == 10 | ID == 11 | ID == 12) %>% 
  select(c(ID, startDate, endDate, rain, duration_days, intensity_mmhr))

rest_events_summary <- majEvents_summary %>% 
  filter(ID != 10, ID != 11, ID != 12) %>% 
  select(c(ID, startDate, endDate, rain, duration_days, intensity_mmhr))

# compare with tests & summarize results
subbset_Wilcoxon_tests_rain <- bind_rows(
  tidy(wilcox.test(narrow_events_summary$rain, rest_events_summary$rain)) %>% 
    mutate(Parameter = "Rain (mm)"),
  tidy(wilcox.test(narrow_events_summary$duration_days, rest_events_summary$duration_days)) %>% 
    mutate(Parameter = "Duration (days)"),
  tidy(wilcox.test(narrow_events_summary$intensity_mmhr, rest_events_summary$intensity_mmhr)) %>%
    mutate(Parameter = "Intensity (mm/hr)")) %>% 
  select(Parameter, p.value) %>% 
  mutate(sig.diff = case_when(p.value < 0.01 ~ "***", # CL = 99%
                              p.value < 0.05 ~ "**",# CL = 95%
                              p.value > 0.05 ~ "NA"))  # means are equal 

# make a summary table

# stage and UV 254 are not comparable but DOC is
narrow_wilcox_DOC <- subbset_Wilcoxon_tests %>% 
  filter(Parameter == "NPOC_ppm") %>% 
  mutate(Parameter = "DOC (mg/L)")
# join with rain summary
full_join(narrow_wilcox_DOC, (subbset_Wilcoxon_tests_rain %>%
                                filter(Parameter != "Duration (days)") %>% 
                                mutate(site = "LWSA"))) %>% 
  select(c(site, Parameter, p.value)) %>%
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/narrow-subbset_wilcoxon.csv")



# compare hold-time days
narrow_results %>% 
  group_by(site, trip) %>% 
  summarise(HT_mean = mean(HoldTime_days, na.rm = T),
            HT_min = min(HoldTime_days, na.rm = T),
            HT_max = max(HoldTime_days, na.rm = T))

```

## Seasonal Sample Method

## seasonal DOC subbasin, Mean/Min/Max 
```{r, all-samples-together}

# grouped-summary (site and sample-type and all)
a <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, rain_season) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>%
  rename(sample_season = "rain_season") %>% 
  ungroup() %>%
# for a site summary of each, include this:
rbind(sixfilter %>%
        filter(sample_type == "Grab" | sample_type == "Rack") %>% 
        group_by(site) %>% 
        summarize(sample_season = "All",
                  count = n(), 
                  DOCmean = mean(NPOC_ppm, na.rm = T), 
                  DOCsd = sd(NPOC_ppm, na.rm = T), 
                  RSD = round((DOCsd/DOCmean)*100, 0),
                  DOCmin = min(NPOC_ppm, na.rm = T), 
                  DOCmedian = median(NPOC_ppm, na.rm = T), 
                  DOCmax = max(NPOC_ppm, na.rm = T))) %>% 
  ungroup() %>% 
  arrange(site)

# un-grouped summary
b <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "ALL SITES",
            sample_season = "SUMMARY",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, sample_season, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# tag totals summary onto site summary
rbind(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/subbasin-seasonal-DOC.csv", col_names = T)

```

### ridgeplot: wet G/R subbasin ridgeplot 
```{r, sample_type-ridgeplots}

# density ridge 
# wrap by sample_type -- wet season only
label <- c(Grab = "Grab samples, wet season", Rack = "Rack samples, wet season")
# plot with adjusted strip label
sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = fct_rev(site))) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.4) +
  facet_wrap(~sample_type, ncol = 1, nrow = 2,
             labeller = labeller(sample_type = label)) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  labs(y = "",  
       #caption = glue::glue("Density distribution plots of DOC concentration by sample type and site \n       Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})"),
       x = "DOC (mg/L)") +
  theme(legend.position = "none",
        text = element_text(size = 12)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC-season-wet_subbasin-ridgeplot_GvsR.png")

```

#### boxplot: wet G/R subbasin boxplot
```{r, DOC-space-time-boxplot}

# wrap by sample_type -- wet season only
label <- c(Grab = "Grab samples, wet season", Rack = "Rack samples, wet season")
# plot with adjusted strip label

# Boxplot with jitter scatter 
# site vs DOC, facet wrap by sample type
sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(rain_season == "wet") %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1),
        text = element_text(size = 12)) +
  facet_wrap(~sample_type, ncol = 2, nrow = 1,
             labeller = labeller(sample_type = label)) +  
  labs(#caption = (glue::glue("DOC concentration by sample type and site during wet season \n Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})")), 
    x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin_GvsR_boxplot.png") 

```

### ridgeplot: grabs= wet vs dry season
```{r}

# density ridge 
# wrap by sample_type -- dry season only
label <- c(dry = "Dry season grab samples", wet = "Wet season grab samples")

# plot with adjusted strip label
sixfilter %>%
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab", sample == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = fct_rev(site))) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.4) +
  facet_wrap(labeller = labeller(rain_season = label),
             ~rain_season, ncol = 1, nrow = 2) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  labs(y = "",  
       #caption = glue::glue("Density distribution plots of DOC concentration by sample type and site \n       Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})"),
       x = "DOC (mg/L)") +
  theme(legend.position = "none",
        text = element_text(size = 12)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC-seasonal_subbasin-ridgeplot_grabs-only.png")

```

#### boxplot: grabs=wet vs dry season subbasin Box DOC
```{r}

# plot with adjusted strip label
# Boxplot with jitter scatter (DOC by season)
sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(~rain_season, ncol = 2, nrow = 1,
             labeller = labeller(rain_season = label)) +  
  labs(x = "", y = "DOC (mg/L)")

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC-seasonal_subbasin_boxplot_grab-only.png", width = 6, height = 3.5, units = "in")

```

### table: DOC means+sd subbasins
```{r, summaryDOC-table}

# DOC summary table, Grabs and Racks combined
a <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

b <- sixfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "All (summary)",
            DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

bind_rows(a, b) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_subbasin_MeanMinMax.csv", col_names = TRUE)
```

### ?table: subbasin Rack DOC trends by event & site
```{r}
# calculate trend with linear model
DOC_rack_trends_lm <- sixfilter %>%
  filter(rain_season == "wet",   # remove baseflow samples (no stage peaks)
         sample_type == "Rack", 
         sample != "Algae",      # remove sample containing whole algae (high DOC)
         QAQC_flag == "OK",      # remove samples with extended hold-time  
         sample != "R1", sample != "R2", sample != "R3", sample != "R4", sample != "R5",# no reps
         !is.na(sampleStage_cm), !is.na(sampleStage_cm), !is.na(NPOC_ppm),
         NPOC_ppm != 0) %>%  # drop NAs
  group_by(site, trip) %>% 
  summarise(yint_DOC = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[1],
            slope = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[2],
            r_sq = summary(lm(formula = NPOC_ppm ~ sampleStage_cm))$r.squared,
            n = n(),
            range_DOC = max(NPOC_ppm, na.rm = TRUE) - min(NPOC_ppm, na.rm = TRUE),
            DOC_min = sample[which.min(NPOC_ppm)],
            DOC_max = sample[which.max(NPOC_ppm)],
            first_event = first(event_ID),
            last_event = last(event_ID),
            first_rack = first(sample, order_by = DateTime_sampled),
            last_rack = last(sample, order_by = DateTime_sampled)) 

```

## Subbasin seasonal (old)


#### 1:1 plot - subbasin NPOC/CDOM
```{r, DOC-vs-CDOM-subbasins, echo = FALSE}
# six primary sites: DOC vs CDOM
sixfilter %>% 
  filter(sample_type == "Rack" | 
           sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm, fill = rain_seasons)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 2.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  facet_wrap(~site, nrow = 3, ncol = 2) +
  ylim(0, 20) + 
  xlim(0, 20)+
  labs(x = "DOC (ppm)",
       y = "DOC estimate (ppm eqv.)",
       caption = 
         glue::glue("Plot of dissolved organic carbon concentrations measured as NPOC and estimated \n via UV-Vis spectroscopy, where the dotted line indicates best-fit (1:1) of equivalent  \n measurements by both techniques"))+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 12),
        legend.position = "top")
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_subbasin-DOC-surrogate.png") 
```

### !?!!? WET G/R count 

Rack and Grab sample wetseason sample count summary
```{r, wet-summary-table}
# how many of each sample_type are there at the 6 main sites?
a <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                rain_season == "Wet season") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()

b <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "Wet season") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

c <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "Wet season") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

# bind & save to outputs
bind_rows(a, b, c) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_wet-season_subbasins-SampleCount.csv")

# Grab samples
wet_n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "Wet season") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples)

# Rack samples
wet_n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "Wet season") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples) 

```

#### table: wet G/R DOC means/min/max
```{r, summaryDOC-table}
# DOC summary table -- Grab vs Rack
sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack",
                rain_season == "wet") %>% 
  group_by(site, sample_type) %>% 
  summarize(DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_wet-season_subbasin_MeanMinMax-SampleType.csv", col_names = TRUE)

```

#### plot: rack DOC by event
```{r, rackDOC}
# rising limb
sixfilter %>% 
  filter(sample_type == "Rack") %>%
  filter(event_ID != "NA") %>% 
  group_by(site, event_ID) %>% 
  mutate(RisingLimb = NumberXtract(sample),
         RisingLimb = factor(RisingLimb, levels = c(1:9))) %>%
  ggplot(aes(x = DateTime_sampled, y = RisingLimb))+
  geom_point(aes(size = NPOC_ppm, colour = event_ID))+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 12),
        legend.position = "left")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  labs(y = "Sampling Rack Position", x = "", size = "DOC (ppm)", colour = "Rain Event")+
  facet_wrap(~site, ncol = 1,
             strip.position = "right",
             scales = "free_y")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_rack-trends.png", 
       height = 8, width = 6, unit ="in")

```




# SYNOPTIC

## table: DOC synoptic grabs by site Mean/Min/Max  
```{r, Grab-synoptic-table}

# synoptic grab samples DOC concs by site
a <- synopticfilter %>%
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab") %>% 
  group_by(site) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T))  

# all together  
b <- synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  filter(sample_type == "Grab") %>% 
  summarize(site = "total summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = round((DOCsd/DOCmean)*100, 0),
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) 

# tag totals summary onto site summary
rbind(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Synoptic_summary.csv", 
            col_names = T)
```

## plot: synoptic box, all sites
```{r, synoptic-all-sites}

# all sites
synopticfilter %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Grab") %>%  
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  geom_jitter(aes(fill = site), alpha = 0.6, shape = 21) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs(#caption = glue::glue("DOC concentrations in grab samples across 13 sites over 16 months (", {n_SynopticGrabs}, " samples)"), 
    x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_syn_13sites_boxplots.png")
```

## plot: synoptic ridge, all sites
```{r, synoptic-all-sites}

# all sites
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  filter(QAQC_flag == "OK") %>% 
  ggplot(aes(y = fct_rev(site), x = NPOC_ppm)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(#caption = glue::glue("DOC concentrations in grab samples across thirteen sites over 16 months (", {n_SynopticGrabs}, " samples)"), 
    x = "DOC (mg/L)", y = "")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_syn_13sites_ridgeplots.png")
```




# SEASONAL dynamics 

## seasonal counts
```{r}
# count dry season samples
n_dry_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "dry") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet season samples
n_wet_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "wet") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)


##  subbasin samples for which DOC and UV surrogate were measured ---

# count samples for both DOC and DOC_eq
n_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm)) %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

#count wet samples
n_wet_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "wet") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count dry samples 
n_dry_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "dry") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet = "first flush" samples 
n_ff_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "first flush") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)
```

## Synoptic seasonal plot: [1:1] NPOC/CDOM scatter 

```{r}
# scatterplot of DOC vs absorb-DOC by season
synopticfilter %>% 
  filter(!is.na(rain_seasons)) %>% 
  filter(QAQC_flag == "OK") %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 3.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  ylim(0, 20) + xlim(0, 20)+
  labs(y = "DOC estimate (ppm eqv.)",
       #caption = glue::glue("Plot of dissolved organic carbon concentrations measured as NPOC and estimated \n via UV-Vis spectroscopy, where the dotted line indicates best-fit (1:1) of equivalent  \n measurements by both techniques (n = {n_DOCCDOM}: wet = {n_wet_DOCCDOM}, first flush = {n_ff_DOCCDOM}, dry = {n_dry_DOCCDOM})."), 
       x = "DOC (ppm)")+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 12),
        legend.position = "top")

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_surrogate-NPOC.png",
       height = 7, width = 7, units = "in") 

```
additional text for caption: 
"Seasonal separation suggestes that characteristics of wet-season samples \n caused positive bias in absorbance-based DOC estimates, while dry-season sample \n characteristics lead to negative bias in DOC estimates based on UV-Vis absorption "



# SPECTRAL Indices

## plot: SUVA vs NPOC
```{r, spectral-plots, echo = FALSE}
# SUVA vs NPOC by season
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = SUVA)) +
  geom_jitter(aes(fill = rain_seasons), size = 3.5, shape = 21, alpha = 0.8) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  ylim(0.2, 4.5) +
  labs(y = expression(paste("SUVA "[254])),
       x = "DOC (mg/L)")+
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  guides(fill = guide_legend("Sample season:", override.aes = list(size = 3.5)))

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_SUVA-NPOC.png") 

```

## plot: E2:E3
```{r}
# E2:E3
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack",
                E2E3 < 15) %>% 
  ggplot(aes(x = NPOC_ppm, y = E2E3 )) +
  geom_jitter(aes(fill = rain_seasons), alpha = 0.8, size = 3.5, shape = 21) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  theme_bw() +
  theme(legend.position = "top")  
```

### questionable plots seasonal
```{r seasonal-plots, include=FALSE}
# Boxplot with jitter scatter 
synopticfilter %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  #scale_fill_brewer(palette="Accent") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90)) +
  facet_wrap(~rain_season, ncol = 2) +  
  labs(caption = "DOC concentrations in the Leech and two main tribs to the Sooke Reservoir", 
       x = "", y = "DOC (mg/L)")


# --- DOC facet wrap scatter plots ---
# I don't think these are good graphics
# Scatter main sites including sooke tribs
sampleresults %>% 
  dplyr::filter(site == "Weeks" |
                  site == "LeechHead" |
                  site == "ChrisCrk" |
                  site == "CraggCrk" |
                  site == "WestLeech"| 
                  site == "Tunnel" |
                  site == "Rithet" |
                  site == "Judge-crk", 
                analysis == "DOC", 
                sample_type == "Grab" & sample == "Grab") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks-out", "Chris-crk", "Leech-head", "Cragg-crk", "West-Leech", "Tunnel", "Rithet", "Judge-crk"))) %>% 
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm, fill = sample_type)) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21, size = 3) +
  theme_bw() +
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(caption = "DOC concentrations", x = "", y = "DOC (mg/L, as NPOC)") +
  theme(axis.text.x = element_text(angle = 90), legend.position = "none") +
  facet_wrap(~site, ncol = 2, nrow = 4)
# this is not a useful plot

```


# Nitrate & DOC
```{r}
# nitrate and DOC
synopticfilter %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 3.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  labs(x = "DOC (mg/L)", y = "nitrate (mg/L)", fill = "Sample type:")+
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
               parse = TRUE, rr.digits = 4)

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOC_scatter.png") 

```

## Nitrate & DOC_eq
```{r}
# nitrate and DOC
synopticfilter %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = DOCeq_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 3.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "bottom",
        text = element_text(size = 12)) +
  labs(x = "DOC eqiv. (estimated mg/L)", y = "nitrate (mg/L)", fill = "Sample type:",
       caption = "Estimated DOC and nitrate concentrations (via spectrophotometry)")+
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
               parse = TRUE, rr.digits = 4)

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOCeq_scatter.png") 

```

# METALS 

## plot: ug/L metals+DOC in solution
```{r}
# filter out the parameters with insufficient data
# plot DOC against metals concentrations 

# ug/L
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"
  ) %>%
  mutate(metal_parameters = factor(metal_parameters, # order as you want to see them in plots
                                   levels = c("Total Mercury (Hg)",
                                              "Total Iron (Fe)",
                                              "Total Manganese (Mn)",
                                              "Total Aluminum (Al)",
                                              "Total Barium (Ba)",
                                              "Total Copper (Cu)",
                                              "Total Arsenic (As)",
                                              "Total Strontium (Sr)",
                                              "Total Silicon (Si)"
                                   ))) %>% 
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE, colour = "red")+ ## to check MAC
  facet_wrap(~metal_parameters, scales = "free") +
  theme_bw() +
  theme(text = element_text(size = 12)) +
  labs(y = "metals concentrations (μg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_ugL_scatterplots.png")

```

## plot: mg/L metals+DOC in solution
```{r}
# mg/L
metalslab %>% 
  filter(metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)") %>%
  # order as you want to see them in plots
  mutate(metal_parameters = factor(metal_parameters, 
                                   levels = c("Total Magnesium (Mg)",
                                              "Total Potassium (K)",
                                              "Total Hardness (CaCO3)",
                                              "Total Calcium (Ca)",
                                              "Total Sodium (Na)"
                                   ))) %>%
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE)  ## to check MAC
  facet_wrap(~metal_parameters, scales = "free", ncol = 3) +
  theme_bw() +
  labs(y = "metals concentrations (mg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_mgL_scatterplots.png")
```

## table: correlation metals/DOC 
```{r}
# make a summary table of Metals regression
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"|
           metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)"
  ) %>%
  group_by(metal_parameters) %>% 
  filter(!is.na(metals_values)) %>% 
  summarise(unit = first(UNITS), 
            count = n(), 
            slope = coefficients(lm(formula = metals_values ~ NPOC_ppm))[2],
            yint_DOC = coefficients(lm(formula = metals_values ~ NPOC_ppm))[1],
            r_sq = summary(lm(formula = metals_values ~ NPOC_ppm))$r.squared) %>% 
  dplyr::arrange(desc(r_sq)) %>%  # strongest correlation to weakest
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/metals-doc_correlations.csv")

```

# TREATABILITY
```{r, message = FALSE}

# add date, timing, update site names
treatdat_UW <- treatdat_UW %>% 
  filter(source == "02") %>%   ## turns out, everything was included in second report
  mutate(day = substr(Sample_ID, 1, 2),
         site = substr(Sample_ID, 20, 22)) %>% 
  mutate(Date = case_when(
    day == "12" ~ as_date("2019-11-12"),
    day == "18" ~ as_date("2020-02-18"))) %>% 
  mutate(Collection = case_when(
    day == "12" ~ "Nov 2019",
    day == "18" ~ "Feb 2020")) %>% 
  mutate(Collection = factor(Collection, levels = c("Nov 2019", "Feb 2020"))) %>% 
  mutate(site = case_when(
    site == "DCP" ~ "Deception-res",
    site == "TUN" ~ "Tunnel",
    site == "JDG" ~ "Judge",
    site == "RTH" ~ "Rithet")) %>% 
  mutate(site = factor(site))

# isolate and join to my UBC lab results for treatability samples
treatdat <- sampleresults %>% 
  filter(sample == "Treatability") %>% 
  full_join(treatdat_UW, by = c("Date", "site")) %>% 
  mutate(site = factor(site))

# pivot long
treatdat_long <- treatdat_UW %>%
  filter(source == "02") %>% 
  select(-c(source, Sample_ID, pH, Turbidity_NTU, Zeta_Potential_mV, TBM, DBCM, MCAA, MBAA, DBAA, Free_Chlorine_Final_mgL, day, Date)) %>%
  tidyr::pivot_longer(names_to = "DBP", cols = c(THMs:TCAA),
                      values_to = "DBPfp_ugL") %>% 
  mutate(DBP = factor(DBP, levels = c(
    "THMs", "TCM", "BDCM", "HAAs", "DCAA", "TCAA")))
```

## plot; DOC/UV254 + DBP-FPs
```{r}

# plot DOC
a <- treatdat_long %>% 
  ggplot(aes(x = DOC_ppm, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 3.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "top")+
  labs(x = "DOC (ppm)", 
       y = "DBP-FPs (ppb)",
       colour = "Sampling site:")+
  guides(shape = FALSE,
         colour = guide_legend(nrow = 2))

# plot UV-254
b <- treatdat_long %>% 
  ggplot(aes(x = `UV254_cm-1`, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 3.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "top")+
  labs(x = "UV254 (abs/cm)", 
       y = "",
       shape = "Collection:")+
  guides(colour = FALSE,
         shape = guide_legend(nrow = 2))

# join side by side
cowplot::plot_grid(a, b, ncol = 2, align = "h") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/treatability_DOC-UV254.png",
       width = 7, height = 9, units = "in")
```


# pending: Random Forest
```{r}

```



# end
For some reason, RStudio truncates the session viewable... so here's some text to hold the place.
```{r}
# and an empty code chunk
```





























