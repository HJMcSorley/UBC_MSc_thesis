---
title: "Reproducible data analysis: thesis data visualization and analysis"
subtitle: "Pacific Maritime forWater Masters Project (NSERC forWater)"
author: "Hannah J McSorley"
output: bookdown::word_document2
---

___Data Visualization and Summaries___
This RMD file generates summary tables and figures but is not included in the final bookdown product (tables and figures will be added to applicable sections by reading them in).

# Set-up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message = FALSE, fig.path="R-outputs_UBC-forWater-MSc_HMc/figures/")
# save figures to folder 'figures' in the 'R-outputs...' folder
```

## Packages
```{r, package.startup.message = FALSE}

# load packages
library(tidyverse)  # includes: dplyr, ggplot2, purrr, readr, forcats
library(lubridate)  # dates and times
library(broom)      # tidy up
library(glue)       # glue() is an object-integrated 'paste'-like function
library(knitr)      # tidy tables
library(RColorBrewer) # Brewer palette for plots
library(viridis)    # nice colours for plots gradient fills
library(cowplot)    # add-on to ggplot for layout (nice grid)
library(gghighlight)# plot highlighting
library(gridExtra)  # for plot & table layout options
library(ggpmisc)    # linear regression line values (ggplot)
library(ggpubr)     # Q-Q plots
library(car)        # stats: Companion to Applied Regression
library(randomForest)

```

## define colours
```{r vectorize-colours}
# use forWater defined colours (hexadecimal codes) for plots
# all colours defined by forWater admin, except 'MyOrange' which I made
forWater_colours1 <- c(MainBlue = "#09A4D2", 
                       MainGreen = "#668536", 
                       AccentBlue = "#5B99CC", 
                       DarkGrey = "#3B3838", 
                       MyOrange = "#f4AB0E")

# colours updated late 2019 :\
forWater_colours2 <- c(DeepBlue = "#0A5EA6", 
                       Green = "#648326", 
                       SkyBlue = "#62ACC8", 
                       Gray = "#535353", 
                       MyOrange = "#f4AB0E")

# colour-blind friendly pallet with grey (no black)
cbPalette <- c(grey = "#999999", 
               orange = "#E69F00", 
               lightblue = "#56B4E9", 
               green = "#009E73", 
               yellow = "#F0E442", 
               darkblue = "#0072B2", 
               red = "#D55E00", 
               pink = "#CC79A7")
```

## define functions
Define function for number extraction from alphanumerics.
```{r NumberXtract}
# define functions

# ---- Alpha-numeric extraction function ---- #
# from http://stla.github.io/stlapblog/posts/Numextract.html
NumberXtract <- function(alphnum){
  unlist(regmatches(alphnum, gregexpr("[[:digit:]]+\\.*[[:digit:]]*", alphnum)))
}

```

# Load datasets
```{r, input-files, message=FALSE}
# assign timezone
TZ <- "Etc/GMT+8"

# File Inputs
#Results of data wrangling (01) were saved as .csv files for tidy loading. 
# read all compiled data files & format

# results df
# compiled sample analyses results (wide)
# including DateTime of Rack sample collection
sampleresults <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Results_complete.csv",
                          col_names = TRUE) %>%   
  mutate(trip = factor(trip, levels = c(0:23)),
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         rain_season = factor(rain_season),
         pseudoSUVA = pseudo254/NPOC_ppm,
         site = factor(site),
         event_ID = factor(event_ID, levels = c(1:18)))

# Wrangled Hobo TidibiT logger data with rain events and trip IDs
Hobo_df <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Hobo_trip-event.csv", 
                    col_names = TRUE) %>% 
  mutate(location = factor(location),
         site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         trip = factor(trip), 
         event_ID = factor(event_ID), 
         rain_season = factor(rain_season) ) %>% 
  rename(TidbiT_location = "location")

# subbasin_Hobos
subbasin_dailyHobo <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Subbasin_Results_complete.csv", 
                        col_names = TRUE) %>% 
  mutate(trip = factor(trip),
         event_ID = factor(event_ID), 
         rain_season = factor(rain_season),
         site = factor(site, levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         TidbiT_location = factor(TidbiT_location))


# odyssey_data df
# stage data compiled with interval/trip
odyssey_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Odyssey-RackCorrected-stage.csv",
                         col_names = TRUE) %>% 
  mutate(source = factor(source,
                         levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")),
         interval = factor(interval),
         event_ID = factor(event_ID),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ))

# precip_data df
# 2018-2020 weather station data compiled and formatted
precip_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/FWx-PrecipTemp_compiled.csv", 
                        col_names = TRUE,
                        col_types = list("c", "T", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d", "D", "d", "c")) %>%
  mutate(StationName = factor(StationName),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         event_ID = factor(event_ID),
         rain_season = factor(rain_season))    

# LWSA mean precip data (FWx-mean-LWSA df)
# 2018-2020 weather station data compiled and formatted
LWSA_meanWx <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/FWx-Mean-LWSA_PrecipTemp.csv", 
                        col_names = TRUE,
                        col_types = list("T", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d")) %>% 
  mutate(DateTime = lubridate::ymd_hms(DateTime, tz = TZ))    


# metalslab df
# metals sample analyses results with OC (long)
metalslab <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/metals-DOCgrab-sample_results-long.csv",
                      col_names = TRUE) %>% 
  mutate(Trip = factor(Trip),
         site = factor(site), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         metal_parameters = factor(Parameters))

# stage_samples
# subbasin sample results with stage, timestamps, and precip event ID
stage_samples <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/subbasins_matched-chemohydro-samples.csv",
                          col_names = TRUE) %>% 
  select(-c(stage_cm, ID, fillStage_cm)) %>% 
  mutate(trip = factor(trip, levels = c(1:23)),
         interval = factor(interval, levels = c(1:23)),
         site = factor(site,
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         event_ID = factor(event_ID, levels = c(1:18)),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         DateTime_sampled = lubridate::ymd_hms(DateTime_sampled, tz = TZ))

# rain events
events <- read_csv("R-outputs_UBC-forWater-MSc_HMc/wrangled_dataframes/Wx-RainEvents.csv", 
                   col_names = TRUE) %>% 
  mutate(ID = factor(ID, levels = c(1:18)))

# Treatability data from U.Waterloo
treatdat_UW <- 
  list.files("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", pattern = "*.csv") %>% 
  set_names(str_extract(., "([0-9]{2,}+)")) %>%
  purrr::map_dfr(~ read_csv(
    file.path("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", .), 
    col_names = TRUE, skip = 15), .id = "source") 

```

# WEATHER - FWx

## 2 stns: CC+MG

### plots: rain/snow/temp
At Chris Creek and Martin's Gulch FWx stations
```{r, FWx-plots}

# Rn15 is 15-minute rainfall (mm) 
# Prec_1 is hourly accummulated precipitation (mm)
# Temp is 15 minute intervals (degrees C)
rainplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n (mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)

# plot LWSA snow
snowplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  
  dplyr::summarise(daily_Snowmean = mean(SnowDep, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = "Snow accum.\n (m /day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)+
  theme(strip.background = NULL, 
        strip.text = element_blank()) 

# plot LWSA temperature
tempplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0, 
             linetype = "dotted") +
  labs(x = "", y = "Daily air temp\n(°C)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1) +
  theme(strip.background = NULL, 
        strip.text = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))


# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(rainplot, snowplot, tempplot, ncol = 1, align = "v",
                   rel_heights = c(1.25,1,1.75))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA.png",
       width = 6, height = 5, units = "in")
```


### table: annual precip, max snow, mean temp 

FWx means
```{r, FWx-table}
# precip_data summary
precip_data %>%
  mutate(Year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017) %>%   #, Year != 2020
  mutate(year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan-Feb 2020")) %>% 
  group_by(year, StationName) %>%
  summarise(total_precip_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDep, na.rm = TRUE), # not sure how to report
            annual_mean_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>% 
  dplyr::rename("Year" = year, 
                "station name" = StationName, 
                "annual precip. (mm)" = total_precip_mm,
                "max snow (m)" = max_snow_m,
                "mean air temp. (°C)" = annual_mean_temp, 
                "stdev air temp. (± °C)" = temp_sd,
                "mean max. temp. (°C)" = annual_min_temp,
                "mean min. temp. (°C)" = annual_max_temp) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-summary.csv")
```


## Mean Wx LWSA 

Arithmetic means from ChrisCrk and MartinsGulch.
*Too few stations to do Theissen polygons (2 point polygon = straight line) or isohyetal lines.*

```{r}
# add seasons to mean weather df
LWSA_meanWx <- precip_data %>% 
  select(DateTime, rain_season) %>% 
  right_join(LWSA_meanWx, by = "DateTime") %>% 
  mutate(Year = lubridate::year(DateTime),
         year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan-Feb 2020")) 

# check seasons visually
LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(date >= "2018-10-23") %>% 
  ggplot(aes(x = DateTime, y = Rn_1_mean)) +
  geom_col(aes(colour = rain_season)) +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme(text = element_text(size = 11),
        axis.text.x = element_text(angle = 60, hjust = 1))

```


### plots
```{r, mean-Wx_plot}
# mean precip plot
mean_rainplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) 

# plot LWSA snow
mean_snowplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Snowmean = mean(SnowDep_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = 'Snow depth\n(m/day)') +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+  
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) 

# plot LWSA temperature
mean_tempplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = 'Daily air temp\n(°C)') +
  theme_bw()+
  theme(text = element_text(size = 11)) +
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months")+
  theme(legend.position = "none")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) 

# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(mean_rainplot, mean_snowplot, mean_tempplot, 
                   ncol = 1, align = "vh", greedy = FALSE,
                   rel_heights = c(1,1,1))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA-means.png", 
       width = 6, 
       height = 5, 
       units = "in")
```

### table: mean Wx

```{r, table_mean-FWx_summary}
# mean weather summary
precip_data %>%
  mutate(Year = lubridate::year(DateTime),
         year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan & Feb 2020")) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017) %>%  
  group_by(Year, year, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDep, na.rm = TRUE),
            annual_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>%
  ungroup() %>% 
  group_by(year) %>%
  summarise(mean_rain_mm = mean(total_rain_mm, na.rm = TRUE),
            sd_rain_mm = sd(total_rain_mm, na.rm = TRUE),
            mean_max_snow_m = mean(max_snow_m, na.rm = TRUE),
            annual_mean_temp = mean(annual_temp, na.rm = TRUE),
            temp_sd = sd(annual_temp, na.rm = TRUE),
            annual_min_temp2 = mean(annual_min_temp, na.rm = TRUE),
            #TMin_sd = sd(annual_min_temp, na.rm = TRUE),
            annual_max_temp2 = mean(annual_max_temp, na.rm = TRUE)) %>%
            #TMax_sd = sd(annual_max_temp, na.rm = TRUE)) %>% 
  ungroup() %>% 
  dplyr::rename("mean annual rain (mm)" = mean_rain_mm,
                "stdev rain. (±mm)" = sd_rain_mm,
                "mean snow accum. (m)" = mean_max_snow_m,
                "mean temp. (°C)" = annual_mean_temp, 
                "st.dev temp. (±°C)" = temp_sd,
                "min. temp. (°C)" = annual_min_temp2,
                #"stdev TMin. (±°C)" = TMin_sd,
                "max. temp. (°C)" = annual_max_temp2) %>%
                #"stdev TMax. (±°C)" = TMax_sd) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-mean-summary.csv")
```

#### questionable objects
```{r, Wx-Stn_summaries}
# I want to know precip totals over the study period
# by month and by season
# use rain to define storm events

# calculate total rainfall at each of the wx-stns (survey mountain went in in late)
rn_MScTotal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime),
         year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx",
         date >= "2018-10-23") %>% 
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_MSc_mm = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup() 

# rain seasons rainfalls
rn_seasonal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(month = lubridate::month(DateTime),
         year = lubridate::year(DateTime)) %>%
  group_by(StationName, year, rain_season) %>% 
  dplyr::summarise(rain_seasonal = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# annual rainfalls
rn_annual <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(year = lubridate::year(DateTime)) %>%
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_monthly = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# water-year rainfalls (Oct 1 - Sept 30)
rn_wateryr <- LWSA_meanWx %>%
  mutate(month = lubridate::month(DateTime),
         water_year = case_when(
           between(month, 1, 9) & Year == "2018" ~ "2018",
           between(month, 10, 12) & Year == "2018" ~ "2019",
           between(month, 1, 9) & Year == "2019" ~ "2019",
           between(month, 10, 12) & Year == "2019" ~ "2020",
           between(month, 1, 9) & Year == "2020" ~ "2020")) %>%
  #filter(water_year != "2018") %>% 
  group_by(water_year) %>% 
  dplyr::summarise(annual_precip_mm = sum(Rn_1_mean, na.rm = TRUE),
                   max_snow_m = max(SnowDep_mean, na.rm = TRUE),
                   annual_mean_temp = mean(Temp_mean, na.rm = TRUE),
                   temp_sd = sd(Temp_mean, na.rm = TRUE)) %>% 
  ungroup() #%>% 
  #write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA_WaterYear-summary.csv", col_names = TRUE)

```

## RAIN EVENTS

### table of Events
```{r}
events %>% 
  mutate('Start date' = format(as.POSIXct(StartDate), "%Y-%m-%d %H:%M"), 
         'End date' = format(as.POSIXct(EndDate), "%Y-%m-%d %H:%M")) %>% 
  select(stormnum, ID, 'Start date', 'End date', rain) %>% 
  dplyr::rename('Storm number' = stormnum,
                'Major event no.' = ID,
                'Rain (mm)' = rain) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Events.csv",
            col_names = TRUE) 
```

## Malahat Wx

Longer data record from the Malahat weather station (for comparison).

```
#{r, malahat-wx}

# malahat weather
malahat_data <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Malahat_station-data-11596.csv", 
                         skip = 16,
                         col_names = TRUE,
                         col_types = list("f", "c", "d", "d")) %>% 
  mutate(Datetime = lubridate::ymd_hms(Datetime, tz = TZ, truncated = 1),
         Date = lubridate::as_date(Datetime),
         Year = lubridate::year(Datetime))

# summary: malahat_data precip + air temp 
malahat_data %>% 
  filter(Analysis == "Precipitation Amount (mm)", 
         between(Year, 2014, 2019)) %>% 
  group_by(Year) %>%
  summarise(total_precip = sum(Value, na.rm = TRUE)) %>% 
  ungroup() %>% 
  right_join((
    malahat_data %>% 
      dplyr::filter(Analysis == "Temperature (Mean) (celsius)", 
                    between(Year, 2014, 2019)) %>% 
      group_by(Year) %>%
      summarise(annual_mean_temp = mean(Value, na.rm = TRUE),
                temp_sd = sd(Value))) %>% 
      ungroup(), 
    by = "Year") %>%
  filter(Year != "2013", Year != "2020") %>% 
  dplyr::rename("year" = Year, 
                "annual precip. (mm)" = total_precip, 
                "mean air temp. (°C)" = annual_mean_temp, 
                "std.dev. (± °C)" = temp_sd) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_malahat-summary.csv")

```

### plots: Malahat Wx
```
#{r, malahat-plots}
# plots
# plot malahat rain and highlight my study period
malahat_rn <- malahat_data %>% 
  filter(Analysis == "Precipitation Amount (mm)") %>% 
  ggplot(aes(x = Datetime, y = Value)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain (mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
  theme(legend.position = "none") +
  gghighlight::gghighlight(Datetime > "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))

# plot malahat temperature and highlight my study period
malahat_temp <- malahat_data %>% 
  filter(Analysis == "Temperature (Mean) (celsius)") %>% 
  ggplot(aes(x = Datetime, y = Value)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = expression('Mean daily air temp ('*~degree*C*')')) +
  theme_bw() +
  scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(Datetime > "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))

# stack with cowplot
cowplot::plot_grid(malahat_rn, malahat_temp, ncol = 1, align = "v")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat.png")

```

### lag-years: Wilcoxon's rank sum test

```
#{r}
# check for normality
# The central limit theorem:
## sampling distribution tends to be normal if the sample is large enough (n > 30)
malahat_data %>% 
  filter(!is.na(Value),
         Analysis == "Precipitation Amount (mm)" | Analysis == "Temperature (Mean) (celsius)") %>% 
  group_by(Year, Analysis) %>% 
  summarise(count = n())
# could assume normal distribution because each year has daily values (>>30)

# visually check for normality 
malahat_data %>% 
  filter(Year != 2013, Year != 2020,  # incomplete data sets
         !is.na(Value),
         Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                 color = "Year", 
                 palette = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" ),
                 facet.by = "Analysis")
## Precipitation was not normally distributed (seasonality)

# tidy wilcoxon tests: lag-year 
## solution from:
## https://stackoverflow.com/questions/32477863/r-run-t-test-on-previous-years-by-group-using-dplyr

# t-test comparing each year to the last year
Malahat_test_lagyear <- malahat_data %>% 
  filter(Year != 2013, Year != 2020,  # incomplete data sets
         !is.na(Value)) %>%  # remove missing values 
  select(Analysis, Year) %>% 
  arrange(Analysis, Year) %>% 
  distinct() %>% 
  group_by(Analysis) %>% 
  mutate(lag_year = lag(Year)) %>% 
  filter(!is.na(lag_year)) %>% 
  group_by(Analysis, Year, lag_year) %>% 
  do(tidy(wilcox.test(malahat_data$Value[malahat_data$Year == .$Year & malahat_data$Analysis == .$Analysis],
                 malahat_data$Value[malahat_data$Year == .$lag_year & malahat_data$Analysis == .$Analysis])))

# identify signficantly different years
Malahat_test_lagyear %>% 
  filter(p.value < 0.10)

# 2015 was an incredible drought year, so it makes sense that 2015-2016 would differ
  
```

#### Wx pre & during MSc
```
#{r}
# group
malahat_test_data <- malahat_data %>% 
  filter(!is.na(Value),
         Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data 
  mutate(set = case_when(Year == 2016 | Year == 2017 ~ "pre",
                         Year == 2018 | Year == 2019 ~ "MSc"),
         set = as_factor(set)) %>% 
  filter(!is.na(set)) 

# subset for tests
pre_MSc <- malahat_test_data %>% filter(set == "pre")
MSc <- malahat_test_data %>% filter(set == "MSc")
```

##### plots
```
#{r}
# plot sets
malahat_test_data %>% 
  ggplot(aes(x = set, y = Value, fill = set))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    labels = c(pre = "2016-2017", MSc = "2018-2019"),
                    name = "Year span")+
  labs(y = "value", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~Analysis)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat_plot_pre-MSc-2years.png")

# looks like precip is not normally distributed because of seasons
# Tests for normality 
# Pre-MSc
pre_MSc %>% 
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                 color = "Year", palette = c("#648326", "#f4AB0E", "#62ACC8", "#535353"),
                 facet.by = "Analysis")

# during
MSc %>% 
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                 color = "Year", palette = c("#648326", "#f4AB0E"),
                 facet.by = "Analysis")

```

##### tests
```
#{r}
# t-tests or Wilcoxon to compare 2014-2017 to 2018-2019
# ggpubr::ggqqplot() to check for normality
## if points fall approximately along the reference line, assume normality

# t-tests for temperature (normally distributed)
# Wilcoxon signed rank test for Precip (not normally distributed)
# make a tibble for tidiness
# note: snow data was only available 2017-2019 -- not included
Malahat_testMSc_Wx <- bind_rows(
  # rain
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Precipitation Amount (mm)"], 
              MSc$Value[MSc$Analysis == "Precipitation Amount (mm)"],
              )) %>% 
    mutate(Parameter = "rain"),
  # air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Mean) (celsius)"], 
              MSc$Value[MSc$Analysis == "Temperature (Mean) (celsius)"])) %>% 
    mutate(Parameter = "temp_mean"),
  # Min air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Min.) (celsius)"], 
              MSc$Value[MSc$Analysis == "Temperature (Min.) (celsius)"])) %>% 
    mutate(Parameter = "temp_min"),
  # Max air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Max.) (celsius)"], 
              MSc$Value[MSc$Analysis == "Temperature (Max.) (celsius)"])) %>% 
    mutate(Parameter = "temp_max")) %>% 
  # pull values of interest to summarize
  select(Parameter, p.value) %>% 
  mutate(signifcance = case_when(p.value < 0.01 ~ "at 99%",
                                p.value < 0.05 ~ "at 95%",
                                p.value < 0.1 ~ "at 90%",
                                p.value > 0.1 ~ "NA")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Malahat_Wilcoxtest_pre-MSc-2years.csv")

# interpretation
# null hypothesis = both means are equal
# if the p-value is less than the significance level critical value, reject the null hypothesis 

```




## STAGE: River Stage 

### plot: normalized stage 

The stage was normalized (min-max norm) to compare relative rises
```{r, stage-line-plots}

# plot stage, lines over time
odyssey_data %>%
  group_by(source) %>% 
  dplyr::mutate(norm_stg = (stage_cm-min(stage_cm))/(max(stage_cm)-min(stage_cm))) %>% 
  ggplot(aes(x = DateTime, y = norm_stg))+
  geom_line(colour = "#0072B2") +
  #viridis::scale_colour_viridis(discrete = TRUE) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(y = "River stage (normalized)", x = "") +
  facet_wrap(~source, ncol = 1, strip.position = "right")  
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_subbasins.png",
       width = 8.5,
       height = 11,
       units = "in")
```

### plot: norm stage ridge
```{r, ridgey}

# plot stage, density ridges -- could be cool -- fix aesthetics 
odyssey_data %>%
  group_by(source) %>% 
  dplyr::mutate(norm_stg = (stage_cm-min(stage_cm))/(max(stage_cm)-min(stage_cm))) %>% 
  ggplot(aes(x = norm_stg, y = fct_rev(source)))+
  ggridges::geom_density_ridges(aes(fill = source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  scale_y_discrete() +
  theme(legend.position = "none")+
  labs(x = "River Stage (normalized)", y = "",
       caption = "Density distribution of min-max normalized stage at six subbasins")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_ridgeplot_subbasins.png")

```


#### trash- EcoHydRology baseflow separation 
```{r}
# note: don't call the 'EcoHydRology' package into the library if you're using it
## access it's functions with "::" only because it masks tidyverse functions and makes workflow annoying if it's loaded into the workspace.

# separate stage into base and quick (no flow data available)
# separate each site, base R style (ugh)
BF_QF_Weeks <- odyssey_data %>% 
  filter(source == "Weeks")  
BF_QF_Weeks <- EcoHydRology::BaseflowSeparation(BF_QF_Weeks$corr_stage_cm) %>% 
  mutate(site = "Weeks")

BF_QF_Chris <- odyssey_data %>% 
  filter(source == "ChrisCrk")  
BF_QF_Chris <- EcoHydRology::BaseflowSeparation(BF_QF_Chris$corr_stage_cm) %>% 
  mutate(site = "ChrisCrk")

BF_QF_Head <- odyssey_data %>% 
  filter(source == "LeechHead")  
BF_QF_Head <- EcoHydRology::BaseflowSeparation(BF_QF_Head$corr_stage_cm) %>% 
  mutate(site = "LeechHead")

BF_QF_Cragg <- odyssey_data %>% 
  filter(source == "CraggCrk")  
BF_QF_Cragg <- EcoHydRology::BaseflowSeparation(BF_QF_Cragg$corr_stage_cm) %>% 
  mutate(site = "CraggCrk")

BF_QF_West <- odyssey_data %>% 
  filter(source == "WestLeech")  
BF_QF_West <- EcoHydRology::BaseflowSeparation(BF_QF_West$corr_stage_cm) %>% 
  mutate(site = "WestLeech")

BF_QF_Tunnel <- odyssey_data %>% 
  filter(source == "Tunnel")  
BF_QF_Tunnel <- EcoHydRology::BaseflowSeparation(BF_QF_Tunnel$corr_stage_cm) %>% 
  mutate(site = "Tunnel")

# combine all 
BF_QF <- bind_rows(BF_QF_Weeks, BF_QF_Chris, BF_QF_Head, BF_QF_Cragg, BF_QF_West, BF_QF_Tunnel) %>%
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  mutate(row = row_number(bt))

# join to stage data for datetime
BF_QF_Odyssey <- odyssey_data %>%
  mutate(row = row_number(corr_stage_cm)) %>% 
  mutate(site = factor(source, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  full_join(BF_QF, by = c("site", "row"))

```

#### WIP -- find peaks(notworking)
```
#r}
# determine the rate of stage rise for each event at each site
# odyssey_data

# pull dates for trip
trip_bysite <- stage_samples %>%
  group_by(trip) %>% 
  summarise(start = first(DateTime),
            end = last(DateTime))
# pull dates for trip and event
event_bysite <- stage_samples %>%
  group_by(event_ID) %>% 
  summarise(start = first(DateTime),
            end = last(DateTime))
# --
# isolate peaks
stage_samples_pks <- stage_samples %>% 
  select(c(site, event_ID, corr_stage_cm, DateTime)) %>% 
  filter(!is.na(event_ID)) %>% 
  group_by(site, event_ID) %>%
  summarise(DateTime_peak = DateTime[which.max(corr_stage_cm)],
            peak = max(corr_stage_cm),
            DateTime = DateTime_peak) %>% 
  full_join(odyssey_data,  
            by = c("site" = "source", "event_ID", "DateTime")) %>% 
  select(-c(stage_cm, Date)) %>% 
  full_join(stage_samples, by = c("site", "event_ID", "DateTime", "interval", "corr_stage_cm"))
  
## plot
stage_samples_pks %>% 
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), na.rm = TRUE, colour = "#0072B2")+  ## stage
  geom_point(aes(y = peak, shape = sample_type), na.rm = TRUE)+ ## samples 
  # scale_shape_manual(values = c("Grab" = 16, "Rack" = 17), na.translate = FALSE)+
  facet_wrap(~site, ncol = 1, strip.position = "right", scales = "free_y")+
  labs(y = "River stage (cm)", x = "", shape = "Sample Type")+
  scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme_bw()


#+
  theme(axis.text.x = element_text(angle = 60, hjust=1), text = element_text(size=12), legend.position = "top")+
  # add vertical lines for events
  geom_vline(xintercept = event_bysite$start, 
             linetype = "dashed", colour = "red", size = 0.7)
  # add vertical lines for trip
  geom_vline(xintercept = trip_bysite$start, 
             linetype = "solid", colour = "red", size = 0.6)
  
```



## Wx MEGAPLOT: FWx+RiverStage
Plot stage, precip, temp and snow and then create a one-page mega plot of all combined.

```{r, Wx-stage-megas-plots}

# 1 plot snow
# LWSA (Chris crk and Martin's Gulch FWx stns)
subasin_snow_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Snow = factor("Snow")) %>% 
  group_by(date, Snow) %>% 
  dplyr::summarise(daily_meansnow = mean(SnowDep_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_meansnow)) +
  geom_col(aes(colour = Snow), colour = "grey40") +
  labs(x = "", y = "m /day") +
  theme_bw() +
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Snow, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0.5,0,0,0), "cm")) # top, right, bottom, left
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_snow-plot_subbasins.png")

# 2 plot 
# LWSA temp for the same time span
subasin_meantemp_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Temp = factor("Temp")) %>% 
  group_by(date, Temp) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(aes(colour = Temp), colour = "#E69F00") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = "°C /day") +
  theme_bw() +
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Temp, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_temp-plot_subbasins.png")

# 3 plot rainfall
# mean LWSA rain for study period
subbasin_meanrain_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Rain = factor("Rain")) %>% 
  group_by(date, Rain) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(aes(colour = Rain), colour = "#0072B2") +
  scale_y_reverse() +
  labs(x = "", y = "mm /day") +
  theme_bw() +
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Rain, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_rain-plot_subbasins.png")

# 4 plot stage
# stage at each of the subbasins
stage_plot <- odyssey_data %>% 
  filter(DateTime >= "2018-10-24 00:00:00") %>% 
  ggplot(aes(x = DateTime, y = corr_stage_cm))+
  geom_line(colour = "#09A4D2")+
  theme_bw()+
  facet_wrap(~source, ncol = 1, 
             scales = "free_y",
             strip.position = "right")+
  labs(y = "River Stage (cm)", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Stage-plot_subbasins.png")

# mega-plot!! 
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subasin_meantemp_plot, subbasin_meanrain_plot, stage_plot, 
                   ncol = 1, 
                   axis = "l", 
                   align = "v",
                   rel_heights = c(1,1,1,5))
# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_megaplot.png",
       width = 8.5,
       height = 11,
       units = "in")

```

# TEMPERATURE (Hobo)
```{r}
# update Hobo wet temperatures 
# most sites were wet by mid-September (2019) 
# all sites water loggers were wet by Oct 15
Hobo <- Hobo_df %>% 
  mutate(Temp_C_fullwet = Temp_C)
  
# Cragg Creek
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & site == "CraggCrk" &
                                  Date < as_date("2019-09-15"), "NA", Temp_C_fullwet)) 
# Tunnel  
Hobo <- within(Hobo, 
               Temp_C <- ifelse(TidbiT_location == "water" & site == "Tunnel" & 
                                  Date < as_date("2019-10-15"), "NA", Temp_C_fullwet))

# Temp_C is numeric, update from character
Hobo <- Hobo %>% 
  mutate(Temp_C = as.numeric(Temp_C)) 

```

## plot: Hobo air/water temps over time
```{r}
Hobo %>% 
  group_by(site, TidbiT_location, Date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date, y = T_daily))+
  geom_line(aes(colour = site), size = 0.6)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  geom_hline(yintercept = 0, linetype = "dashed", colour = "darkgrey", size = 0.4)+
  facet_wrap(~TidbiT_location, ncol = 1,
             scales = "free_y",
             strip.position = "left")+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Site:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
                   date_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs_line-by-time_daily.png", 
       width = 6, height = 6, units = "in")
```

## plot: Hobo A/W over space
```{r}
# all sites water loggers were submerged by 2019-10-15  
Hobo <- within(Hobo, 
              Temp_C <- ifelse(TidbiT_location == "water" & 
                                Date < as_date("2019-10-15"), "NA", Temp_C_fullwet)) 

# Temp_C is numeric, update from character
Hobo <- Hobo %>% 
  mutate(Temp_C = as.numeric(Temp_C)) 

## Boxplot
Hobo %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, TidbiT_location, date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = site, y = T_daily, fill = site))+
  geom_jitter(aes(fill = site), alpha = 0.6, shape = 21)+
  geom_boxplot(alpha = 0.4)+
  scale_fill_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~TidbiT_location, 
             ncol = 1,
             scales = "free_y",
             strip.position = "left")+
  labs(x = "", y = "Mean Daily Temperature (°C)")+
  theme(legend.position = "none", 
        text = element_text(size = 12))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs_box-by-location_daily.png", 
       width = 5.5, height = 5.5, units = "in") 
```

## Compare: Hobo / LWSA
```{r}

# find overlapping ranges
Hobo %>% 
  group_by(site) %>% 
  summarize(count = n(),
            earliest = first(Date),
            latest = last(Date)) %>% 
  arrange(count)

# join the air temp from subbasins with the mean LWSA temperature data to compare
# augment Hobo df to include full range of DateTime to match to FWx df

# need FWx for each site before Hobo TidbiTs were installed
# range: start = "2018-10-23" & end = "2019-08-23"
project_start <- ymd_hms("2018-10-23 01:00:00", tz = TZ) # first overlapping field day
Hobo_start <- ymd_hms("2019-08-24 01:00:00", tz = TZ)  # all TidbiTs deployed
project_end <- ymd_hms("2020-02-18 15:00:00", tz = TZ) # last overlapping field day

# create a dataframe of full DateTimes
Hobo_FWx_joiner <- 
  # FWx data came in ever 15 minutes (Hobo ever 30 min)
  tidyr::tibble(DateTime = seq(project_start, project_end, by = "15 min")) %>% 
  # and join to wide Hobo air temp data
  full_join(Hobo %>% 
              filter(TidbiT_location == "air",
                     !is.na(site),
                     DateTime < project_end) %>% 
              select(site, DateTime, Temp_C) %>% 
              pivot_wider(names_from = site, values_from = Temp_C), 
            by = c("DateTime")) %>% 
  # then, pivot longer again so each site has a full DateTime range
  pivot_longer(cols = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"), names_to = "site", values_to = "Temp_C") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  group_by(site) 

# join FWx and Hobo
# 30 minute temp intervals from start of project to end
Hobo_WxLWSA_full <- LWSA_meanWx %>%
  select(c(DateTime, Temp_mean)) %>%
  filter(DateTime < project_end,
         DateTime >= project_start) %>% 
  full_join(Hobo_FWx_joiner, by = c("DateTime")) %>% 
  rename(FWx = "Temp_mean", Hobo = "Temp_C") %>%
  filter(lubridate::minute(DateTime) != 15,
         lubridate::minute(DateTime) != 45) %>%  # drops 15 minute Hobo nulls
  group_by(site) %>% 
  distinct() %>% # drop duplicate rows
  mutate(Date = as_date(DateTime)) %>% 
  select(c(site, Date, DateTime, Hobo, FWx))  # reorganize for viewing


# isolate overlapping date ranges of Hobo and FWx
Hobo_WxLWSA <- Hobo_WxLWSA_full %>% 
  filter(DateTime >= Hobo_start) 
```

### plot: [1:1] FWx vs HOBO
```{r}

## plot: 1:1 scatter of temperatures
Hobo_WxLWSA %>% 
  ggplot(aes(x = FWx, y = Hobo))+
  geom_point(alpha = 0.35)+
  theme_bw()+
  facet_wrap(~ site)+
  labs(y = "Site temperature (°C)", x = "Mean LWSA temperature (°C)") +
  theme(text = element_text(size = 12))+
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) +
## to get equations include this line:
  stat_poly_eq(formula = y ~ x, aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), parse = TRUE, rr.digits = 4) 

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Temp_TidbiTs-FWx_lm-scatter.png", 
       width = 8, height = 6, units = "in")

```

#### visual checks
```{r}
# pivot longer
Hobo_Fwx <- Hobo_WxLWSA %>%
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx"),
               names_to = "data_source",
               values_to = "Temp_C") %>% 
  mutate(data_source = factor(data_source))

# check daily temp overlap
Hobo_Fwx %>% 
  group_by(site, data_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  filter(data_source == "FWx") %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = site), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  labs(x = "", y = "Daily mean air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d",
                   date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# perfect :)

```

### air temp over time
```{r}
# compare temps from FWx to HOBO at each site
Hobo_Fwx %>% 
  group_by(site, data_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = data_source), size = 0.8)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~site, ncol = 1,
             scales = "free_y",
             strip.position = "right")+
  labs(x = "", y = "Air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d", date_breaks = "1 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_subbasin_daily-temps.png", 
       width = 6, height = 7, units = "in")

```

### air temp over space
```{r}
# set FWx like it's a site
HoboFWx_sites <- Hobo %>% 
  filter(TidbiT_location == "air",
         DateTime < project_end, DateTime >= Hobo_start) %>%
  select(site, DateTime, Temp_C) %>% 
  pivot_wider(names_from = site, values_from = Temp_C) %>%
  
  left_join(
    LWSA_meanWx %>% select(c(DateTime, Temp_mean)) %>% filter(DateTime < project_end, DateTime >= Hobo_start),
            by = c("DateTime")) %>% 
  rename(FWx = "Temp_mean") %>% 
  # then, pivot longer again so each site has a full DateTime range
  pivot_longer(cols = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel", "FWx"), names_to = "site", values_to = "Temp_C") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel", "FWx"))) 

# boxplot
# compare temps from FWx to HOBO at each site
HoboFWx_sites %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = site, y = T_daily, fill = site))+
  geom_jitter(alpha = 0.6, shape = 21)+
  geom_boxplot(alpha = 0.4)+
  scale_fill_brewer(palette = "Dark2")+
  theme_bw() +
  labs(x = "", y = "Mean Daily Air temperature (°C)",
       colour = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_box-air-by-site.png", 
       width = 6, height = 7, units = "in")

```

### Stats: FWx-Hobo differences 

#### Normality tests (ADD TO APPENDIX)
```{r}
# make a comparison between subbasin hobos and the LWSA FWx data
# Test temps for normality

# density by weather station source
# these should be the same 
## -- they came from the same source & are limited to the same date range
Hobo_Fwx %>% 
  ggplot(aes(Temp_C))+
  geom_density(aes(colour = site))+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~ data_source)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_DensityNormalityCheck-subbasins.png", 
       width = 4, height = 4, units = "in")

# density ridges by TidbiT site
Hobo_Fwx %>% 
  ggplot(aes(x = Temp_C, y = fct_rev(site)))+
  ggridges::geom_density_ridges(aes(fill = data_source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw()+
  theme(legend.position = "top")+
  labs(x = "Air temperature (°C)",
       y = "",
       fill = "Data origin:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/TidbiTs-FWx_ridgeplot-subbasins.png", 
       width = 4, height = 4, units = "in")

```

#### Wilcoxon tests
```{r}
# Wilcoxon tests (not normally distributed)

# null hypothesis: there is no difference between the means
# p-value > 0.05 --> cannot reject null hypothesis (accept that there is no sig.diff)

# tests
test <- Hobo_Fwx$Temp_C
stn <- Hobo_Fwx$data_source
site <- Hobo_Fwx$site

# run tests and compile results
Temp_Wilcoxon_tests <- bind_rows(
  tidy(wilcox.test(test[stn == "FWx" & site == "Weeks"], test[stn == "Hobo" & site == "Weeks"])) %>% 
    mutate(site = "Weeks"),
  tidy(wilcox.test(test[stn == "FWx" & site == "ChrisCrk"], test[stn == "Hobo" & site == "ChrisCrk"])) %>% 
    mutate(site = "ChrisCrk"),
  tidy(wilcox.test(test[stn == "FWx" & site == "LeechHead"], test[stn == "Hobo" & site == "LeechHead"])) %>% 
    mutate(site = "LeechHead"),
  tidy(wilcox.test(test[stn == "FWx" & site == "CraggCrk"], test[stn == "Hobo" & site == "CraggCrk"])) %>% 
    mutate(site = "CraggCrk"),
  tidy(wilcox.test(test[stn == "FWx" & site == "WestLeech"], test[stn == "Hobo" & site == "WestLeech"])) %>% 
    mutate(site = "WestLeech"),
  tidy(wilcox.test(test[stn == "FWx" & site == "Tunnel"], test[stn == "Hobo" & site == "Tunnel"])) %>% 
    mutate(site = "Tunnel"))

# summarize p-values
Wilcoxon_Temp_summary <- Temp_Wilcoxon_tests %>% 
  select(c(site, p.value)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/TidbiT-FWx_Wilcoxon-pvalues.csv", col_names = TRUE)

```

### Linear Regression

Relate subbasins to FWx & use linear regression to estimate temperature for each subbasin 
```{r}
# lm(y ~ x) == lm(dependent ~ independent) 
# save summary object
# use wide dataframe (Hobo_WxLWSA) rather than long(Hobo_Fwx)
sites_lm <- Hobo_WxLWSA %>% 
  filter(Date > "2019-08-23") %>% # overlapping range
  group_by(site) %>% 
  summarise(slope = coefficients(lm(formula = Hobo ~ FWx))[2],
            yint_DOC = coefficients(lm(formula = Hobo ~ FWx))[1],
            r_sq = summary(lm(formula = Hobo ~ FWx))$r.squared) 

# use linear regression to calculate earlier temperatures
Hobo_FWx_filled <- Hobo_WxLWSA_full %>% 
  group_by(site) %>% 
  mutate(Predicted = case_when(# y = m*x + b
    site == "Weeks" ~ sites_lm[[1,2]]*FWx + sites_lm[[1,3]], 
    site == "ChrisCrk" ~ sites_lm[[2,2]]*FWx + sites_lm[[2,3]], 
    site == "LeechHead" ~ sites_lm[[3,2]]*FWx + sites_lm[[3,3]], 
    site == "CraggCrk" ~ sites_lm[[4,2]]*FWx + sites_lm[[4,3]], 
    site == "WestLeech" ~ sites_lm[[5,2]]*FWx + sites_lm[[5,3]], 
    site == "Tunnel" ~ sites_lm[[6,2]]*FWx + sites_lm[[6,3]]
  )) %>% 
  filter(!is.na(site))
```

#### table: error for overlap Hobo + estimates
```{r}
# isolate overlapping date range & summarize percent error
Hobo_overlapPredictionErrors <- Hobo_FWx_filled %>% 
  filter(Date > as_date(Hobo_start), Date < as_date(project_end)) %>% 
  group_by(site) %>% 
  mutate(error = ((Hobo - Predicted)/Hobo)*100) %>%  # positive error = regression under-estimated subbasin temp
  group_by(site) %>% 
  summarise(error_mean = mean(error, na.rm = TRUE),
            #Hobo_mean = mean(Hobo, na.rm = TRUE),
            #sd_Hobo = sd(Hobo, na.rm = TRUE), 
            Hobo_median = median(Hobo, na.rm = TRUE),
            Predicted_median = median(Predicted, na.rm = TRUE),
            #Predicted_mean = mean(Predicted, na.rm = TRUE),
            #sd_Predicted = sd(Predicted, na.rm = TRUE), 
            min_Hobo = min(Hobo, na.rm = TRUE),
            min_Predicted = min(Predicted, na.rm = TRUE),
            max_Hobo = max(Hobo, na.rm = TRUE),
            max_Predicted = max(Predicted, na.rm = TRUE)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/TidbiT-FWx_lm_prediction-errors.csv", col_names = TRUE)

```

#### plot: lines of estimated earlier +FWx +Hobo temps
```{r}

# take the study period data frame with temp estimates at each site
# pivot longer
HoboFWx_filled_L <- Hobo_FWx_filled %>%
  group_by(site) %>% 
  pivot_longer(cols = c("Hobo", "FWx", "Predicted"),
               names_to = "Temp_source",
               values_to = "Temp_C") %>% 
  mutate(Temp_source = factor(Temp_source))

# visualize and compare each site
HoboFWx_filled_L %>% 
  group_by(site, Temp_source, Date) %>% 
  summarise(Tdaily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date))+
  geom_line(aes(y = Tdaily, colour = Temp_source), size = 0.5)+
  scale_color_brewer(palette = "Dark2")+ 
  theme_bw()+
  facet_wrap(~site, ncol = 1,
             scales = "free_y",
             strip.position = "right")+
  labs(x = "", y = "Air temperature (°C)",
       colour = "Temp source:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  scale_x_date(date_labels = "%Y %b %d", date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Temp_TidbiTs-FWx-predicted_lm.png", 
       width = 5.5, height = 7, units = "in")


# line plot of all, not separated by site
HoboFWx_filled_L %>% 
  group_by(site, Temp_source, Date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = Date, y = T_daily))+
  geom_line(aes(colour = Temp_source))+
  scale_color_brewer(palette = "Set2")+ 
  theme_bw()+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Temperature:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
                   date_breaks = "1 months")

```

# QA-QC ANALYSIS 
```{r}
QAQC <- sampleresults %>% 
  filter(sample_type == "QA-QC")

# subset for calibration verification 
# extract cal-ver concentrations from sample name (with 'str_extract()')
calver <- QAQC %>% 
  filter(site == "Lab") %>% 
  select(c(site, sample_type, sample, analysis, NPOC_ppm, SAC254_Abs.m, DOCeq_ppm)) %>% 
  mutate(cal_ver = str_extract(sample, "([0-9]{1,}+\\.[0-9]{1,}+)"),
         cal_ver = as.numeric(cal_ver),
         rn = row_number(cal_ver)) %>% 
  mutate(sample_type = case_when(
    !is.na(cal_ver) ~ "cal_ver",
    is.na(cal_ver) ~ "RO" )) 
```


## Hold-time experiments (Tunnel rack)
```{r}
# three cycles of hold time experiments (A, B , C)
# each time, 5 samples were collected (grab) while 5 were placed on the rack with siphon lids
# the held samples (rack) were collected later after sitting out
# compare results between fresh and held samples

# subset QAQC df for holdtime samples
# extract set and rep values and group sets
HT <- QAQC %>% 
  filter(site == "Tunnel",
         !is.na(NPOC_ppm)) %>% 
  select(-c(sampleStage_cm, fillStage_cm, corr_stage_cm)) %>% 
  mutate(HoldTime_set = substr(sample, 10, 10),
         HoldTime_rep = substr(sample, 11, 12),
         HoldTime_group = case_when(
           HoldTime_rep == c(1:5) ~ "G",  # 'fresh' grab samples
           HoldTime_rep == c(6:10) ~ "R", # 'held' rack samples
         )) %>% 
 # groups
  mutate(group = case_when(
    HoldTime_set == "A" & HoldTime_rep == c(1:5) ~ "AG", # first set grabs, 2019-10-12 (trip 16)
    HoldTime_set == "A" & HoldTime_rep == c(6:10) ~ "AR", # first set rack, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(1:5) ~ "BG", # second set grabs, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(6:10) ~ "BR", # second set rack, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(1:5) ~ "CG", # third set grabs, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(6:10) ~ "CR", # third set rack, 2019-12-16 (trip 20)
  ))

# how many days passed between collecting fresh and held samples?
a <- HT %>% 
  group_by(HoldTime_set, Date) %>% 
  summarise(group = first(group)) %>%
  group_by(HoldTime_set) %>% 
  summarize(lapse = diff.Date(Date))

# mutate lapse to HT df
HT <- full_join(HT, a, by = "HoldTime_set") %>% 
  mutate(HoldTime_set = factor(HoldTime_set, levels = c("A", "B", "C")), 
         HoldTime_rep= as_factor(HoldTime_rep), 
         HoldTime_group = as_factor(HoldTime_group), 
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR"))) %>% 
  mutate(HT_set_labels = HoldTime_set,
         HT_group_labels = HoldTime_group)


# Join Tunnel HOBO TidbiT data with HT data
HT_Hobo <- Hobo %>% 
  filter(site == "Tunnel",
         TidbiT_location == "air") %>% 
  mutate(Date = as_date(DateTime)) %>% 
  full_join(HT, by = c("site", "Date", "DateTime", "trip", "event_ID", "rain_season")) %>% 
  mutate(site = factor(site),
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR")))

# summarize Hobo HT 
Hobo_summ <- HT_Hobo %>% 
  filter(!is.na(group)) %>% 
  group_by(HoldTime_set) %>% 
  summarise(lapse = first(lapse),
            median_T = median(Temp_C),
            mean_T = mean(Temp_C),
            sd_T = sd(Temp_C))

```

### HT plots
```{r}

# create labels for plots
HT$HT_group_labels <- fct_recode(HT$HT_group_labels, Fresh = "G", Held = "R")
HT$HT_set_labels <- fct_recode(HT$HT_set_labels, "A (11 days)" = "A", "B (20 days)" = "B", "C (34 days)" = "C")

# plot sets
a <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = NPOC_ppm, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "DOC (mg/L)", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~HoldTime_set)

b <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = SAC254_Abs.m, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "UV abs at 254nm (a.u.)", x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HoldTime_set)

c <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = DOCeq_ppm, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "Est. DOC (mg/L)", x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HoldTime_set)

# with Estimated DOC
#cowplot::plot_grid(a, b, c, align = "v", ncol = 1, rel_heights = c(2, 1.6, 1.6))  
  
# without estimated DOC
cowplot::plot_grid(a, b, align = "v", ncol = 1, rel_heights = c(2, 1.6))  
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HT-exp_stat-boxplots.png")

```

### HT tests: Wilcoxon
```{r}

# density distribution normality 
# NPOC
HT %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "NPOC_ppm",
                 color = "HoldTime_set")

# Tests UV254 abs for normality 
HT %>% 
  ggplot(aes(SAC254_Abs.m))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "SAC254_Abs.m",
                 color = "HoldTime_set")

# Tests DOC estimate abs for normality 
HT %>% 
  ggplot(aes(DOCeq_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "DOCeq_ppm",
                 color = "HoldTime_set")
# ---
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis
# p-value < 0.05 --> reject the null hypothesis 

# run tests and compile results
HT_Wilcoxon_tests <- bind_rows(
  ## NPOC ---
  # set A
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "AG"], HT$NPOC_ppm[HT$group == "AR"])) %>% 
    mutate(Set = "A", Analysis = "NPOC_ppm"),
  # set B 
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "BG"], HT$NPOC_ppm[HT$group == "BR"])) %>% 
    mutate(Set = "B", Analysis = "NPOC_ppm"),
  # set C
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "CG"], HT$NPOC_ppm[HT$group == "CR"])) %>% 
    mutate(Set = "C", Analysis = "NPOC_ppm"),
  ## Est. DOC ---
  # set A
  #tidy(wilcox.test(HT$DOCeq_ppm[HT$group == "AG"], HT$DOCeq_ppm[HT$group == "AR"])) %>% 
  #  mutate(Set = "A", Analysis = "DOCeq_ppm"),
  # set B
  #tidy(wilcox.test(HT$DOCeq_ppm[HT$group == "BG"], HT$DOCeq_ppm[HT$group == "BR"])) %>% 
  #  mutate(Set = "B", Analysis = "DOCeq_ppm"),
  # set C
  #tidy(wilcox.test(HT$DOCeq_ppm[HT$group == "CG"], HT$DOCeq_ppm[HT$group == "CR"])) %>% 
  #  mutate(Set = "C", Analysis = "DOCeq_ppm"),
  ## UV-254 ---
  # set A
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "AG"], HT$SAC254_Abs.m[HT$group == "AR"])) %>% 
    mutate(Set = "A", Analysis = "SAC254_Abs.m"),
  # set B
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "BG"], HT$SAC254_Abs.m[HT$group == "BR"])) %>% 
    mutate(Set = "B", Analysis = "SAC254_Abs.m"),
  # set C
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "CG"], HT$SAC254_Abs.m[HT$group == "CR"])) %>% 
    mutate(Set = "C", Analysis = "SAC254_Abs.m")) %>% 
  select(Analysis, Set, p.value) %>% 
  # pull values of interest to summarize
  mutate(sig.diff = case_when(p.value < 0.01 ~ "at 99%",
                                p.value < 0.05 ~ "at 95%",
                                p.value < 0.1 ~ "at 90%",
                                p.value > 0.1 ~ "NA")) 

## view
# HT_Wilcoxon_tests
# cowplot::plot_grid(a, b, align = "v", ncol = 1, rel_heights = c(2, 1.6)) 

```

#### table: results summary
```{r}
# summarize
HT_summ <- HT %>% 
  group_by(group) %>% 
  summarise(set = first(HoldTime_set),
            lapse = first(lapse),
            count = n(),
            mean_DOC = mean(NPOC_ppm),
            sd_DOC = sd(NPOC_ppm),
            RSD_DOC = (sd_DOC/mean_DOC)*100,
            mean_UV254 = mean(SAC254_Abs.m),
            sd_UV254 = sd(SAC254_Abs.m)) 
# save results
HT_summ %>% 
  select(-set) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_sample-summary.csv")

# summarize percent change for each set
# vector
HTDOCresult <- HT_summ$mean_DOC
HTUVresult <- HT_summ$mean_UV254
# summarize
change <- 
  tibble(set = c("A", "B", "C"),
         percent_change_DOC = c(
           round((((HTDOCresult[2]-HTDOCresult[1])/HTDOCresult[1])*100),0),
           round((((HTDOCresult[4]-HTDOCresult[3])/HTDOCresult[3])*100),0),
           round((((HTDOCresult[6]-HTDOCresult[5])/HTDOCresult[5])*100),0)),
         percent_change_UV254 = c(
           round((((HTUVresult[2]-HTUVresult[1])/HTUVresult[1])*100),0),
           round((((HTUVresult[4]-HTUVresult[3])/HTUVresult[3])*100),0),
           round((((HTUVresult[6]-HTUVresult[5])/HTUVresult[5])*100),0)))

# join statistical results with Hobo results
HT_tests_summary <- HT_Wilcoxon_tests %>% 
  pivot_wider(names_from = Analysis, values_from = c("p.value", "sig.diff")) %>% 
  full_join(., Hobo_summ,
            by = c("Set" = "HoldTime_set")) %>% 
  mutate(temp_range = paste0(round(mean_T, 1), "°C ± ", round(sd_T, 1), "°C"),
         temp_median = paste0(median_T, "°C")) %>% 
  full_join(change, by = c("Set" = "set")) %>% 
  select(Set, "Days held" = lapse, 
         "Temp range" = temp_range, 
       "Median Temp." = temp_median,
       "DOC change (%)" = percent_change_DOC, # rename: new = old
       "sig.diff (DOC)" = sig.diff_NPOC_ppm,  
       "p-value (DOC)" = p.value_NPOC_ppm,
       "UV 254 change (%)" = percent_change_UV254,
       "sig.diff (UV 254)" = sig.diff_SAC254_Abs.m, 
       "p-value (UV 254)" = p.value_SAC254_Abs.m) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_results-summary.csv")

```

# YOU ARE HERE

### plot: HT megaplot
```{r}
# pull & set values for plot
# set dates
HT_range <- HT %>% 
  group_by(HoldTime_set) %>% 
  summarise(start = first(Date),
            end = last(Date))

# set sample dates
HT_dates <- HT %>% 
  group_by(HoldTime_set) %>% 
  mutate(lapse = as.numeric(lapse)) %>% 
  summarise(date_fresh = as_date(first(DateTime_sampled)),
            date_held = as_date(last(DateTime_sampled)),
            lapse = mean(lapse),
            half_lapse = lapse*0.5)


# summarize mean temp for each hold-time set
A_temp <- HT_Hobo %>% 
  filter(!is.na(Temp_C),
         Date %within% interval(HT_range$start[1], HT_range$end[1])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(A_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

B_temp <- HT_Hobo %>% 
  filter(!is.na(Temp_C),
         Date %within% interval(HT_range$start[2], HT_range$end[2])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(B_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

C_temp <- HT_Hobo %>% 
  filter(!is.na(Temp_C),
         Date %within% interval(HT_range$start[3], HT_range$end[3])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) %>% 
  summarise(C_temp = paste(round(.$set_temp, 1), "±", round(.$set_temp_sd, 1))) %>% 
  pull()

## ---------------
# pivot long
HT_Hobo_L <- HT_Hobo %>% 
  mutate(Date = as_date(DateTime)) %>% 
  group_by(Date) %>% 
  summarise(daily_mean_T = mean(Temp_C)) %>% 
  full_join(HT_Hobo) %>% 
  pivot_longer(cols = c(daily_mean_T, Temp_C),
               values_to = "degrees_C",
               names_to = "Temp") %>% 
  mutate(Temp = factor(Temp, levels = c("Temp_C", "daily_mean_T")))
  
# plot it  
HT_Hobo_L %>% 
  ggplot(aes(x = Date, y = degrees_C))+
  geom_line(aes(colour = Temp, size = Temp))+
  scale_colour_manual(values = c(forWater_colours2[["SkyBlue"]], ## 30 minute 
                                 forWater_colours2[["DeepBlue"]]), ## daily average
                      labels = c("30 minute measurement", "Daily mean"))+
  scale_size_manual(values = c(1, 1.5), labels = c("30 minute measurement", "Daily mean"))+
  guides(colour = guide_legend("Temperature:"), size = guide_legend("Temperature:"))+
  # horizontal lines for lab refrigerator range (0-7 C)
  geom_hline(yintercept = c(0, 7), linetype = "solid", colour = "red")+
  annotate("text", label = "fridge range", angle = 90, colour = "red",
           x = first(HT_Hobo_L$Date)+1, y = 3.5)+
  # vertical lines for HT sample dates
  geom_vline(xintercept = c(HT_dates$date_fresh, HT_dates$date_held), 
             linetype = "dashed", colour = "black", size = 0.75) +
  annotate("text", label = c("Hold-time set:\n", paste(HT_dates$HoldTime_set, "\n")), ## set 
           x = c(HT_dates$date_fresh[1]-15, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 27)+
  annotate("text", label = c("Days:\n", paste(HT_dates$lapse, "\n")), ## time lapse
           x = c(HT_dates$date_fresh[1]-8, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 25)+
  theme_bw()+
  labs(y = "Air Temperature (°C)",
       #caption = glue::glue("Mean temperatures during vertical rack hold-time experiments: {A_temp} (set A), {B_temp} (set B), {C_temp} (set C)."),
       x = "") +
  theme(legend.position = "top", 
        text = element_text(size = 12)) +
  scale_x_date(date_breaks = "1 months")

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_air-Temp.png", width = 7, height = 7 , units = "in")

```

## LAB 

### blanks
```{r}
# check lab blanks
# this is a difficult measure of precision because the RO water is not the most reliably stable
calver %>% 
  filter(sample_type == "RO",
         sample == "RO" | sample == "RO_pH<2",
         NPOC_ppm != 0) %>% 
  group_by(sample) %>% 
  summarise(count = n(),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            RSD = (sd_DOC/DOC_mean)*100)
  
```

### cal vers
```{r}
# percent error calculated as 'measured' minus 'actual'
# negative error indicates the method was under-estimating DOC concentration 
# positive error indicates the method was over-estimating DOC concentration

# check cal vers for shimadzu
a <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(NPOC_ppm),
         rn != 7,  # error -- did not add standard 
         cal_ver != 5.7) %>%  # true concs were not calculated
  group_by(rn) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            percent_error = ((DOC_mean - calc)/ calc)*100) %>% 
  ungroup() %>% 
  summarise(count = sum(count),
            error_percent = mean(percent_error))

# check cal vers for spectrolyser
b <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(DOCeq_ppm)) %>% 
  group_by(rn) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOCeq_mean = mean(DOCeq_ppm, na.rm = TRUE),
            sd_DOCeq = sd(DOCeq_ppm, na.rm = T),
            percent_error = ((DOCeq_mean - calc)/ calc)*100) %>% 
  ungroup() %>%  
  summarise(count = sum(count),
            error_percent = mean(percent_error))

# total cal-vers included
n_calvers_total <- calver %>% 
  filter(sample_type == "cal_ver") %>% 
  summarise(n = n())

# cal-vers included
n_calvers <- a[1,1]+b[1,1]

# percent error from shimadzu
error_shimadzu <- a %>% pull(error_percent)

# percent error from spectrolyser
error_spectrolyser <- b %>% pull(error_percent)

# average percent error from both methods:
error_overall <- (error_shimadzu + error_spectrolyser)/2

```


# SAMPLES

## augment dataframes
```{r, mutate}
# create a "first-flush category in rain_season(s)
sampleresults <- sampleresults %>% 
  select(-c(ID, DateTime)) %>% 
  mutate(rain_seasons = case_when(
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-21", "2019-03-01") ~ "wet",
    Date %within% interval("2019-03-01", "2019-04-30") ~ "wet", # snow",
    Date %within% interval("2019-05-01", "2019-09-11") ~ "dry",
    event_ID == 9 ~ "first flush",
    event_ID %in% 10:18 ~ "wet")) %>% 
  mutate(rain_season = as.character(rain_season))

# fill in any gaps and save as factors
sampleresults <- within(sampleresults, 
                        rain_seasons <- ifelse(
                          is.na(rain_seasons), rain_season, rain_seasons)) %>% 
  mutate(rain_season = factor(rain_season),
         rain_seasons = factor(rain_seasons))

# further group sites
sampleresults <- sampleresults %>% 
  mutate(site_type = case_when(
    site == "Weeks" ~ "subbasin",   
    site == "ChrisCrk" ~ "subbasin",
    site == "LeechHead"  ~ "subbasin",
    site == "CraggCrk" ~ "subbasin",
    site == "WestLeech" ~ "subbasin",
    site == "Tunnel" ~ "subbasin",
    site == "Lab" ~ "LabQAQC",
    TRUE ~ "synoptic")) %>% 
  mutate(site_type = factor(site_type))

```

# RIVER SAMPLES

## subset df + sample counts
```{r, subsetting-campaign}
# primary synoptic sampling sites (n > 1)
# 15 sites total

# how many synoptic samples were grabbed?
# save value as object to implant in text
n_SynopticGrabs <- sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab") %>%
  group_by(site = forcats::fct_explicit_na(site)) %>% 
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% 
  mutate(what = "synoptic grab count") %>% 
  ungroup() %>%  # drop the following code to see samples by sites
  group_by(what) %>% 
  summarise(total = sum(grab_sample_count)) %>% 
  pull(total)

# create a subset dataframe for the synoptically sampled sites for tidier calling
synopticfilter <- sampleresults %>% 
  filter(# subbasin sites 
    site == "Weeks"|
      site == "ChrisCrk"|
      site == "LeechHead"|
      site == "CraggCrk"|
      site == "WestLeech"|
      site == "Tunnel"|
      # other sites
      site == "Rithet"|
      site == "Lazar"|
      site == "Jarvis"|
      site == "Judge"|
      site == "Leech-downstreamconf"|
      site == "Boneyard"|
      #site == "Deception-crk"|  ## only two samples
      #site == "West-Jordan"| ## only two samples
      site == "Deception-res",
    analysis == "DOC"
  ) %>% 
  mutate(site = factor(site, # order as you want to see them in plots
                       levels = c("West-Jordan", "Weeks", "ChrisCrk", "LeechHead", "Jarvis", "Lazar", "CraggCrk", "WestLeech", "Leech-downstreamconf", "Tunnel", "Rithet", "Judge", "Deception-res", "Deception-crk", "Boneyard" ))) 
# rename funky names
synopticfilter$site <- synopticfilter$site %>% 
  plyr::revalue(c("Leech-downstreamconf" = "Leech-Beach",  ## old = new
                  "Jarvis" = "Jarvis-crk",
                  "Judge" = "Judge-crk", 
                  "Lazar" = "Lazar-crk", 
                  #"West-Jordan" = "W.Jordan-Trib",
                  #"Deception-crk" = "Deception-Gluch",
                  "Rithet" = "Rithet-crk"))
# ---

# create a subset dataframe for the six install sites for tidier calling
sixfilter <- sampleresults %>% 
  filter(site_type == "subbasin",
         analysis == "DOC") %>% 
  mutate(site = factor(site, levels = 
                         c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech","Tunnel")))

# further categorize site_type
sixfilter <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "headwater",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "mainstem")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

```

### table: all samples count summary
```{r, summary-table}
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()
# save to outputs
write_csv(n_subbbasinSamples, "R-outputs_UBC-forWater-MSc_HMc/tables/summary_subbasins-SampleCount.csv", na = "NA") 

# how many of each type total?
# save values as objects to implant in text

# Grab samples
n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  summarise(number_of_samples = n()) %>% 
  summarize(total = sum(number_of_samples)) %>% 
  pull(total)

# Rack samples
n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% 
  summarize(total = sum(number_of_samples)) %>% 
  pull(total) 

# How many samples were collected overall
n_totalSamples <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                analysis == "DOC") %>%
  #group_by(sample_type) %>% 
  summarise(sample_count = n()) %>% 
  ungroup() %>% 
  pull(sample_count)


# 15 synoptic sites (including the install sites)
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>%
  group_by(site = forcats::fct_explicit_na(site)) %>% 
  summarise(grab_sample_count = n()) %>% 
  ungroup() 


# ----------------------------------
# make a summary table:
tibble::tibble(
  "synoptic samples outside of subbasin sites" = n_SynopticGrabs-n_installGrabSamples,
  "opportunistic grab samples" = n_totalSamples-(n_SynopticGrabs+n_installRackSamples),
  "sub-basin synoptic grab samples" = n_installGrabSamples,
  "sub-basin rack samples" = n_installRackSamples,
  "total" = n_totalSamples) %>% 
  pivot_longer(everything(),
               names_to = "sample category", values_to = "count") %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_AllSamples_Count.csv")

```

### table: DOC synoptic grabs by site Mean/Min/Max  
```{r, Grab-synoptic-table}
# synoptic grab samples DOC concs by site
a <- synopticfilter %>%
  filter(sample_type == "Grab") %>% 
  group_by(site) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T))  

# all together  
b <- synopticfilter %>% 
  filter(sample_type == "Grab") %>% 
  summarize(site = "total summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) 

# tag totals summary onto site summary
rbind(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Synoptic_grab-summary.csv", 
            col_names = T)
```

### table: DOC all sites, by sample_type Mean/Min/Max 
```{r, all-samples-together}
# synoptic samples DOC concs by site (Grab + Rack)
a <- synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped summary
b <- synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(sample_type) %>% 
  summarize(site = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, sample_type, count, DOCmean, DOCsd, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# full summary
c <- synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "total",
            sample_type = "all_G&R",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T))

# tag totals summary onto site summary
rbind(a, b, c) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Synoptic_all-summary.csv", col_names = T)

```

## SYNOPTIC

### plot: synoptic box, all sites
```{r, synoptic-all-sites}

# all sites
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>%  
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  geom_jitter(aes(fill = site), alpha = 0.6, shape = 21) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs(#caption = glue::glue("DOC concentrations in grab samples across 13 sites over 16 months (", {n_SynopticGrabs}, " samples)"), 
       x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_syn_13sites_boxplots.png")
```

### plot: synoptic ridge, all sites
```{r, synoptic-all-sites}

# all sites
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  ggplot(aes(y = fct_rev(site), x = NPOC_ppm)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(#caption = glue::glue("DOC concentrations in grab samples across thirteen sites over 16 months (", {n_SynopticGrabs}, " samples)"), 
       x = "DOC (mg/L)", y = "")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_syn_13sites_ridgeplots.png")
```
## SUBBASINS

### table: subbasin DOC trends by event & site
```{r}
# calculate trend
sixfilter %>% 
  filter(sample_type == "Rack", analysis != "QA-QC") %>%
  group_by(site, forcats::fct_explicit_na(event_ID) ) %>% 
  summarise(yint_DOC = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[1],
            slope = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[2],
            r_sq = summary(lm(formula = NPOC_ppm ~ sampleStage_cm))$r.squared,
            n = n(),
            range_DOC = max(NPOC_ppm, na.rm = TRUE) - min(NPOC_ppm, na.rm = TRUE),
            DOC_min = sample[which.min(NPOC_ppm)],
            DOC_max = sample[which.max(NPOC_ppm)],
            first_event = first(event_ID),
            last_event = last(event_ID),
            first_rack = first(sample, order_by = DateTime_sampled),
            last_rack = last(sample, order_by = DateTime_sampled)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_rack-trends_lm.csv")

```

### plot: subbasin DOC by time geom_smooth -- site & subbasin type
```{r DOC_overtime-by-site}

# at each of the six sites (DOC over time)
sixfilter %>% 
  mutate(site = factor(site, levels = c("Weeks", "CraggCrk", "ChrisCrk", "WestLeech", "LeechHead", "Tunnel"))) %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm)) +
  geom_point(aes(fill = site), size = 2, shape = 21, alpha = 0.4)+
  geom_smooth(aes(group = site, colour = site, linetype = site), se = FALSE)+
  scale_fill_brewer(palette="Dark2")+
  scale_colour_brewer(palette="Dark2")+
  scale_linetype_manual(values=c(4,4,3,3,1,1)) + 
  labs(y = "DOC (mg/L)", fill = "Sample type:",
       #caption = glue::glue("DOC over sixteen months (Oct 2018 to Feb 2020) in {n_installGrabSamples+n_installRackSamples} samples \n(Grab samples (n = {n_installGrabSamples}) and vertical Rack samples (n = {n_installRackSamples})"),
       x = "") +
  theme_bw() +
  guides(fill = guide_legend("Site:"),
         colour = guide_legend("Site:"),
         linetype = guide_legend("Site:"))+
  facet_wrap(~subbasin_type, ncol = 1, strip.position = "right", scales = "free_y")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "top",
        text = element_text(size = 12))+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")

ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin-types-overtime_loess.png")
#, width = 4, height = 6, units = "in") 

```

### VARIANCE 

#### plot: subbasins boxplot
```{r, subbasin-DOCspace}

# Boxplot with jitter scatter 
# DOC by site 
# grab and rack combined (all)
sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(#caption = glue::glue("DOC concentrations across six sub-basin sites over 16 months (", {n_installGrabSamples+n_installRackSamples}, " samples)"),
       x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin_boxplots.png")

```


#### within or among subbasins - DOC ranges  

Q: is the variance greater within each site or among all sites?

Ha: there is greater variance within each site compared to the variance among all sites 
Ho: the variance within each site is not greater than variance among all sites 

```{r}
# calculate range of DOC within each site and among all sites 

# subbasin samples DOC concs (Grab + Rack)
a <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(subbasin_type = first(subbasin_type),
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped by headwaters VS mainstem
b <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(subbasin_type) %>% 
  summarize(site = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, subbasin_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# full summary
c <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "Total",
            subbasin_type = "all",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# combine 
rbind(a, b, c) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-subbasin_variance-summary.csv", col_names = T)

```

#### Tunnel as outlet nested catchments - DOC ranges

Q: is the variance at the watershed outlet greater than the variance in each subbasin?

##### table: descriptive stats summary
```{r}
# calculate range of DOC within each site and between each site for subbasins
# this code was copied -- needs to be modified and updated

# separate Tunnel from mainstems in subbasin_type
a <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "headwater",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "outlet")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

# subbasin samples DOC concs (Grab + Rack)
b <- a %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(subbasin_type = first(subbasin_type),
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped by headwaters / mainstem / outlet
C <- a %>%
  filter(sample_type == "Grab" | sample_type == "Rack",
         subbasin_type != "outlet") %>% 
  group_by(subbasin_type) %>% 
  summarize(site = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, subbasin_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# combine 
rbind(b, C, c) %>%
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-subbasin_variance-tunnelIntegration.csv", col_names = T)

```


##### inferential/inductive stats

Levene's test: And alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 
```{r}
car::leveneTest(NPOC_ppm ~ site, data = sixfilter) # response ~ independent variable

# p-value is << 0.001 -- reject the null hypothesis of homogeneous variance and conclude there is significant difference between site variances.

# piece-wise compare to tunnel:

# 1 - 6 -- Reject that the variances are equal
v1 <- sixfilter %>%
  filter(site == "Weeks" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 2 - 6 -- Reject that the variances are equal
v2 <- sixfilter %>%
  filter(site == "ChrisCrk" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 3 - 6 -- Reject that the variances are equal 
v3 <- sixfilter %>%
  filter(site == "LeechHead" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 4 - 6 -- Reject that the variances are equal 
v4 <- sixfilter %>%
  filter(site == "CraggCrk" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 5 - 6 -- the variances are equal with 98%  
v5 <- sixfilter %>%
  filter(site == "WestLeech" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# write a table
# *** = 99.9% confidence, * = 95% confidence
tibble::tibble("sub-basin site compared to outlet" = c("Weeks ***", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech *"),
               "p-value" = c(v1, v2, v3, v4, v5)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-subbasin_variance-LeveneTest.csv", col_names = T)

```

### sample method
#### plot: G/R subbasin ridgeplot 
```{r, sample_type-ridgeplots}

# density ridge 
# wrap by sample_type
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = fct_rev(site))) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.4) +
  facet_wrap(~sample_type, ncol = 1, nrow = 2) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  labs(y = "",  
       #caption = glue::glue("Density distribution plots of DOC concentration by sample type and site \n       Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})"),
       x = "DOC (mg/L)") +
  theme(legend.position = "none",
        text = element_text(size = 12)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin-ridgeplot_GvsR.png")

```

#### table: subbasin DOC means+sd
```{r, summaryDOC-table}

# DOC summary table, Grabs and Racks combined
a <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

b <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "All (summary)",
            DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

bind_rows(a, b) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_subbasin_MeanMinMax.csv", col_names = TRUE)
```

# SEASONAL dynamics 

## seasonal counts
```{r}
# count dry season samples
n_dry_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "dry") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet season samples
n_wet_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "wet") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)


##  subbasin samples for which DOC and UV surrogate were measured ---

# count samples for both DOC and DOC_eq
n_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm)) %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

#count wet samples
n_wet_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "wet") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count dry samples 
n_dry_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "dry") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet = "first flush" samples 
n_ff_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "first flush") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)
```

## Synoptic seasonal

### plot: [1:1] NPOC/CDOM scatter 

```{r}
# scatterplot of DOC vs absorb-DOC by season
synopticfilter %>% 
  filter(!is.na(rain_seasons)) %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 3.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  ylim(0, 20) + 
  xlim(0, 20)+
  labs(y = "DOC estimate (ppm eqv.)",
       #caption = glue::glue("Plot of dissolved organic carbon concentrations measured as NPOC and estimated \n via UV-Vis spectroscopy, where the dotted line indicates best-fit (1:1) of equivalent  \n measurements by both techniques (n = {n_DOCCDOM}: wet = {n_wet_DOCCDOM}, first flush = {n_ff_DOCCDOM}, dry = {n_dry_DOCCDOM})."), 
       x = "DOC (ppm)")+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 12),
        legend.position = "top")

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_surrogate-NPOC.png",
       height = 7, width = 7, units = "in") 

```
additional text for caption: 
"Seasonal separation suggestes that characteristics of wet-season samples \n caused positive bias in absorbance-based DOC estimates, while dry-season sample \n characteristics lead to negative bias in DOC estimates based on UV-Vis absorption "


## Subbasin seasonal

### plot: dry-wet subbasin Box DOC
```{r}

sixfilter$rain_season <- fct_recode(sixfilter$rain_season, 
             'Dry season' = "dry", 
             'Wet season' = "wet") # new = old

# Boxplot with jitter scatter (DOC by season)
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(~rain_season, ncol = 2, nrow = 1) +  
  labs(x = "", y = "DOC (mg/L)")

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal-subbasin_boxplots.png", width = 6, height = 3.5, units = "in")

```

### plot: dry/wet subbasin Ridge seasonal DOC
```{r}
# density ridge plots (facet wrap by season)
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = fct_rev(site))) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.4) +
  facet_wrap(~rain_season, ncol = 1) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  labs(y = "",  
       #caption = glue::glue("Density distribution of DOC concentration by season (dry: n = {n_dry_samples}, wet: n = {n_wet_samples})"),
       x = "DOC (mg/L)") +
  theme(legend.position = "none") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal-subbasin-ridgeplot.png")

```


#### ?plot: [1:1] subbasin NPOC/CDOM
```{r, DOC-vs-CDOM-subbasins, echo = FALSE}
# six primary sites: DOC vs CDOM
sixfilter %>% 
  filter(sample_type == "Rack" | 
           sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm, fill = rain_seasons)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 2.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  facet_wrap(~site, nrow = 3, ncol = 2) +
  ylim(0, 20) + 
  xlim(0, 20)+
  labs(x = "DOC (ppm)",
       y = "DOC estimate (ppm eqv.)",
       caption = 
         glue::glue("Plot of dissolved organic carbon concentrations measured as NPOC and estimated \n via UV-Vis spectroscopy, where the dotted line indicates best-fit (1:1) of equivalent  \n measurements by both techniques"))+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 12),
        legend.position = "top")
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_subbasin-DOC-surrogate.png") 
```

### WET G/R count 

Rack and Grab sample wetseason sample count summary
```{r, wet-summary-table}
# how many of each sample_type are there at the 6 main sites?
a <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                rain_season == "Wet season") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()

b <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "Wet season") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

c <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "Wet season") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

# bind & save to outputs
bind_rows(a, b, c) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_wet-season_subbasins-SampleCount.csv")

# Grab samples
wet_n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "Wet season") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples)

# Rack samples
wet_n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "Wet season") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples) 

```

#### plot: wet G/R subbasin boxplot
```{r, DOC-space-time-boxplot}
# Boxplot with jitter scatter 
# site vs DOC
# facet wrap by sample type
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                rain_season == "Wet season") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1),
        text = element_text(size = 12)) +
  facet_wrap(~sample_type, ncol = 2, nrow = 1) +  
  labs(#caption = (glue::glue("DOC concentration by sample type and site during wet season \n Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})")), 
       x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin_GvsR_boxplot.png") 

```


#### table: wet G/R DOC means/min/max
```{r, summaryDOC-table}
# DOC summary table -- Grab vs Rack
sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack",
                rain_season == "Wet season") %>% 
  group_by(site, sample_type) %>% 
  summarize(DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_wet-season_subbasin_MeanMinMax-SampleType.csv", col_names = TRUE)

```

#### plot: rack DOC by event
```{r, rackDOC}
# rising limb
sixfilter %>% 
  filter(sample_type == "Rack") %>%
  filter(event_ID != "NA") %>% 
  group_by(site, event_ID) %>% 
  mutate(RisingLimb = NumberXtract(sample),
         RisingLimb = factor(RisingLimb, levels = c(1:9))) %>%
  ggplot(aes(x = DateTime_sampled, y = RisingLimb))+
  geom_point(aes(size = NPOC_ppm, colour = event_ID))+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 12),
        legend.position = "left")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  labs(y = "Sampling Rack Position", x = "", size = "DOC (ppm)", colour = "Rain Event")+
  facet_wrap(~site, ncol = 1,
             strip.position = "right",
             scales = "free_y")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_rack-trends.png", 
       height = 8, width = 6, unit ="in")

```


# SPECTRAL Indices

## plot: SUVA vs NPOC
```{r, spectral-plots, echo = FALSE}
# SUVA vs NPOC by season
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = SUVA)) +
  geom_jitter(aes(fill = rain_seasons), size = 3.5, shape = 21, alpha = 0.8) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  ylim(0.2, 4.5) +
  labs(y = expression(paste("SUVA "[254])),
       x = "DOC (mg/L)")+
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  guides(fill = guide_legend("Sample season:", override.aes = list(size = 3.5)))

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_SUVA-NPOC.png") 

```

## plot: E2:E3
```{r}
# E2:E3
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack",
                E2E3 < 15) %>% 
  ggplot(aes(x = NPOC_ppm, y = E2E3 )) +
  geom_jitter(aes(fill = rain_seasons), alpha = 0.8, size = 3.5, shape = 21) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  theme_bw() +
  theme(legend.position = "top")  
```

### questionable plots seasonal
```{r seasonal-plots, include=FALSE}
# Boxplot with jitter scatter 
synopticfilter %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  #scale_fill_brewer(palette="Accent") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90)) +
  facet_wrap(~rain_season, ncol = 2) +  
  labs(caption = "DOC concentrations in the Leech and two main tribs to the Sooke Reservoir", 
       x = "", y = "DOC (mg/L)")


# --- DOC facet wrap scatter plots ---
# I don't think these are good graphics
# Scatter main sites including sooke tribs
sampleresults %>% 
  dplyr::filter(site == "Weeks" |
                  site == "LeechHead" |
                  site == "ChrisCrk" |
                  site == "CraggCrk" |
                  site == "WestLeech"| 
                  site == "Tunnel" |
                  site == "Rithet" |
                  site == "Judge-crk", 
                analysis == "DOC", 
                sample_type == "Grab" & sample == "Grab") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks-out", "Chris-crk", "Leech-head", "Cragg-crk", "West-Leech", "Tunnel", "Rithet", "Judge-crk"))) %>% 
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm, fill = sample_type)) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21, size = 3) +
  theme_bw() +
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(caption = "DOC concentrations", x = "", y = "DOC (mg/L, as NPOC)") +
  theme(axis.text.x = element_text(angle = 90), legend.position = "none") +
  facet_wrap(~site, ncol = 2, nrow = 4)
# this is not a useful plot

```


# Nitrate & DOC
```{r}
# nitrate and DOC
synopticfilter %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 3.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  labs(x = "DOC (mg/L)", y = "nitrate (mg/L)", fill = "Sample type:")+
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
               parse = TRUE, rr.digits = 4)

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOC_scatter.png") 

```

## Nitrate & DOC_eq
```{r}
# nitrate and DOC
synopticfilter %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = DOCeq_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 3.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "bottom",
        text = element_text(size = 12)) +
  labs(x = "DOC eqiv. (estimated mg/L)", y = "nitrate (mg/L)", fill = "Sample type:",
       caption = "Estimated DOC and nitrate concentrations (via spectrophotometry)")+
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
               parse = TRUE, rr.digits = 4)

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOCeq_scatter.png") 

```

# METALS 

## plot: ug/L metals+DOC in solution
```{r}
# filter out the parameters with insufficient data
# plot DOC against metals concentrations 

# ug/L
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"
  ) %>%
  mutate(metal_parameters = factor(metal_parameters, # order as you want to see them in plots
                                   levels = c("Total Mercury (Hg)",
                                              "Total Iron (Fe)",
                                              "Total Manganese (Mn)",
                                              "Total Aluminum (Al)",
                                              "Total Barium (Ba)",
                                              "Total Copper (Cu)",
                                              "Total Arsenic (As)",
                                              "Total Strontium (Sr)",
                                              "Total Silicon (Si)"
                                              ))) %>% 
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE, colour = "red")+ ## to check MAC
  facet_wrap(~metal_parameters, scales = "free") +
  theme_bw() +
  theme(text = element_text(size = 12)) +
  labs(y = "metals concentrations (μg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_ugL_scatterplots.png")

```

## plot: mg/L metals+DOC in solution
```{r}
# mg/L
metalslab %>% 
  filter(metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)") %>%
  # order as you want to see them in plots
  mutate(metal_parameters = factor(metal_parameters, 
                                   levels = c("Total Magnesium (Mg)",
                                              "Total Potassium (K)",
                                              "Total Hardness (CaCO3)",
                                              "Total Calcium (Ca)",
                                              "Total Sodium (Na)"
                                              ))) %>%
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE)  ## to check MAC
  facet_wrap(~metal_parameters, scales = "free", ncol = 3) +
  theme_bw() +
  labs(y = "metals concentrations (mg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_mgL_scatterplots.png")
```

## table: correlation metals/DOC 
```{r}
# make a summary table of Metals regression
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"|
           metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)"
  ) %>%
  group_by(metal_parameters) %>% 
  filter(!is.na(metals_values)) %>% 
  summarise(unit = first(UNITS), 
            count = n(), 
            slope = coefficients(lm(formula = metals_values ~ NPOC_ppm))[2],
            yint_DOC = coefficients(lm(formula = metals_values ~ NPOC_ppm))[1],
            r_sq = summary(lm(formula = metals_values ~ NPOC_ppm))$r.squared) %>% 
  dplyr::arrange(desc(r_sq)) %>%  # strongest correlation to weakest
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/metals-doc_correlations.csv")

```

# TREATABILITY
```{r, message = FALSE}

# add date, timing, update site names
treatdat_UW <- treatdat_UW %>% 
  filter(source == "02") %>%   ## turns out, everything was included in second report
  mutate(day = substr(Sample_ID, 1, 2),
         site = substr(Sample_ID, 20, 22)) %>% 
  mutate(Date = case_when(
    day == "12" ~ as_date("2019-11-12"),
    day == "18" ~ as_date("2020-02-18"))) %>% 
  mutate(Collection = case_when(
    day == "12" ~ "Nov 2019",
    day == "18" ~ "Feb 2020")) %>% 
  mutate(Collection = factor(Collection, levels = c("Nov 2019", "Feb 2020"))) %>% 
  mutate(site = case_when(
    site == "DCP" ~ "Deception-res",
    site == "TUN" ~ "Tunnel",
    site == "JDG" ~ "Judge",
    site == "RTH" ~ "Rithet")) %>% 
  mutate(site = factor(site))

# isolate and join to my UBC lab results for treatability samples
treatdat <- sampleresults %>% 
  filter(sample == "Treatability") %>% 
  full_join(treatdat_UW, by = c("Date", "site")) %>% 
  mutate(site = factor(site))

# pivot long
treatdat_long <- treatdat_UW %>%
  filter(source == "02") %>% 
  select(-c(source, Sample_ID, pH, Turbidity_NTU, Zeta_Potential_mV, TBM, DBCM, MCAA, MBAA, DBAA, Free_Chlorine_Final_mgL, day, Date)) %>%
  tidyr::pivot_longer(names_to = "DBP", cols = c(THMs:TCAA),
                      values_to = "DBPfp_ugL") %>% 
  mutate(DBP = factor(DBP, levels = c(
    "THMs", "TCM", "BDCM", "HAAs", "DCAA", "TCAA")))
```

## plot; DOC/UV254 + DBP-FPs
```{r}
  
# plot DOC
a <- treatdat_long %>% 
  ggplot(aes(x = DOC_ppm, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 3.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "top")+
  labs(x = "DOC (ppm)", 
       y = "DBP-FPs (ppb)",
       colour = "Sampling site:")+
  guides(shape = FALSE,
         colour = guide_legend(nrow = 2))

# plot UV-254
b <- treatdat_long %>% 
  ggplot(aes(x = `UV254_cm-1`, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 3.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "top")+
  labs(x = "UV254 (abs/cm)", 
       y = "",
       shape = "Collection:")+
  guides(colour = FALSE,
         shape = guide_legend(nrow = 2))

# join side by side
cowplot::plot_grid(a, b, ncol = 2, align = "h") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/treatability_DOC-UV254.png",
         width = 7, height = 9, units = "in")
```


# pending: Random Forest
```{r}

```


  
# end
For some reason, RStudio truncates the session viewable... so here's some text to hold the place.
```{r}
# and an empty code chunk
```





























