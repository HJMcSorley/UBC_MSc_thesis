---
title: "Reproducible data analysis: thesis data visualization and analysis"
subtitle: "Pacific Maritime forWater Masters Project (NSERC forWater)"
author: "Hannah J McSorley"
output: bookdown::word_document2
---

# Data Visualization and Summaries
This RMD file generates summary tables and figures but is not included in the final bookdown product (tables and figures will be 
added to applicable sections).

# Set-up
```{r, processing-setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message = FALSE, fig.path="R-outputs_UBC-forWater-MSc_HMc/figures/")
# save figures to folder 'figures' in the 'R-outputs...' folder
```
## Packages
```{r, processing-packages, package.startup.message = FALSE}

# load packages
library(tidyverse)  # includes: dplyr, ggplot2, purrr, readr, forcats
library(lubridate)  # dates and times
library(broom)      # tidy up
library(glue)       # glue() is an object-integrated 'paste'-like function
library(knitr)      # tidy tables
library(viridis)    # nice colours for plots gradient fills
library(cowplot)    # add-on to ggplot for layout (nice grid)
library(gghighlight)# plot highlighting
library(ggpmisc)    # linear regression line values (ggplot)
library(ggpubr)     # Q-Q plots
library(car)        # stats: Companion to Applied Regression
library(randomForest)


```
## define colours
```{r vectorize-colours}
# use forWater defined colours (hexadecimal codes) for plots
# all colours defined by forWater admin, except 'MyOrange' which I made
forWater_colours1 <- c(MainBlue = "#09A4D2", 
                       MainGreen = "#668536", 
                       AccentBlue = "#5B99CC", 
                       DarkGrey = "#3B3838", 
                       MyOrange = "#f4AB0E")

# colours updated late 2019 :\
forWater_colours2 <- c(DeepBlue = "#0A5EA6", 
                       Green = "#648326", 
                       SkyBlue = "#62ACC8", 
                       Gray = "#535353", 
                       MyOrange = "#f4AB0E")

# colour-blind friendly pallet with grey (no black)
cbPalette <- c(grey = "#999999", 
               orange = "#E69F00", 
               lightblue = "#56B4E9", 
               green = "#009E73", 
               yellow = "#F0E442", 
               darkblue = "#0072B2", 
               red = "#D55E00", 
               pink = "#CC79A7")
```

## define functions
Define function for number extraction from alphanumerics.
```{r NumberXtract}
# define functions

# ---- Alpha-numeric extraction function ---- #
# from http://stla.github.io/stlapblog/posts/Numextract.html
NumberXtract <- function(alphnum){
  unlist(regmatches(alphnum, gregexpr("[[:digit:]]+\\.*[[:digit:]]*", alphnum)))
}

```

# Load datasets
```{r, input-files, message=FALSE}
# assign timezone
TZ <- "Etc/GMT+8"

# File Inputs
#Results of data wrangling (01) were saved as .csv files for tidy loading. 
# read all compiled data files & format

# results df
# compiled sample analyses results (wide)
# including DateTime of Rack sample collection
sampleresults <- read_csv("R-outputs_UBC-forWater-MSc_HMc/Results_complete.csv",
                          col_names = TRUE) %>%   
  mutate(trip = factor(trip, levels = c(0:23)),
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         rain_season = factor(rain_season),
         pseudoSUVA = pseudo254/NPOC_ppm,
         site = factor(site),
         event_ID = factor(event_ID, levels = c(1:18)))

# odyssey_data df
# stage data compiled with interval/trip
odyssey_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/Odyssey-RackCorrected-stage.csv",
                         col_names = TRUE) %>% 
  mutate(source = factor(source,
                         levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")),
         interval = factor(interval),
         event_ID = factor(event_ID),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ))

# precip_data df
# 2018-2020 weather station data compiled and formatted
precip_data <- read_csv("R-outputs_UBC-forWater-MSc_HMc/FWx-PrecipTemp_compiled.csv", 
                        col_names = TRUE,
                        col_types = list("c", "T", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d", "D", "d", "c")) %>% 
  mutate(StationName = factor(StationName),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         event_ID = factor(event_ID),
         rain_season = factor(rain_season))    

# LWSA mean precip data (FWx-mean-LWSA df)
# 2018-2020 weather station data compiled and formatted
LWSA_meanWx <- read_csv("R-outputs_UBC-forWater-MSc_HMc/FWx-Mean-LWSA_PrecipTemp.csv", 
                        col_names = TRUE,
                        col_types = list("T", "d", "d", "d", "d", "d", "d", "d", "d", "d", "d")) %>% 
  mutate(DateTime = lubridate::ymd_hms(DateTime, tz = TZ))    


# metalslab df
# metals sample analyses results with OC (long)
metalslab <- read_csv("R-outputs_UBC-forWater-MSc_HMc/metals-DOCgrab-sample_results-long.csv",
                      col_names = TRUE) %>% 
  mutate(Trip = factor(Trip),
         site = factor(site), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         metal_parameters = factor(Parameters))

# stage_samples
# subbasin sample results with stage, timestamps, and precip event ID
stage_samples <- read_csv("R-outputs_UBC-forWater-MSc_HMc/subbasins_matched-chemohydro-samples.csv",
                          col_names = TRUE) %>% 
  select(-c(stage_cm, ID, fillStage_cm)) %>% 
  mutate(trip = factor(trip, levels = c(1:23)),
         interval = factor(interval, levels = c(1:23)),
         site = factor(site,
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel")), 
         sample_type = factor(sample_type),
         sample = factor(sample),
         analysis = factor(analysis),
         two_seasons = factor(two_seasons),
         event_ID = factor(event_ID, levels = c(1:18)),
         DateTime = lubridate::ymd_hms(DateTime, tz = TZ),
         DateTime_sampled = lubridate::ymd_hms(DateTime_sampled, tz = TZ))

# rain events
events <- read_csv("R-outputs_UBC-forWater-MSc_HMc/Wx-RainEvents.csv", col_names = TRUE) %>% 
  mutate(ID = factor(ID, levels = c(1:18)))

```


# FWx (CC+MG) 

## plots: rain/snow/temp
At Chris Creek and Martin's Gulch FWx stations
```{r, FWx-plots}

# Rn15 is 15-minute rainfall (mm) 
# Prec_1 is hourly accummulated precipitation (mm)
# Temp is 15 minute intervals (degrees C)
rainplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n (mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)

# plot LWSA snow
snowplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  
  dplyr::summarise(daily_Snowmean = mean(SnowDep, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = "Snow accum.\n (m /day)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1)+
  theme(strip.background = NULL, 
        strip.text = element_blank()) 

# plot LWSA temperature
tempplot <- precip_data %>% 
  filter(StationName == "FWx Chris Creek" | StationName == "FWx Martins Gulch") %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(StationName, date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0, 
             linetype = "dotted") +
  labs(x = "", y = "Daily air temp\n(°C)") +
  theme_bw() +
  theme(text = element_text(size = 11),
        legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) +
  facet_wrap(~StationName, nrow = 1) +
  theme(strip.background = NULL, 
        strip.text = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1))


# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(rainplot, snowplot, tempplot, ncol = 1, align = "v",
                   rel_heights = c(1.25,1,1.75))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA.png",
       width = 6, height = 5, units = "in")
```


## table: annual precip, max snow, mean temp 

FWx means
```{r, FWx-table}
# precip_data summary
precip_data %>%
  mutate(Year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017) %>%   #, Year != 2020
  mutate(year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan-Feb 2020")) %>% 
  group_by(year, StationName) %>%
  summarise(total_precip_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDep, na.rm = TRUE), # not sure how to report
            annual_mean_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>% 
  dplyr::rename("Year" = year, 
                "station name" = StationName, 
                "annual precip. (mm)" = total_precip_mm,
                "max snow (m)" = max_snow_m,
                "mean air temp. (°C)" = annual_mean_temp, 
                "stdev air temp. (± °C)" = temp_sd,
                "mean max. temp. (°C)" = annual_min_temp,
                "mean min. temp. (°C)" = annual_max_temp) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-summary.csv")
```


## Mean Wx LWSA 

Arithmetic means from ChrisCrk and MartinsGulch.
*Too few stations to do Theissen polygons (2 point polygon = straight line) or isohyetal lines.*

```{r}
# add seasons to mean weather df
LWSA_meanWx <- precip_data %>% 
  select(DateTime, rain_season) %>% 
  right_join(LWSA_meanWx, by = "DateTime") %>% 
  mutate(Year = lubridate::year(DateTime),
         year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan-Feb 2020")) 

# check seasons visually
LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(date >= "2018-10-23") %>% 
  ggplot(aes(x = DateTime, y = Rn_1_mean)) +
  geom_col(aes(colour = rain_season)) +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme(text = element_text(size = 11),
        axis.text.x = element_text(angle = 60, hjust = 1))

```


### plots
```{r, mean-Wx_plot}
# mean precip plot
mean_rainplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain\n(mm/day)") +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) 

# plot LWSA snow
mean_snowplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Snowmean = mean(SnowDep_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Snowmean)) +
  geom_col(colour = "grey60") +
  labs(x = "", y = 'Snow depth\n(m/day)') +
  theme_bw() +
  theme(text = element_text(size = 11)) +
  theme(legend.position = "none")+
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months", labels = NULL)+  
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) 

# plot LWSA temperature
mean_tempplot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  group_by(date) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = 'Daily air temp\n(°C)') +
  theme_bw()+
  theme(text = element_text(size = 11)) +
  scale_x_date(date_breaks = "4 months", date_minor_breaks = "1 months")+
  theme(legend.position = "none")+
  gghighlight::gghighlight(date >= "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838")) 

# LWSA Wx -- stack precip and temp with cowplot
cowplot::plot_grid(mean_rainplot, mean_snowplot, mean_tempplot, 
                   ncol = 1, align = "vh", greedy = FALSE,
                   rel_heights = c(1,1,1))

# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_LWSA-means.png", 
       width = 6, 
       height = 5, 
       units = "in")
```

### table 
```{r, table_mean-FWx_summary}
# mean weather summary
precip_data %>%
  mutate(Year = lubridate::year(DateTime),
         year = case_when(Year == 2018 ~ "2018",
                          Year == 2019 ~ "2019",
                          Year == 2020 ~ "Jan & Feb 2020")) %>% 
  filter(StationName != "Survey Mtn Wx", 
         Year != 2017) %>%  
  group_by(Year, year, StationName) %>%
  summarise(total_rain_mm = sum(Rn15, na.rm = TRUE),
            max_snow_m = max(SnowDep, na.rm = TRUE),
            annual_temp = mean(Temp, na.rm = TRUE),
            temp_sd = sd(Temp, na.rm = TRUE),
            annual_min_temp = min(TMin, na.rm = TRUE),
            annual_max_temp = max(TMax, na.rm = TRUE)) %>%
  ungroup() %>% 
  group_by(year) %>%
  summarise(mean_rain_mm = mean(total_rain_mm, na.rm = TRUE),
            sd_rain_mm = sd(total_rain_mm, na.rm = TRUE),
            mean_max_snow_m = mean(max_snow_m, na.rm = TRUE),
            annual_mean_temp = mean(annual_temp, na.rm = TRUE),
            temp_sd = sd(annual_temp, na.rm = TRUE),
            annual_min_temp2 = mean(annual_min_temp, na.rm = TRUE),
            #TMin_sd = sd(annual_min_temp, na.rm = TRUE),
            annual_max_temp2 = mean(annual_max_temp, na.rm = TRUE)) %>%
            #TMax_sd = sd(annual_max_temp, na.rm = TRUE)) %>% 
  ungroup() %>% 
  dplyr::rename("mean annual rain (mm)" = mean_rain_mm,
                "stdev rain. (±mm)" = sd_rain_mm,
                "mean snow accum. (m)" = mean_max_snow_m,
                "mean temp. (°C)" = annual_mean_temp, 
                "st.dev temp. (±°C)" = temp_sd,
                "min. temp. (°C)" = annual_min_temp2,
                #"stdev TMin. (±°C)" = TMin_sd,
                "max. temp. (°C)" = annual_max_temp2) %>%
                #"stdev TMax. (±°C)" = TMax_sd) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA-mean-summary.csv")
```

#### questionable objects
```{r, Wx-Stn_summaries}
# I want to know precip totals over the study period
# by month and by season
# use rain to define storm events

# calculate total rainfall at each of the wx-stns (survey mountain went in in late)
rn_MScTotal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime),
         year = lubridate::year(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx",
         date >= "2018-10-23") %>% 
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_MSc_mm = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup() 

# rain seasons rainfalls
rn_seasonal <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(month = lubridate::month(DateTime),
         year = lubridate::year(DateTime)) %>%
  group_by(StationName, year, rain_season) %>% 
  dplyr::summarise(rain_seasonal = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# annual rainfalls
rn_annual <- precip_data %>% 
  mutate(date = lubridate::as_date(DateTime)) %>% 
  filter(StationName != "Survey Mtn Wx", date >= "2018-10-23") %>% 
  mutate(year = lubridate::year(DateTime)) %>%
  group_by(StationName, year) %>% 
  dplyr::summarise(rain_monthly = sum(Rn_1, na.rm = TRUE)) %>% 
  ungroup()

# water-year rainfalls (Oct 1 - Sept 30)
rn_wateryr <- LWSA_meanWx %>%
  mutate(month = lubridate::month(DateTime),
         water_year = case_when(
           between(month, 1, 9) & Year == "2018" ~ "2018",
           between(month, 10, 12) & Year == "2018" ~ "2019",
           between(month, 1, 9) & Year == "2019" ~ "2019",
           between(month, 10, 12) & Year == "2019" ~ "2020",
           between(month, 1, 9) & Year == "2020" ~ "2020")) %>%
  #filter(water_year != "2018") %>% 
  group_by(water_year) %>% 
  dplyr::summarise(annual_precip_mm = sum(Rn_1_mean, na.rm = TRUE),
                   max_snow_m = max(SnowDep_mean, na.rm = TRUE),
                   annual_mean_temp = mean(Temp_mean, na.rm = TRUE),
                   temp_sd = sd(Temp_mean, na.rm = TRUE)) %>% 
  ungroup() #%>% 
  #write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/Wx_LWSA_WaterYear-summary.csv", col_names = TRUE)

```

### table of Events
```{r}
events %>% 
  mutate('Start date' = format(as.POSIXct(StartDate), "%Y-%m-%d %H:%M"), 
         'End date' = format(as.POSIXct(EndDate), "%Y-%m-%d %H:%M")) %>% 
  select(stormnum, ID, 'Start date', 'End date', rain) %>% 
  dplyr::rename('Storm number' = stormnum,
                'Major event no.' = ID,
                'Rain (mm)' = rain) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Events.csv",
            col_names = TRUE) 
```

# Malahat Wx

Longer data record from the Malahat weather station (for comparison).

```
#{r, malahat-wx}

# malahat weather
malahat_data <- read_csv("R-inputs_UBC-forWater-MSc_HMc/Malahat_station-data-11596.csv", 
                         skip = 16,
                         col_names = TRUE,
                         col_types = list("f", "c", "d", "d")) %>% 
  mutate(Datetime = lubridate::ymd_hms(Datetime, tz = TZ, truncated = 1),
         Date = lubridate::as_date(Datetime),
         Year = lubridate::year(Datetime))

# summary: malahat_data precip + air temp 
malahat_data %>% 
  filter(Analysis == "Precipitation Amount (mm)", 
         between(Year, 2014, 2019)) %>% 
  group_by(Year) %>%
  summarise(total_precip = sum(Value, na.rm = TRUE)) %>% 
  ungroup() %>% 
  right_join((
    malahat_data %>% 
      dplyr::filter(Analysis == "Temperature (Mean) (celsius)", 
                    between(Year, 2014, 2019)) %>% 
      group_by(Year) %>%
      summarise(annual_mean_temp = mean(Value, na.rm = TRUE),
                temp_sd = sd(Value))) %>% 
      ungroup(), 
    by = "Year") %>%
  filter(Year != "2013", Year != "2020") %>% 
  dplyr::rename("year" = Year, 
                "annual precip. (mm)" = total_precip, 
                "mean air temp. (°C)" = annual_mean_temp, 
                "std.dev. (± °C)" = temp_sd) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_malahat-summary.csv")

```

## plots: Malahat Wx
```
#{r, malahat-plots}
# plots
# plot malahat rain and highlight my study period
malahat_rn <- malahat_data %>% 
  filter(Analysis == "Precipitation Amount (mm)") %>% 
  ggplot(aes(x = Datetime, y = Value)) +
  geom_col(colour = "#09A4D2") +
  scale_y_reverse() +
  labs(x = "", y = "Rain (mm/day)") +
  theme_bw() +
  scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
  theme(legend.position = "none") +
  gghighlight::gghighlight(Datetime > "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))

# plot malahat temperature and highlight my study period
malahat_temp <- malahat_data %>% 
  filter(Analysis == "Temperature (Mean) (celsius)") %>% 
  ggplot(aes(x = Datetime, y = Value)) +
  geom_line(colour = "#f4AB0E") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = expression('Mean daily air temp ('*~degree*C*')')) +
  theme_bw() +
  scale_x_datetime(date_breaks = "12 months", date_minor_breaks = "1 months")+
  gghighlight::gghighlight(Datetime > "2018-10-23",
                           unhighlighted_params = list(colour = "#3B3838"))

# stack with cowplot
cowplot::plot_grid(malahat_rn, malahat_temp, ncol = 1, align = "v")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat.png")

```

## t-test -- Wilcoxon's rank sum test

### lag-years
```
#{r}
# check for normality
# The central limit theorem:
## sampling distribution tends to be normal if the sample is large enough (n > 30)
malahat_data %>% 
  filter(!is.na(Value),
         Analysis == "Precipitation Amount (mm)" | Analysis == "Temperature (Mean) (celsius)") %>% 
  group_by(Year, Analysis) %>% 
  summarise(count = n())
# could assume normal distribution because each year has daily values (>>30)

# visually check for normality 
malahat_data %>% 
  filter(Year != 2013, Year != 2020,  # incomplete data sets
         !is.na(Value),
         Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                 color = "Year", 
                 palette = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" ),
                 facet.by = "Analysis")
## Precipitation was not normally distributed (seasonality)

# tidy wilcoxon tests: lag-year 
## solution from:
## https://stackoverflow.com/questions/32477863/r-run-t-test-on-previous-years-by-group-using-dplyr

# t-test comparing each year to the last year
Malahat_test_lagyear <- malahat_data %>% 
  filter(Year != 2013, Year != 2020,  # incomplete data sets
         !is.na(Value)) %>%  # remove missing values 
  select(Analysis, Year) %>% 
  arrange(Analysis, Year) %>% 
  distinct() %>% 
  group_by(Analysis) %>% 
  mutate(lag_year = lag(Year)) %>% 
  filter(!is.na(lag_year)) %>% 
  group_by(Analysis, Year, lag_year) %>% 
  do(tidy(wilcox.test(malahat_data$Value[malahat_data$Year == .$Year & malahat_data$Analysis == .$Analysis],
                 malahat_data$Value[malahat_data$Year == .$lag_year & malahat_data$Analysis == .$Analysis])))

# identify signficantly different years
Malahat_test_lagyear %>% 
  filter(p.value < 0.10)

# 2015 was an incredible drought year, so it makes sense that 2015-2016 would differ
  
```

### Wx pre & during MSc
```
#{r}
# group
malahat_test_data <- malahat_data %>% 
  filter(!is.na(Value),
         Analysis != "Surface Snow Depth (Point) (cm)") %>% ## insufficient data 
  mutate(set = case_when(Year == 2016 | Year == 2017 ~ "pre",
                         Year == 2018 | Year == 2019 ~ "MSc"),
         set = as_factor(set)) %>% 
  filter(!is.na(set)) 

# subset for tests
pre_MSc <- malahat_test_data %>% filter(set == "pre")
MSc <- malahat_test_data %>% filter(set == "MSc")
```

#### plots
```
#{r}
# plot sets
malahat_test_data %>% 
  ggplot(aes(x = set, y = Value, fill = set))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    labels = c(pre = "2016-2017", MSc = "2018-2019"),
                    name = "Year span")+
  labs(y = "value", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~Analysis)
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Malahat_plot_pre-MSc-2years.png")

# looks like precip is not normally distributed because of seasons
# Tests for normality 
# Pre-MSc
pre_MSc %>% 
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                 color = "Year", palette = c("#648326", "#f4AB0E", "#62ACC8", "#535353"),
                 facet.by = "Analysis")

# during
MSc %>% 
  mutate(Year = as_factor(Year)) %>% 
  ggpubr::ggqqplot(data = ., x = "Value", 
                 color = "Year", palette = c("#648326", "#f4AB0E"),
                 facet.by = "Analysis")

```

#### tests
```
#{r}
# t-tests or Wilcoxon to compare 2014-2017 to 2018-2019
# ggpubr::ggqqplot() to check for normality
## if points fall approximately along the reference line, assume normality

# t-tests for temperature (normally distributed)
# Wilcoxon signed rank test for Precip (not normally distributed)
# make a tibble for tidiness
# note: snow data was only available 2017-2019 -- not included
Malahat_testMSc_Wx <- bind_rows(
  # rain
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Precipitation Amount (mm)"], 
              MSc$Value[MSc$Analysis == "Precipitation Amount (mm)"],
              )) %>% 
    mutate(Parameter = "rain"),
  # air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Mean) (celsius)"], 
              MSc$Value[MSc$Analysis == "Temperature (Mean) (celsius)"])) %>% 
    mutate(Parameter = "temp_mean"),
  # Min air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Min.) (celsius)"], 
              MSc$Value[MSc$Analysis == "Temperature (Min.) (celsius)"])) %>% 
    mutate(Parameter = "temp_min"),
  # Max air temp
  tidy(wilcox.test(pre_MSc$Value[pre_MSc$Analysis == "Temperature (Max.) (celsius)"], 
              MSc$Value[MSc$Analysis == "Temperature (Max.) (celsius)"])) %>% 
    mutate(Parameter = "temp_max")) %>% 
  # pull values of interest to summarize
  select(Parameter, p.value) %>% 
  mutate(signicance = case_when(p.value < 0.01 ~ "at 99%",
                                p.value < 0.05 ~ "at 95%",
                                p.value < 0.1 ~ "at 90%",
                                p.value > 0.1 ~ "NA")) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Wx_Malahat_Wilcoxtest_pre-MSc-2years.csv")

# interpretation
# null hypothesis = both means are equal
# if the p-value is less than the significance level critical value, reject the null hypothesis 

```

# Mega Plot: FWx+RiverStage

Plot stage, precip, temp and snow and then create a one-page mega plot of all combined.

```{r, Wx-stage-megas-plots}

# 1 plot snow
# LWSA (Chris crk and Martin's Gulch FWx stns)
subasin_snow_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Snow = factor("Snow")) %>% 
  group_by(date, Snow) %>% 
  dplyr::summarise(daily_meansnow = mean(SnowDep_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_meansnow)) +
  geom_col(aes(colour = Snow), colour = "grey40") +
  labs(x = "", y = "m /day") +
  theme_bw() +
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Snow, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0.5,0,0,0), "cm")) # top, right, bottom, left
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_snow-plot_subbasins.png")

# 2 plot 
# LWSA temp for the same time span
subasin_meantemp_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Temp = factor("Temp")) %>% 
  group_by(date, Temp) %>% 
  dplyr::summarise(daily_Tmean = mean(Temp_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_Tmean)) +
  geom_line(aes(colour = Temp), colour = "#E69F00") +
  geom_hline(yintercept = 0,
             linetype = "dotted") +
  labs(x = "", y = "°C /day") +
  theme_bw() +
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Temp, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_temp-plot_subbasins.png")

# 3 plot rainfall
# mean LWSA rain for study period
subbasin_meanrain_plot <- LWSA_meanWx %>% 
  mutate(date = lubridate::as_date(DateTime),
         Rain = factor("Rain")) %>% 
  group_by(date, Rain) %>% 
  dplyr::summarise(daily_rn = sum(Rn_1_mean, na.rm = TRUE)) %>% 
  ungroup()  %>% 
  filter(date >= "2018-10-24") %>% 
  ggplot(aes(x = date, y = daily_rn)) +
  geom_col(aes(colour = Rain), colour = "#0072B2") +
  scale_y_reverse() +
  labs(x = "", y = "mm /day") +
  theme_bw() +
  #scale_x_date(date_breaks = "1.5 months", date_labels = "%Y-%m")+ # use to check alignment 
  scale_x_date(date_breaks = "1.5 months", labels = NULL)+  # remove axis labels when you're confident
  facet_wrap(~Rain, ncol = 1, 
             strip.position = "right") +
  theme(text = element_text(size = 12),
        legend.position = "none",
        strip.background = element_blank(),
        axis.text.x = element_text(angle = 90),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_rain-plot_subbasins.png")

# 4 plot stage
# stage at each of the subbasins
stage_plot <- odyssey_data %>% 
  filter(DateTime >= "2018-10-24 00:00:00") %>% 
  ggplot(aes(x = DateTime, y = corr_stage_cm))+
  geom_line(colour = "#09A4D2")+
  theme_bw()+
  facet_wrap(~source, ncol = 1, 
             scales = "free_y",
             strip.position = "right")+
  labs(y = "River Stage (cm)", x = "")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1),
        plot.margin = unit(c(0,0,0,0), "cm")) # top, right, bottom, left)
# save plot
# ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx_Stage-plot_subbasins.png")

# mega-plot!! 
# stack snow, temp, precip and stage with cowplot::plot_grid
cowplot::plot_grid(subasin_snow_plot, subasin_meantemp_plot, subbasin_meanrain_plot, stage_plot, 
                   ncol = 1, 
                   axis = "l", 
                   align = "v",
                   rel_heights = c(1,1,1,5))
# save megaplot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage_subbasins_megaplot.png",
       width = 8.5,
       height = 11,
       units = "in")

```


# River Stage 

## plot: normalized stage 

The stage was normalized (min-max norm) to compare relative rises
```{r, stage-line-plots}

# plot stage, lines over time
odyssey_data %>%
  group_by(source) %>% 
  dplyr::mutate(norm_stg = (stage_cm-min(stage_cm))/(max(stage_cm)-min(stage_cm))) %>% 
  ggplot(aes(x = DateTime, y = norm_stg))+
  geom_line(colour = "#0072B2") +
  #viridis::scale_colour_viridis(discrete = TRUE) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(y = "River stage (normalized)", x = "") +
  facet_wrap(~source, ncol = 1, strip.position = "right")  
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_subbasins.png",
       width = 8.5,
       height = 11,
       units = "in")
```

## plot: norm stage ridge
```{r, ridgey}

# plot stage, density ridges -- could be cool -- fix aesthetics 
odyssey_data %>%
  group_by(source) %>% 
  dplyr::mutate(norm_stg = (stage_cm-min(stage_cm))/(max(stage_cm)-min(stage_cm))) %>% 
  ggplot(aes(x = norm_stg, y = fct_rev(source)))+
  ggridges::geom_density_ridges(aes(fill = source), alpha = 0.6) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  scale_y_discrete() +
  theme(legend.position = "none")+
  labs(x = "River Stage (normalized)", y = "",
       caption = "Density distribution of min-max normalized stage at six subbasins")
# save plot
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Wx-stage-normalized_ridgeplot_subbasins.png")

```

# Samples

## augment dataframes
```{r, mutate}
# create a "first-flush category in rain_season(s)
sampleresults <- sampleresults %>% 
  select(-c(ID, DateTime)) %>% 
  mutate(rain_seasons = case_when(
    event_ID %in% 1:8 ~ "wet",   
    Date %within% interval("2019-01-21", "2019-03-01") ~ "wet",
    Date %within% interval("2019-03-01", "2019-04-30") ~ "wet", # snow",
    Date %within% interval("2019-05-01", "2019-09-11") ~ "dry",
    event_ID == 9 ~ "first flush",
    event_ID %in% 10:18 ~ "wet")) %>% 
  mutate(rain_season = as.character(rain_season))

# fill in any gaps and save as factors
sampleresults <- within(sampleresults, 
                        rain_seasons <- ifelse(
                          is.na(rain_seasons), rain_season, rain_seasons)) %>% 
  mutate(rain_season = factor(rain_season),
         rain_seasons = factor(rain_seasons))

# further group sites
sampleresults <- sampleresults %>% 
  mutate(site_type = case_when(
    site == "Weeks" ~ "subbasin",   
    site == "ChrisCrk" ~ "subbasin",
    site == "LeechHead"  ~ "subbasin",
    site == "CraggCrk" ~ "subbasin",
    site == "WestLeech" ~ "subbasin",
    site == "Tunnel" ~ "subbasin",
    site == "Lab" ~ "LabQAQC",
    TRUE ~ "synoptic")) %>% 
  mutate(site_type = factor(site_type))

```


## subset df + sample counts
```{r, subsetting-campaign}
# primary synoptic sampling sites (n > 1)
# 15 sites total

# how many synoptic samples were grabbed?
# save value as object to implant in text
n_SynopticGrabs <- sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab") %>%
  group_by(site = forcats::fct_explicit_na(site)) %>% 
  summarise(grab_sample_count = n()) %>% 
  filter(grab_sample_count > 2) %>% 
  mutate(what = "synoptic grab count") %>% 
  ungroup() %>%  # drop the following code to see samples by sites
  group_by(what) %>% 
  summarise(total = sum(grab_sample_count)) %>% 
  pull(total)

# create a subset dataframe for the synoptically sampled sites for tidier calling
synopticfilter <- sampleresults %>% 
  filter(# subbasin sites 
    site == "Weeks"|
      site == "ChrisCrk"|
      site == "LeechHead"|
      site == "CraggCrk"|
      site == "WestLeech"|
      site == "Tunnel"|
      # other sites
      site == "Rithet"|
      site == "Lazar"|
      site == "Jarvis"|
      site == "Judge"|
      site == "Leech-downstreamconf"|
      site == "Boneyard"|
      #site == "Deception-crk"|  ## only two samples
      #site == "West-Jordan"| ## only two samples
      site == "Deception-res",
    analysis == "DOC"
  ) %>% 
  mutate(site = factor(site, # order as you want to see them in plots
                       levels = c("West-Jordan", "Weeks", "ChrisCrk", "LeechHead", "Jarvis", "Lazar", "CraggCrk", "WestLeech", "Leech-downstreamconf", "Tunnel", "Rithet", "Judge", "Deception-res", "Deception-crk", "Boneyard" ))) 
# rename funky names
synopticfilter$site <- synopticfilter$site %>% 
  plyr::revalue(c("Leech-downstreamconf" = "Leech-Beach",  ## old = new
                  "Jarvis" = "Jarvis-crk",
                  "Judge" = "Judge-crk", 
                  "Lazar" = "Lazar-crk", 
                  #"West-Jordan" = "W.Jordan-Trib",
                  #"Deception-crk" = "Deception-Gluch",
                  "Rithet" = "Rithet-crk"))
# ---

# create a subset dataframe for the six install sites for tidier calling
sixfilter <- sampleresults %>% 
  filter(site_type == "subbasin",
         analysis == "DOC") %>% 
  mutate(site = factor(site, levels = 
                         c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech","Tunnel")))

# further categorize site_type
sixfilter <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "headwater",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "mainstem")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

```

## tables: 

### count sample summary
```{r, summary-table}
# how many of each sample_type are there at the 6 main sites?
n_subbbasinSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()
# save to outputs
write_csv(n_subbbasinSamples, "R-outputs_UBC-forWater-MSc_HMc/tables/summary_subbasins-SampleCount.csv", na = "NA") 

# how many of each type total?
# save values as objects to implant in text

# Grab samples
n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  summarise(number_of_samples = n()) %>% 
  summarize(total = sum(number_of_samples)) %>% 
  pull(total)

# Rack samples
n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack") %>% 
  summarise(number_of_samples = n()) %>% 
  summarize(total = sum(number_of_samples)) %>% 
  pull(total) 

# How many samples were collected overall
n_totalSamples <- sampleresults %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                analysis == "DOC") %>%
  #group_by(sample_type) %>% 
  summarise(sample_count = n()) %>% 
  ungroup() %>% 
  pull(sample_count)


# 15 synoptic sites (including the install sites)
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>%
  group_by(site = forcats::fct_explicit_na(site)) %>% 
  summarise(grab_sample_count = n()) %>% 
  ungroup() 


# ----------------------------------
# make a summary table:
tibble::tibble(
  "synoptic samples outside of subbasin sites" = n_SynopticGrabs-n_installGrabSamples,
  "opportunistic grab samples" = n_totalSamples-(n_SynopticGrabs+n_installRackSamples),
  "sub-basin synoptic grab samples" = n_installGrabSamples,
  "sub-basin rack samples" = n_installRackSamples,
  "total" = n_totalSamples) %>% 
  pivot_longer(everything(),
               names_to = "sample category", values_to = "count") %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_AllSamples_Count.csv")

```

### DOC synoptic grabs by site Mean/Min/Max  
```{r, Grab-synoptic-table}
# synoptic grab samples DOC concs by site
a <- synopticfilter %>%
  filter(sample_type == "Grab") %>% 
  group_by(site) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T))  

# all together  
b <- synopticfilter %>% 
  filter(sample_type == "Grab") %>% 
  summarize(site = "total summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) 

# tag totals summary onto site summary
rbind(a, b) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Synoptic_grab-summary.csv", 
            col_names = T)
```

### DOC all sites, by sample_type Mean/Min/Max 
```{r, all-samples-together}
# synoptic samples DOC concs by site (Grab + Rack)
a <- synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, sample_type) %>% 
  summarize(count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped summary
b <- synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(sample_type) %>% 
  summarize(site = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, sample_type, count, DOCmean, DOCsd, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# full summary
c <- synopticfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "total",
            sample_type = "all_G&R",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T))

# tag totals summary onto site summary
rbind(a, b, c) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-Synoptic_all-summary.csv", col_names = T)

```


## plot: synoptic box, all sites
```{r, synoptic-all-sites}

# all sites
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>%  
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  geom_jitter(aes(fill = site), alpha = 0.6, shape = 21) +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12),
        axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs(#caption = glue::glue("DOC concentrations in grab samples across 13 sites over 16 months (", {n_SynopticGrabs}, " samples)"), 
       x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_syn_13sites_boxplots.png")
```

## plot: synoptic ridge, all sites
```{r, synoptic-all-sites}

# all sites
synopticfilter %>% 
  dplyr::filter(sample_type == "Grab") %>% 
  ggplot(aes(y = fct_rev(site), x = NPOC_ppm)) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.5) +
  scale_fill_viridis(discrete = TRUE)+
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(#caption = glue::glue("DOC concentrations in grab samples across thirteen sites over 16 months (", {n_SynopticGrabs}, " samples)"), 
       x = "DOC (mg/L)", y = "")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_syn_13sites_ridgeplots.png")
```

## Subbasin DOC summaries

### table: subbasin DOC means+sd
```{r, summaryDOC-table}

# DOC summary table, Grabs and Racks combined
a <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

b <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "All (summary)",
            DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

bind_rows(a, b) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_subbasin_MeanMinMax.csv", col_names = TRUE)
```


#### table: DOC trends by event & site
```{r}
# calculate trend
sixfilter %>% 
  filter(sample_type == "Rack", analysis != "QA-QC") %>%
  group_by(site, forcats::fct_explicit_na(event_ID) ) %>% 
  summarise(yint_DOC = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[1],
            slope = coefficients(lm(formula = NPOC_ppm ~ sampleStage_cm))[2],
            r_sq = summary(lm(formula = NPOC_ppm ~ sampleStage_cm))$r.squared,
            n = n(),
            range_DOC = max(NPOC_ppm, na.rm = TRUE) - min(NPOC_ppm, na.rm = TRUE),
            DOC_min = sample[which.min(NPOC_ppm)],
            DOC_max = sample[which.max(NPOC_ppm)],
            first_event = first(event_ID),
            last_event = last(event_ID),
            first_rack = first(sample, order_by = DateTime_sampled),
            last_rack = last(sample, order_by = DateTime_sampled)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_rack-trends_lm.csv")

```

### plot: DOC/time lm() site & subbasin type
```{r DOC_overtime-by-site}

# at each of the six sites (DOC over time)
sixfilter %>% 
  mutate(site = factor(site, levels = c("Weeks", "CraggCrk", "ChrisCrk", "WestLeech", "LeechHead", "Tunnel"))) %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm)) +
  geom_point(aes(fill = site), size = 2, shape = 21, alpha = 0.4)+
  geom_smooth(aes(group = site, colour = site, linetype = site), se = FALSE)+
  scale_fill_brewer(palette="Dark2")+
  scale_colour_brewer(palette="Dark2")+
  scale_linetype_manual(values=c(4,4,3,3,1,1)) + 
  labs(y = "DOC (mg/L)", fill = "Sample type:",
       #caption = glue::glue("DOC over sixteen months (Oct 2018 to Feb 2020) in {n_installGrabSamples+n_installRackSamples} samples \n(Grab samples (n = {n_installGrabSamples}) and vertical Rack samples (n = {n_installRackSamples})"),
       x = "") +
  theme_bw() +
  guides(fill = guide_legend("Site:"),
         colour = guide_legend("Site:"),
         linetype = guide_legend("Site:"))+
  facet_wrap(~subbasin_type, ncol = 1, strip.position = "right", scales = "free_y")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "top",
        text = element_text(size = 12))+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")

ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin-types-overtime_loess.png")
#, width = 4, height = 6, units = "in") 

```
### Variance 

#### 1: within or among - DOC ranges  

Q: is the variance greater within each site or among all sites?

Ha: there is greater variance within each site compared to the variance among all sites 
Ho: the variance within each site is not greater than variance among all sites 

```{r}
# calculate range of DOC within each site and among all sites 

# subbasin samples DOC concs (Grab + Rack)
a <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(subbasin_type = first(subbasin_type),
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped by headwaters VS mainstem
b <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(subbasin_type) %>% 
  summarize(site = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, subbasin_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# full summary
c <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  summarize(site = "Total",
            subbasin_type = "all",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# combine 
rbind(a, b, c) %>% 
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-subbasin_variance-summary.csv", col_names = T)

```

#### 2: Tunnel integration - DOC ranges

Q: is the variance at the watershed outlet greater than the variance in each subbasin?

##### table: descriptive stats summary
```{r}
# calculate range of DOC within each site and between each site for subbasins
# this code was copied -- needs to be modified and updated

# separate Tunnel from mainstems in subbasin_type
a <- sixfilter %>% 
  mutate(subbasin_type = case_when(
    site == "Weeks" ~ "headwater",   
    site == "ChrisCrk" ~ "headwater",
    site == "LeechHead"  ~ "headwater",
    site == "CraggCrk" ~ "mainstem",
    site == "WestLeech" ~ "mainstem",
    site == "Tunnel" ~ "outlet")) %>% 
  mutate(subbasin_type = factor(subbasin_type))

# subbasin samples DOC concs (Grab + Rack)
b <- a %>%
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site) %>% 
  summarize(subbasin_type = first(subbasin_type),
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T), 
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup()

# grouped by headwaters / mainstem / outlet
C <- a %>%
  filter(sample_type == "Grab" | sample_type == "Rack",
         subbasin_type != "outlet") %>% 
  group_by(subbasin_type) %>% 
  summarize(site = "summary",
            count = n(), 
            DOCmean = mean(NPOC_ppm, na.rm = T), 
            DOCsd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOCsd/DOCmean)*100,
            DOCmin = min(NPOC_ppm, na.rm = T), 
            DOCmedian = median(NPOC_ppm, na.rm = T), 
            DOCmax = max(NPOC_ppm, na.rm = T)) %>% 
  select(site, subbasin_type, count, DOCmean, DOCsd, RSD, DOCmin, DOCmedian, DOCmax) %>%  # reorder
  ungroup()

# combine 
rbind(b, C, c) %>%
  write_csv(path = "R-outputs_UBC-forWater-MSc_HMc/tables/DOC-subbasin_variance-tunnelIntegration.csv", col_names = T)

```

##### inferential/inductive stats

Levene's test: And alternative to the Bartlett’s test that is less sensitive to departures from normality. Test for Ho, homoscedasticity (homogeneity of variance). If p-value is less than significance level (e.g. 0.05 for 95% confidence) the differences are unlikely to have been caused randomly and it's concluded that there is a difference between variances.

Ha: at least two subbasins have different variances 
Ho: the variances are equal (there is no difference in the range observed among each site 
```{r}
car::leveneTest(NPOC_ppm ~ site, data = sixfilter) # response ~ independent variable

# p-value is << 0.001 -- reject the null hypothesis of homogeneous variance and conclude there is significant difference between site variances.

# piece-wise compare to tunnel:

# 1 - 6 -- Reject that the variances are equal
v1 <- sixfilter %>%
  filter(site == "Weeks" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 2 - 6 -- Reject that the variances are equal
v2 <- sixfilter %>%
  filter(site == "ChrisCrk" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 3 - 6 -- Reject that the variances are equal 
v3 <- sixfilter %>%
  filter(site == "LeechHead" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 4 - 6 -- Reject that the variances are equal 
v4 <- sixfilter %>%
  filter(site == "CraggCrk" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# 5 - 6 -- the variances are equal with 98%  
v5 <- sixfilter %>%
  filter(site == "WestLeech" |
           site == "Tunnel") %>% 
  car::leveneTest(NPOC_ppm ~ site, data = .) %>% 
  pull("Pr(>F)"[[1]]) %>% 
  first()

# write a table
# *** = 99.9% confidence, * = 95% confidence
tibble::tibble("sub-basin site compared to outlet" = c("Weeks ***", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech *"),
               "p-value" = c(v1, v2, v3, v4, v5)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC-subbasin_variance-LeveneTest.csv", col_names = T)

```

#### plot: subbasins boxplot
```{r, subbasin-DOCspace}

# Boxplot with jitter scatter 
# DOC by site 
# grab and rack combined (all)
sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        text = element_text(size = 12)) +
  labs(#caption = glue::glue("DOC concentrations across six sub-basin sites over 16 months (", {n_installGrabSamples+n_installRackSamples}, " samples)"),
       x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin_boxplots.png")

```

## Seasonal dynamics 

### seasonal sample count
```{r}
# count dry season samples
n_dry_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "dry") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet season samples
n_wet_samples <- sixfilter %>%
  filter(sample_type == "Grab" | sample_type == "Rack", rain_season == "wet") %>% 
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)


##  subbasin samples for which DOC and UV surrogate were measured ---

# count samples for both DOC and DOC_eq
n_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm)) %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

#count wet samples
n_wet_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "wet") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count dry samples 
n_dry_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "dry") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)

# count wet = "first flush" samples 
n_ff_DOCCDOM <- synopticfilter %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab",
                !is.na(DOCeq_ppm),
                rain_seasons == "first flush") %>%
  group_by(site) %>% 
  summarise(samples = n()) %>% 
  ungroup() %>% 
  summarise(total = sum(samples)) %>% 
  pull(total)
```

### plot: boxplot subbasin seasonal DOC
```{r}

sixfilter$rain_season <- fct_recode(sixfilter$rain_season, 
             'Dry season' = "dry", 
             'Wet season' = "wet") # new = old

# Boxplot with jitter scatter (DOC by season)
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(~rain_season, ncol = 2, nrow = 1) +  
  labs(x = "", y = "DOC (mg/L)")

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal-subbasin_boxplots.png", width = 6, height = 3.5, units = "in")

```

### plot: Ridge subbasin seasonal DOC
```{r}
# density ridge plots (facet wrap by season)
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = fct_rev(site))) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.4) +
  facet_wrap(~rain_season, ncol = 1) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  labs(y = "",  
       #caption = glue::glue("Density distribution of DOC concentration by season (dry: n = {n_dry_samples}, wet: n = {n_wet_samples})"),
       x = "DOC (mg/L)") +
  theme(legend.position = "none") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal-subbasin-ridgeplot.png")

```

### plot NPOC/CDOM scatter 1:1 plot
```{r}
# scatterplot of DOC vs absorb-DOC by season
synopticfilter %>% 
  filter(!is.na(rain_seasons)) %>% 
  dplyr::filter(sample_type == "Rack" | 
                  sample_type == "Grab" & sample == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 3.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  ylim(0, 20) + 
  xlim(0, 20)+
  labs(y = "DOC estimate (ppm eqv.)",
       #caption = glue::glue("Plot of dissolved organic carbon concentrations measured as NPOC and estimated \n via UV-Vis spectroscopy, where the dotted line indicates best-fit (1:1) of equivalent  \n measurements by both techniques (n = {n_DOCCDOM}: wet = {n_wet_DOCCDOM}, first flush = {n_ff_DOCCDOM}, dry = {n_dry_DOCCDOM})."), 
       x = "DOC (ppm)")+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 12),
        legend.position = "top")

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_surrogate-NPOC.png",
       height = 7, width = 7, units = "in") 

```
additional text for caption: 
"Seasonal separation suggestes that characteristics of wet-season samples \n caused positive bias in absorbance-based DOC estimates, while dry-season sample \n characteristics lead to negative bias in DOC estimates based on UV-Vis absorption "

#### ?plot: subbasin NPOC/CDOM
```{r, DOC-vs-CDOM-subbasins, echo = FALSE}
# six primary sites: DOC vs CDOM
sixfilter %>% 
  filter(sample_type == "Rack" | 
           sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = DOCeq_ppm, fill = rain_seasons)) +
  geom_point(aes(fill = rain_seasons, shape = rain_seasons), size = 2.5, alpha = 0.8)+
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  scale_shape_manual(values = c("wet"=23, "first flush"=22, "dry"=21))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()+
  facet_wrap(~site, nrow = 3, ncol = 2) +
  ylim(0, 20) + 
  xlim(0, 20)+
  labs(x = "DOC (ppm)",
       y = "DOC estimate (ppm eqv.)",
       caption = 
         glue::glue("Plot of dissolved organic carbon concentrations measured as NPOC and estimated \n via UV-Vis spectroscopy, where the dotted line indicates best-fit (1:1) of equivalent  \n measurements by both techniques"))+
  guides(fill = guide_legend("Sample season:"),
         shape = guide_legend("Sample season:"))+
  theme(text = element_text(size = 12),
        legend.position = "top")
#ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_subbasin-DOC-surrogate.png") 
```
# Spectral Indices

## plot: SUVA vs NPOC
```{r, spectral-plots, echo = FALSE}
# SUVA vs NPOC by season
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = SUVA)) +
  geom_jitter(aes(fill = rain_seasons), size = 3.5, shape = 21, alpha = 0.8) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  ylim(0.2, 4.5) +
  labs(y = expression(paste("SUVA "[254])),
       x = "DOC (mg/L)")+
  theme_bw() +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  guides(fill = guide_legend("Sample season:", override.aes = list(size = 3.5)))

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_seasonal_SUVA-NPOC.png") 

```

## plot: E2:E3
```{r}
# E2:E3
sampleresults %>% 
  dplyr::filter(analysis == "DOC", 
                sample_type == "Grab" | sample_type == "Rack",
                E2E3 < 15) %>% 
  ggplot(aes(x = NPOC_ppm, y = E2E3 )) +
  geom_jitter(aes(fill = rain_seasons), alpha = 0.8, size = 3.5, shape = 21) +
  scale_fill_manual(values = c("wet" = forWater_colours2[["SkyBlue"]], 
                               "dry" = forWater_colours2[["MyOrange"]], 
                               "first flush" = cbPalette[["grey"]]))+
  theme_bw() +
  theme(legend.position = "top")  
```

## questionable

```{r, seasonal-plots, include=FALSE}
# Boxplot with jitter scatter 
synopticfilter %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  #scale_fill_brewer(palette="Accent") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90)) +
  facet_wrap(~rain_season, ncol = 2) +  
  labs(caption = "DOC concentrations in the Leech and two main tribs to the Sooke Reservoir", 
       x = "", y = "DOC (mg/L)")


# --- DOC facet wrap scatter plots ---
# I don't think these are good graphics
# Scatter main sites including sooke tribs
sampleresults %>% 
  dplyr::filter(site == "Weeks" |
                  site == "LeechHead" |
                  site == "ChrisCrk" |
                  site == "CraggCrk" |
                  site == "WestLeech"| 
                  site == "Tunnel" |
                  site == "Rithet" |
                  site == "Judge-crk", 
                analysis == "DOC", 
                sample_type == "Grab" & sample == "Grab") %>% 
  mutate(site = factor(site, 
                       levels = c("Weeks-out", "Chris-crk", "Leech-head", "Cragg-crk", "West-Leech", "Tunnel", "Rithet", "Judge-crk"))) %>% 
  ggplot(aes(x = DateTime_sampled, y = NPOC_ppm, fill = sample_type)) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21, size = 3) +
  theme_bw() +
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(caption = "DOC concentrations", x = "", y = "DOC (mg/L, as NPOC)") +
  theme(axis.text.x = element_text(angle = 90), legend.position = "none") +
  facet_wrap(~site, ncol = 2, nrow = 4)
# this is not a useful plot

```


### table: subbasin seasonal DOC
```{r}
# summary table
sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  group_by(site, rain_season) %>% 
  summarize(count = n(),
            DOC_mean = mean(NPOC_ppm),
            DOC_sd = sd(NPOC_ppm),
            RSD = (DOC_sd/DOC_mean)*100) %>% 
  ungroup() %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/subbasin-seasonal-DOC.csv")

# for when you read this into results
#  knitr::kable(digits = 1, col.names = c("season", "site", "mean DOC (mg/L)", "std.dev. (± mg/L)", "RSD (%)"), label = "DOC concentrations by season at the six main sites")
```

# Racks and Grabs - wet season

## wet count sample summary
```{r, wet-summary-table}
# how many of each sample_type are there at the 6 main sites?
a <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                rain_season == "Wet season") %>%
  group_by(site, sample_type) %>%   
  summarise(number_of_samples = n()) %>% 
  ungroup()

b <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "Wet season") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

c <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "Wet season") %>% 
  group_by(sample_type) %>% 
  summarise(site = "TOTAL", 
            number_of_samples = n()) %>% 
  select(site, sample_type, number_of_samples)

# bind & save to outputs
bind_rows(a, b, c) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/summary_wet-season_subbasins-SampleCount.csv")

# Grab samples
wet_n_installGrabSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Grab",
                rain_season == "Wet season") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples)

# Rack samples
wet_n_installRackSamples <- sixfilter %>% 
  dplyr::filter(sample_type == "Rack",
                rain_season == "Wet season") %>% 
  summarise(number_of_samples = n()) %>% 
  pull(number_of_samples) 

```


### plot: wet G/R subbasin boxplot
```{r, DOC-space-time-boxplot}
# Boxplot with jitter scatter 
# site vs DOC
# facet wrap by sample type
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab",
                rain_season == "Wet season") %>% 
  ggplot(aes(x = site, y = NPOC_ppm, fill = site)) +
  geom_boxplot(alpha = 0.5) +
  geom_jitter(aes(fill = site), alpha = 0.8, shape = 21) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1),
        text = element_text(size = 12)) +
  facet_wrap(~sample_type, ncol = 2, nrow = 1) +  
  labs(#caption = (glue::glue("DOC concentration by sample type and site during wet season \n Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})")), 
       x = "", y = "DOC (mg/L)")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin_GvsR_boxplot.png") 

```


### table: G/R DOC means+sd min/max
```{r, summaryDOC-table}
# DOC summary table -- Grab vs Rack
sixfilter %>% 
  dplyr::filter(sample_type == "Grab" | sample_type == "Rack",
                rain_season == "Wet season") %>% 
  group_by(site, sample_type) %>% 
  summarize(DOC_mean = mean(NPOC_ppm, na.rm = T),
            DOC_sd = sd(NPOC_ppm, na.rm = T),
            RSD = (DOC_sd/DOC_mean)*100,
            DOC_min = min(NPOC_ppm, na.rm = T),
            DOC_max = max(NPOC_ppm, na.rm = T)) %>% 
  ungroup() %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/DOC_wet-season_subbasin_MeanMinMax-SampleType.csv", col_names = TRUE)

```

### plot: subbasin ridgeplot (G/R)
```{r, sample_type-ridgeplots}

# density ridge 
# wrap by sample_type
sixfilter %>% 
  dplyr::filter(sample_type == "Rack" | sample_type == "Grab") %>%
  ggplot(aes(x = NPOC_ppm, y = fct_rev(site))) +
  ggridges::geom_density_ridges(aes(fill = site), alpha = 0.4) +
  facet_wrap(~sample_type, ncol = 1, nrow = 2) +
  scale_fill_brewer(palette="Set2") +
  theme_bw() +
  labs(y = "",  
       #caption = glue::glue("Density distribution plots of DOC concentration by sample type and site \n       Grab samples (n =  {n_installGrabSamples} ) and rising limb Rack samples (n =  {n_installRackSamples})"),
       x = "DOC (mg/L)") +
  theme(legend.position = "none",
        text = element_text(size = 12)) 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_subbasin-ridgeplot_GvsR.png")

```

### Rack DOC trends
#### plot: rack DOC by event
```{r, rackDOC}
# rising limb
sixfilter %>% 
  filter(sample_type == "Rack") %>%
  filter(event_ID != "NA") %>% 
  group_by(site, event_ID) %>% 
  mutate(RisingLimb = NumberXtract(sample),
         RisingLimb = factor(RisingLimb, levels = c(1:9))) %>%
  ggplot(aes(x = DateTime_sampled, y = RisingLimb))+
  geom_point(aes(size = NPOC_ppm, colour = event_ID))+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 12),
        legend.position = "left")+
  scale_x_datetime(date_labels = "%Y %b %d",
                   date_breaks = "2 months",
                   date_minor_breaks = "1 months")+
  labs(y = "Sampling Rack Position", x = "", size = "DOC (ppm)", colour = "Rain Event")+
  facet_wrap(~site, ncol = 1,
             strip.position = "right",
             scales = "free_y")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/DOC_rack-trends.png", 
       height = 8, width = 6, unit ="in")

```




# Nitrate & DOC
```{r}
# nitrate and DOC
synopticfilter %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = NPOC_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 3.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "top",
        text = element_text(size = 12)) +
  labs(x = "DOC (mg/L)", y = "nitrate (mg/L)", fill = "Sample type:")+
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
               parse = TRUE, rr.digits = 4)

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOC_scatter.png") 

```

## Nitrate & DOC_eq
```{r}
# nitrate and DOC
synopticfilter %>% 
  filter(sample_type == "Grab" | sample_type == "Rack") %>% 
  ggplot(aes(x = DOCeq_ppm, y = NO3.Neq_ppm)) +  
  geom_point(aes(fill = sample_type), shape = 21, size = 3.5) +
  theme_bw() +
  scale_fill_brewer(palette="Set2") +
  theme(legend.position = "bottom",
        text = element_text(size = 12)) +
  labs(x = "DOC eqiv. (estimated mg/L)", y = "nitrate (mg/L)", fill = "Sample type:",
       caption = "Estimated DOC and nitrate concentrations (via spectrophotometry)")+
  stat_poly_eq(formula = y ~ x, 
               aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
               parse = TRUE, rr.digits = 4)

#save image
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/nitrate-DOCeq_scatter.png") 

```

# Metals 

## plots: metals+DOC in solution

### ug/L
```{r}
# filter out the parameters with insufficient data
# plot DOC against metals concentrations 

# ug/L
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"
  ) %>%
  mutate(metal_parameters = factor(metal_parameters, # order as you want to see them in plots
                                   levels = c("Total Mercury (Hg)",
                                              "Total Iron (Fe)",
                                              "Total Manganese (Mn)",
                                              "Total Aluminum (Al)",
                                              "Total Barium (Ba)",
                                              "Total Copper (Cu)",
                                              "Total Arsenic (As)",
                                              "Total Strontium (Sr)",
                                              "Total Silicon (Si)"
                                              ))) %>% 
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE, colour = "red")+ ## to check MAC
  facet_wrap(~metal_parameters, scales = "free") +
  theme_bw() +
  theme(text = element_text(size = 12)) +
  labs(y = "metals concentrations (μg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_ugL_scatterplots.png")

```

### mg/L
```{r}
# mg/L
metalslab %>% 
  filter(metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)") %>%
  # order as you want to see them in plots
  mutate(metal_parameters = factor(metal_parameters, 
                                   levels = c("Total Magnesium (Mg)",
                                              "Total Potassium (K)",
                                              "Total Hardness (CaCO3)",
                                              "Total Calcium (Ca)",
                                              "Total Sodium (Na)"
                                              ))) %>%
  ggplot(aes(x = NPOC_ppm, y = metals_values)) +
  geom_jitter() +
  #geom_hline(aes(yintercept = MAC), na.rm = TRUE)  ## to check MAC
  facet_wrap(~metal_parameters, scales = "free", ncol = 3) +
  theme_bw() +
  labs(y = "metals concentrations (mg/L)", x = "DOC (mg/L)") +
  stat_smooth(method=lm, formula = y ~ x, colour = forWater_colours2[1]) #+
## to get equations include these lines:
#stat_poly_eq(formula = y ~ x, 
#              aes(label = paste0("atop(",..eq.label.., ",", ..rr.label.., ")")), 
#              parse = TRUE, rr.digits = 4) #+

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/metals-doc_mgL_scatterplots.png")
```

## table: correlation metals/DOC 
```{r}
# make a summary table of Metals regression
metalslab %>% 
  filter(metal_parameters == "Total Aluminum (Al)"|
           metal_parameters == "Total Barium (Ba)"|
           metal_parameters == "Total Copper (Cu)"|
           metal_parameters == "Total Iron (Fe)"|
           metal_parameters == "Total Mercury (Hg)"|
           metal_parameters == "Total Manganese (Mn)"|
           metal_parameters == "Total Silicon (Si)"|
           metal_parameters == "Total Arsenic (As)"|
           metal_parameters == "Total Strontium (Sr)"|
           metal_parameters == "Total Magnesium (Mg)"|
           metal_parameters == "Total Calcium (Ca)" |
           metal_parameters == "Total Potassium (K)"|
           metal_parameters == "Total Sodium (Na)"|
           metal_parameters == "Total Hardness (CaCO3)"
  ) %>%
  group_by(metal_parameters) %>% 
  filter(!is.na(metals_values)) %>% 
  summarise(unit = first(UNITS), 
            count = n(), 
            slope = coefficients(lm(formula = metals_values ~ NPOC_ppm))[2],
            yint_DOC = coefficients(lm(formula = metals_values ~ NPOC_ppm))[1],
            r_sq = summary(lm(formula = metals_values ~ NPOC_ppm))$r.squared) %>% 
  dplyr::arrange(desc(r_sq)) %>%  # strongest correlation to weakest
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/metals-doc_correlations.csv")

```

# Treatability
```{r, message = FALSE}
# read in data
treatdat_UW <- 
  list.files("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", pattern = "*.csv") %>% 
  set_names(str_extract(., "([0-9]{2,}+)")) %>%
  purrr::map_dfr(~ read_csv(
    file.path("R-inputs_UBC-forWater-MSc_HMc/Treatability-results_UW/", .), 
    col_names = TRUE, skip = 15), .id = "source") 

# add date, timing, update site names
treatdat_UW <- treatdat_UW %>% 
  filter(source == "02") %>%   ## turns out, everything was included in second report
  mutate(day = substr(Sample_ID, 1, 2),
         site = substr(Sample_ID, 20, 22)) %>% 
  mutate(Date = case_when(
    day == "12" ~ as_date("2019-11-12"),
    day == "18" ~ as_date("2020-02-18"))) %>% 
  mutate(Collection = case_when(
    day == "12" ~ "Nov 2019",
    day == "18" ~ "Feb 2020")) %>% 
  mutate(Collection = factor(Collection, levels = c("Nov 2019", "Feb 2020"))) %>% 
  mutate(site = case_when(
    site == "DCP" ~ "Deception-res",
    site == "TUN" ~ "Tunnel",
    site == "JDG" ~ "Judge",
    site == "RTH" ~ "Rithet")) %>% 
  mutate(site = factor(site))

# isolate and join to my UBC lab results for treatability samples
treatdat <- sampleresults %>% 
  filter(sample == "Treatability") %>% 
  full_join(treatdat_UW, by = c("Date", "site")) %>% 
  mutate(site = factor(site))

# pivot long
treatdat_long <- treatdat_UW %>%
  filter(source == "02") %>% 
  select(-c(source, Sample_ID, pH, Turbidity_NTU, Zeta_Potential_mV, TBM, DBCM, MCAA, MBAA, DBAA, Free_Chlorine_Final_mgL, day, Date)) %>%
  tidyr::pivot_longer(names_to = "DBP", cols = c(THMs:TCAA),
                      values_to = "DBPfp_ugL") %>% 
  mutate(DBP = factor(DBP, levels = c(
    "THMs", "TCM", "BDCM", "HAAs", "DCAA", "TCAA")))
```

## plot DOC/UV254 + DBP-FPs
```{r}
  
# plot DOC
a <- treatdat_long %>% 
  ggplot(aes(x = DOC_ppm, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 3.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "top")+
  labs(x = "DOC (ppm)", 
       y = "DBP-FPs (ppb)",
       colour = "Sampling site:")+
  guides(shape = FALSE,
         colour = guide_legend(nrow = 2))

# plot UV-254
b <- treatdat_long %>% 
  ggplot(aes(x = `UV254_cm-1`, y = DBPfp_ugL))+
  geom_point(aes(colour = site,
                 shape = Collection),
             size = 3.5)+
  scale_colour_brewer(palette="Set2") +
  theme_bw()+
  facet_wrap(~DBP, strip.position = "right", ncol = 1,
             scales = "free_y")+
  theme(text = element_text(size = 11),
        legend.position = "top")+
  labs(x = "UV254 (abs/cm)", 
       y = "",
       shape = "Collection:")+
  guides(colour = FALSE,
         shape = guide_legend(nrow = 2))

# join side by side
cowplot::plot_grid(a, b, ncol = 2, align = "h") 
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/treatability_DOC-UV254.png",
         width = 7, height = 9, units = "in")
```
# Hobo TidbiTs
```{r, message=FALSE, warning=FALSE}
# read in data
Hobo_dat <- 
  list.files("R-inputs_UBC-forWater-MSc_HMc/Hobo_TidbiTs/", pattern = "*.csv") %>% 
  set_names(str_extract(., "([a-z]+\\-*[a-z]*\\_[a-z]+)")) %>%
  purrr::map_dfr(~read_csv(
    file.path("R-inputs_UBC-forWater-MSc_HMc/Hobo_TidbiTs/", .), 
    skip = 2,  ## column names contain unique SN values 
    col_names = FALSE), # don'tread names, it prevents row binding
    .id = "source") 

# simplify
Hobo_dat <- Hobo_dat[1:4] # drop serial numbers
names(Hobo_dat) <- c("source", "num", "DateTime", "Temp_C")  # rename, less verbose

# update
Hobo <- Hobo_dat %>% 
  filter(!is.na(Temp_C)) %>%   ## NA values occurred on the day loggers were removed from field
  filter(Temp_C < 35.0) %>% 
  mutate(DateTime = lubridate::mdy_hms(DateTime),
         location = stringr::str_sub(source, -3, -1),
         location = factor(location),
         site = substr(source, 1, 3), # first three characters
         site = case_when(
           site == "chr" ~ "ChrisCrk",
           site == "cra" ~ "CraggCrk",
           site == "lee" ~ "LeechHead",
           site == "tun" ~ "Tunnel",
           site == "wes" ~ "WestLeech",
           site == "wks" ~ "Weeks"),
         site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) 
# rename position from wet/dry to water/air
Hobo$location <- fct_recode(Hobo$location, air = "dry", water = "wet")

```

## plot: Hobo temp
```{r}
Hobo %>% 
  mutate(date = as_date(DateTime)) %>%
  group_by(site, location, date) %>% 
  summarise(T_daily = mean(Temp_C)) %>% 
  ggplot(aes(x = date, y = T_daily))+
  geom_line(aes(colour = location), size = 1.5)+
  scale_color_manual(values = c("water" = forWater_colours2[["SkyBlue"]], 
                                "air" = forWater_colours2[["MyOrange"]]))+
  theme_bw()+
  geom_hline(yintercept = 0, linetype = "dashed", colour = "darkgrey", size = 0.7)+
  geom_hline(yintercept = 7, linetype = "dashed", colour = "darkgrey", size = 0.7)+
  facet_wrap(~site, ncol = 1,
             strip.position = "right")+
  labs(x = "", y = "Mean Daily Temperature (°C)",
       colour = "Temperature measurement:")+
  theme(legend.position = "top", 
        text = element_text(size = 12))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_x_date(date_labels = "%Y %b %d",
                   date_breaks = "1.5 months",
                   date_minor_breaks = "1 months")
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/Hobo-TidbiTs_daily-temps.png", 
       width = 6, height = 7, units = "in")
```

## table: Hobo temp
```{r}
Hobo %>%
  mutate(month = lubridate::month(DateTime, label = TRUE),
         year = lubridate::year(DateTime)) %>% 
  group_by(site, location, year, month) %>% 
  summarise(T_mean = mean(Temp_C),
            T_sd = sd(Temp_C)) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/Hobo-TidbiTs_monthly-site_summary.csv")
```

# QA-QC 
```{r}
QAQC <- sampleresults %>% 
  filter(sample_type == "QA-QC")

# subset for calibration verification 
# extract cal-ver concentrations from sample name (with 'str_extract()')
calver <- QAQC %>% 
  filter(site == "Lab") %>% 
  select(c(site, sample_type, sample, analysis, NPOC_ppm, SAC254_Abs.m, DOCeq_ppm)) %>% 
  mutate(cal_ver = str_extract(sample, "([0-9]{1,}+\\.[0-9]{1,}+)"),
         cal_ver = as.numeric(cal_ver),
         rn = row_number(cal_ver)) %>% 
  mutate(sample_type = case_when(
    !is.na(cal_ver) ~ "cal_ver",
    is.na(cal_ver) ~ "RO" )) 
```


## Hold-time experiments (Tunnel rack)
```{r}
# three cycles of hold time experiments (A, B , C)
# each time, 5 samples were collected (grab) while 5 were placed on the rack with siphon lids
# the held samples (rack) were collected later after sitting out
# compare results between fresh and held samples

# subset QAQC df for holdtime samples
# extract set and rep values and group sets
HT <- QAQC %>% 
  filter(site == "Tunnel",
         !is.na(NPOC_ppm)) %>% 
  select(-c(sampleStage_cm, fillStage_cm, corr_stage_cm)) %>% 
  mutate(HoldTime_set = substr(sample, 10, 10),
         HoldTime_rep = substr(sample, 11, 12),
         HoldTime_group = case_when(
           HoldTime_rep == c(1:5) ~ "G",  # 'fresh' grab samples
           HoldTime_rep == c(6:10) ~ "R", # 'held' rack samples
         )) %>% 
 # groups
  mutate(group = case_when(
    HoldTime_set == "A" & HoldTime_rep == c(1:5) ~ "AG", # first set grabs, 2019-10-12 (trip 16)
    HoldTime_set == "A" & HoldTime_rep == c(6:10) ~ "AR", # first set rack, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(1:5) ~ "BG", # second set grabs, 2019-10-23 (trip 17)
    HoldTime_set == "B" & HoldTime_rep == c(6:10) ~ "BR", # second set rack, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(1:5) ~ "CG", # third set grabs, 2019-11-12 (trip 18)
    HoldTime_set == "C" & HoldTime_rep == c(6:10) ~ "CR", # third set rack, 2019-12-16 (trip 20)
  ))

# how many days passed between collecting fresh and held samples?
a <- HT %>% 
  group_by(HoldTime_set, Date) %>% 
  summarise(group = first(group)) %>%
  group_by(HoldTime_set) %>% 
  summarize(lapse = diff.Date(Date))
# mutate lapse to HT df
HT <- full_join(HT, a, by = "HoldTime_set") %>% 
  mutate(HoldTime_set = factor(HoldTime_set, levels = c("A", "B", "C")), 
         HoldTime_rep= as_factor(HoldTime_rep), 
         HoldTime_group = as_factor(HoldTime_group), 
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR"))) %>% 
  mutate(HT_set_labels = HoldTime_set,
         HT_group_labels = HoldTime_group)

# add labels for plots
HT$HT_group_labels <- fct_recode(HT$HT_group_labels, Fresh = "G", Held = "R")
HT$HT_set_labels <- fct_recode(HT$HT_set_labels, "A (11 days)" = "A", "B (20 days)" = "B", "C (34 days)" = "C")


# ---
# Join Tunnel HOBO TidbiT data with HT data
# combine Temperature with hold-time
HT_Hobo <- Hobo %>% 
  filter(site == "Tunnel",
         location == "air") %>% 
  mutate(Date = as_date(DateTime)) %>% 
  full_join(HT, by = c("site", "Date")) %>% 
  mutate(site = factor(site),
         group = factor(group, levels = c("AG", "AR", "BG", "BR", "CG", "CR")))

```

### HT plots
```{r}
# plot sets
a <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = NPOC_ppm, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "DOC (mg/L)", x = "")+
  theme_bw()+
  theme(legend.position = "top")+
  facet_wrap(~HoldTime_set)

b <- HT %>% 
  ggplot(aes(x = HT_group_labels, y = SAC254_Abs.m, fill = HT_group_labels))+
  geom_boxplot(alpha = 0.8)+
  scale_fill_manual(values = c(forWater_colours2[["SkyBlue"]], forWater_colours2[["MyOrange"]]),
                    #labels = c(G = "Fresh", R = "Held"),
                    name = "Hold-time sample type:")+
  labs(y = "UV abs at 254nm (a.u.)", x = "")+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~HoldTime_set)
  
cowplot::plot_grid(a, b, align = "v", ncol = 1, rel_heights = c(2, 1.6))  
# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HT-exp_stat-boxplots.png")


# ---
# Visual Tests NPOC for normality 
# density
HT %>% 
  ggplot(aes(NPOC_ppm))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "NPOC_ppm",
                 color = "HoldTime_set")
# A = not normal
# B = not normal
# C = not normal

# Tests UV254 abs for normality 
HT %>% 
  ggplot(aes(SAC254_Abs.m))+
  geom_density(aes(colour = HoldTime_set))+
  theme_bw()+
  theme(legend.position = "none")+
  facet_wrap(~ HoldTime_set,
             nrow = 3,
             scales = "free_y")
# QQ plot
ggpubr::ggqqplot(data = HT, x = "SAC254_Abs.m",
                 color = "HoldTime_set")
# A = not normal
# B = not normal
# C = not normal

```

### HT tests: Wilcoxon
```{r}
# Wilcoxon tests (not normally distributed + small sample size)
# null hypothesis: there is no difference between the means
# alternative hypothesis: the difference between means is significant 
# p-value > 0.05 --> cannot reject null hypothesis
# p-value < 0.05 --> reject the null hypothesis 

# tests
# note -- this could probably be a function for tidiness
HT_Wilcoxon_tests <- bind_rows(
  ## NPOC ---
  # set A
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "AG"], HT$NPOC_ppm[HT$group == "AR"])) %>% 
    mutate(Set = "A", Analysis = "NPOC_ppm"),
  # set B 
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "BG"], HT$NPOC_ppm[HT$group == "BR"])) %>% 
    mutate(Set = "B", Analysis = "NPOC_ppm"),
  # set C
  tidy(wilcox.test(HT$NPOC_ppm[HT$group == "CG"], HT$NPOC_ppm[HT$group == "CR"])) %>% 
    mutate(Set = "C", Analysis = "NPOC_ppm"),
  ## UV-254 ---
  # set A
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "AG"], HT$SAC254_Abs.m[HT$group == "AR"])) %>% 
    mutate(Set = "A", Analysis = "SAC254_Abs.m"),
  # set B
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "BG"], HT$SAC254_Abs.m[HT$group == "BR"])) %>% 
    mutate(Set = "B", Analysis = "SAC254_Abs.m"),
  # set C
  tidy(wilcox.test(HT$SAC254_Abs.m[HT$group == "CG"], HT$SAC254_Abs.m[HT$group == "CR"])) %>% 
    mutate(Set = "C", Analysis = "SAC254_Abs.m")) %>% 
  select(Analysis, Set, p.value) %>% 
  # pull values of interest to summarize
  mutate(sig.diff = case_when(p.value < 0.01 ~ "at 99%",
                                p.value < 0.05 ~ "at 95%",
                                p.value < 0.1 ~ "at 90%",
                                p.value > 0.1 ~ "NA")) 

## view
# HT_Wilcoxon_tests
# cowplot::plot_grid(a, b, align = "v", ncol = 1, rel_heights = c(2, 1.6)) 

```

### table: results summary
```{r}
# summarize
HT_summ <- HT %>% 
  group_by(group) %>% 
  summarise(lapse = first(lapse),
            count = n(),
            mean_DOC = mean(NPOC_ppm),
            sd_DOC = sd(NPOC_ppm),
            RSD_DOC = (sd_DOC/mean_DOC)*100,
            mean_UV254 = mean(SAC254_Abs.m),
            sd_UV254 = sd(SAC254_Abs.m)) %>% 
  # save
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_F-H-summary.csv")

# summarize Hobo HT 
Hobo_summ <- HT_Hobo %>% 
  filter(!is.na(group)) %>% 
  group_by(HoldTime_set) %>% 
  summarise(lapse = first(lapse),
            mean_T = mean(Temp_C),
            sd_T = sd(Temp_C))

# join statistical results with Hobo results
HT_tests_summary <- HT_Wilcoxon_tests %>% 
  pivot_wider(names_from = Analysis, values_from = c("p.value", "sig.diff")) %>% 
  full_join(., Hobo_summ,
            by = c("Set" = "HoldTime_set")) %>% 
  mutate('temp range' = paste(round(mean_T, 2), "±", round(sd_T, 2))) %>% 
  select(Set, "Days held" = lapse, 
         'temp range', 
         "DOC sig.diff" = sig.diff_NPOC_ppm,  # new = old
         "DOC p-value" = p.value_NPOC_ppm, 
         "UV 254 sig.diff" = sig.diff_SAC254_Abs.m, 
         "UV 254 p-value" = p.value_SAC254_Abs.m) %>% 
  write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_stat-tests.csv")

```


#### tabulate MESS
```{r}


# COMPILE -- bigg ol mess
HT %>% 
  group_by(HoldTime_set) %>% 
  summarise(season_G = first(rain_seasons),
            HoldTime_days = first(lapse)) %>% 
  mutate(
    Mean_temps = c("7.3°C ± 2.1°C", "6.1°C ± 2.7°C", "4.4°C ± 3.2°C"),
    Analysis = "NPOC_ppm",
    # DOC
    fresh_held = paste(c(round(HT_summ$mean_DOC[1], 2), 
                            round(HT_summ$mean_DOC[3], 2),
                            round(HT_summ$mean_DOC[5], 2)),
                          "±",
                          c(round(HT_summ$sd_DOC[1], 2), 
                            round(HT_summ$sd_DOC[3], 2), 
                            round(HT_summ$sd_DOC[5], 2)),
                          " // ",
                          c(round(HT_summ$mean_DOC[2], 2), 
                           round(HT_summ$mean_DOC[4], 2), 
                           round(HT_summ$mean_DOC[6], 2)),
                         "±",
                         c(round(HT_summ$sd_DOC[2], 2), 
                           round(HT_summ$sd_DOC[4], 2), 
                           round(HT_summ$sd_DOC[6], 2)))) %>% 
  bind_rows(
     # UV254
    HT %>% 
  group_by(HoldTime_set) %>% 
  summarise(season_G = first(rain_seasons),
            HoldTime_days = first(lapse)) %>% 
  mutate(
    Mean_temps = c("7.3°C ± 2.1°C", "6.1°C ± 2.7°C", "4.4°C ± 3.2°C"),
    Analysis = "UV254",
    fresh_held = paste(c(round(HT_summ$mean_UV254[1], 2), 
                              round(HT_summ$mean_UV254[3], 2), 
                              round(HT_summ$mean_UV254[5], 2)),
                            "±",
                            c(round(HT_summ$sd_UV254[1], 2), 
                              round(HT_summ$sd_UV254[3], 2), 
                              round(HT_summ$sd_UV254[5], 2)),
                            " // ",
                            c(round(HT_summ$mean_UV254[2], 2), 
                             round(HT_summ$mean_UV254[4], 2), 
                             round(HT_summ$mean_UV254[6], 2)),
                           "±",
                           c(round(HT_summ$sd_UV254[2], 2), 
                             round(HT_summ$sd_UV254[4], 2), 
                             round(HT_summ$sd_UV254[6], 2)))))
    #UV254_pValues = c(A_UV254_pvalue, B_UV254_pvalue, C_UV254_pvalue),
    #sig_UV254 = c(A_UV254_sig, B_UV254_sig, C_UV254_sig)) %>% write_csv("R-outputs_UBC-forWater-MSc_HMc/tables/HoldTime_tTests.csv")

```


### plot: Hobo HT
```{r}
# pull & set values for plot

# set dates
HT_range <- HT %>% 
  group_by(HoldTime_set) %>% 
  summarise(start = first(Date),
            end = last(Date))

# set sample dates
HT_dates <- HT %>% 
  group_by(HoldTime_set) %>% 
  mutate(lapse = as.numeric(lapse)) %>% 
  summarise(date_fresh = as_date(first(DateTime_sampled)),
            date_held = as_date(last(DateTime_sampled)),
            lapse = mean(lapse),
            half_lapse = lapse*0.5)

# save mean temp
HT_Hobo_L <- HT_Hobo %>% 
  group_by(Date) %>% 
  summarise(Temp_daily = mean(Temp_C)) %>% 
  full_join(HT_Hobo, by = "Date") %>% 
  pivot_longer(cols = starts_with("Temp_"),
               names_to = "Temp",
               values_to = "degrees_C") %>% 
  mutate(Temp = factor(Temp))

# summarize mean temp for each hold-time set
A_temp <- HT_Hobo %>% 
  filter(!is.na(Temp_C),
         Date %within% interval(HT_range$start[1], HT_range$end[1])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) 
A_temp <- paste(round(A_temp$set_temp, 1), "±", round(A_temp$set_temp_sd, 1))

B_temp <- HT_Hobo %>% 
  filter(!is.na(Temp_C),
         Date %within% interval(HT_range$start[2], HT_range$end[2])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE)) 
B_temp <- paste(round(B_temp$set_temp, 1), "±", round(B_temp$set_temp_sd, 1))

C_temp <- HT_Hobo %>% 
  filter(!is.na(Temp_C),
         Date %within% interval(HT_range$start[3], HT_range$end[3])) %>%
  summarise(set_temp = mean(Temp_C, na.rm = TRUE),
            set_temp_sd = sd(Temp_C, na.rm = TRUE))
C_temp <- paste(round(C_temp$set_temp, 1), "±", round(C_temp$set_temp_sd, 1))

## ---------------
# plot it  
HT_Hobo_L %>% 
  ggplot(aes(x = Date, y = degrees_C))+
  geom_line(aes(colour = Temp, size = Temp))+
  scale_colour_manual(values = c(forWater_colours2[["SkyBlue"]], ## 30 minute 
                                 forWater_colours2[["DeepBlue"]]), ## daily average
                      labels = c("30 minute measurement", "Daily mean"))+
  scale_size_manual(values = c(1, 1.5), labels = c("30 minute measurement", "Daily mean"))+
  guides(colour = guide_legend("Temperature:"), size = guide_legend("Temperature:"))+
  # horizontal lines for lab refrigerator range (0-7 C)
  geom_hline(yintercept = c(0, 7), linetype = "solid", colour = "red")+
  annotate("text", label = "fridge range", angle = 90, colour = "red",
           x = first(HT_Hobo_L$Date)+1, y = 3.5)+
  # vertical lines for HT sample dates
  geom_vline(xintercept = c(HT_dates$date_fresh, HT_dates$date_held), 
             linetype = "dashed", colour = "black", size = 0.8) +
  annotate("text", label = c("Hold-time set:\n", paste(HT_dates$HoldTime_set, "\n")), ## set 
           x = c(HT_dates$date_fresh[1]-15, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 27)+
  annotate("text", label = c("Days:\n", paste(HT_dates$lapse, "\n")), ## time lapse
           x = c(HT_dates$date_fresh[1]-8, 
                 HT_dates$date_held[1]-HT_dates$half_lapse[1],
                 HT_dates$date_held[2]-HT_dates$half_lapse[2],
                 HT_dates$date_held[3]-HT_dates$half_lapse[3]), 
           y = 25)+
  theme_bw()+
  labs(y = "Air Temperature (°C)",
       #caption = glue::glue("Mean temperatures during vertical rack hold-time experiments: {A_temp} (set A), {B_temp} (set B), {C_temp} (set C)."),
       x = "") +
  theme(legend.position = "top", 
        text = element_text(size = 12)) +
  scale_x_date(date_breaks = "1 months")

# save
ggsave("R-outputs_UBC-forWater-MSc_HMc/figures/HoldTime_air-Temp.png", 
       width = 7, height = 7 , units = "in")

```

## Lab: blanks
```{r}
# check lab blanks
# this is a difficult measure of precision because the RO water is not the most reliably stable
calver %>% 
  filter(sample_type == "RO",
         sample == "RO" | sample == "RO_pH<2",
         NPOC_ppm != 0) %>% 
  group_by(sample) %>% 
  summarise(count = n(),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            RSD = (sd_DOC/DOC_mean)*100)
  
```
## Lab: Cal Vers
```{r}
# percent error calculated as 'measured' minus 'actual'
# negative error indicates the method was under-estimating DOC concentration 
# positive error indicates the method was over-estimating DOC concentration

# check cal vers for shimadzu
a <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(NPOC_ppm),
         rn != 7,  # error -- did not add standard 
         cal_ver != 5.7) %>%  # true concs were not calculated
  group_by(rn) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOC_mean = mean(NPOC_ppm, na.rm = TRUE),
            sd_DOC = sd(NPOC_ppm, na.rm = T),
            percent_error = ((DOC_mean - calc)/ calc)*100) %>% 
  ungroup() %>% 
  summarise(count = sum(count),
            error_percent = mean(percent_error))

# check cal vers for spectrolyser
b <- calver %>% 
  filter(sample_type == "cal_ver",
         !is.na(DOCeq_ppm)) %>% 
  group_by(rn) %>% 
  summarise(count = n(),
            calc = mean(cal_ver),
            DOCeq_mean = mean(DOCeq_ppm, na.rm = TRUE),
            sd_DOCeq = sd(DOCeq_ppm, na.rm = T),
            percent_error = ((DOCeq_mean - calc)/ calc)*100) %>% 
  ungroup() %>%  
  summarise(count = sum(count),
            error_percent = mean(percent_error))

# total cal-vers included
n_calvers_total <- calver %>% 
  filter(sample_type == "cal_ver") %>% 
  summarise(n = n())

# cal-vers included
n_calvers <- a[1,1]+b[1,1]

# percent error from shimadzu
error_shimadzu <- a %>% pull(error_percent)

# percent error from spectrolyser
error_spectrolyser <- b %>% pull(error_percent)

# average percent error from both methods:
error_overall <- (error_shimadzu + error_spectrolyser)/2

```


# Stage --WIP

## trash- EcoHydRology baseflow separation 
```{r}
# note: don't call the 'EcoHydRology' package into the library if you're using it
## access it's functions with "::" only because it masks tidyverse functions and makes workflow annoying if it's loaded into the workspace.

# separate stage into base and quick (no flow data available)
# separate each site, base R style (ugh)
BF_QF_Weeks <- odyssey_data %>% 
  filter(source == "Weeks")  
BF_QF_Weeks <- EcoHydRology::BaseflowSeparation(BF_QF_Weeks$corr_stage_cm) %>% 
  mutate(site = "Weeks")

BF_QF_Chris <- odyssey_data %>% 
  filter(source == "ChrisCrk")  
BF_QF_Chris <- EcoHydRology::BaseflowSeparation(BF_QF_Chris$corr_stage_cm) %>% 
  mutate(site = "ChrisCrk")

BF_QF_Head <- odyssey_data %>% 
  filter(source == "LeechHead")  
BF_QF_Head <- EcoHydRology::BaseflowSeparation(BF_QF_Head$corr_stage_cm) %>% 
  mutate(site = "LeechHead")

BF_QF_Cragg <- odyssey_data %>% 
  filter(source == "CraggCrk")  
BF_QF_Cragg <- EcoHydRology::BaseflowSeparation(BF_QF_Cragg$corr_stage_cm) %>% 
  mutate(site = "CraggCrk")

BF_QF_West <- odyssey_data %>% 
  filter(source == "WestLeech")  
BF_QF_West <- EcoHydRology::BaseflowSeparation(BF_QF_West$corr_stage_cm) %>% 
  mutate(site = "WestLeech")

BF_QF_Tunnel <- odyssey_data %>% 
  filter(source == "Tunnel")  
BF_QF_Tunnel <- EcoHydRology::BaseflowSeparation(BF_QF_Tunnel$corr_stage_cm) %>% 
  mutate(site = "Tunnel")

# combine all 
BF_QF <- bind_rows(BF_QF_Weeks, BF_QF_Chris, BF_QF_Head, BF_QF_Cragg, BF_QF_West, BF_QF_Tunnel) %>%
  mutate(site = factor(site, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  mutate(row = row_number(bt))

# join to stage data for datetime
BF_QF_Odyssey <- odyssey_data %>%
  mutate(row = row_number(corr_stage_cm)) %>% 
  mutate(site = factor(source, 
                       levels = c("Weeks", "ChrisCrk", "LeechHead", "CraggCrk", "WestLeech", "Tunnel"))) %>% 
  full_join(BF_QF, by = c("site", "row"))

```

## WIP -- find peaks(notworking)
```{r}
# determine the rate of stage rise for each event at each site
# odyssey_data

# pull dates for trip
trip_bysite <- stage_samples %>%
  group_by(trip) %>% 
  summarise(start = first(DateTime),
            end = last(DateTime))
# pull dates for trip and event
event_bysite <- stage_samples %>%
  group_by(event_ID) %>% 
  summarise(start = first(DateTime),
            end = last(DateTime))
# --
# isolate peaks
stage_samples_pks <- stage_samples %>% 
  select(c(site, event_ID, corr_stage_cm, DateTime)) %>% 
  filter(!is.na(event_ID)) %>% 
  group_by(site, event_ID) %>%
  summarise(DateTime_peak = DateTime[which.max(corr_stage_cm)],
            peak = max(corr_stage_cm),
            DateTime = DateTime_peak) %>% 
  full_join(odyssey_data,  
            by = c("site" = "source", "event_ID", "DateTime")) %>% 
  select(-c(stage_cm, Date)) %>% 
  full_join(stage_samples, by = c("site", "event_ID", "DateTime", "interval", "corr_stage_cm"))
  
## plot
stage_samples_pks %>% 
  ggplot(aes(x = DateTime))+
  geom_line(aes(y = corr_stage_cm), na.rm = TRUE, colour = "#0072B2")+  ## stage
  geom_point(aes(y = peak, shape = sample_type), na.rm = TRUE)+ ## samples 
  # scale_shape_manual(values = c("Grab" = 16, "Rack" = 17), na.translate = FALSE)+
  facet_wrap(~site, ncol = 1, strip.position = "right", scales = "free_y")+
  labs(y = "River stage (cm)", x = "", shape = "Sample Type")+
  scale_x_datetime(date_labels = "%Y %b %d", date_breaks = "2 months", date_minor_breaks = "1 months")+
  theme_bw()


#+
  theme(axis.text.x = element_text(angle = 60, hjust=1), text = element_text(size=12), legend.position = "top")+
  # add vertical lines for events
  geom_vline(xintercept = event_bysite$start, 
             linetype = "dashed", colour = "red", size = 0.7)
  # add vertical lines for trip
  geom_vline(xintercept = trip_bysite$start, 
             linetype = "solid", colour = "red", size = 0.6)
  
```


# Next: Random Forest
```{r}

```


  
# fin

For some reason, RStudio truncates the session viewable... so here's some text to hold the place.
```{r}
# and an empty code chunk
```





























